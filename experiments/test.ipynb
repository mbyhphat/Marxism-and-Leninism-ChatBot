{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\Machine-Learning-ChatBot\\\\experiments'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e:\\Machine-Learning-ChatBot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\anaconda3\\envs\\firstbot\\lib\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\Machine-Learning-ChatBot'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf_file(data):\n",
    "    loader = DirectoryLoader(data, glob=\"*.pdf\", loader_cls=PyPDFLoader)\n",
    "    documents = loader.load()\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_split(extracted_data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=200)\n",
    "    text_chunks = text_splitter.split_documents(extracted_data)\n",
    "    return text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data = load_pdf_file(data=\"data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 0, 'page_label': '1'}, page_content='Vũ Hữu Tiệp \\nMachine Learning \\ncơ bản \\nmachinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 1, 'page_label': '2'}, page_content='Vũ Hữu Tiệp\\nMachine Learning cơ bản\\nOrder ebook tạihttps://machinelearningcoban.com/ebook/\\nBlog: https://machinelearningcoban.com\\nFacebook Page:https://www.facebook.com/machinelearningbasicvn/\\nFacebook Group:https://www.facebook.com/groups/machinelearningcoban/\\nInteractive Learning:https:fundaml.com\\nLast update:\\nMarch 27, 2018'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 2, 'page_label': 'i'}, page_content='Chương 0\\nLời tác giả\\nNhững năm gần đây,trí tuệ nhân tạo(artificial intelligence–AI) nổi lên như một bằng chứng\\ncủa cuộc cách mạng công nghiệp lần thứ tư (1–động cơ hơi nước, 2–năng lượng điện, 3–công\\nnghệ thông tin). Trí tuệ nhân tạo đã và đang trở thành thành phần cốt lõi trong các hệ\\nthống công nghệ cao. Nó đã len lỏi vào hầu hết các lĩnh vực trong đời sống mà có thể chúng\\nta không nhận ra. Xe tự hành của Google và Tesla, hệ thống tự tag khuôn mặt trong ảnh\\ncủa Facebook; trợ lý ảo Siri của Apple, hệ thống gợi ý sản phẩm của Amazon, hệ thống gợi\\ný phim của Netflix, hệ thống dịch đa ngôn ngữ Google Translate, máy chơi cờ vây AlphaGo\\nvà gần đây là AlphaGo Zero của Google DeepMind, v.v., chỉ là một vài ứng dụng nổi bật\\ntrong vô vàn những ứng dụng của trí tuệ nhân tạo.\\nHọc máy (machine learning–ML) là một tập con của trí tuệ nhân tạo. Nó là một lĩnh vực\\nnhỏ trong khoa học máy tính, có khả năng tự học hỏi dựa trên dữ liệu được đưa vào mà\\nkhông cần phải được lập trình cụ thể (Machine Learning is the subfiled of computer science,\\nthat “gives computers the ability to learn without being explicitly programmed”–Wikipedia).\\nNhững năm gần đây, sự phát triển của các hệ thống tính toán cùng với lượng dữ liệu khổng\\nlồ được thu thập bởi các hãng công nghệ lớn đã giúp machine learning tiến thêm một bước\\ndài. Một lĩnh vực mới được ra đời được gọi làhọc sâu(deep learning–DL). Deep learning đã\\ngiúp máy tính thực thi những việc tưởng chừng như không thể vào mười năm trước: phân\\nloại cả ngàn vật thể khác nhau trong các bức ảnh, tự tạo chú thích cho ảnh, bắt chước giọng\\nnói và chữ viết của con người, giao tiếp với con người, chuyển đổi ngôn ngữ, hay thậm chí\\ncả sáng tác văn thơ hay âm nhạc1.\\nMối quan hệ AI-ML-DL\\nDeep learning là một tập con của machine learning. Machine learning là một tập con\\ncủa artificial intelligence (xem Hình 0.1).\\n1 Đọc thêm:8 Inspirational Applications of Deep Learning(https://goo.gl/Ds3rRy )'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 3, 'page_label': 'ii'}, page_content='CHƯƠNG 0. LỜI TÁC GIẢ ii\\nHình 0.1: Mối quan hệ giữa artificial intelligence, machine learning, và deep learning (Nguồn\\nWhat’s the Difference Between Artificial Intelligence, Machine Learning, and Deep Learning?–\\nhttps://goo.gl/NNwGCi ).\\n0.1 Mục đích của cuốn sách\\nNhững phát triển thần kỳ của trí tuệ nhân tạo dẫn đến nhu cầu cao về nhân lực những\\nngành khoa học dữ liệu, machine learning, và các ngành liên quan trên toàn thế giới cũng\\nnhư ở Việt Nam trong những năm sắp tới. Đó cũng là động lực để tôi bắt đầu viết blog\\nMachine Learning cơ bản (https://machinelearningcoban.com) từ đầu năm 2017. Tính tới\\nthời điểm tôi viết những dòng này, trang blog đã có hơn 650 ngàn lượt ghé thăm. Facebook\\npage Machine Learning cơ bản (https://goo.gl/wyUEjr ) của blog cũng đã có hơn 10 nghìn\\nlượt likes, Forum Machine Learning cơ bản (https://goo.gl/gDPTKX ) có gần 8 nghìn thành\\nviên. Trong quá trình viết blog và duy trì các trang Facebook, tôi nhận được rất nhiều những\\nủng hộ của bạn đọc về tinh thần cũng như vật chất. Ngoài ra, rất nhiều bạn đọc đã khuyến\\nkhích tôi tổng hợp những kiến thức trên blog lại thành một cuốn sách cho cộng đồng những\\nngười làm machine learning sử dụng tiếng Việt. Những sự ủng hộ và lời động viên đó là động\\nlực lớn cho tôi bắt tay vào thực hiện và hoàn thành cuốn sách này.\\nLĩnh vực machine learning và deep learning là cực kỳ rộng lớn và có nhiều nhánh nhỏ. Để\\nđi sâu vào từng nhánh, một cuốn sách chắc chắn không thể bao quát được mọi vấn đề. Mục\\nđích chính của cuốn sách này là cung cấp cho các bạn những khái niệm, kỹ thuật chung và\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 4, 'page_label': 'iii'}, page_content='iii CHƯƠNG 0. LỜI TÁC GIẢ\\ncác thuật toán cơ bản nhất của machine learning. Từ đó, bạn đọc muốn đi sâu vào từng vấn\\nđề cụ thể có thể tìm đọc thêm các tài liệu, cuốn sách, và khoá học liên quan.\\nHãy luôn nhớ rằngđơn giản trước hết. Khi bắt tay vào giải quyết một bài toán machine\\nlearning hay bất cứ bài toán nào, chúng ta nên bắt đầu từ những thuật toán đơn giản nhất.\\nKhông nên nghĩ rằng chỉ có những thuật toán phức tạp mới có thể giải quyết được vấn đề.\\nNhững thuật toán phức tạp thường yêu cầu độ tính toán cao và nhạy cảm với cách chọn\\ncác tham số đầu vào. Thêm vào đó, những thuật toán đơn giản giúp chúng ta sớm có một\\nmô hình tổng quát cho mỗi bài toán. Kết quả của các thuật toán đơn giản, thường được gọi\\nlà baseline, cũng giúp chúng ta có cái nhìn ban đầu về sự phức tạp của mỗi bài toán. Việc\\ncải thiện kết quả sẽ được dần thực hiện ở các bước sau. Cuốn sách này sẽ giúp các bạn có\\nnhững cái nhìn đầu tiên và các hướng giải quyết cho các bài toán machine learning. Để có\\ncác sản phẩm thực tiễn, chúng ta sẽ phải học hỏi và thực hành thêm rất nhiều.\\n0.2 Hướng tiếp cận của cuốn sách\\nĐể giải quyết mỗi bài toán machine learning, chúng ta cần chọn một mô hình phù hợp. Mô\\nhình này được mô tả bởi bộ các tham số, có thể lên tới cả triệu tham số, mà chúng ta cần\\nđi tìm. Thông thường, bộ các tham số này được tìm bằng cách giải một bài toán tối ưu.\\nKhi viết về các thuật toán machine learning, tôi sẽ bắt đầu bằng những ý tưởng trực quan,\\ntheo sau bởi một mô hình toán học mô tả ý tưởng đó. Các tham số mô hình được tìm bằng\\ncách tối ưu mô hình toán học đó. Các suy luận toán học và các ví dụ mẫu trên Python ở\\ncuối mỗi bài sẽ giúp bạn đọc hiểu rõ hơn về nguồn gốc, ý nghĩa, và cách sử dụng mỗi thuật\\ntoán. Xen kẽ giữa các phần về các thuật toán machine learning, tôi cũng sẽ giới thiệu các\\nkỹ thuật tối ưu cơ bản, với hy vọng giúp bạn đọc hiểu rõ hơn về bản chất của vấn đề.\\n0.3 Đối tượng của cuốn sách\\nCuốn sách được thực hiện hướng đến nhiều nhóm độc giả khác nhau. Nếu bạn không thực\\nsự muốn đi sâu vào phần toán, bạn vẫn có thể tham khảo source code và cách sử dụng các\\nthư viện. Nhưng để sử dụng các thư viện một cách hiệu quả, bạn cũng cần hiểu nguồn gốc\\ncủa mô hình và ý nghĩa của các tham số. Nếu bạn thực sự muốn tìm hiểu nguồn gốc, ý nghĩa\\ncủa các thuật toán, bạn có thể học được nhiều điều từ cách xây dựng và tối ưu các mô hình.\\nPhần tổng hợp các kiến thức toán cần thiết trong Phần I sẽ là một nguồn tham khảo súc\\ntích bất cứ khi nào bạn có thắc mắc về các dẫn giải toán học trong sách2. Phần VII được\\ndành riêng để nói về tối ưu lồi–một mảng rất quan trọng trong tối ưu, phù hợp với các bạn\\nthực sự muốn đi sâu thêm về tối ưu.\\nRất nhiều hình vẽ trong cuốn sách được vẽ dưới dạng vector graphics (độ phân giải rất cao),\\ncó thể được dùng trong các bài giảng hoặc thuyết trình. Các kiến thức trong sách cũng được\\nsắp xếp theo thứ tự từ dễ đến khó, vì vậy cuốn sách cũng được hy vọng là một cuốn giáo\\ntrình cho các khoá học machine learning tiếng Việt.\\n2 Bạn đọc chưa quen với nhiều khái niệm toán học trong phần này có thể đọc từ Phần II và quay lại bất cứ khi nào\\nbạn gặp khó khăn.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 5, 'page_label': 'iv'}, page_content='CHƯƠNG 0. LỜI TÁC GIẢ iv\\nCác dẫn giải toán học được xây dựng phù hợp với chương trình toán phổ thông và đại học ở\\nViệt Nam. Các từ khoá khi được dịch sang tiếng Việt đều dựa trên những tài liệu tôi được\\nhọc trong nhiều năm học toán tại Việt Nam. Các thuật ngữ tiếng Anh cũng thường xuyên\\nđược sử dụng, với hy vọng giúp bạn đọc dần làm quen với các tài liệu tiếng Anh, và giúp\\ncác bạn học đại học ở nước ngoài có thể tiếp cận. Phần cuối cùng của sách có mục Index\\ncác thuật ngữ quan trọng bằng tiếng Anh và nghĩa tiếng Việt đi kèm nếu tôi tìm được cách\\ndịch phù hợp.\\n0.4 Yêu cầu về kiến thức\\nĐể có thể bắt đầu đọc cuốn sách này, bạn cần có một kiến thức nhất định về đại số tuyến\\ntính, giải tích ma trận, xác suất thống kê, và kỹ năng lập trình.\\nPhần I của cuốn sách ôn tập lại các kiến thức toán quan trọng cho machine learning. Bất\\ncứ khi nào bạn đọc gặp khó khăn về toán, bạn được khuyến khích đọc lại các chương trong\\nphần này.\\nNgôn ngữ lập trình được sử dụng trong cuốn sách là Python. Lý do tôi sử dụng ngôn ngữ\\nnày vì đây là một ngôn ngữ lập trình miễn phí, có thể được cài đặt dễ dàng trên các nền tảng\\nhệ điều hành khác nhau. Quan trọng hơn, có rất nhiều các thư viện hỗ trợ machine learning\\ncũng như deep learning được viết cho Python. Có hai thư viện python chính thường được\\nsử dụng trong cuốn sách là numpy và scikit-learn. Numpy (http://www.numpy.org/ ) là một\\nthư viện phổ biến giúp xử lý các phép toán liên quan đến các mảng nhiều chiều, với các hàm\\ngần gũi với đại số tuyến tính. Nếu bạn đọc chưa quen thuộc với numpy, bạn có thể tham gia\\nmột khoá học ngắn miễn phí trên trang web kèm theo cuốn sách này (https://fundaml.com).\\nBạn sẽ được làm quen với cách xử lý các mảng nhiều chiều với nhiều ví dụ và bài tập thực\\nhành trực tiếp trên trình duyệt. Các kỹ thuật xử lý mảng trong cuốn sách này đều được\\nđề cập tại đây. Scikit-learn, hay sklearn, (http://scikit-learn.org/ ) là một thư viện chứa rất\\nnhiều các thuật toán machine learning cơ bản và rất dễ sử dụng. Tài liệu của scikit-learn\\ncũng là một nguồn chất lượng cho các bạn làm machine learning. Scikit-learn sẽ được dùng\\ntrong cuốn sách như một cách kiểm chứng lại các kết quả mà chúng ta thực hiện dựa trên\\nsuy luận toán học cũng như lập trình thông qua numpy.\\nTất nhiên, các thư viện machine learning hiện nay rất phổ biến và có những bạn có thể tạo\\nra sản phẩm bằng cách chỉ sử dụng những thư viện này mà không cần nhiều kiến thức toán.\\nTuy nhiên, cuốn sách này không hướng tới việc sử dụng các thư viện sẵn có mà không hiểu\\nbản chất đằng sau của chúng. Việc sử dụng các thư viện cũng yêu cầu những kiến thức nhất\\nđịnh về việc lựa chọn và điều chỉnh tham số mô hình.\\n0.5 Source code đi kèm\\nToànbộsourcecodetrongcuốnsáchcóthểđượctìmthấytại https://github.com/tiepvupsu/\\nebookML_src. Các file có đuôi.ipynb là các file chứa code (Jupyter notebook). Các file có\\nđuôi .pdf, .png là các hình tạo được từ file.ipynb.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 6, 'page_label': 'v'}, page_content='v CHƯƠNG 0. LỜI TÁC GIẢ\\n0.6 Bố cục của cuốn sách\\nCuốn sách này được chia thành 8 phần và sẽ tiếp tục được cập nhật:\\nPhần I ôn tập lại cho bạn đọc những kiến thức quan trọng trong đại số tuyến tính, giải tích\\nma trận, xác suất, và hai phương pháp phổ biến trong việc ước lượng tham số cho các mô\\nhình machine learning thống kê.\\nPhần II giới thiệu các khái niệm cơ bản trong machine learning, kỹ thuật xây dựng vector\\nđặc trưng cho dữ liệu, một mô hình machine learning cơ bản–linear regression, và một hiện\\ntượng cần tránh khi xây dựng các mô hình machine learning.\\nPhần III giúp các bạn làm quen với các mô hình machine learning rất trực quan, không yêu\\ncầu nhiều kiến thức toán phức tạp. Qua đây, bạn đọc sẽ có cái nhìn đầu tiên về việc xây\\ndựng các mô hình machine learning.\\nPhần IV đề cập tới một lớp các thuật toán machine learning phổ biến nhất–neural networks,\\nlà nền tảng cho các mô hình deep learning phức tạp hiện nay. Phần này cũng giới thiệu một\\nkỹ thuật cơ bản và hữu dụng trong việc giải quyết các bài toán tối ưu không ràng buộc.\\nPhần V giới thiệu về các kỹ thuật thường dùng trong các hệ thống khuyến nghị sản phầm.\\nPhần VI giới thiệu các kỹ thuật giảm chiều dữ liệu.\\nPhần VII mang lại cho các bạn một cái nhìn bao quát hơn về tối ưu, đặc biệt là tối ưu lồi.\\nCác bài toán tối ưu lồi có ràng buộc cũng được giới thiệu trong phần này.\\nPhần VIII giới thiệu các thuật toán phân lớp dựa trên ý tưởng của support vector machine.\\n0.7 Các lưu ý về ký hiệu\\nCác ký hiệu toán học trong sách được mô tả ở Bảng 0.1 và đầu Chương 1. Các khung với\\nfont chữ có chiều rộng các ký tự như nhau được dùng để chứa các đoạn source code.\\ntext in a box with constant width represents source codes.\\nCác đoạn ký tự vớiconstant width, deep red, ’string, dark green’ được dùng để chỉ các\\nbiến, hàm số, chuỗi, v.v., trong các đoạn code.\\nĐóng khung và in nghiêng\\nCác khái niệm, định nghĩa, định lý, và lưu ý quan trọng được đóng khung và in nghiêng.\\nKý tự phân cách giữa phần nguyên và phần thập phân của các số thực là dấu chấm,\\n‘.’, thay vì dấu phẩy, ‘,’, như trong các tài liệu tiếng Việt khác. Cách làm này thống\\nnhất với các tài liệu tiếng Anh và các ngôn ngữ lập trình.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 7, 'page_label': 'vi'}, page_content='CHƯƠNG 0. LỜI TÁC GIẢ vi\\n0.8 Tham khảo thêm\\nCó rất nhiều những cuốn sách, khoá học, website hay về machine learning cũng như deep\\nlearning, trong đó, có một số mà tôi muốn đặc biệt nhấn mạnh:\\n0.8.1 Khoá học\\n1. Khóa họcMachine Learningcủa Andrew Ng trên Coursera (https://goo.gl/WBwU3K ).\\n2. Khoá học mới Deep Learning Specialization cũng của Andrew Ng ( https://goo.gl/\\nssXfYN).\\n3. Các khoá CS224n: Natural Language Processing with Deep Learning(https://goo.gl/\\n6XTNkH); CS231n: Convolutional Neural Networks for Visual Recognition (http://\\ncs231n.stanford.edu/); CS246: Mining Massive Data Sets (https://goo.gl/TEMQ9H )\\ncủa Stanford.\\n4. Introduction to Computer Science and Programming Using Python (https://goo.gl/\\n4nNXvJ) của MIT.\\n0.8.2 Sách\\n1. C. Bishop,Pattern Recognition and Machine Learning(https://goo.gl/pjgqRr ), Springer,\\n2006 [Bis06].\\n2. I. Goodfellowet al.,Deep Learning(https://goo.gl/sXaGwV ), MIT press, 2016 [GBC16].\\n3. J. Friedman et al., The Elements of Statistical Learning (https://goo.gl/Qh9EkB ),\\nSpringer, 2001 [FHT01].\\n4. Y. Abu-Mostafa et al., Learning from data(https://goo.gl/SRfNFJ ), AMLBook New\\nYork, 2012 [AMMIL12].\\n5. S.JDPrince, Computer Vision: Models, Learning, and Inference(https://goo.gl/9Fchf3 ),\\nCambridge University Press, 2012 [Pri12].\\n6. S. Boydet al., Convex Optimization (https://goo.gl/NomDpC ), Cambridge university\\npress, 2004 [BV04].\\nNgoài ra, các website Machine Learning Mastery (https://goo.gl/5DwGbU ), Pyimage-\\nsearch (https://goo.gl/5DwGbU ). Kaggle (https://www.kaggle.com/ ), Scikit-learn (http:\\n//scikit-learn.org/ ) cũng là các nguồn thông tin rất hữu ích.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 8, 'page_label': 'vii'}, page_content='vii CHƯƠNG 0. LỜI TÁC GIẢ\\n0.9 Đóng góp ý kiến\\nMọi ý kiến đóng góp, phản hồi, báo lỗi cho nội dung của cuốn sách được tốt hơn đều\\nđáng quý. Các bạn có thể gửi ý kiến tớivuhuutiep@gmail.com hoặc tạo mộtissue mới tại\\nhttps://goo.gl/zPYWKV .\\nCuốn sách sẽ tiếp tục được chỉnh sửa và thêm các chương mớicho tới khi bản sách giấy được\\nra mắt. Tất cả các bạn đã đặt ebook sẽ nhận được các bản cập nhật và một bản sách giấy\\n(dự tính vào giữa năm 2018).\\n0.10 Vấn đề bản quyền\\nToàn bộ nội dung trên blog cũng như cuốn sách này (bao gồm cả source code và hình ảnh\\nminh hoạ) đều thuộc bản quyền của tôi–Vũ Hữu Tiệp.\\nTôi rất mong muốn kiến thức của mình tạo ra đến được với nhiều bạn đọc. Tuy nhiên, tôi\\nkhông ủng hộ bất kỳ một hình thức sao chép không trích nguồn nào. Mọi trích dẫn cần được\\nnêu rõ tên cuốn sách, tên tác giả (Vũ Hữu Tiệp), và link gốc tới blog. Các bài viết trích dẫn\\nquá 25% toàn văn bất kỳ một post nào trên blog hoặc một chương trong cuốn sách này đều\\nkhông được phép, trừ trường hợp có sự đồng ý của tác giả.\\nMọi vấn đề liên quan đến sao chép, phân phát, đăng tải, sử dụng sách và blog, cũng như\\ntrao đổi, cộng tác, xin vui lòng liên hệ với tôi tại địa chỉ email vuhuutiep@gmail.com.\\n0.11 Lời cảm ơn\\nTrước hết, tôi xin cảm ơn bạn bè trong friend list Facebook của tôi đã nhiệt tình ủng hộ và\\nchia sẻ blog ngay ngày đầu blog được ra mắt. Tôi cũng xin chân thành cảm ơn bạn đọc blog\\nMachine Learning cơ bản và Facebook page Machine Learning cơ bản đã đồng hành cùng\\ntôi trong suốt một năm qua. Không có độc giả, chắc chắn tôi không có đủ động lực viết hơn\\n30 bài trên blog và rất nhiều các ghi chép nhanh trên Facebook page.\\nTrong quá trình viết blog, tôi nhận được rất rất nhiều sự ủng hộ của bạn đọc về cả vật chất\\nlẫn tinh thần. Không có những sự ủng hộ đó và những lời động viên viết sách, dự án này sẽ\\nkhông thể được bắt đầu. Khi tôi đã bắt đầu, số lượng pre-order cuốn sách này tăng lên từng\\nngày. Tôi thực sự biết ơn các bạn đã pre-order cũng những lời nhắn gửi ấm áp. Quan trọng\\nhơn hết, số lượng sách được đặt trước khi tôi hoàn thành khiến tôi tin rằng sản phẩm mình\\ntạo ra đã mang lại những giá trị nhất định cho cộng đồng. Những điều đó góp phần tôi duy\\ntrì tinh thần làm việc và cố gắng hết mình để tạo ra một sản phẩm chất lượng.\\nTôi may mắn nhận được những phản hồi tích cực cũng như các góp ý từ các thầy cô trong\\ncác trường đại học lớn trong và ngoài nước. Tôi xin được gửi lời cảm ơn tới thầy Phạm Ngọc\\nNam và cô Nguyễn Việt Hương (ĐH Bách Khoa Hà Nội), thầy Chế Viết Nhật Anh (ĐH\\nBách Khoa Tp.HCM), thầy Nguyễn Thanh Tùng (ĐH Thuỷ Lợi), thầy Trần Duy Trác (ĐH\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 9, 'page_label': 'viii'}, page_content='CHƯƠNG 0. LỜI TÁC GIẢ viii\\nJohns Hopkins), và anh Nguyễn Hồng Lâm (người hướng dẫn trong thời gian tôi thực tập\\ntại U.S. Army Research Lab).\\nTôi đặc biệt cảm ơn bạn Nguyễn Hoàng Linh và Hoàng Đức Huy, Đại học Waterloo–Canada,\\nnhững người bạn đã nhiệt tình giúp tôi xây dựng trang FundaML.com giúp bạn đọc có thể\\nhọc Python/Numpy trực tiếp trên trình duyệt. Tôi cũng xin cảm ơn bạn Lê Việt Hải–nghiên\\ncứu sinh ngành toán ứng dụng tại Penn State, và Đinh Hoàng Phong–kỹ sư phần mềm tại\\nFacebook–đã góp ý sửa đổi rất nhiều điểm về ngôn ngữ và toán trong các bản nháp. Tôi tin\\nrằng cuốn sách đã được sửa đổi rất nhiều so với phiên bản trên blog.\\nTôi xin cảm ơn ba người bạn thân–Nguyễn Tiến Cường, Nguyễn Văn Giang, Vũ Đình Quyền–\\nđã luôn động viên tôi và đóng góp nhiều phản hồi quý giá cho cuốn sách. Ngoài ra, tôi xin\\ncảm ơn những người bạn thân thiết khác của tôi tại Penn State đã luôn bên cạnh tôi trong\\nthời gian tôi thực hiện dự án, bao gồm gia đình anh Triệu Thanh Quang, gia đình anh\\nTrần Quốc Long, bạn thân (cũng là một blogger) Nguyễn Phương Chi, và các đồng nghiệp\\nJohn McKay, Tiantong Guo, Hojjat Mousavi, Omar Aldayel, và Mohammad Tofighi trong\\nPhòng nghiên cứu Xử lý Thông tin và Thuật toán (Information Processing and Algorithm\\nLaboratory–iPAL), ĐH bang Pennsylvania.\\nCuối cùng và quan trọng nhất, tôi xin cảm ơn gia đình tôi, những người luôn ủng hộ tôi vô\\nđiều kiện và hỗ trợ tôi hết mình trong quá trình tôi thực hiện dự án này.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 10, 'page_label': 'ix'}, page_content='ix CHƯƠNG 0. LỜI TÁC GIẢ\\n0.12 Bảng các ký hiệu\\nCác ký hiệu sử dụng trong sách được liệt kê trong Bảng 0.1\\nBảng 0.1: Bảng các ký hiệu\\nKý hiệu Ý nghĩa\\nx,y,N,k in nghiêng, thường hoặc hoa, là các số vô hướng\\nx,y in đậm, chữ thường, là các vector\\nX,Y in đậm, chữ hoa, là các ma trận\\nR tập hợp các số thực\\nN tập hợp các số tự nhiên\\nC tập hợp các số phức\\nRm tập hợp các vector thực cóm phần tử\\nRm×n tập hợp các ma trận thực cóm hàng, n cột\\nSn tập hợp các ma trận vuông đối xứng bậcn\\nSn\\n+ tập hợp các ma trận nửa xác định dương bậcn\\nSn\\n++ tập hợp các ma trận xác định dương bậcn\\n∈ phần tử thuộc tập hợp\\n∃ tồn tại\\n∀ mọi\\n≜ ký hiệu là/bởi. Ví dụa≜f(x) nghĩa là “ký hiệuf(x) bởi a”.\\nxi phần tử thứi (tính từ 1) của vectorx\\nsgn(x) hàm xác định dấu. Bằng 1 nếux≥0, bằng -1 nếux< 0.\\nexp(x) ex\\nlog(x) logarit tự nhiên của số thực dươngx\\naij phần tử hàng thứi, cột thứj của ma trậnA\\nAT chuyển vị của ma trậnA\\nAH chuyển vị liên hợp (Hermitian) của ma trận phứcA\\nA−1 nghịch đảo của ma trận vuôngA, nếu tồn tại\\nA† giả nghịch đảo của ma trận không nhất thiết vuôngA\\nA−T chuyển vị của nghịch đảo của ma trậnA, nếu tồn tại\\n∥x∥p ℓp norm của vectorx\\n∥A∥F Frobenius norm của ma trậnA\\ndiag(A) đường chéo chính của ma trậnA\\ntrace(A) trace của ma trậnA\\ndet(A) định thức của ma trận vuôngA\\nrank(A) hạng của ma trậnA\\no.w otherwise – trong các trường hợp còn lại\\n∂f\\n∂x đạo hàm của hàm sốf theo x∈R\\n∇xf gradient (đạo hàm) của hàm sốf theo x (x là vector hoặc ma trận)\\n∇2\\nxf đạo hàm bậc hai của hàm sốf theo x, còn được gọi làHessian\\n⊙ Hadamard product (elemenwise product). Phép nhân từng phần tử của hai vector hoặc ma trận cùng kích thước.\\n∝ tỉ lệ với\\nv.v. vân vân\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 11, 'page_label': 'x'}, page_content=''),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 12, 'page_label': '1'}, page_content='Mục lục\\nLời tác giả................................................................. i\\n0.1 Mục đích của cuốn sách ............................................... ii\\n0.2 Hướng tiếp cận của cuốn sách .......................................... iii\\n0.3 Đối tượng của cuốn sách............................................... iii\\n0.4 Yêu cầu về kiến thức .................................................. iv\\n0.5 Source code đi kèm ................................................... iv\\n0.6 Bố cục của cuốn sách ................................................. v\\n0.7 Các lưu ý về ký hiệu .................................................. v\\n0.8 Tham khảo thêm ..................................................... vi\\n0.9 Đóng góp ý kiến...................................................... vii\\n0.10 Vấn đề bản quyền .................................................... vii\\n0.11 Lời cảm ơn .......................................................... vii\\n0.12 Bảng các ký hiệu ..................................................... ix\\nPhần I Kiến thức toán cơ bản cho machine learning\\n1 Ôn tập Đại số tuyến tính............................................... 12\\n1.1 Lưu ý về ký hiệu ..................................................... 12'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 13, 'page_label': '2'}, page_content='Mục lục 2\\n1.2 Chuyển vị và Hermitian ............................................... 12\\n1.3 Phép nhân hai ma trận................................................ 13\\n1.4 Ma trận đơn vị và ma trận nghịch đảo................................... 14\\n1.5 Một vài ma trận đặc biệt khác ......................................... 15\\n1.6 Định thức ........................................................... 16\\n1.7 Tổ hợp tuyến tính, không gian sinh ..................................... 17\\n1.8 Hạng của ma trận .................................................... 19\\n1.9 Hệ trực chuẩn, ma trận trực giao ....................................... 20\\n1.10 Biễu diễn vector trong các hệ cơ sở khác nhau ............................ 21\\n1.11 Trị riêng và vector riêng ............................................... 22\\n1.12 Chéo hoá ma trận .................................................... 23\\n1.13 Ma trận xác định dương ............................................... 24\\n1.14 Chuẩn của vector và ma trận........................................... 26\\n2 Giải tích ma trận....................................................... 30\\n2.1 Đạo hàm của hàm trả về một số vô hướng ............................... 30\\n2.2 Đạo hàm của hàm trả về một vector .................................... 31\\n2.3 Tính chất quan trọng của đạo hàm ..................................... 32\\n2.4 Đạo hàm của các hàm số thường gặp ................................... 33\\n2.5 Bảng các đạo hàm thường gặp ......................................... 36\\n2.6 Kiểm tra đạo hàm .................................................... 36\\n3 Ôn tập Xác Suất ....................................................... 40\\n3.1 Xác Suất ............................................................ 40\\n3.2 Một vài phân phối thường gặp ......................................... 47\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 14, 'page_label': '3'}, page_content='3 Mục lục\\n4 Maximum Likelihood và Maximum A Posteriori........................ 52\\n4.1 Giới thiệu ........................................................... 52\\n4.2 Maximum likelihood estimation......................................... 53\\n4.3 Maximum a Posteriori................................................. 58\\n4.4 Tóm tắt ............................................................. 62\\nPhần II Tổng quan về machine learning\\n5 Các khái niệm cơ bản................................................... 64\\n5.1 Nhiệm vụ, T ......................................................... 64\\n5.2 Phép đánh giá, P..................................................... 67\\n5.3 Kinh nghiệm, E ...................................................... 67\\n5.4 Hàm mất mát và tham số mô hình...................................... 69\\n6 Giới thiệu về feature engineering....................................... 71\\n6.1 Giới thiệu ........................................................... 71\\n6.2 Mô hình chung cho các bài toán Machine Learning ....................... 72\\n6.3 Một số ví dụ về Feature Engineering .................................... 74\\n6.4 Transfer Learning cho bài toán phân loại ảnh............................. 79\\n6.5 Chuẩn hoá vector đặc trưng............................................ 81\\n6.6 Đọc thêm ........................................................... 82\\n7 Linear regression ....................................................... 83\\n7.1 Giới thiệu ........................................................... 83\\n7.2 Xây dựng và tối ưu hàm mất mát....................................... 84\\n7.3 Ví dụ trên Python .................................................... 86\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 15, 'page_label': '4'}, page_content='Mục lục 4\\n7.4 Thảo luận ........................................................... 89\\n8 Overfitting ............................................................. 91\\n8.1 Giới thiệu ........................................................... 91\\n8.2 Validation ........................................................... 94\\n8.3 Regularization ....................................................... 96\\n8.4 Đọc thêm ........................................................... 97\\nPhần III Khởi động\\n9 K-nearest neighbors .................................................... 100\\n9.1 Giới thiệu ........................................................... 100\\n9.2 Phân tích toán học ................................................... 101\\n9.3 Ví dụ trên cơ sở dữ liệu Iris ............................................ 105\\n9.4 Thảo luận ........................................................... 108\\n10 K-means clustering..................................................... 110\\n10.1 Giới thiệu ........................................................... 110\\n10.2 Phân tích toán học ................................................... 111\\n10.3 Ví dụ trên Python .................................................... 114\\n10.4 Phân nhóm chữ số viết tay ............................................ 117\\n10.5 Tách vật thể trong ảnh ................................................ 121\\n10.6 Image Compression (nén ảnh và nén dữ liệu nói chung) .................... 122\\n10.7 Thảo luận ........................................................... 123\\n11 Naive Bayes classifier................................................... 127\\n11.1 Naive Bayes classifier ................................................. 127\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 16, 'page_label': '5'}, page_content='5 Mục lục\\n11.2 Các phân phối thường dùng trong NBC ................................. 128\\n11.3 Ví dụ .............................................................. 130\\n11.4 Thảo luận ........................................................... 137\\nPhần IV Neural networks\\n12 Gradient descent....................................................... 140\\n12.1 Giới thiệu ........................................................... 140\\n12.2 GD cho hàm một biến................................................. 141\\n12.3 GD cho hàm nhiều biến ............................................... 145\\n12.4 GD với momentum ................................................... 148\\n12.5 Nesterov accelerated gradient .......................................... 151\\n12.6 Stochastic gradient descent ............................................ 152\\n12.7 Thảo luận ........................................................... 155\\n13 Perceptron learning algorithm.......................................... 156\\n13.1 Giới thiệu ........................................................... 156\\n13.2 Thuật toán perceptron ................................................ 157\\n13.3 Ví dụ và minh hoạ trên Python ........................................ 160\\n13.4 Mô hình neural network đầu tiên ....................................... 162\\n13.5 Thảo Luận .......................................................... 163\\n14 Logistic regression...................................................... 165\\n14.1 Giới thiệu ........................................................... 165\\n14.2 Hàm mất mát và phương pháp tối ưu ................................... 167\\n14.3 Triển khai thuật toán trên Python ...................................... 169\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 17, 'page_label': '6'}, page_content='Mục lục 6\\n14.4 Tính chất của logistic regression ........................................ 172\\n14.5 Bài toán phân biệt hai chữ số viết tay .................................. 174\\n14.6 Bộ phân lớp nhị phân cho bài toán phân lớp đa lớp ....................... 175\\n14.7 Thảo luận .......................................................... 177\\n15 Softmax regression ..................................................... 180\\n15.1 Giới thiệu ........................................................... 180\\n15.2 Softmax function .................................................... 181\\n15.3 Hàm mất mát và phương pháp tối ưu ................................... 184\\n15.4 Ví dụ trên Python .................................................... 189\\n15.5 Thảo luận .......................................................... 191\\n16 Multilayer neural network và backpropagation.......................... 193\\n16.1 Giới thiệu ........................................................... 193\\n16.2 Các ký hiệu và khái niệm .............................................. 196\\n16.3 Activation function–Hàm kích hoạt ..................................... 197\\n16.4 Backpropagation ..................................................... 200\\n16.5 Ví dụ trên Python .................................................... 204\\n16.6 Tránh overfitting cho neural network bằng weight decay ................... 209\\n16.7 Đọc thêm ........................................................... 211\\nPhần V Recommendation systems–Hệ thống khuyến nghị\\n17 Content-based recommendation system................................. 214\\n17.1 Giới thiệu ........................................................... 214\\n17.2 Utility matrix ........................................................ 215\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 18, 'page_label': '7'}, page_content='7 Mục lục\\n17.3 Content-based recommendation......................................... 217\\n17.4 Bài toán với cơ sở dữ liệu MovieLens 100k ............................... 220\\n17.5 Thảo luận ........................................................... 224\\n18 Neighborhood-based collaborative filtering.............................. 225\\n18.1 Giới thiệu ........................................................... 225\\n18.2 User-user collaborative filtering ........................................ 226\\n18.3 Item-item collaborative filtering ........................................ 230\\n18.4 Lập trình trên Python ................................................ 232\\n18.5 Thảo luận ........................................................... 235\\n19 Matrix factorization collaborative filtering.............................. 236\\n19.1 Giới thiệu ........................................................... 236\\n19.2 Xây dựng và tối ưu hàm mất mát....................................... 238\\n19.3 Lập trình Python .................................................... 240\\n19.4 Thảo luận ........................................................... 243\\nPhần VI Dimensionality reduction–Giảm chiều dữ liệu\\n20 Singular value decomposition........................................... 246\\n20.1 Giới thiệu ........................................................... 246\\n20.2 Singular value decomposition........................................... 247\\n20.3 SVD cho image compression ........................................... 252\\n20.4 Thảo luận ........................................................... 253\\n21 Principal component analysis........................................... 254\\n21.1 Principal component analysis........................................... 254\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 19, 'page_label': '8'}, page_content='Mục lục 8\\n21.2 Các bước thực hiện PCA .............................................. 259\\n21.3 Mối quan hệ giữa PCA và SVD......................................... 259\\n21.4 Làm thế nào để chọn số chiều của dữ liệu mới ............................ 261\\n21.5 Lưu ý về tính PCA trong các bài toán thực tế ............................ 262\\n21.6 Một vài ứng dụng của PCA ............................................ 263\\n21.7 Thảo luận ........................................................... 266\\n22 Linear discriminant analysis............................................ 268\\n22.1 Giới thiệu ........................................................... 268\\n22.2 LDA cho bài toán phân lớp nhị phân .................................... 270\\n22.3 LDA cho bài toán phân lớp nhiều lớp ................................... 273\\n22.4 Ví dụ trên Python .................................................... 276\\n22.5 Thảo luận ........................................................... 278\\nPhần VII Convex optimization–Tối ưu lồi\\n23 Tập lồi và hàm lồi...................................................... 282\\n23.1 Giới thiệu ........................................................... 282\\n23.2 Tập lồi – Convex sets ................................................. 283\\n23.3 Convex functions ..................................................... 288\\n23.4 Tóm tắt ............................................................. 298\\n24 Bài toán tối ưu lồi...................................................... 299\\n24.1 Giới thiệu ........................................................... 299\\n24.2 Nhắc lại bài toán tối ưu ............................................... 303\\n24.3 Bài toán tối ưu lồi .................................................... 305\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 20, 'page_label': '9'}, page_content='9 Mục lục\\n24.4 Linear programming .................................................. 307\\n24.5 Quadratic programming ............................................... 310\\n24.6 Geometric Programming............................................... 313\\n24.7 Tóm tắt ............................................................. 316\\n25 Duality................................................................. 317\\n25.1 Giới thiệu ........................................................... 317\\n25.2 Hàm đối ngẫu Lagrange ............................................... 318\\n25.3 Bài toán đối ngẫu Lagrange ............................................ 321\\n25.4 Các điều kiện tối ưu .................................................. 323\\n25.5 Tóm tắt ............................................................. 325\\nPhần VIII Support vector machines\\n26 Support vector machine................................................ 328\\n26.1 Giới thiệu ........................................................... 328\\n26.2 Xây dựng bài toán tối ưu cho SVM ..................................... 330\\n26.3 Bài toán đối ngẫu của SVM ........................................... 332\\n26.4 Lập trình tìm nghiệm cho SVM ........................................ 336\\n26.5 Tóm tắt và thảo luận ................................................. 338\\n27 Soft-margin support vector machine.................................... 339\\n27.1 Giới thiệu ........................................................... 339\\n27.2 Phân tích toán học ................................................... 340\\n27.3 Bài toán đối ngẫu Lagrange ........................................... 342\\n27.4 Bài toán tối ưu không ràng buộc chosoft-margin SVM ................... 345\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 21, 'page_label': '10'}, page_content='Mục lục 10\\n27.5 Lập trình vớisoft-margin SVM......................................... 349\\n27.6 Tóm tắt và thảo luận ................................................. 353\\n28 Kernel support vector machine......................................... 355\\n28.1 Giới thiệu ........................................................... 355\\n28.2 Cơ sở toán học ...................................................... 357\\n28.3 Hàm số kernel ....................................................... 359\\n28.4 Ví dụ minh họa ...................................................... 361\\n28.5 Tóm tắt ............................................................ 363\\n29 Multi-class support vector machine..................................... 364\\n29.1 Giới thiệu ........................................................... 364\\n29.2 Xây dựng hàm mất mát .............................................. 368\\n29.3 Tính toán hàm mất mát và đạo hàm của nó ............................. 371\\n29.4 Thảo luận .......................................................... 378\\nA Phương pháp nhân tử Lagrange........................................ 379\\nTài liệu tham khảo......................................................... 383\\nIndex ...................................................................... 386\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 22, 'page_label': '11'}, page_content='Phần I\\nKiến thức toán cơ bản cho machine learning'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 23, 'page_label': '12'}, page_content='Chương 1\\nÔn tập Đại số tuyến tính\\n1.1 Lưu ý về ký hiệu\\nTrong các bài viết của tôi, các số vô hướng được biểu diễn bởi các chữ cái viết ở dạng in\\nnghiêng, có thể viết hoa, ví dụx1,N,y,k . Các vector được biểu diễn bằng các chữ cái thường\\nin đậm, ví dụy,x1. Nếu không giải thích gì thêm, các vector được mặc định hiểu là các\\nvector cột. Các ma trận được biểu diễn bởi các chữ viết hoa in đậm, ví dụX,Y,W.\\nĐối với vector,x = [x1,x2,...,x n] được hiểu là một vector hàng, vàx = [x1; x2; ... ; xn] được\\nhiểu là vector cột. Chú ý sự khác nhau giữa dấu phẩy (,) và dấu chấm phẩy (;). Đây chính\\nlà ký hiệu được Matlab sử dụng. Nếu không giải thích gì thêm, một chữ cái viết thường in\\nđậm được hiểu là một vector cột.\\nTương tự, trong ma trận,X = [x1,x2,..., xn] được hiểu là các vector cộtxj được đặt cạnh\\nnhau theo thứ tự từ trái qua phải để tạo ra ma trậnX. Trong khiX = [x1; x2; ... ; xm] được\\nhiểu là các vectorxi được đặt chồng lên nhau theo thứ tự từ trên xuống dưới dể tạo ra ma\\ntrận X. Các vector được ngầm hiểu là có kích thước phù hợp để có thể xếp cạnh hoặc xếp\\nchồng lên nhau. Phần tử ở hàng thứi, cột thứj được ký hiệu làxij.\\nCho một ma trậnW, nếu không giải thích gì thêm, chúng ta hiểu rằngwi là vector cột\\nthứ i của ma trận đó. Chú ý sự tương ứng giữa ký tự viết hoa và viết thường.\\n1.2 Chuyển vị và Hermitian\\nMột toán tử quan trọng của ma trận hay vector là toán tửchuyển vị (transpose).\\nCho A ∈Rm×n, ta nóiB ∈Rn×m là chuyển vị củaA nếu bij = aji, ∀1 ≤i≤n,1 ≤j ≤m.\\nMột cách ngắn gọn, chuyển vị của một ma trận là một ma trận nhận được từ ma trận cũ\\nthông qua phép phản xạ gương qua đường chéo chính của ma trận ban đầu. Toán tử chuyển'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 24, 'page_label': '13'}, page_content='13 CHƯƠNG 1. ÔN TẬP ĐẠI SỐ TUYẾN TÍNH\\nvị thường được ký hiểu bởi chữT, thoặc ký tự⊤. Trong cuốn sách này, chúng ta sẽ sử dụng\\nchữ cáiT. Ví dụ, chuyển vị của một vectorx được ký hiệu làxT; chuyển vị của một ma trận\\nA được ký hiệu làAT. Cụ thể:\\nx =\\n\\uf8ee\\n\\uf8ef\\uf8ef\\uf8ef\\uf8f0\\nx1\\nx2\\n...\\nxm\\n\\uf8f9\\n\\uf8fa\\uf8fa\\uf8fa\\uf8fb⇒xT =\\n[\\nx1 x2 ...x m\\n]\\n; A =\\n\\uf8ee\\n\\uf8ef\\uf8ef\\uf8ef\\uf8f0\\na11 a12 ... a1n\\na21 a22 ... a2n\\n... ... ... ...\\nam1 am2 ...a mn\\n\\uf8f9\\n\\uf8fa\\uf8fa\\uf8fa\\uf8fb⇒AT =\\n\\uf8ee\\n\\uf8ef\\uf8ef\\uf8ef\\uf8f0\\na11 a21 ...a m1\\na12 a22 ...a m2\\n... ... ... ...\\na1n a2n ...a mn\\n\\uf8f9\\n\\uf8fa\\uf8fa\\uf8fa\\uf8fb\\nNếu A ∈Rm×n thì AT ∈Rn×m. NếuAT = A, ta nóiA là mộtma trận đối xứng(symmetric\\nmatrix).\\nTrong trường hợp vector hay ma trận có các phần tử là số phức, việc lấy chuyển vị thường\\nđi kèm với việc lấy liên hợp phức. Tức là ngoài việc đổi vị trí của các phần tử, ta còn lấy\\nliên hợp phức của các phần tử đó. Tên gọi của phép toán chuyển vị và lấy liên hợp này còn\\nđược gọi làchuyển vị liên hợp(conjugate transpose), và thường được ký hiệu bằng chữH\\nthay cho chữT. Chuyển vị liên hợp của một ma trậnA được ký hiệu làAH (cũng được đọc\\nlà A Hermitian).\\nCho A ∈Cm×n, ta nóiB ∈Cn×m là chuyển vị liên hợp củaA nếu bij = aji, ∀1 ≤i≤n,1 ≤\\nj ≤m, trong đóa là liên hiệp phức củaa.\\nVí dụ:\\nA =\\n[1 + 2i 3 −4i\\ni 2\\n]\\n⇒AH =\\n[1 −2i −i\\n3 + 4i 2\\n]\\n; x =\\n[2 + 3i\\n2i\\n]\\n⇒xH =\\n[\\n2 −3i −2i\\n]\\n(1.1)\\nNếu A,x là các ma trận và vector thực thìAH = AT,xH = xT.\\nNếu chuyển vị liên hợp của một ma trận phức bằng với chính nó,AH = A, thì ta nói ma\\ntrận đó làHermitian.\\n1.3 Phép nhân hai ma trận\\nCho hai ma trậnA ∈Rm×n,B ∈Rn×p, tích của hai ma trận được ký hiệu làC = AB ∈Rm×p\\ntrong đó phần tử ở hàng thứi, cột thứj của ma trận kết quả được tính bởi:\\ncij =\\nn∑\\nk=1\\naikbkj, ∀1 ≤i≤m,1 ≤j ≤p (1.2)\\nĐể nhân được hai ma trận, số cột của ma trận thứ nhất phải bằng số hàng của ma trận thứ\\nhai. Trong ví dụ trên, chúng đều bằngn.\\nMột vài tính chất của phép nhân hai ma trận (giả sử kích thước các ma trận là phù hợp để\\ncác phép nhân ma trận tồn tại):\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 25, 'page_label': '14'}, page_content='CHƯƠNG 1. ÔN TẬP ĐẠI SỐ TUYẾN TÍNH 14\\n1. Phép nhân ma trận không có tính chất giao hoán. Thông thường (không phải luôn luôn),\\nAB ̸= BA. Thậm chí, trong nhiều trường hợp, các phép tính này không tồn tại vì kích\\nthước các ma trận lệch nhau.\\n2. Phép nhân ma trận có tính chất kết hợp:ABC = (AB)C = A(BC)\\n3. Phép nhân ma trận có tính chất phân phối đối với phép cộng:A(B + C) = AB + AC.\\n4. Chuyển vị của một tích bằng tích các chuyển vị theo thứ tự ngược lại. Điều tương tự xảy\\nra với Hermitian của một tích:\\n(AB)T = BTAT; ( AB)H = BHAH (1.3)\\nTheo định nghĩa trên, bằng cách coi vector là một trường hợp đặc biệt của ma trận, tích vô\\nhướng của hai vector (inner product) x,y ∈Rn được định nghĩa là:\\nxTy = yTx =\\nn∑\\ni=1\\nxiyi (1.4)\\nChú ý,xHy = (yHx)H = yHx. Chúng bằng nhau khi và chỉ khi chúng là các số thực. Nếu\\ntích vô hướng của hai vector khác không bằng không, hai vector đó vuông góc với nhau.\\nxHx ≥0, ∀x ∈Cn vì tích của một số phức với liên hiệp của nó luôn là một số không âm.\\nPhép nhân của một ma trậnA ∈Rm×n với một vectorx ∈Rn là một vectorb ∈Rm:\\nAx = b, với bi = A:,ix (1.5)\\nvới A:,i là vector hàng thứi của A.\\nNgoài ra, một phép nhân khác được gọi làHadamard (hay element-wise) hay được sử dụng\\ntrong Machine Learning. Tích Hadamard của hai ma trậncùng kích thướcA,B ∈Rm×n,\\nký hiệu làC = A ⊙B ∈Rm×n, trong đó:\\ncij = aijbij (1.6)\\n1.4 Ma trận đơn vị và ma trận nghịch đảo\\n1.4.1 Ma trận đơn vị\\nĐường chéo chínhcủa một ma trận là tập hợp các điểm có chỉ số hàng và cột là như nhau.\\nCách định nghĩa này cũng có thể được định nghĩa cho một ma trận không vuông. Cụ thể, nếu\\nA ∈Rm×n thì đường chéo chính củaA bao gồm{a11,a22,...,a pp}, trong đóp= min{m,n}.\\nMột ma trận đơn vị bậcn là một ma trận đặc biệt trongRn×n với các phần tử trên đường\\nchéo chính bằng 1, các phần tử còn lại bằng 0. Ma trận đơn vị thường được ký hiệu làI\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 26, 'page_label': '15'}, page_content='15 CHƯƠNG 1. ÔN TẬP ĐẠI SỐ TUYẾN TÍNH\\n(identity matrix). Nếu làm việc với nhiều ma trận đơn vị với bậc khác nhau, ta thường ký\\nkiệu In cho ma trận đơn vị bậcn. Dưới đây là ma trận đơn vị bậc 3 và bậc 4:\\nI3 =\\n\\uf8ee\\n\\uf8f0\\n1 0 0\\n0 1 0\\n0 0 1\\n\\uf8f9\\n\\uf8fb, I4 =\\n\\uf8ee\\n\\uf8ef\\uf8ef\\uf8f0\\n1 0 0 0\\n0 1 0 0\\n0 0 1 0\\n0 0 0 1\\n\\uf8f9\\n\\uf8fa\\uf8fa\\uf8fb (1.7)\\nMa trận đơn vị có tính chất đặc biệt trong phép nhân. NếuA ∈Rm×n,B ∈Rn×m và I là\\nma trận đơn vị bậcn, ta có:AI = A, IB = B.\\nVới mọi vectorx ∈Rn, ta cóInx = x.\\n1.4.2 Ma trận nghịch đảo\\nCho một ma trận vuôngA ∈Rn×n, nếu tồn tại ma trận vuôngB ∈Rn×n sao choAB = In,\\nthì ta nóiA là khả nghịch (invertible, nonsingular hoặc nondegenerate), vàB được gọi là\\nma trận nghịch đảo(inverse matrix ) củaA. Nếu không tồn tại ma trậnB thoả mãn điều\\nkiện trên, ta nói rằng ma trậnA là không khả nghịch (singular hoặc degenerate).\\nNếu A là khả nghịch, ma trận nghịch đảo của nó thường được ký hiệu làA−1. Ta cũng có:\\nA−1A = AA−1 = I (1.8)\\nMa trận nghịch đảo thường được sử dụng để giải hệ phương trình tuyến tính. Giả sử rằng\\nA ∈Rn×n là một ma trận khả nghịch và một vector bất kỳb ∈Rn. Khi đó, phương trình:\\nAx = b (1.9)\\ncó nghiệm duy nhất làx = A−1b. Thật vậy, nhân bên trái cả hai vế của phương trình với\\nA−1, ta cóAx = b ⇔A−1Ax = A−1b ⇔x = A−1b.\\nNếu A không khả nghịch, thậm chí không vuông, phương trình tuyến tính (1.9) có thể không\\ncó nghiệm hoặc có vô số nghiệm.\\nGiả sử các ma trận vuôngA,B là khả nghịch, khi đó tích của chúng cũng khả nghịch, và\\n(AB)−1 = B−1A−1. Quy tắc này cũng khá giống với cách tính ma trận chuyển vị của tích\\ncác ma trận.\\n1.5 Một vài ma trận đặc biệt khác\\n1.5.1 Ma trận đường chéo\\nMa trận đường chéo(diagonal matrix) là ma trận chỉ có các thành phần trên đường chéo\\nchính là khác không. Định nghĩa này cũng có thể được áp dụng lên các ma trận không vuông.\\nMa trận không (tất cả các phần tử bằng 0) và đơn vị là các ma trận đường chéo. Một vài ví\\ndụ về các ma trận đường chéo\\n[\\n1\\n]\\n,\\n[2 0\\n0 0\\n]\\n,\\n[1 0 0\\n0 2 0\\n]\\n,\\n\\uf8ee\\n\\uf8f0\\n−1 0\\n0 2\\n0 0\\n\\uf8f9\\n\\uf8fb.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 27, 'page_label': '16'}, page_content='CHƯƠNG 1. ÔN TẬP ĐẠI SỐ TUYẾN TÍNH 16\\nVới các ma trận đường chéo vuông, thay vì viết cả ma trận, ta có thể chỉ liệt kê các thành\\nphần trên đường chéo. Ví dụ, một ma trận đường chéo vuôngA ∈Rm×m có thể được ký\\nhiệu là diag(a11,a22,...,a mm) với aii là phần tử hàng thứi, cột thứi của ma trậnA.\\nTích, tổng của hai ma trận đường chéo vuông cùng bậc là một ma trận đường chéo. Một\\nma trận đường chéo vuông là khả nghịch nếu và chỉ nếu mọi phần tử trên đường chéo chính\\nlà khác không. Nghịch đảo của một ma trận đường chéo khả nghịch cũng là một ma trận\\nđường chéo. Cụ thể hơn,(diag(a1,a2,...,a n))−1 = diag(a−1\\n1 ,a−1\\n2 ,...,a −1\\nn ).\\n1.5.2 Ma trận tam giác\\nMột ma trận vuông được gọi làma trận tam giác trên(upper triangular matrix) nếu tất cả\\ncác thành phầnnằm phía dưới đường chéo chính bằng 0. Tương tự, một ma trận vuông được\\ngọi làma trận tam giác dưới(lower triangular matrix) nếu tất cả các thành phầnnằm phía\\ntrên đường chéo chính bằng 0.\\nCác hệ phương trình tuyến tính mà ma trận hệ số có dạng tam giác thường được quan tâm\\nvì chúng có thể được giải với chi phí tính toán thấp (low computational cost). Xét hệ:\\n\\uf8f1\\n\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f2\\n\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f3\\na11x1+ a12x2+ ···+ a1,n−1xn−1+ a1nxn = b1\\na22x2+ ···+ a2,n−1xn−2+ a2nxn = b2\\n... ... ... ...\\nan−1,n−1xn−1+ an−1,nxn = bn−1\\nannxn = bn\\n(1.10)\\nHệ này có thể được viết gọn dưới dạngAx = b với A là một ma trận tam giác trên. Nhận\\nthấy rằng phương trình này có thể giải mà không cần tính ma trận nghịch đảoA−1 (quá\\ntrình tính ma trận nghịch đảo thường tốn khá nhiều thời gian), thay vào đó, ta có thể giải\\nxn dựa vào phương trình cuối cùng. Sau khi cóxn, ta có thể thay nó vào phương trình gần\\ncuối để suy raxn−1. Tiếp tục quá trình này, ta sẽ có nghiệm cuối cùngx. Quá trình giải từ\\ncuối lên đầu và thay toàn bộ các thành phần đã tìm được vào phương trình hiện tại được\\ngọi làback substitution. Nếu ma trận hệ số là một ma trận tam giác dưới, hệ phương trình\\ncó thể được giải bằng một quá trình ngược lại – lần lượt tínhx1 rồi x2,...,x n, quá trình\\nnày được gọi làforward substitution.\\n1.6 Định thức\\n1.6.1 Định nghĩa\\nĐịnh thức của một ma trận vuôngA được ký hiệu làdet(A) hoặc det A. Có nhiều cách\\nđịnh nghĩa khác nhau củađịnh thức (determinant). Chúng ta sẽ sử dụng cách định nghĩa\\ndựa trên quy nạp theo bậcn của ma trận.\\nVới n= 1, det(A) chính là phần tử duy nhất của ma trận đó.\\nVới một ma trận vuông bậcn> 1:\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 28, 'page_label': '17'}, page_content='17 CHƯƠNG 1. ÔN TẬP ĐẠI SỐ TUYẾN TÍNH\\nA =\\n\\uf8ee\\n\\uf8ef\\uf8ef\\uf8ef\\uf8f0\\na11 a12 ... a1n\\na21 a22 ... a2n\\n... ... ... ...\\nam1 am2 ...a mn\\n\\uf8f9\\n\\uf8fa\\uf8fa\\uf8fa\\uf8fb⇒det(A) =\\nn∑\\nj=1\\n(−1)i+jaij det(Aij) (1.11)\\nTrong đó1 ≤i≤n bất kỳ vàAij là phần bù đại số củaA ứng với phần tử ở hàngi, cộtj.\\nPhần bù đại số này là mộtma trận concủa A nhận được từA bằng cách xoá hàng thứi\\nvà cột thứj của nó. Đây chính là cách tính định thức dựa trên cách khai triển hàng thứi\\ncủa ma trận1.\\n1.6.2 Tính chất\\n1. det(A) = det(AT): Một ma trận bất kỳ và chuyển vị của nó có định thức như nhau.\\n2. Định thức của một ma trận đường chéo (và vuông) bằng tích các phần tử trên đường chéo\\nchính. Nói cách khác, nếuA = diag(a1,a2,...,a n), thìdet(A) = a1a2 ...a n.\\n3. Định thức của một ma trận đơn vị bằng 1.\\n4. Định thức của một tích bằng tích các định thức.\\ndet(AB) = det(A) det(B) (1.12)\\nvới A,B là hai ma trận vuông cùng chiều.\\n5. Nếu một ma trận có một hàng hoặc một cột là một vector0, thì định thức của nó bằng 0.\\n6. Một ma trận là khả nghịch khi và chỉ khi định thức của nó khác 0.\\n7. Nếu một ma trận khả nghịch, định thức của ma trận nghịch đảo của nó bằng nghịch đảo\\nđịnh thức của nó.\\ndet(A−1) = 1\\ndet(A) vì det(A) det(A−1) = det(AA−1) = det(I) = 1. (1.13)\\n1.7 Tổ hợp tuyến tính, không gian sinh\\n1.7.1 Tổ hợp tuyến tính\\nCho các vector khác khônga1,..., an ∈Rm và các số thựcx1,...,x n ∈R, vector:\\nb = x1a1 + x2a2 + ··· + xnan (1.14)\\nđược gọi là mộttổ hợp tuyến tính(linear combination) củaa1,..., an. Xét ma trậnA =\\n[a1,a2,..., an] ∈Rm×n và x = [x1,x2,...,x n]T, biểu thức (1.14) có thể được viết lại thành\\nb = Ax. Ta có thể nói rằngb là một tổ hợp tuyến tính các cột củaA.\\n1 Việc ghi nhớ định nghĩa này không thực sự quan trọng bằng việc ta cần nhớ một vài tính chất của nó.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 29, 'page_label': '18'}, page_content='CHƯƠNG 1. ÔN TẬP ĐẠI SỐ TUYẾN TÍNH 18\\nTập hợp tất cả các vector có thể biểu diễn được dưới dạng một tổ hợp tuyến tính của các\\ncột của một ma trận được gọi làkhông gian sinh(span space, hoặc gọn làspan) các cột của\\nma trận đó. Không gian sinh của một hệ các vector thường được ký hiệu là span(a1,..., an).\\nNếu phương trình:\\n0 = x1a1 + x2a2 + ··· + xnan (1.15)\\ncó nghiệm duy nhấtx1 = x2 = ··· = xn = 0, ta nói rằng hệ{a1,a2,..., an}là một hệđộc\\nlập tuyến tính (linear independence). Ngược lại, Nếu tồn tạixi ̸= 0 sao cho phương trình\\ntrên thoả mãn, ta nói rằng đó là một hệphụ thuộc tuyến tính(linear dependence).\\n1.7.2 Tính chất\\n1. Một hệ là phụ thuộc tuyến tính nếu và chỉ nếu tồn tại một vector trong hệ đó là tổ hợp\\ntuyến tính của các vector còn lại.Thật vậy, giả sử phương trình (1.15) có nghiệm khác\\nkhông. Giả sử hệ số khác không làxi, ta sẽ có:\\nai = −x1\\nxi\\na1 + ··· + −xi−1\\nxi\\nai−1 + −xi+1\\nxi\\nai+1 + ... −xn\\nxi\\nan (1.16)\\ntức ai là một tổ hợp tuyến tính của các vector còn lại.\\n2. Tập con khác rỗng của một hệ độc lập tuyến tính là một hệ độc lập tuyến tính.\\n3. Tập hợp các cột của một ma trận khả nghịch tạo thành một hệ độc lập tuyến tính.\\nGiả sử ma trậnA khả nghịch, phương trìnhAx = 0 có nghiệmduy nhấtx = A−10 = 0.\\nVì vậy, các cột củaA tạo thành một hệ độc lập tuyến tính.\\n4. Nếu A là một ma trận cao (tall matrix), tức số hàng lớn hơn số cột,m >n, thì tồn tại\\nvector b sao choAx = b vô nghiệm.\\nViệc này có thể dễ hình dung trong không gian ba chiều. Không gian sinh của một vector\\nlà một đường thẳng, không gian sinh của hai vector độc lập tuyến tính là một mặt phẳng,\\ntức chỉ biểu diễn được các vector nằm trong mặt phẳng đó.\\nTa cũng có thể chứng minh tính chất này bằng phản chứng. Giả sử mọi vector trong\\nkhông gianm chiều đều nằm trong không gian sinh của một hện<m vector là các cột\\ncủa một ma trậnA. Xét các cột của ma trận đơn vị bậcm. Vì mọi cột của ma trận này\\nđều có thể biểu diễn dưới dạng một tổ hợp tuyến tính củan vector đã cho nên phương\\ntrình AX = I có nghiệm. Nếu ta thêm các vào các cột bằng 0 và các hàng bằng 0 vàoA\\nvà X để được các ma trận vuông, ta sẽ có\\n[\\nA 0\\n][X\\n0\\n]\\n= I. Việc này chỉ ra rằng\\n[\\nA 0\\n]\\nlà\\nmột ma trận khả nghịch trong khi nó có các cột bằng 0. Đây là một điều vô lý vì theo\\ntính chất của định thức, định thức của\\n[\\nA 0\\n]\\nbằng 0.\\n5. Nếu n > m, thì n vector bất kỳ trong không gianm chiều tạo thành một hệ phụ thuộc\\ntuyến tính. Xin được bỏ qua phần chứng minh.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 30, 'page_label': '19'}, page_content='19 CHƯƠNG 1. ÔN TẬP ĐẠI SỐ TUYẾN TÍNH\\n1.7.3 Cơ sở của một không gian\\nMột hệ các vector{a1,..., an}trong không gian vectormchiều V = Rm được gọi là mộtcơ\\nsở (basic) nếu hai điều kiện sau được thoả mãn:\\n1. V ≡span(a1,..., an)\\n2. {a1,..., an}là một hệ độc lập tuyến tính.\\nKhi đó, mọi vectorb ∈V đều có thể biểu diễnduy nhất dưới dạng một tổ hợp tuyến tính\\ncủa cácai.\\nTừ hai tính chất cuối ở mục trước, ta có thể suy ra rằngm= n.\\n1.7.4 Range và Null space\\nVới mỗi ma trậnA ∈Rm×n, có hai không gian con quan trọng ứng với ma trận này.\\n1. Range củaA. Range củaA, được định nghĩa là:\\nR(A) = {y ∈Rm : ∃x ∈Rn,Ax = y} (1.17)\\nNói cách khác,R(A) là tập hợp các điểm là tổ hợp tuyến tính của các cột củaA, hay\\nchính là không gian sinh (span) của các cột củaA.R(A) là một không gian con củaRm\\nvới số chiều chính bằng sô lượng lớn nhất các cột củaA độc lập tuyến tính.\\n2. Null củaA, ký hiệu làN(A), được định nghĩa là:\\nN(A) = {x ∈Rn : Ax = 0} (1.18)\\nMỗi vector trongN(A) chính là một bộ các hệ số làm cho tổ hợp tuyến tính các cột của\\nA tạo thành một vector 0.N(A) có thể được chứng minh là một không gian con trong\\nRn. Khi các cột củaA là độc lập tuyến tính, theo định nghĩa,N(A) = {0}(chỉ gồm\\nvector 0).\\nR(A) và N(A) là các không gian con vector với số chiều lần lượt là dim(R(A)) và\\ndim(N(A)), ta có tính chất quan trọng sau đây:\\ndim(R(A)) + dim(N(A)) = n (1.19)\\n1.8 Hạng của ma trận\\nXét một ma trậnA ∈Rm×n. Hạng (rank) của ma trận này, ký hiệu là rank(A), được định\\nnghĩa là số lượng lớn nhất các cột của nó tạo thành một hệ độc lập tuyến tính.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 31, 'page_label': '20'}, page_content='CHƯƠNG 1. ÔN TẬP ĐẠI SỐ TUYẾN TÍNH 20\\nCác tính chất quan trọng của hạng:\\n1. Một ma trận có hạng bằng 0 khi và chỉ khi nó là ma trận 0.\\n2. rank(A) = rank(AT). Hạng của một ma trận bằng hạng của ma trận chuyển vị. Nói cách\\nkhác, số lượng lớn nhất các cột độc lập tuyến tính của một ma trận bằng với số lượng\\nlớn nhất các hàng độc lập tuyến tính của ma trận đó. Từ đây ta suy ra:\\n3. Nếu A ∈Rm×n, thì rank(A) ≤min(m,n) vì theo định nghĩa, hạng của một ma trận\\nkhông thể lớn hơn số hàng hoặc số cột của nó.\\n4. rank(AB) ≤min(rank(A),rank(B))\\n5. rank(A + B) ≤rank(A) + rank(B). Điều này chỉ ra rằng một ma trận có hạng bằngk\\nkhông được biểu diễn dưới dạng ít hơnkma trận có hạng bằng 1. Đến bài Singular Value\\nDecomposition, chúng ta sẽ thấy rằng một ma trận có hạng bằngkcó thể biểu diễn được\\ndưới dạng đúngk ma trận có hạng bằng 1.\\n6. Bất đẳng thức Sylvester về hạng: NếuA ∈Rm×n,B ∈Rn×k, thì\\nrank(A) + rank(B) −n≤rank(AB)\\nXét một ma trận vuôngA ∈Rn×, hai điều kiện bất kỳ dưới đây là tương đương:\\n1. A là một ma trận khả nghịch.\\n2. Các cột củaA tạo thành một cơ sở trong\\nkhông giann chiều.\\n3. det(A) ̸= 0.\\n4. rank(A) = n\\n1.9 Hệ trực chuẩn, ma trận trực giao\\n1.9.1 Định nghĩa\\nMột hệ cơ sở{u1,u2,..., um ∈Rm}được gọi làtrực giao (orthogonal) nếu mỗi vector là\\nkhác 0 và tích của hai vector khác nhau bất kỳ bằng 0:\\nui ̸= 0; uT\\ni uj = 0 ∀1 ≤i̸= j ≤m (1.20)\\nMột hệ cơ sở{u1,u2,..., um ∈Rm}được gọi làtrực chuẩn(orthonormal) nếu nó là một hệ\\ntrực giaovà độ dài Euclidean (xem thêm phầnℓ2 norm) của mỗi vector bằng 1:\\nuT\\ni uj =\\n{\\n1 nếu i= j\\n0 o.w. (1.21)\\n(o.w. là cách viết ngắn gọn củatrong các trường hợp còn lai(viết tắt củaotherwise).)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 32, 'page_label': '21'}, page_content='21 CHƯƠNG 1. ÔN TẬP ĐẠI SỐ TUYẾN TÍNH\\nGọi U = [u1,u2,..., um] với {u1,u2,..., um ∈Rm}là trực chuẩn, từ (1.21) có thể suy ra:\\nUUT = UTU = I (1.22)\\ntrong đóI là ma trận đơn vị bậcm. Nếu một ma trận thoả mãn điều kiện 1.22, ta gọi nó\\nlà ma trận trực giao(orthogonal matrix). Ma trận loại này không không được gọi là ma trận\\ntrực chuẩn, không có định nghĩa cho ma trận trực chuẩn.\\nNếu một ma trận vuông phứcU thoả mãn UUH = UHU = I, ta nói rằngU là một ma\\ntrận unitary(unitary matrix).\\n1.9.2 Tính chất của ma trận trực giao\\n1. U−1 = UT: nghịch đảo của một ma trận trực giao chính là chuyển vị của nó.\\n2. Nếu U là ma trận trực giao thì chuyển vị của nóUT cũng là một ma trận trực giao.\\n3. Định thức của ma trận trực giao bằng1 hoặc −1. Điều này có thể suy ra từ việcdet(U) =\\ndet(UT) và det(U) det(UT) = det(I) = 1.\\n4. Ma trận trực giao thể hiện cho phép xoay một vector (xem thêm mục 1.10). Giả sử có\\nhai vectorx,y ∈Rm và một ma trận trực giaoU ∈Rm×m. Dùng ma trận này để xoay\\nhai vector trên ta đượcUx,Uy. Tích vô hướng của hai vector mới là:\\n(Ux)T(Uy) = xTUTUy = xTy (1.23)\\nnhư vậyphép xoay không làm thay đổi tích vô hướng giữa hai vector.\\n5. Giả sửˆU ∈Rm×r,r <m là môt ma trận con của ma trận trực giaoU được tạo bởir cột\\ncủa U, ta sẽ cóˆUT ˆU = Ir. Việc này có thể được suy ra từ (1.21).\\n1.10 Biễu diễn vector trong các hệ cơ sở khác nhau\\nTrong không gianm chiều, toạ độ của mỗi điểm được xác định dựa trên một hệ toạ độ nào\\nđó. Ở các hệ toạ độ khác nhau, hiển nhiên là toạ độ của mỗi điểm cũng khác nhau.\\nTập hợp các vectore1,..., em mà mỗi vectorei có đúng 1 phần tử khác 0 ở thành phần thứ\\nivà phần tử đó bằng 1, được gọi là hệ cơ sở đơn vị (hoặc hệ đơn vị, hoặc hệ chính tắc) trong\\nkhông gianm chiều. Nếu xếp các vectorei,i = 1,2,...,m theo đúng thứ tự đó, ta sẽ được\\nma trận đơn vịm chiều.\\nMỗi vector cộtx = [x1,x2,...,x m] ∈Rm có thể coi là một tổ hợp tuyến tính của các vector\\ntrong hệ cơ sở chính tắc:\\nx = x1e1 + x2e2 + ··· + xmem (1.24)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 33, 'page_label': '22'}, page_content='CHƯƠNG 1. ÔN TẬP ĐẠI SỐ TUYẾN TÍNH 22\\nO\\ne1\\ne2\\nu1\\nu2\\nx1\\nx2\\ny1\\ny2\\nx\\nHình 1.1:Chuyển đổi toạ độ trong\\ncác hệ cơ sở khác nhau. Trong\\nhệ toạ độ Oe1e2, x có toạ độ là\\n(x1,x2). Trong hệ toạ độOu1u2,\\nx có toạ độ là(y2,y2).\\nGiả sử có một hệ cơ sở khácu1,u2,..., um (các vector này độc lập tuyến tính), biểu diễn\\ncủa vectorx trong hệ cơ sở mới này có dạng:\\nx = y1u1 + y2u2 + ··· + ymum = Uy (1.25)\\nvới U =\\n[\\nu1 ... um\\n]\\n. Lúc này, vectory = [y1,y2,...,y m]T chính là biểu diễn củax trong hệ\\ncơ sở mới. Biểu diễn này là duy nhất vìy = U−1x.\\nTrong các ma trận đóng vai trò như hệ cơ sở, các ma trận trực giao, tứcUTU = I, được quan\\ntâm nhiềuhơn vì nghịch đảocủa chúngchính là chuyển vị củachúng:U−1 = UT. Khi đó,y có\\nthể được tính một cách nhanh chóngy = UTx. Từ đó suy ra:yi = xTui = uT\\ni x,i = 1,...,m .\\nDưới góc nhìn hình học, hệ trực giao tạo thành một hệ trục toạ độ Descartes vuông góc mà\\nchúng ta đã quen thuộc trong không gian hai chiều hoặc ba chiều.\\nCó thể nhận thấy rằng vector0 được biểu diễn như nhau trong mọi hệ cơ sở. Hình 1.1 là\\nmột ví dụ về việc chuyển hệ cơ sở trong không gian hai chiều.\\nViệc chuyển đổi hệ cơ sở sử dụng ma trận trực giao có thể được coi như một phép xoay\\ntrục toạ độ. Nhìn theo một cách khác, đây cũng chính là một phép xoay vector dữ liệu theo\\nchiều ngược lại, nếu ta coi các trục toạ độ là cố định. Trong chương Principle Component\\nAnalysis, chúng ta sẽ thấy được một ứng dụng quan trọng của việc đổi hệ cơ sở.\\n1.11 Trị riêng và vector riêng\\n1.11.1 Định nghĩa\\nCho một ma trận vuôngA ∈Rn×n, một vectorx ∈Rn(x ̸= 0) và một số vô hướng (có\\nthể thực hoặc phức)λ. NếuAx = λx, thì ta nóiλ và x là một cặptrị riêng, vector riêng\\n(eigenvalue, eigenvector) của ma trậnA.\\nTừ định nghĩa ta cũng có(A −λI)x = 0, tứcx nằm trong null space củaA −λI. Vìx ̸= 0,\\nA −λI là một ma trận không khả nghịch. Nói cách khácdet(A −λI) = 0, tứcλ là nghiệm\\ncủa phương trìnhdet(A −tI) = 0. Định thức này là một đa thức bậcn của t, được gọi là\\nđa thức đặc trưng(characteristic polynomial) củaA, được ký hiệu làpA(t). Tập hợp tất cả\\ncác trị riêng của một ma trận vuông còn được gọi làphổ (spectrum) của ma trận đó.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 34, 'page_label': '23'}, page_content='23 CHƯƠNG 1. ÔN TẬP ĐẠI SỐ TUYẾN TÍNH\\n1.11.2 Tính chất\\n1. Nếu x là một vector riêng củaA ứng vớiλ thì kx, ∀k ̸= 0 cũng là vector riêng ứng với\\ntrị riêng đó. Nếux1,x2 là hai vector riêng ứng với cùng trị riêngλ, thì tổng của chúng\\ncũng là một vector ứng với trị riêng đó. Từ đó suy ra tập hợp các vector riêng ứng với\\nmột trị riêng của một ma trận vuông tạo thành một không gian vector con, thường được\\ngọi làkhông gian riêng(eigenspace) ứng với trị riêng đó.\\n2. Mọi ma trận vuông bậcn đều cón trị riêng (kể cả lặp) và có thể là các số phức.\\n3. Tích của tất cả các trị riêng của một ma trận bằng định thức của ma trận đó. Tổng tất\\ncả các trị riêng của một ma trận bằng tổng các phần tử trên đường chéo của ma trận đó.\\n4. Phổ của một ma trận bằng phổ của ma trận chuyển vị của nó.\\n5. Nếu A,B là các ma trận vuông cùng bậc thìpAB(t) = pBA(t). Điều này nghĩa là, mặc\\ndù tích của hai ma trận không có tính chất giao hoán, đa thức đặc trưng củaAB vàBA\\nlà như nhau. Tức phổ của hai tích này là trùng nhau.\\n6. Với ma trận đối xứng (hoặc tổng quát, Hermitian), tất cả các trị riêng của nó đều là các\\nsố thực. Thật vậy, giả sửλ là một trị riêng của một ma trận HermitianA và x là một\\nvector riêng ứng với trị riêng đó. Từ định nghĩa ta suy ra:\\nAx = λx ⇒(Ax)H = ¯λxH ⇒¯λxH = xHA (1.26)\\nvới ¯λ là liên hiệp phức của số vô hướngλ. Nhân cả hai vế vào bên phải vớix ta có:\\n¯λxHx = xHAx = λxHx ⇒(λ−¯λ)xHx = 0 (1.27)\\nvì x ̸= 0 nên xHx ̸= 0. Từ đó suy ra¯λ= λ, tứcλ phải là một số thực.\\n7. Nếu(λ,x) là một cặp trị riêng, vector riêng của một ma trận khả nghichA, thì(1\\nλ,x) là\\nmột cặp trị riêng, vector riêng củaA−1, vìAx = λx ⇒1\\nλx = A−1x.\\n1.12 Chéo hoá ma trận\\nViệc phân tích một đại lượng toán học ra thành các đại lượng nhỏ hơn mang lại nhiều hiệu\\nquả. Phân tích một số thành tích các thừa số nguyên tố giúp kiểm tra một số có bao nhiêu\\nước số. Phân tích đa thức thành nhân tử giúp tìm nghiệm của đa thức. Việc phân tích một\\nma trận thành tích của các ma trận có dạng đặc biệt khác (quá trình này được gọi làmatrix\\ndecomposition) cũng mang lại nhiều lợi ích trong việc giải hệ phương trình một cách hiệu\\nquả, tính luỹ thừa của ma trận, xấp xỉ ma trận, nén dữ liệu, phân cụm dữ liệu, v.v. Trong\\nmục này, chúng ta sẽ ôn lại một phương pháp matrix decomposition quen thuộc–phương\\npháp chéo hoá ma trận (diagonalization hoặc eigendecomposition).\\nGiả sử x1,..., xn ̸= 0 là các vector riêng của một ma trận vuôngA ứng với các trị riêng\\nλ1,...,λ n (có thể lặp hoặc là các số phức) của nó. Tức làAxi = λixi, ∀i= 1,...,n .\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 35, 'page_label': '24'}, page_content='CHƯƠNG 1. ÔN TẬP ĐẠI SỐ TUYẾN TÍNH 24\\nĐặt Λ= diag(λ1,λ2,...,λ n), vàX =\\n[\\nx1,x2,..., xn\\n]\\n, ta sẽ cóAX = XΛ. Hơn nữa, nếu\\ncác trị riêngx1,..., xn là độc lập tuyến tính, ma trậnX là một ma trận khả nghịch. Khi đó\\nta có thể viêtA dưới dạng tích của ba ma trận:\\nA = XΛX−1 (1.28)\\nCác vector riêng xi thường được chọn sao cho xT\\ni xi = 1 . Cách biểu diễn một ma trận\\nnhư (1.28) được gọi làeigendecompositionvì nó tách ra thành tích của các ma trận đặc biệt\\ndựa trên vector riêng (eigenvectors) và trị riêng (eigenvalues). Ma trận các trị riêngΛ là\\nmột ma trận đường chéo. Vì vậy, cách khai triển này cũng có tên gọi là chéo hoá ma trận.\\nTính chất:\\n1. Khái niệm chéo hoá ma trận chỉ áp dụng với ma trận vuông. Vì không có định nghĩa\\nvector riêng hay trị riêng cho ma trận không vuông.\\n2. Không phải ma trận vuông nào cũng có thểchéo hoá được(diagonalizable). Một ma trận\\nvuông bậcn là chéo hoá được nếu và chỉ nếu nó có đủn trị riêng độc lập tuyến tính.\\n3. Nếu một ma trận là chéo hoá được, có nhiều hơn một cách chéo hoá ma trận đó. Chỉ cần\\nđổi vị trí của cácλi và vị trí tương ứng các cột củaX, ta sẽ có một cách chéo hoá mới.\\n4. NếuA có thể viết được dưới dạng (1.28), khi đó các luỹ thừa có nó cũng chéo hoá được.\\nCụ thể:\\nA2 = (XΛX−1)(XΛX−1) = XΛ2X−1; Ak = XΛkX−1, ∀k∈N (1.29)\\nXin chú ý rằng nếuλ và x là một cặp (trị riêng, vector riêng) củaA, thìλk và x là một\\ncặp (trị riêng, vector riêng) củaAk. Thật vậy,Akx = Ak−1(Ax) = λAk−1x = ··· = λkx.\\n5. Nếu A khả nghịch, thìA−1 = (XΛX−1)−1 = XΛ−1X−1. Vậy chéo hoá ma trận cũng có\\ních trong việc tính ma trận nghịch đảo.\\n1.13 Ma trận xác định dương\\n1.13.1 Định nghĩa\\nMột ma trận đối xứng2 A ∈Rn×n được gọi làxác định dương(positive definite) nếu:\\nxTAx >0,∀x ∈Rn,x ̸= 0. (1.30)\\nMột ma trận đối xứngA ∈Rn×n được gọi lànửa xác định dương(positive semidefinite) nếu:\\nxTAx ≥0,∀x ∈Rn,x ̸= 0. (1.31)\\nTrên thực tế, ma trận nửa xác định dương, dược viết tắt làPSD, được sử dụng nhiều hơn.\\n2 Chú ý, tồn tại những ma trận không đối xứng thoả mãn điều kiện (1.30). Ta sẽ không xét những ma trận này.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 36, 'page_label': '25'}, page_content='25 CHƯƠNG 1. ÔN TẬP ĐẠI SỐ TUYẾN TÍNH\\nMa trậnxác định âm(negative definite) vànửa xác định âm(negative semi-definite) cũng\\nđược định nghĩa tương tự.\\nKý hiệu A ≻0,⪰0,≺0,⪯0 được dùng để chỉ một ma trận là xác định dương, nửa xác\\nđịnh dương, xác định âm, nửa xác định âm, theo thứ tự đó. Ký hiệuA ≻B cũng được dùng\\nđể chỉ ra rằngA −B ≻0.\\nMở rộng, một ma trận phức, HermitianA ∈Cn×n được gọi là xác định dương nếu:\\nxHAx >0,∀x ∈Cn,x ̸= 0. (1.32)\\nVí dụ,A =\\n[1 −1\\n−1 1\\n]\\nlà nửa xác định dương vì với mọi vectorx =\\n[u\\nv\\n]\\n, ta có:\\nxTAx =\\n[\\nuv\\n][1 −1\\n−1 1\\n][u\\nv\\n]\\n= u2 + v2 −2uv= (u−v)2 ≥0,∀u,v ∈R (1.33)\\n1.13.2 Tính chất\\n1. Mọi trị riêng của một ma trận xác định dương đều là một số thực dương.\\nTrước hết, các trị riêng của các ma trận dạng này là số thực vì các ma trận đều là đối\\nxứng. Để chứng minh chúng là các số thực dương, ta giả sửλ là một trị riêng của một\\nma trận xác định dươngA và x ̸= 0 là một vector riêng ứng với trị riêng đó. Nhân vào\\nbên trái cả hai vế củaAx = λx với xH ta có:\\nλxHx = xHAx >0 (1.34)\\n(ở đây Hermitian được dùng để xét tổng quát cho cả trường hợp ma trận phức). VìxHx\\nluôn dương với mọix nên ta phải cóλ >0. Tương tự, ta có thể chứng minh được rằng\\nmọi trị riêng của một ma trận nửa xác định dương là không âm.\\n2. Mọi ma trận xác định dương là khả nghịch. Hơn nữa, định thức của nó là một số dương.\\nĐiều này được trực tiếp suy ra từ tính chất 1. Nhắc lại rằng định thức của một ma trận\\nbằng tích tất cả các trị riêng của nó.\\n3. Tiêu chuẩn Sylvester:Một ma trận Hermitian là xác định dương nếu và chỉ nếu mọi\\nleading principal minors của nó là dương. Một ma trận Hermitian là nửa xác định dương\\nnếu mọi principal minors của nó là không âm. Đây là một tiêu chuẩn để kiểm tra một ma\\ntrận HermitianA ∈Rn có là (nửa) xác định dương hay không. Ở đây,leading principal\\nminors và principal minorsđược định nghĩa như sau:\\nGọi Ilà một tập con bất kỳ của{1,2,...,n }, AI là ma trận con củaA nhận được bằng\\ncách trích ra các hàng và cột có chỉ số nằm trongIcủa A. Khi đó,AI và det(AI) lần\\nlượt được gọi là mộtma trận con chính(principal submatrix) vàprincipal minorcủa A.\\nNếu Ichỉ bao gồm các số tự nhiên liên tiếp từ1 đến k ≤n, ta nóiAI và det(AI) lần\\nlượt là mộtleading principal submatrixvà leading principal minorbậc k của A.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 37, 'page_label': '26'}, page_content='CHƯƠNG 1. ÔN TẬP ĐẠI SỐ TUYẾN TÍNH 26\\n4. A = BHB là nửa xác định dương với mọi ma trậnB (B không nhất thiết vuông).\\nThật vậy, với mọi vectorx ̸= 0 với chiều phù hợp,xHAx = xHBHBx = (Bx)H(Bx) ≥0.\\n5. Khai triển Cholesky (Cholesky decomposition):Mọi ma trận Hermitian, nửa xác định\\ndương A đều biểu diễn được duy nhất dưới dạngA = LLH, trong đóL là một ma trận\\ntam giác dưới với các thành phần trên đường chéo là thực dương.\\n6. Nếu A là một ma trận nửa xác định dương, thìxTAx = 0 ⇔Ax = 0.\\nNếu Ax = 0 ⇒xTAx = 0 một cách hiển nhiên.\\nNếu xTAx = 0. Với vectory ̸= 0 bất kỳ có cùng kích thước vớix, xét hàm số sau đây:\\nf(λ) = (x + λy)TA(x + λy) (1.35)\\nHàm số này không âm với mọiλ vì A là một ma trận nửa xác định dương. Đây là một\\ntam thức bậc hai củaλ:\\nf(λ) = yTAyλ2 + 2yTAxλ+ xTAx = yTAyλ2 + 2yTAxλ (1.36)\\nXét hai trường hợp:\\n• yTAy = 0. Khi đó,f(λ) = 2yTAxλ≥0,∀λ nếu và chỉ nếuyTAx = 0.\\n• yTAy >0. Khi đó tam thức bậc haif(λ) ≥0,∀λ nếu và chỉ nếu∆′= (yTAx)2 ≤0\\nvì hệ số ứng với thành phần bậc hai bằngyTAy >0. Điều này cũng đồng nghĩa với\\nviệc yTAx = 0\\nTóm lại,yTAx = 0, ∀y ̸= 0. Điều này chỉ xảy ra nếuAx = 0. □\\n1.14 Chuẩn của vector và ma trận\\nTrong không gian một chiều, khoảng cách giữa hai điểm là trị tuyệt đối của hiệu giữa hai giá\\ntrị đó. Trong không gian hai chiều, tức mặt phẳng, chúng ta thường dùng khoảng cách Euclid\\nđể đo khoảng cách giữa hai điểm. Khoảng cách này chính là đại lượng chúng ta thường nói\\nbằng ngôn ngữ thông thường làđường chim bay. Đôi khi, để đi từ một điểm này tới một\\nđiểm kia, con người chúng ta không thể đi bằng đường chim bay được mà còn phụ thuộc\\nvào việc đường đi nối giữa hai điểm có dạng như thế nào.\\nViệc đo khoảng cách giữa hai điểm dữ liệu nhiều chiều, tức hai vector, là rất cần thiết trong\\nMachine Learning. Và đó chính là lý do mà khái niệmchuẩn (norm) ra đời. Để xác định\\nkhoảng cách giữa hai vectory và z, người ta thường áp dụng một hàm số lên vector hiệu\\nx = y −z. Hàm số này cần có một vài tính chất đặc biệt.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 38, 'page_label': '27'}, page_content='27 CHƯƠNG 1. ÔN TẬP ĐẠI SỐ TUYẾN TÍNH\\nx\\ny\\nz\\nx1 y1\\nx2\\ny2\\n∥x −y∥2\\n|x1 −y1|\\n|x2−y2|\\n∥x −y∥1 = |x1 −y1|+ |x2 −y2|\\nHình 1.2:Minh họaℓ1 norm vàℓ2\\nnorm trong không gian hai chiều.ℓ2\\nnorm chính là khoảng cách giữa hai\\nđiểm trong mặt phẳng. Trong khi\\nđó ℓ1 norm là quãng đường ngắn\\nnhất giữa hai điểm nếu chỉ được đi\\ntheo các đường song song với các\\ntrục toạ độ.\\nĐịnh nghĩa 1.1: Norm\\nMột hàm sốf :Rn →R được gọi là một norm nếu nó thỏa mãn ba điều kiện sau đây:\\n1. f(x)≥0. Dấu bằng xảy ra⇔x = 0.\\n2. f(αx) =|α|f(x), ∀α∈R\\n3. f(x1) +f(x2)≥f(x1 + x2), ∀x1,x2 ∈Rn\\nĐiều kiện thứ nhấtlà dễ hiểu vì khoảng cách không thể là một số âm. Hơn nữa, khoảng\\ncách giữa hai điểmy vàz bằng 0 nếu và chỉ nếu hai điểm nó trùng nhau, tứcx = y −z = 0.\\nĐiều kiện thứ haicũng có thể được lý giải như sau. Nếu ba điểmy,v và z thẳng hàng,\\nhơn nữav −y = α(v −z)thì khoảng cách giữav vày gấp |α|lần khoảng cách giữav vàz.\\nĐiều kiện thứ bachính là bất đẳng thức tam giác nếu ta coix1 = y −w,x2 = w −z với\\nw là một điểm bất kỳ trong cùng không gian.\\n1.14.1 Một số chuẩn vector thường dùng\\nĐộ dài Euclid của một vectorx ∈Rn chính là một norm, norm này được gọi làℓ2 norm hoặc\\nEuclidean norm:\\n∥x∥2 =\\n√\\nx2\\n1 + x2\\n2 + ··· + x2\\nn (1.37)\\nBình phương củaℓ2 norm chính là tích vô hướng của một vector với chính nó,∥x∥2\\n2 = xTx.\\nVới p là một số không nhỏ hơn 1bất kỳ, hàm số:\\n∥x∥p = (|x1|p + |x2|p + ... |xn|p)\\n1\\np (1.38)\\nđược chứng minh thỏa mãn ba điều kiện của norm, và được gọi làℓp norm.\\nCó một vài giá trị củap thường được dùng:\\n1. Khi p= 2chúng ta cóℓ2 norm như ở trên.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 39, 'page_label': '28'}, page_content='CHƯƠNG 1. ÔN TẬP ĐẠI SỐ TUYẾN TÍNH 28\\n2. Khi p = 1 chúng ta cóℓ1 norm: ∥x∥1 = |x1|+ |x2|+ ··· + |xn|là tổng các trị tuyệt đối\\ncủa từng phần tử củax. Hình 1.2 là một ví dụ sánhℓ1 norm vàℓ2 norm trong không\\ngian hai chiều. Norm 2 (màu xanh) chính là đường thằngchim baynối giữa hai vectorx\\nvà y. Khoảng cáchℓ1 norm giữa hai điểm này (màu đỏ) có thể diễn giải như là đường đi\\ntừ x tới y trong một thành phố mà đường phố tạo thành hình bàn cờ. Chúng ta chỉ có\\ncách đi dọc theo cạnh của bàn cờ mà không được đi thẳng như đường chim bay.\\n3. Khi p→∞, giả sửi= arg maxj=1,2,...,n|xj|. Khi đó:\\n∥x∥p = |xi|\\n(\\n1 +\\n⏐⏐⏐⏐\\nx1\\nxi\\n⏐⏐⏐⏐\\np\\n+ ··· +\\n⏐⏐⏐⏐\\nxi−1\\nxi\\n⏐⏐⏐⏐\\np\\n+\\n⏐⏐⏐⏐\\nxi+1\\nxi\\n⏐⏐⏐⏐\\np\\n+ ··· +\\n⏐⏐⏐⏐\\nxn\\nxi\\n⏐⏐⏐⏐\\np)1\\np\\n(1.39)\\nTa thấy rằng:\\nlim\\np→∞\\n(\\n1 +\\n⏐⏐⏐⏐\\nx1\\nxi\\n⏐⏐⏐⏐\\np\\n+ ··· +\\n⏐⏐⏐⏐\\nxi−1\\nxi\\n⏐⏐⏐⏐\\np\\n+\\n⏐⏐⏐⏐\\nxi+1\\nxi\\n⏐⏐⏐⏐\\np\\n+ ··· +\\n⏐⏐⏐⏐\\nxn\\nxi\\n⏐⏐⏐⏐\\np)1\\np\\n= 1 (1.40)\\nvì đại lượng trong dấu ngoặc đơn không vượt quán, ta sẽ có:\\n∥x∥∞≜lim\\np→∞\\n∥x∥p = |xi|= max\\nj=1,2,...,n\\n|xj| (1.41)\\n1.14.2 Chuẩn Frobenius của ma trận\\nVới một ma trậnA ∈Rm×n, chuẩn thường được dùng nhất là chuẩn Frobenius, ký hiệu là\\n∥A∥F là căn bậc hai của tổng bình phương tất cả các phần tử của ma trận đó.\\n∥A∥F =\\n\\ued6a\\ued6b\\ued6b√\\nm∑\\ni=1\\nn∑\\nj=1\\na2\\nij\\nChú ý rằngℓ2 norm ∥A∥2 là một norm khác của ma trận, không phổ biến bằng Frobenius\\nnorm. Bạn đọc có thể xemℓ2 norm của ma trận trong Phụ lục A.\\n1.14.3 Vết của ma trận\\nVết (trace) của một ma trận vuông là tổng tất cả cả phần tử trên đường chéo chính của nó.\\nVết của một ma trận đượcA được ký hiệu là trace(A). Hàm số trace xác định trên tập các\\nma trận vuông được sử dụng rất nhiều trong tối ưu vì những tính chất đẹp của nó.\\nCác tính chất quan trọng của hàm trace, với giả sử rằng các ma trận trong hàm trace là\\nvuông và các phép nhân ma trận thực hiện được:\\n• Một ma trận vuông bất kỳ và chuyển vị của nó có trace bằng nhautrace(A) = trace(AT).\\nViệc này khá hiển nhiên vì phép chuyển vị không làm thay đổi các phần tử trên đường\\nchéo chính của một ma trận.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 40, 'page_label': '29'}, page_content='29 CHƯƠNG 1. ÔN TẬP ĐẠI SỐ TUYẾN TÍNH\\n• trace của một tổng bằng tổng các trace: trace(∑k\\ni=1 Ai) = ∑k\\ni=1 trace(Ai).\\n• trace(kA) = ktrace(A) với k là một số vô hướng bất kỳ.\\n• trace(A) = ∑D\\ni=1 λi với A là một ma trận vuông vàλi,i = 1,2,...,N là toàn bộ các trị\\nriêng của nó, có thể phức hoặc lặp. Việc chứng minh tính chất này có thể được dựa trên\\nma trận đặc trưng củaA và định lý Viète.\\n• trace(AB) = trace(BA). Đẳng thức này được suy ra từ việc đa thức đặc trưng củaAB\\nvà BA là như nhau. Bạn đọc cũng có thể chứng minh bằng cách tính trực tiếp các phần\\ntử trên đường chéo chính củaAB và BA.\\n• trace(ABC) = trace(BCA) nhưng trace(ABC) không đồng nhất với trace(ACB).\\n• Nếu X là một ma trận khả nghịch cùng chiều vớiA:\\ntrace(XAX−1) = trace(X−1XA) = trace(A) (1.42)\\n• ∥A∥2\\nF = trace(ATA) = trace(AAT) với A là một ma trận bất kỳ. Từ đây ta cũng suy ra\\ntrace(AAT) ≥0 với mọi ma trậnA.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 41, 'page_label': '30'}, page_content='Chương 2\\nGiải tích ma trận\\nTrong chương này, nếu không nói gì thêm, chúng ta giả sử rằng các đạo hàm tồn tại. Tài\\nliệu tham khảo chính của chương làMatrix calculus–Stanford(https://goo.gl/BjTPLr ).\\n2.1 Đạo hàm của hàm trả về một số vô hướng\\nĐạo hàm bậc nhất(first-order gradient) hay viết gọn làđạo hàm (gradient) của một hàm\\nsố f(x) : Rn →R theo x được định nghĩa là\\n∇xf(x) ≜\\n\\uf8ee\\n\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8f0\\n∂f(x)\\n∂x1\\n∂f(x)\\n∂x2\\n...\\n∂f(x)\\n∂xn\\n\\uf8f9\\n\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fb\\n∈Rn (2.1)\\ntrong đó∂f(x)\\n∂xi\\nlà đạo hàm riêng(partial derivative) của hàm số theo thành phần thứicủa\\nvector x. Đạo hàm này được lấy khi tất cả các biến, ngoàixi, được giả sử là hằng số. Nếu\\nkhông có thêm biến nào khác,∇xf(x) thường được viết gọn là∇f(x). Đạo hàm của hàm\\nsố này là một vector có cùng chiều với vector đang được lấy đạo hàm. Tức nếu\\nvector được viết ở dạng cột thì đạo hàm cũng phải được viết ở dạng cột.\\nĐạo hàm bậc hai(second-order gradient) của hàm số trên còn được gọi làHessian và được\\nđịnh nghĩa như sau, vớiSn ∈Rn×n là tập các ma trận vuông đối xứng bậcn.\\n∇2f(x) ≜\\n\\uf8ee\\n\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8f0\\n∂2f(x)\\n∂x2\\n1\\n∂2f(x)\\n∂x1∂x2\\n... ∂2f(x)\\n∂x1∂xn\\n∂2f(x)\\n∂x2∂x1\\n∂2f(x)\\n∂x2\\n2\\n... ∂2f(x)\\n∂x2∂xn\\n... ... ... ...\\n∂2f(x)\\n∂xn∂x1\\n∂2f(x)\\n∂xn∂x2\\n... ∂2f(x)\\n∂x2\\nn\\n\\uf8f9\\n\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fb\\n∈Sn (2.2)'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 42, 'page_label': '31'}, page_content='31 CHƯƠNG 2. GIẢI TÍCH MA TRẬN\\nĐạo hàm của một hàm sốf(X) : Rn×m →R theo ma trậnX được định nghĩa là\\n∇f(X) =\\n\\uf8ee\\n\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8f0\\n∂f(X)\\n∂x11\\n∂f(X)\\n∂x12\\n... ∂f(X)\\n∂x1m\\n∂f(X)\\n∂x21\\n∂f(X)\\n∂x22\\n... ∂f(X)\\n∂x2m\\n... ... ... ...\\n∂f(X)\\n∂xn1\\n∂f(X)\\n∂xn2\\n... ∂f(X)\\n∂xnm\\n\\uf8f9\\n\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fb\\n∈Rn×m (2.3)\\nChiều của đạo hàm\\nĐạo hàm của hàm sốf : Rm×n →R là một ma trận trongRm×n, ∀m,n ∈N∗.\\nCụ thể, để tính đạo hàm của một hàmf : Rm×n →R, ta tính đạo hàm riêng của hàm số đó\\ntheo từng thành phần của ma trậnkhi toàn bộ các thành phần khác được giả sử là hằng số.\\nTiếp theo, ta sắp xếp các đạo hàm riêng tính được theo đúng thứ tự trong ma trận.\\nVí dụ:Xét hàm sốf : R2 →R, f(x) = x2\\n1 + 2x1x2 + sin(x1) + 2.\\nĐạo hàm bậc nhất theox của hàm số đó là\\n∇f(x) =\\n\\uf8ee\\n\\uf8ef\\uf8ef\\uf8f0\\n∂f(x)\\n∂x1\\n∂f(x)\\n∂x2\\n\\uf8f9\\n\\uf8fa\\uf8fa\\uf8fb=\\n\\uf8ee\\n\\uf8ef\\uf8ef\\uf8f0\\n2x1 + 2x2 + cos(x1)\\n2x1\\n\\uf8f9\\n\\uf8fa\\uf8fa\\uf8fb\\nĐạo hàm bậc hai theox, hayHessian là ∇2f(x) =\\n\\uf8ee\\n\\uf8ef\\uf8ef\\uf8ef\\uf8f0\\n∂2f(x)\\n∂x2\\n1\\n∂f2(x)\\n∂x1∂x2\\n∂2f(x)\\n∂x2∂x1\\n∂f2(x)\\n∂x2\\n2\\n\\uf8f9\\n\\uf8fa\\uf8fa\\uf8fa\\uf8fb=\\n\\uf8ee\\n\\uf8ef\\uf8ef\\uf8f0\\n2 −sin(x1) 2\\n2 0\\n\\uf8f9\\n\\uf8fa\\uf8fa\\uf8fb\\nChú ý rằngHessian luôn là một ma trận đối xứng.\\n2.2 Đạo hàm của hàm trả về một vector\\nNhững hàm số trả về một vector, hoặc gọn hơnhàm trả về vectorđược gọi làvector-valued\\nfunction trong tiếng Anh.\\nXét một hàm trả về vector vớiđầu vào là một số thựcv(x) : R →Rn:\\nv(x) =\\n\\uf8ee\\n\\uf8ef\\uf8ef\\uf8ef\\uf8f0\\nv1(x)\\nv2(x)\\n...\\nvn(x)\\n\\uf8f9\\n\\uf8fa\\uf8fa\\uf8fa\\uf8fb (2.4)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 43, 'page_label': '32'}, page_content='CHƯƠNG 2. GIẢI TÍCH MA TRẬN 32\\nĐạo hàm của hàm số này theox là mộtvector hàngnhư sau:\\n∇v(x) ≜\\n[\\n∂v1(x)\\n∂x\\n∂v2(x)\\n∂x ... ∂vn(x)\\n∂x\\n]\\n(2.5)\\nĐạo hàm bậc hai của hàm số này có dạng\\n∇2v(x) ≜\\n[\\n∂2v1(x)\\n∂x2\\n∂2v2(x)\\n∂x2 ... ∂2vn(x)\\n∂x2\\n]\\n(2.6)\\nVí dụ:Cho một vectora ∈Rn và một hàm sốvector-valued v(x) = xa, đạo hàm bậc nhất\\nvà Hession của nó lần lượt là\\n∇v(x) = aT, ∇2v(x) = 0 ∈R1×n (2.7)\\nXét một hàm trả về vector vớiđầu vào là một vectorh(x) : Rk →Rn, đạo hàm bậc nhất\\ncủa nó là\\n∇h(x) ≜\\n\\uf8ee\\n\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8f0\\n∂h1(x)\\n∂x1\\n∂h2(x)\\n∂x1\\n... ∂hn(x)\\n∂x1\\n∂h1(x)\\n∂x2\\n∂h2(x)\\n∂x2\\n... ∂hn(x)\\n∂x2\\n... ... ... ...\\n∂h1(x)\\n∂xk\\n∂h2(x)\\n∂xk\\n... ∂hn(x)\\n∂xk\\n\\uf8f9\\n\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fb\\n=\\n[\\n∇h1(x) ∇h2(x) ... ∇hn(x)\\n]\\n∈Rk×n (2.8)\\nNếu một hàm sốg: Rm →Rn, thì đạo hàm của nó là một ma trận thuộcRm×n.\\nĐạo hàm bậc hai của hàm số trên là mộtmảng ba chiều, chúng ta sẽ không nhắc đến ở đây.\\nTrước khi đến phần tính đạo hàm của các hàm số thường gặp, chúng ta cần biết hai tính\\nchất quan trọng khá giống với đạo hàm của hàm một biến.\\n2.3 Tính chất quan trọng của đạo hàm\\n2.3.1 Quy tắc tích (Product rule)\\nĐể cho tổng quát, ta giả sử biến đầu vào là một ma trận. Giả sử rằng các hàm số có chiều\\nphù hợp để các phép nhân thực hiện được. Ta có:\\n∇\\n(\\nf(X)Tg(X)\\n)\\n= (∇f(X)) g(X) + (∇g(X)) f(X) (2.9)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 44, 'page_label': '33'}, page_content='33 CHƯƠNG 2. GIẢI TÍCH MA TRẬN\\nBiểu thức này giống như biểu thức chúng ta đã quen thuộc:\\n(f(x)g(x))′= f′(x)g(x) + g′(x)f(x)\\nChú ý rằng với tích của vector và ma trận, ta không được sử dụng tính chất giao hoán.\\n2.3.2 Quy tắc chuỗi (Chain rule)\\nKhi có các hàm hợp thì\\n∇Xg(f(X)) = (∇Xf)T(∇fg) (2.10)\\nQuy tắc này cũng giống với quy tắc trong hàm một biến:\\n(g(f(x)))′= f′(x)g′(f)\\nMột lưu ý nhỏ nhưng quan trọng khi làm việc với tích các ma trận là sự phù hợp về kích\\nthước của các ma trận trong tích.\\n2.4 Đạo hàm của các hàm số thường gặp\\n2.4.1 f(x) = aTx\\nGiả sửa,x ∈Rn, ta viết lại f(x) = aTx = a1x1 + a2x2 + ··· + anxn\\nCó thể nhận thấy rằng ∂f(x)\\n∂xi\\n= ai, ∀i= 1,2 ...,n .\\nVậy,∇(aTx) =\\n[\\na1 a2 ...a n\\n]T\\n= a. Ngoài ra, vìaTx = xTa nên ∇(xTa) = a.\\n2.4.2 f(x) = Ax\\nĐây là một hàm trả về vectorf : Rn →Rm với x ∈Rn,A ∈Rm×n. Giả sử rằngai là hàng\\nthứ i của ma trậnA. Ta có\\nAx =\\n\\uf8ee\\n\\uf8ef\\uf8ef\\uf8ef\\uf8f0\\na1x\\na2x\\n...\\namx\\n\\uf8f9\\n\\uf8fa\\uf8fa\\uf8fa\\uf8fb\\nTheo định nghĩa (2.8), và công thức đạo hàm củaaix, ta có thể suy ra\\n∇x(Ax) =\\n[\\naT\\n1 aT\\n2 ... aT\\nm\\n]\\n= AT (2.11)\\nTừ đây ta có thể suy ra đạo hàm của hàm sốf(x) = x = Ix, vớiI là ma trận đơn vị, là\\n∇x = I\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 45, 'page_label': '34'}, page_content='CHƯƠNG 2. GIẢI TÍCH MA TRẬN 34\\n2.4.3 f(x) = xTAx\\nvới x ∈Rn,A ∈Rn×n. Áp dụng quy tắc tích (2.9) ta có\\n∇f(x) = ∇\\n((\\nxT)\\n(Ax)\\n)\\n= (∇(x)) Ax + (∇(Ax)) x\\n= IAx + ATx\\n= (A + AT)x (2.12)\\nTừ (2.12) và (2.11), ta có thể suy ra∇2xTAx = AT + A\\nNếu A là một ma trận đối xứng, ta sẽ có∇xTAx = 2Ax, ∇2xTAx = 2A\\nNếu A là ma trận đơn vị, tứcf(x) = xTIx = xTx = ∥x∥2\\n2, ta có\\n∇∥x∥2\\n2 = 2x, ∇2∥x∥2\\n2 = 2I (2.13)\\n2.4.4 f(x) = ∥Ax −b∥2\\n2\\nCó hai cách tính đạo hàm của hàm số này:\\nCách 1:Trước hết, biến đổi\\nf(x) = ∥Ax −b∥2\\n2 = (Ax −b)T(Ax −b) = (xTAT −bT)(Ax −b)\\n= xTATAx −2bTAx + bTb\\nLấy đạo hàm cho từng số hạng rồi cộng lại ta có\\n∇∥Ax −b∥2\\n2 = 2ATAx −2ATb = 2AT(Ax −b)\\nCách 2:Sử dụng∇(Ax −b) = AT và ∇∥x∥2\\n2 = 2x và quy tắc chuỗi (2.10), ta cũng sẽ thu\\nđược kết quả tương tự.\\n2.4.5 f(x) = aTxxTb\\nBằng cách viết lạif(x) = (aTx)(xTb), ta có thể dùng Quy tắc tích (2.9) và có kết quả\\n∇(aTxxTb) = axTb + baTx = abTx + baTx = (abT + baT)x,\\nở đây ta đã sử dụng tính chấtyTz = zTy.\\n2.4.6 f(X) = trace(AX)\\nGiả sửA ∈Rn×m,X = Rm×n, vàB = AX ∈Rn×n. Theo định nghĩa của trace,\\nf(X) = trace(AX) = trace(B) =\\nn∑\\nj=1\\nbjj =\\nn∑\\nj=1\\nn∑\\ni=1\\najixji (2.14)\\nTừđâytathấyrằng ∂f(X)\\n∂xij\\n= aji.Sửdụngđịnhnghĩa(2.3)tađạtđược ∇Xtrace(AX) = AT.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 46, 'page_label': '35'}, page_content='35 CHƯƠNG 2. GIẢI TÍCH MA TRẬN\\nBảng 2.1: Bảng các đạo hàm cơ bản.\\nf(x) ∇f(x) f(X) ∇Xf(X)\\nx I trace(X) I\\naTx a trace(ATX) A\\nxTAx (A + AT)x trace(XTAX) (A + AT)X\\nxTx = ∥x∥2\\n2 2x trace(XTX) = ∥X∥2\\nF 2X\\n∥Ax −b∥2\\n2 2AT(Ax −b) ∥AX −B∥2\\nF 2AT(AX −B)\\naTxTxb 2aTbx aTXb abT\\naTxxTb (abT + baT)x trace(ATXB) ABT\\n2.4.7 f(X) = aTXb\\nGiả sử rằnga ∈Rm,X ∈Rm×n,b ∈Rn. Bạn đọc có thể chứng minh được\\nf(X) =\\nm∑\\ni=1\\nn∑\\nj=1\\nxijaibj\\nTừ đó, sử dụng định nghĩa (2.3) ta sẽ có∇X(aTXbT) =\\n\\uf8ee\\n\\uf8ef\\uf8ef\\uf8ef\\uf8f0\\na1b1 a1b2 ... a1bn\\na2b1 a2b2 ... a2bn\\n... ... ... ...\\namb1 amb2 ...a mbn\\n\\uf8f9\\n\\uf8fa\\uf8fa\\uf8fa\\uf8fb= abT.\\n2.4.8 f(X) = ∥X∥2\\nF\\nGiả sử X ∈Rn×n, bằng cách viết lại∥X∥2\\nF = ∑n\\ni=1\\n∑n\\nj=1 x2\\nij, ta có thể suy ra∂f\\n∂xij\\n= 2xij.\\nVà vì vậy,∇∥X∥2\\nF = 2X.\\n2.4.9 f(X) = trace(XTAX)\\nGiả sử rằngX =\\n[\\nx1 x2 ... xm\\n]\\n∈Rm×n,A ∈Rm×m. Bằng cách khai triển\\nXTAX =\\n\\uf8ee\\n\\uf8ef\\uf8ef\\uf8ef\\uf8f0\\nxT\\n1\\nxT\\n2\\n...\\nxT\\nn\\n\\uf8f9\\n\\uf8fa\\uf8fa\\uf8fa\\uf8fbA\\n[\\nx1 x2 ..., xn\\n]\\n=\\n\\uf8ee\\n\\uf8ef\\uf8ef\\uf8ef\\uf8f0\\nxT\\n1 Ax1 xT\\n1 Ax2 ... xT\\n1 Axn\\nxT\\n2 Ax1 xT\\n2 Ax2 ... xT\\n2 Axn\\n... ... ... ...\\nxT\\nnAx1 xT\\nnAx2 ... xT\\nnAxn\\n\\uf8f9\\n\\uf8fa\\uf8fa\\uf8fa\\uf8fb, (2.15)\\nta tính được trace(XTAX) = ∑n\\ni=1 xT\\ni Axi. Nhắc lại rằng∇xixT\\ni Axi = (A + AT)xi, ta có\\n∇Xtrace(XTAX) = (A + AT)\\n[\\nx1 x2 ... xn\\n]\\n= (A + AT)X (2.16)\\nBằng cách thayA = I, ta cũng thu được∇Xtrace(XTX) = ∇X∥X∥2\\nF = 2X.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 47, 'page_label': '36'}, page_content='CHƯƠNG 2. GIẢI TÍCH MA TRẬN 36\\n2.4.10 f(X) = ∥AX −B∥2\\nF\\nBằng kỹ thuật hoàn toàn tương tự như đã làm trong mục 2.4.4, ta thu được\\n∇X∥AX −B∥2\\nF = 2AT(AX −B)\\n2.5 Bảng các đạo hàm thường gặp\\nBảng 2.1 bao gồm đạo hàm của các hàm số thường gặp với biến là vector hoặc đạo hàm.\\n2.6 Kiểm tra đạo hàm\\nViệc tính đạo hàm của hàm nhiều biến thông thường khá phức tạp và rất dễ mắc lỗi. Trong\\nthực nghiệm, có một cách để kiểm tra liệu đạo hàm tính được có chính xác không. Cách này\\ndựa trên định nghĩa của đạo hàm cho hàm một biến.\\n2.6.1 Xấp xỉ đạo hàm của hàm một biến\\nTheo định nghĩa,\\nf′(x) = lim\\nε→0\\nf(x+ ε) −f(x)\\nε (2.17)\\nMột cách thường được sử dụng là lấy một giá trịεrất nhỏ, ví dụ10−6, và sử dụng công thức\\nf′(x) ≈f(x+ ε) −f(x−ε)\\n2ε (2.18)\\nCách tính này được gọi lànumerical gradient. Biểu thức (2.18) được sử dụng rộng rãi hơn\\nđể tínhnumerical gradient. Có hai cách giải thích cho vấn đề này.\\nBằng giải tích\\nChúng ta cùng quay lại một chút với khai triển Taylor. Vớiε rất nhỏ, ta có hai xấp xỉ sau:\\nf(x+ ε) ≈f(x) + f′(x)ε+ f”(x)\\n2 ε2 + f(3)\\n6 ε3 + ... (2.19)\\nf(x−ε) ≈f(x) −f′(x)ε+ f”(x)\\n2 ε2 −f(3)\\n6 ε3 + ... (2.20)\\nTừ đó ta có:\\nf(x+ ε) −f(x)\\nε ≈f′(x) + f”(x)\\n2 ε+ ··· = f′(x) + O(ε) (2.21)\\nf(x+ ε) −f(x−ε)\\n2ε ≈f′(x) + f(3)(x)\\n6 ε2 + ··· = f′(x) + O(ε2) (2.22)\\ntrong đóO() là Big O notation.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 48, 'page_label': '37'}, page_content='37 CHƯƠNG 2. GIẢI TÍCH MA TRẬN\\nε\\nε\\nf(x0) − f(x0 − ε)\\nf(x0 + ε) − f(x0)\\nf(x0 + ε) − f(x0 − ε)\\n2ε\\nHình 2.1: Giải thích\\ncách xấp xỉ đạo hàm\\nbằng hình học.\\nTừ đó, nếu xấp xỉ đạo hàm bằng công thức (2.21) (xấp xỉ đạo hàm phải), sai số sẽ làO(ε).\\nTrong khi đó, nếu xấp xỉ đạo hàm bằng công thức (2.22) (xấp xỉ đạo hàm hai phía), sai số\\nsẽ làO(ε2). Khiε rất nhỏ,O(ε2) ≪O(ε), tức cách đánh giá sử dụng công thức 2.22 có sai\\nsố nhỏ hơn, và vì vậy nó được sử dụng nhiều hơn.\\nChúng ta cũng có thể giải thích điều này bằng hình học.\\nBằng hình học\\nQuan sát Hình 2.1, vector màu đỏ là đạo hàmchính xác của hàm số tại điểm có hoành độ\\nbằng x0. Vector màu xanh lam và xanh lục lần lượt thể hiện cách xấp xỉ đạo hàm phía phải\\nvà phía trái. Vector màu nâu thể hiện cách xấp xỉ đạo hàm hai phía. Trong ba vector xấp\\nxỉ đó, vector xấp xỉ hai phía màu nâu là gần với vector đỏ nhất nếu xét theo hướng.\\nSự khác biệt giữa các cách xấp xỉ còn lớn hơn nữa nếu tại điểmx, hàm số bịbẻ congmạnh\\nhơn. Khi đó, xấp xỉ trái và phải sẽ khác nhau rất nhiều. Xấp xỉ hai bên sẽổn định hơn.\\nTừ đó ta thấy rằng xấp xỉ đạo hàm hai phía là xấp xỉ tốt hơn.\\n2.6.2 Xấp xỉ đạo hàm của hàm nhiều biến\\nVới hàm nhiều biến, công thức (2.22) được áp dụng cho từng biến khi các biến khác cố định.\\nCụ thể, ta sử dụng định nghĩa của hàm số nhận đầu vào là một ma trận như công thức (2.3).\\nMỗi thành phần của ma trận kết quả là đạo hàm của hàm số tại thành phần đó khi ta coi\\ncác thành phần còn lại cố định. Chúng ta sẽ thấy rõ điều này hơn ở cách lập trình so sánh\\nhai cách tính đạo hàm ngay phía dưới.\\nCách tính xấp xỉ đạo hàm theo phương phápnumerical thường cho giá trị khá chính xác.\\nTuy nhiên, cách này không được sử dụng để tính đạo hàm vì độ phức tạp quá cao so với\\ncách tính trực tiếp. Tại mỗi thành phần, ta cần tính giá trị của hàm số tại phía trái và phía\\nphải, như vậy sẽ không khả thi với các ma trận lớn. Khi so sánh đạo hàmnumerical này\\nvới đạo hàm tính theo công thức, người ta thường giảm số chiều dữ liệu và giảm số điểm dữ\\nliệu để thuận tiện cho tính toán. Nếu công thức đạo hàm ta tính được là chính xác, nó sẽ\\nrất gần với đạo hàmnumerical.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 49, 'page_label': '38'}, page_content='CHƯƠNG 2. GIẢI TÍCH MA TRẬN 38\\nĐoạn Code 2.1 giúp kiểm tra đạo hàm của một hàm số khả vif : Rm×n →R, có kèm theo\\nhai ví dụ. Để sử dụng hàm kiểm tracheck_grad này, ta cần viết hai hàm. Hàm thứ nhất là\\nhàm fn(X) tính giá trị của hàm số tạiX. Hàm thứ hai là hàmgr(X) tính giá trị của đạo hàm\\nmà ta cần kiểm tra.\\nfrom __future__ import print_function\\nimport numpy as np\\ndef check_grad(fn, gr, X):\\nX_flat = X.reshape(-1) # convert X to an 1d array -> 1 for loop needed\\nshape_X = X.shape # original shape of X\\nnum_grad = np.zeros_like(X) # numerical grad, shape = shape of X\\ngrad_flat = np.zeros_like(X_flat) # 1d version of grad\\neps = 1e-6 # a small number, 1e-10 -> 1e-6 is usually good\\nnumElems = X_flat.shape[0] # number of elements in X\\n# calculate numerical gradient\\nfor i in range(numElems): # iterate over all elements of X\\nXp_flat = X_flat.copy()\\nXn_flat = X_flat.copy()\\nXp_flat[i] += eps\\nXn_flat[i] -= eps\\nXp = Xp_flat.reshape(shape_X)\\nXn = Xn_flat.reshape(shape_X)\\ngrad_flat[i] = (fn(Xp) - fn(Xn))/(2*eps)\\nnum_grad = grad_flat.reshape(shape_X)\\ndiff = np.linalg.norm(num_grad - gr(X))\\nprint(’Difference between two methods should be small:’, diff)\\n# ==== check if grad(trace(A*X)) == A^T ====\\nm, n = 10, 20\\nA = np.random.rand(m, n)\\nX = np.random.rand(n, m)\\ndef fn1(X):\\nreturn np.trace(A.dot(X))\\ndef gr1(X):\\nreturn A.T\\ncheck_grad(fn1, gr1, X)\\n# ==== check if grad(x^T*A*x) == (A + A^T)*x ====\\nA = np.random.rand(m, m)\\nx = np.random.rand(m, 1)\\ndef fn2(x):\\nreturn x.T.dot(A).dot(x)\\ndef gr2(x):\\nreturn (A + A.T).dot(x)\\ncheck_grad(fn2, gr2, x)\\nCode 2.1: Kiểm tra đạo hàm bằng phương pháp numerical.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 50, 'page_label': '39'}, page_content='39 CHƯƠNG 2. GIẢI TÍCH MA TRẬN\\nKết quả:\\nDifference between two methods should be small: 2.02303323394e-08\\nDifference between two methods should be small: 2.10853872281e-09\\nKết quả cho thấy sự khác nhau giữa Frobenious norm (mặc định củanp.linalg.norm) của\\nkết quả của hai cách tính là rất nhỏ. Sau khi chạy lại đoạn code với các giá trịm, n khác\\nnhau và biếnX khác nhau, nếu sự khác nhau vẫn là nhỏ, ta có thể tự tin rằng đạo hàm mà\\nta tính được là chính xác.\\nBạn đọc có thể tự kiểm tra lại các công thức trong Bảng 2.1 theo phương pháp này.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 51, 'page_label': '40'}, page_content='Chương 3\\nÔn tập Xác Suất\\nChương này được viết dựa trên Chương 2 và 3 của cuốn Computer Vision: Models, Learning,\\nand Inference–Simon J.D. Prince (http://www.computervisionmodels.com).\\n3.1 Xác Suất\\n3.1.1 Random variables\\nMột biến ngẫu nhiên (random variable) x là một đại lượng dùng để đo những đại lượng\\nkhông xác định. Biến này có thể được dùng để ký hiệu kết quả/đầu ra (outcome) của một\\nthí nghiệm, ví dụ như tung đồng xu, hoặc một đại lượng biến đổi trong tự nhiên, ví dụ như\\nnhiệt độ trong ngày. Nếu chúng ta quan sát rất nhiều đầu ra{xi}I\\ni=1 của các thí nghiệm này,\\nta có thể nhận được những giá trị khác nhau ở mỗi thí nghiệm. Tuy nhiên, sẽ có những giá\\ntrị xảy ra nhiều lần hơn những giá trị khác, hoặc xảy ra gần một giá trị này hơn những giá trị\\nkhác. Thông tin về đầu ra này được đo bởi mộtphân phối xác suất(probaility distribution)\\nđược biểu diễn bằng một hàmp(x). Một biến ngẫu nhiên có thể làrời rạc(discrete) hoặc\\nliên tục(continuous).\\nMột biến ngẫu nhiên rời rạc sẽ lấy giá trị trong một tập hợp các điểm rời rạc cho trước. Ví\\ndụ tung đồng xu thì có hai khả năng làhead và tail1.Tập các giá trị này có thể làcó thứ tự\\nnhư khi tung xúc xắc hoặckhông có thứ tự, ví dụ khi đầu ra là các giá trịnắng, mưa, bão.\\nMỗi đầu ra có một giá trị xác suất tương ứng với nó. Các giá trị xác suất này không âm và\\ncó tổng bằng một.\\nNếu x là biến ngẫu nhiên rời rạc thì\\n∑\\nx\\np(x) = 1 (3.1)\\nBiến ngẫu nhiên liên tục lấy các giá trị là các số thực. Những giá trị này có thể là hữu hạn,\\nví dụ thời gian làm bài của mỗi thí sinh trong một bài thi 180 phút, hoặc vô hạn, ví dụ thời\\n1 đồng xu thường có một mặt có hình đầu người, được gọi làhead, trái ngược với mặt này được gọi là mặttail'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 52, 'page_label': '41'}, page_content='41 CHƯƠNG 3. ÔN TẬP XÁC SUẤT\\ngian phải chờ tới khách hàng tiếp theo. Không như biến ngẫu nhiên rời rạc, xác suất để đầu\\nra bằngchính xácmột giá trị nào đó, theo lý thuyết, là bằng không. Thay vào đó, xác suất\\nđể đầu ra rời vào một khoảng giá trị nào đó là khác không. Việc này được mô tả bởihàm\\nmật độ xác suất(probability density function - pdf). Hàm mật độ xác suất luôn cho giá trị\\ndương, và tích phân của nó trên toàn miền giá trị đầu rapossible outcomephải bằng một.\\nNếu x là biến ngẫu nhiên liên tục thì\\n∫\\np(x)dx= 1 (3.2)\\nNếu x là biến ngẫu nhiên rời rạc, thìp(x) ≤1, ∀x. Trong khi đó, nếux là biến ngẫu\\nnhiên liên tục,p(x) có thể nhận giá trị không âm bất kỳ, điều này vẫn đảm bảo là tích\\nphân của hàm mật độ xác suất theo toàn bộ giá trị có thể có củax bằng một.\\n3.1.2 Xác suất đồng thời\\nXét hai biến ngẫu nhiênx và y. Nếu ta quan sát rất nhiều cặp đầu ra củax và y, thì có\\nnhững tổ hợp hai đầu ra xảy ra thường xuyên hơn những tổ hợp khác. Thông tin này được\\nbiểu diễn bằng một phân phối được gọi làxác suất đồng thời(joint probability) củax và y,\\nđược ký hiệu làp(x,y), đọc là xác suất củax và y. Hai biến ngẫu nhiênx và y có thể đồng\\nthời là biến ngẫu nhiên rời rạc, liên tục, hoặc một rời rạc, một liên tục. Luôn nhớ rằng tổng\\ncác xác suất trên mọi cặp giá trị có thể xảy ra(x,y) bằng một.\\nCả x và y là rời rạc:\\n∑\\nx,y\\np(x,y) = 1 (3.3)\\nCả x và y là liên tục:\\n∫\\np(x,y)dxdy= 1 (3.4)\\nx rời rạc, yliên tục:\\n∑\\nx\\n∫\\np(x,y)dy=\\n∫ (∑\\nx\\np(x,y)\\n)\\ndy= 1 (3.5)\\nXét ví dụ trong Hình 3.1, phần có nền màu lục nhạt. Biến ngẫu nhiênx thể hiện điểm thi\\nmôn Toán của học sinh ở một trường THPT trong một kỳ thi Quốc gia, biến ngẫu nhiêny\\nthể hiện điểm thi môn Vật Lý cũng trong kỳ thi đó. Đại lượngp(x= x∗,y = y∗) là tỉ lệ giữa\\ntần suất số học sinh đượcđồng thời x∗ điểm trong môn Toán vày∗ điểm trong môn Vật Lý\\nvà toàn bộ số học sinh của trường đó. Tỉ lệ này có thể coi là xác suất khi số học sinh trong\\ntrường là lớn. Ở đâyx∗ và y∗ là các số xác định. Thông thường, xác suất này được viết gọn\\nlại thànhp(x∗,y∗), vàp(x,y) được dùng như một hàm tổng quát để mô tả các xác suất. Giả\\nsử thêm rằng điểm các môn là các số tự nhiên từ 1 đến 10.\\nCác ô vuông màu lam thể hiện xác suấtp(x,y), với diện tích ô vuông càng to thể hiện xác\\nsuất đó càng lớn. Chú ý rằng tổng các xác suất này bằng một.\\nCác bạn có thể thấy rằng xác suất để một học sinh được 10 điểm một Toán và 1 điểm môn\\nLý rất thấp, điều tương tự xảy ra với 10 điểm môn Lý và 1 điểm môn Toán. Ngược lại, xác\\nsuất để một học sinh được khoảng 7 điểm cả hai môn là cao nhất.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 53, 'page_label': '42'}, page_content='CHƯƠNG 3. ÔN TẬP XÁC SUẤT 42\\nJoint probability\\nConditional\\nProbabilities\\nMarginalization\\n1\\n1\\n2\\n2\\n3\\n3\\n4\\n4\\n5\\n5\\n6\\n6\\n7\\n7\\n8\\n8\\n9\\n9\\n10\\n10\\nx : Math score\\n( x, y )\\ny : Physics score\\n1 2 3 4 5 6 7 8 9 10\\n( x | y = 9)\\n1 2 3 4 5 6 7 8 9 10\\n( x | y = 3)\\n1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n9\\n10\\n(y|x= 10)\\n1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n9\\n10\\n(y|x= 2)\\n1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n9\\n10\\n(y) =\\n∑\\nx\\n(x, y)\\n1 2 3 4 5 6 7 8 9 10\\n( x ) =\\n∑\\ny\\n( x, y )\\nHình 3.1: Xác suất đồng thời (phần trung tâm có nền màu lục nhạt), Xác suất biên (phía trên\\nvà bên trái) và Xác suất có điền kiện (phía dưới và bên phải).\\nThông thường, chúng ta sẽ làm việc với các bài toán ở đó xác suất có điều kiện được xác\\nđịnh trên nhiều hơn hai biến ngẫu nhiên. Chẳng hạn,p(x,y,z ) thể hiện joint probability của\\nba biến ngẫu nhiênx,y và z. Khi có nhiều biến ngẫu nhiên, ta có thể viết chúng dưới dạng\\nvector. Cụ thể, ta có thể viếtp(x) để thể hiện xác suất có điều kiện của biến ngẫu nhiên\\nnhiều chiềux = [x1,x2,...,x n]T. Khi có nhiều tập các biến ngẫu nhiên, ví dụx và y, ta có\\nthể biếtp(x,y) để thể hiện xác suất có điều kiện của tất cả các thành phần trong hai biến\\nngẫu nhiên nhiều chiều này.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 54, 'page_label': '43'}, page_content='43 CHƯƠNG 3. ÔN TẬP XÁC SUẤT\\n3.1.3 Xác suất biên\\nNếu biết xác suất đồng thời của nhiều biến ngẫu nhiên, ta cũng có thể xác định được phân\\nphối xác suất của từng biến bằng cách lấy tổng với biến ngẫu nhiên rời rạc hoặc tích phân\\nvới biến ngẫu nhiên liên tục theo tất cả các biến còn lại:\\nNếu x,y rời rạc: p(x) =\\n∑\\ny\\np(x,y) (3.6)\\np(y) =\\n∑\\nx\\np(x,y) (3.7)\\nNếu x,y liên tục: p(x) =\\n∫\\np(x,y)dy (3.8)\\np(y) =\\n∫\\np(x,y)dx (3.9)\\nVới nhiều biến hơn, chẳng hạn bốn biến rời rạcx,y,z,w , cách tính được thực hiện tương tự:\\np(x) =\\n∑\\ny,z,w\\np(x,y,z,w ) (3.10)\\np(x,y) =\\n∑\\nz,w\\np(x,y,z,w ) (3.11)\\nCách xác định xác suất của một biến dựa trên xác suất đồng thời của nó với các biến khác\\nđược gọi làmarginalization. Phân phối đó được gọi làxác suất biên(marginal probability).\\nTừ đây trở đi, nếu không đề cập gì thêm, chúng ta sẽ dùng ký hiệu∑ để chỉ chung cho\\ncả hai loại biến. Nếu biến ngẫu nhiên là liên tục, bạn đọc ngầm hiểu rằng dấu∑cần được\\nthay bằng dấu tích phân\\n∫\\n, biến lấy vi phân chính là biến được viết dưới dấu∑. Chẳng\\nhạn, trong (3.11), nếuz là liên tục,w là rời rạc, công thức đúng sẽ là\\np(x,y) =\\n∑\\nw\\n(∫\\np(x,y,z,w )dz\\n)\\n=\\n∫ (∑\\nw\\np(x,y,z,w )\\n)\\ndz (3.12)\\nQuay lại ví dụ trong Hình 3.1 với hai biến ngẫu nhiên rời rạcx,y. Lúc này,p(x) được hiểu\\nlà xác suất để một học sinh đạt đượcx điểm môn Toán. Xác suất này được thể hiện ở khu\\nvực có nền màu tím nhạt, phía trên. Nhắc lại rằng xác suất ở đây thực ra là tỉ lệ giữa số\\nhọc sinh đạtxđiểm môn Toán và toàn bộ số học sinh. Có hai cách tính xác suất này. Cách\\nthứ nhất, dựa trên cách vừa định nghĩa, là đếm số học sinh đượcx điểm môn toán rồi chia\\ncho tổng số học sinh. Cách tính thứ hai dựa trên xác suất đồng thời đã biết về xác suất để\\nmột học sinh đượcxđiểm môn Toán vày điểm môn Lý. Số lượng học sinh đạtx= x∗ điểm\\nmôn Toán sẽ bằng tổng số lượng học sinh đạtx = x∗ điểm môn Toánvà y điểm môn Lý,\\nvới y là một giá trị bất kỳ từ 1 đến 10. vì vậy, để tính xác suấtp(x), ta chỉ cần tính tổng\\ncủa toàn bộp(x,y) với y chạy từ 1 đến 10. Tương tự nếu ta muốn tínhp(y) (xem phần bên\\ntrái của khu vực nền tím nhạt).\\nDựa trên nhận xét này, mỗi giá trị củap(x) chính bằng tổng các giá trị trong cột thứxcủa\\nhình vuông trung tâm nền xanh lục. Mỗi giá trị củap(y) sẽ bằng tổng các giá trị trong hàng\\nthứ y tính từ đưới lên. Chú ý rằng tổng các xác suất luôn bằng một.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 55, 'page_label': '44'}, page_content='CHƯƠNG 3. ÔN TẬP XÁC SUẤT 44\\n3.1.4 Xác suất có điều kiện.\\nDựa vào phân phối điểm của các học sinh, liệu ta có thể tính được xác suất để một học sinh\\nđược điểm 10 môn Lý, biết rằng học sinh đó được điểm 1 môn Toán?\\nXác suất để một biến ngẫu nhiênx nhận một giá trị nào đó biết rằng biến ngẫu nhiên\\ny có giá trịy∗ được gọi làxác suất có điều kiện(conditional probability), được ký hiệu là\\np(x|y= y∗).\\nXác suất có điều kiệnp(x|y= y∗) có thể được tính dựa trên xác suất đồng thờip(x,y). Quay\\nlại Hình 3.1 với vùng có nền màu nâu nhạt. Nếu biết rằngy= 9, xác suấtp(x|y= 9) có thể\\ntính được dựa trên hàng thứ chín của hình vuông trung tâm, tức hàngp(x,y = 9). Trong\\nhàng này, những ô vuông lớn hơn thể hiện xác suất lớn hơn. Tương ứng như thế,p(x|y= 9)\\ncũng lớn nếup(x,y = 9) lớn. Chú ý rằng tổng các xác suất∑\\nxp(x,y = 9) nhỏ hơn một, và\\nbằng tổng các xác suất trên hàng thứ chín này. Để thoả mãn điều kiện tổng các xác suất\\nbằng một, ta cần chia mỗi đại lượngp(x,y = 9) cho tổng của toàn hàng này. Tức là\\np(x|y= 9) = p(x,y = 9)∑\\nx\\np(x,y = 9) = p(x,y = 9)\\np(y= 9) (3.13)\\nTổng quát,\\np(x|y= y∗) = p(x,y = y∗)∑\\nx\\np(x,y = y∗) = p(x,y = y∗)\\np(y= y∗) (3.14)\\nở đây ta đã sử dụng công thức tính xác suất biên trong (3.7) cho mẫu số. Thông thường, ta\\ncó thể viết xác suất có điều kiện mà không cần chỉ rõ giá trịy= y∗và có công thức gọn hơn:\\np(x|y) = p(x,y)\\np(y) , và tương tự, p(y|x) = p(y,x)\\np(x) (3.15)\\nTừ đó ta có quan hệ\\np(x,y) = p(x|y)p(y) = p(y|x)p(x) (3.16)\\nKhi có nhiều hơn hai biến ngẫu nhiên, ta có các công thức\\np(x,y,z,w ) = p(x,y,z |w)p(w) (3.17)\\n= p(x,y|z,w)p(z,w) = p(x,y|z,w)p(z|w)p(w) (3.18)\\n= p(x|y,z,w )p(y|z,w)p(z|w)p(w) (3.19)\\nCông thức (3.19) có dạngchuỗi (chain) và được sử dụng nhiều sau này.\\n3.1.5 Quy tắc Bayes\\nCông thức (3.16) biểu diễn xác suất đồng thời theo hai cách. Từ đó ta có thể suy ra:\\np(y|x)p(x) = p(x|y)p(y) (3.20)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 56, 'page_label': '45'}, page_content='45 CHƯƠNG 3. ÔN TẬP XÁC SUẤT\\nBiến đối một chút:\\np(y|x) = p(x|y)p(y)\\np(x) (3.21)\\n= p(x|y)p(y)∑\\ny\\np(x,y) (3.22)\\n= p(x|y)p(y)∑\\ny\\np(x|y)p(y) (3.23)\\nở đó dòng thứ hai và thứ ba các công thức về xác suất biên và xác suất đồng thời ở mẫu số\\nđã được sử dụng. Từ (3.23) ta có thể thấy rằngp(y|x) hoàn toàn có thể tính được nếu ta\\nbiết mọip(x|y) và p(y). Tuy nhiên, việc tính trực tiếp xác suất này thường là phức tạp.\\nBa công thức(3.21)-(3.23) thường được gọi làQuy tắc Bayes(Bayes’ rule). Chúng\\nđược sử dụng rộng rãi trong Machine Learning\\n3.1.6 Biến ngẫu nhiên độc lập\\nNếu biết giá trị của một biến ngẫu nhiênx không mang lại thông tin về việc suy ra giá\\ntrị của biến ngẫu nhiêny (và ngược lại), thì ta nói rằng hai biến ngẫu nhiên làđộc lập\\n(independent). Chẳng hạn, chiều cao của một học sinh và điểm thi môn Toán của học sinh\\nđó có thể coi là hai biến ngẫu nhiênđộc lập.\\nKhi hai biến ngẫu nhiênx và y là độc lập, ta sẽ có:\\np(x|y) = p(x) (3.24)\\np(y|x) = p(y) (3.25)\\nThay vào biểu thức xác suất đồng thời trong (3.16), ta có:\\np(x,y) = p(x|y)p(y) = p(x)p(y) (3.26)\\n3.1.7 Kỳ vọng và ma trận hiệp phương sai\\nKỳ vọng (expectation) của một biến ngẫu nhiên được định nghĩa là\\nE[x] =\\n∑\\nx\\nxp(x) nếu x là rời rạc (3.27)\\nE[x] =\\n∫\\nxp(x)dx nếu x là liên tục (3.28)\\nGiả sửf(.) là một hàm số trả về một số với mỗi giá trịx∗ của biến ngẫu nhiênx. Khi đó,\\nnếu x là biến ngẫu nhiên rời rạc, ta sẽ có\\nE[f(x)] =\\n∑\\nx\\nf(x)p(x) (3.29)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 57, 'page_label': '46'}, page_content='CHƯƠNG 3. ÔN TẬP XÁC SUẤT 46\\nCông thức cho biến ngẫu nhiên liên tục cũng được viết tương tự.\\nVới xác suất đồng thời\\nE[f(x,y)] =\\n∑\\nx,y\\nf(x,y)p(x,y)dxdy (3.30)\\nCó ba tính chất cần nhớ về kỳ vọng:\\n1. Kỳ vọng của một hằng số theo một biến ngẫu nhiênx bất kỳ bằng chính hằng số đó:\\nE[α] = α (3.31)\\n2. Kỳ vọng có tính chất tuyến tính:\\nE[αx] = αE[x] (3.32)\\nE[f(x) + g(x)] = E[f(x)] + E[g(x)] (3.33)\\n3. Kỳ vọng của tích hai biến ngẫu nhiên bằng tích kỳ vọng của hai biến đónếu hai biến\\nngẫu nhiên đó là độc lập.\\nE[f(x)g(y)] = E[f(x)]E[g(y)] (3.34)\\nKhái niệm kỳ vọng thường đi kèm với khái niệmphương sai(variance) trong không gian một\\nchiều, vàma trận hiệp phương sai(covariance matrix) trong không gian nhiều chiều.\\nVới dữ liệu một chiều\\nCho N giá trịx1,x2,...,x N. Kỳ vọngvàphương saicủa bộ dữ liệu này được tính theo công\\nthức:\\n¯x= 1\\nN\\nN∑\\nn=1\\nxn = 1\\nNx1 (3.35)\\nσ2 = 1\\nN\\nN∑\\nn=1\\n(xn −¯x)2 (3.36)\\nvới x =\\n[\\nx1,x2,...,x N\\n]\\n, và1 ∈RN là vector cột chứa toàn phần tử 1. Kỳ vọng đơn giản\\nlà trung bình cộng của toàn bộ các giá trị. Phương sai là trung bình cộng của bình phương\\nkhoảng cách từ mỗi điểm tới kỳ vọng. Phương sai càng nhỏ thì các điểm dữ liệu càng gần\\nvới kỳ vọng, tức các điểm dữ liệu càng giống nhau. Phương sai càng lớn thì ta nói dữ liệu\\ncàng có tính phân tán. Ví dụ về kỳ vọng và phương sai của dữ liệu một chiều có thể được\\nthấy trong Hình 3.2a. Căn bậc hai của phương sai,σcòn được gọi làđộ lệch chuẩn(standard\\ndeviation) của dữ liệu.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 58, 'page_label': '47'}, page_content='47 CHƯƠNG 3. ÔN TẬP XÁC SUẤT\\nVới dữ liệu nhiều chiều\\nCho N điểm dữ liệu được biểu diễn bởi các vector cộtx1,..., xN, khi đó,vector kỳ vọngvà\\nma trận hiệp phương saicủa toàn bộ dữ liệu được định nghĩa là:\\n¯x = 1\\nN\\nN∑\\nn=1\\nxn (3.37)\\nS = 1\\nN\\nN∑\\nn=1\\n(xn −¯x)(xn −¯x)T = 1\\nN\\nˆX ˆXT (3.38)\\nTrong đó ˆX được tạo bằng cách trừ mỗi cột củaX đi ¯x:\\nˆxn = xn −¯x (3.39)\\nMột vài tính chất của ma trận hiệp phương sai:\\n• Ma trận hiệp phương sai là một ma trận đối xứng, hơn nữa, nó là một ma trận nửa xác\\nđịnh dương.\\n• Mọi phần tử trên đường chéo của ma trận hiệp phương sai là các số không âm. Chúng\\ncũng chính là phương sai của từng chiều của dữ liệu.\\n• Các phần tử ngoài đường chéosij,i ̸= j thể hiện sự tương quan giữa thành phần thứi\\nvà thứj của dữ liệu, còn được gọi là hiệp phương sai. Giá trị này có thể dương, âm hoặc\\nbằng không. Khi nó bằng không, ta nói rằng hai thành phầni,j trong dữ liệu làkhông\\ntương quan (uncorrelated).\\n• Nếu ma trận hiệp phương sai là ma trận đường chéo, ta có dữ liệu hoàn toàn không tương\\nquan giữa các chiều.\\nVí dụ về dữ liệu không tương quan và tương quan được cho trong Hình 3.2b và 3.2c.\\n3.2 Một vài phân phối thường gặp\\n3.2.1 Phân phối Bernoulli\\nPhân phối Bernoulli là một phân phối rời rạc mô tả các biến ngẫu nhiên nhị phân: trường\\nhợp đầu ra chỉ nhận một trong hai giá trịx∈{0,1}. Hai giá trị này có thể làhead và tail\\nkhi tung đồng xu; có thể làgiao dịch lừa đảovà giao dịch thông thườngtrong bài toán xác\\nđịnh giao dịch lừa đảo trong tín dụng; có thể làngười và không phải ngườitrong bài toán\\ntìm xem trong một bức ảnh có người hay không.\\nBernoulli distribution được mô tả bằng một tham sốλ∈[0,1] và là xác suất để biến ngẫu\\nnhiên x= 1. Xác suất của mỗi đầu ra sẽ là\\np(x= 1) = λ, p (x= 0) = 1 −p(x= 1) = 1 −λ (3.40)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 59, 'page_label': '48'}, page_content='CHƯƠNG 3. ÔN TẬP XÁC SUẤT 48\\nx\\nσ ¯x\\n(a)\\nσ1\\nσ2 e1\\ne2 (b)\\ne1\\ne2\\nσ1\\nσ2\\n(c)\\nHình 3.2: Ví dụ về kỳ vọng và phương sai. (a) Trong không gian một chiều. (b) Trong không\\ngian hai chiều mà hai chiều không tương quan. Trong trường hợp này, ma trận hiệp phương sai\\nlà ma trận đường chéo với hai phần tử trên đường chéo làσ1,σ2, đây cũng chính là hai trị riêng\\ncủa ma trận hiệp phương sai và là phương sai của mỗi chiều dữ liệu. (c) Dữ liệu trong không gian\\nhai chiều có tương quan. Theo mỗi chiều, ta có thể tính được kỳ vọng và phương sai. Phương\\nsai càng lớn thì dữ liệu trong chiều đó càng phân tán. Trong ví dụ này, dữ liệu theo chiều thứ hai\\nphân tán nhiều hơn so so với chiều thứ nhất.\\nHai đẳng thức này thường được viết gọn lại:\\np(x) =λx(1−λ)1−x (3.41)\\nvới giả định rằng00 = 1. Thật vậy,p(0) =λ0(1−λ)1 = 1 −λ, vàp(1) =λ1(1−λ)0 = λ.\\nPhân phối Bernoulli thường được ký hiệu ngắn gọn dưới dạng\\np(x) =Bernx[λ] (3.42)\\n3.2.2 Phân phối Categorical\\nTrong nhiều trường hợp, đầu ra của biến ngẫu nhiên rời rạc có thể là một trong nhiều hơn\\nhai giá trị khác nhau. Ví dụ, một bức ảnh có thể chứa một chiếc xe, một người, hoặc một\\ncon mèo. Khi đó, ta dùng một phân phối tổng quát của phân phối Bernoulli, được gọi là\\nphân phối Categorical. Các đầu ra được mô tả bởi một phần tử trong tập hợp{1,2,...,K }.\\nNếu cóK đầu ra, phân phối Categorical sẽ được mô tả bởiK tham số, viết dưới dạng vector:\\nλ = [λ1,λ2,...,λ K]với cácλk không âm và có tổng bằng một. Mỗi giá trịλk thể hiện xác\\nsuất để đầu ra nhận giá trịk: p(x= k) =λk.\\nPhân phối Categorical thường được ký hiệu dưới dạng:\\np(x) =Catx[λ] (3.43)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 60, 'page_label': '49'}, page_content='49 CHƯƠNG 3. ÔN TẬP XÁC SUẤT\\n−7.5 −5.0 −2.5 0.0 2.5 5.0 7.5\\nx\\n0.0\\n0.1\\n0.2\\n0.3\\n0.4\\n0.5\\np(x) µ = 0, σ2 = 1\\nµ = .5, σ2 = .5\\nµ = −1, σ2 = 2\\n(a)\\n(b)\\nHình 3.3:Ví dụ về hàm mật độ xác suất của (a) phân phối chuẩn một chiều, và (b) phân phối\\nchuẩn hai chiều.\\nNếu thay vì biểu diễn đầu ra là một sốk trong tập hợp{1,2,...,K }, ta biểu diễn đầu ra là\\nmột vector ở dạngone-hot, tức một vectorK phần tử với chỉ phần tử thứk bằng một, các\\nphần tử còn lại bằng không. Nói cách khác, tập hợp các đầu ra là tập hợp các vector đơn vị\\nbậc K: x ∈{e1,e2,..., eK}với ek là vector đơn vị thứk. Khi đó, ta sẽ có\\np(x = ek) =\\nK∏\\nj=1\\nλ\\nxj\\nj = λk (3.44)\\nKhi x = ek,xk = 1,xj = 0, ∀j ̸= k. Thay vào (3.44) ta sẽ đượcp(x = ek) = λk = p(x= k).\\n3.2.3 Phân phối chuẩn một chiều\\nPhân phối chuẩn một chiều(univariate normalhoặc Gaussian distribution) được định nghĩa\\ntrên các biến liên tục nhận giá trịx∈(−∞,∞). Đây là một phân phối được sử dụng nhiều\\nnhất với các biến ngẫu nhiên liên tục. Phân phối này được mô tả bởi hai tham số:kỳ vọng\\nµvà phương sai(variance) σ2. Giá trịµcó thể là bất kỳ số thực nào, thể hiện vị trí của giá\\ntrị mà tại đó mà hàm mật độ xác suất đạt giá trị cao nhất. Giá trịσ2 là một giá trị dương,\\nvới σ thể hiệnđộ rộng của phân phối này.σ lớn chứng tỏ khoảng giá trị đầu ra có khoảng\\nbiến đổi mạnh, và ngược lại.\\nHàm mật độ xác suất của phân phối này được định nghĩa là\\np(x) = 1√\\n2πσ2\\nexp\\n(\\n−(x−µ)2\\n2σ2\\n)\\n(3.45)\\nHoặc được viết gọn hơn dưới dạngp(x) = Normx[µ,σ2], hoặcN(µ,σ2).\\nVí dụ về đồ thị hàm mật độ xác suất của phân phối chuẩn một chiều được cho trên Hình 3.3a.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 61, 'page_label': '50'}, page_content='CHƯƠNG 3. ÔN TẬP XÁC SUẤT 50\\n3.2.4 Phân phối chuẩn nhiều chiều\\nPhân phối này là trường hợp tổng quát của phân phối chuẩn khi biến ngẫu nhiên là nhiều\\nchiều, giả sử làD chiều. Có hai tham số mô tả phân phối này:vector kỳ vọngµ∈RD và\\nma trận hiệp phương saiΣ ∈SD là một ma trậnđối xứng xác định dương.\\nHàm mật độ xác suất có dạng\\np(x) = 1\\n(2π)D/2|Σ|1/2 exp\\n(1\\n2(x −µ)TΣ−1(x −µ)\\n)\\n(3.46)\\nvới |Σ|là định thức của ma trận hiệp phương saiΣ.\\nPhân phối này thường được viết gọn lại dưới dạngp(x) = Normx[µ,Σ], hoặcN(µ,Σ).\\nVí dụ về hàm mật độ xác suất của một phân phối chuẩn hai chiều (bivariate normal distri-\\nbution) được mô tả bởi một mặt cong cho trên Hình 3.3b. Nếu cắt mặt này theo các mặt\\nphẳng song song với mặt đáy, ta sẽ thu được các hình ellipse đồng tâm.\\n3.2.5 Phân phối Beta\\nPhân phối Beta (Beta distribution) là một phân phối liên tục được định nghĩa trên một biến\\nngẫu nhiên λ ∈[0,1] Phân phối Beta distribution được dùng để mô tảtham số cho một\\ndistribution khác. Cụ thể, phân phối này phù hợp với việc mô tả sựbiến động của tham số\\nλ trong phân phối Bernoulli.\\nPhân phối Beta được mô tả bởi hai tham sốdương α,β. Hàm mật độ xác suất của nó là\\np(λ) = Γ(α+ β)\\nΓ(α)Γ(β)λα−1(1 −λ)β−1 (3.47)\\nvới Γ(.) là hàm số gamma, được định nghĩa là\\nΓ(z) =\\n∫ ∞\\n0\\ntz−1 exp(−t)dt (3.48)\\nTrên thực tế, việc tính giá trị của hàm số gamma không thực sự quan trọng vì nó chỉ mang\\ntính chuẩn hoá để tổng xác suất bằng một.\\nDạng gọn của phân phối Beta:p(λ) = Betaλ[α,β]\\nHình 3.4 minh hoạ các hàm mật độ xác suất của phân phối Beta với các cặp giá trị(α,β)\\nkhác nhau.\\n• Trong Hình 3.4a, khiα = β. Đồ thị của các hàm mật độ xác suất đối xứng qua đường\\nthẳng λ= 0.5. Khiα= β = 1, thay vào (3.47) ta thấyp(λ) = 1 với mọiλ. Trong trường\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 62, 'page_label': '51'}, page_content='51 CHƯƠNG 3. ÔN TẬP XÁC SUẤT\\n(a)\\n (b)\\n (c)\\nHình 3.4: Ví dụ về hàm mật độ xác suất của phân phối Beta. (a)α= β, đồ thị hàm số là đối\\nxứng. (b)α<β , đồ thị hàm số lệch sang trái, chứng tỏ xác suấtλnhỏ là lớn. (c)α>β , đồ thị\\nhàm số lệch sang phải, chứng tỏ xác suấtλ lớn là lớn.\\nhợp này, phân phối Beta trở thànhphân phối đều(uniform distribution). Khiα= β >1,\\ncác hàm số đạt giá trị cao tại gần trung tâm, tức là khả năng cao làλ sẽ nhận giá trị\\nxung quanh điểm 0.5. Khiα= β <1, hàm số đạt giá trị cao tại các điểm gần 0 và 1.\\n• Trong Hình 3.4b, khiα<β , ta thấy rằng đồ thị có xu hướng lệch sang bên trái. Các giá\\ntrị (α,β) này nên được sử dụng nếu ta dự đoán rằngλ là một số nhỏ hơn0.5.\\n• Trong Hình 3.4c, khiα >β, điều ngược lại xảy ra với các hàm sồ đạt giá trị cao tại các\\nđiểm gần 1.\\n3.2.6 Phân phối Dirichlet\\nPhân phối Dirichlet chính là trưởng hợp tổng quát của phân phối Beta khi được dùng để mô\\ntả tham số của phân phối Categorical. Nhắc lại rằng phân phối Categorical là trường hợp\\ntổng quát của phân phối Bernoulli.\\nPhân phối Dirichlet được định nghĩa trênK biến liên tụcλ1,...,λ K trong đó cácλk không\\nâm và có tổng bằng một. Bởi vậy, nó phù hợp để mô tả tham số của phân phối Categorical.\\nCó K tham sốdương để mô tả một phân phối Dirichlet:α1,...,α K.\\nHàm mật độ xác suất của phân phối Dirichlet là\\np(λ1,...,λ K) = Γ(∑K\\nk=1 αk)∏K\\nk=1 Γ(αk)\\nK∏\\nk=1\\nλαk−1\\nk (3.49)\\nCách biểu diễn ngắn gọn:p(λ1,...,λ K) = Dirλ1,...,λK [α1,...,α K]\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 63, 'page_label': '52'}, page_content='Chương 4\\nMaximum Likelihood và Maximum A\\nPosteriori\\n4.1 Giới thiệu\\nCó rất nhiều mô hình machine learning được xây dựng dựa trên các mô hình thống kê\\n(statistical models). Các mô hình thống kê thường dựa trên các phân phối xác suất đã được\\nđề cập trong Chương 3. Với phân phối Bernoulli, tham số là biếnλ. Với phân phối chuẩn\\nnhiều chiều, các tham số là mean vectorµvà ma trận hiệp phương saiΣ. Với một mô hình\\nthông kê bất kỳ, ký hiệuθ là tập hợp tất cả các tham số của mô hình đó. Learning chính là\\nquá trìnhước lượng(estimate) bộ tham sốθ sao cho mô hình tìm được khớp với phân phối\\ncủa dữ liệu nhất. Quá trình này còn được gọi làước lượng tham số(parameter estimation).\\nCó hai cách ước lượng tham số thường được dùng trong các mô hình machine learning thống\\nkê. Cách thứ nhất chỉ dựa trên dữ liệu đã biết trong tập huấn luyện, được gọi làmaximum\\nlikelihood estimationhay ML estimationhoặc MLE. Cách thứ hai không những dựa trên tập\\nhuấn luyện mà còn dựa trên những thông tin biết trước của các tham số. Những thông tin\\nnày có thể có được bằngcảm quan của người xây dựng mô hình.Cảm quan càng rõ ràng,\\ncàng hợp lý thì khả năng thu được bộ tham số tốt là càng cao. Chẳng hạn, thông tin biết\\ntrước củaλ trong Bernoulli distribution là việc nó là một số trong đoạn[0,1]. Với bài toán\\ntung đồng xu, vớiλ là xác suất có được mặthead, ta dự đoán được rằng giá trị này nên là\\nmột số gần với0.5. Cách ước lượng tham số thứ hai này được gọi làmaximum a posteriori\\nestimation hay MAP estimation. Trong chương này, chúng ta cùng tìm hiểu ý tưởng và cách\\ngiải quyết bài toán ước lượng tham số mô hình theoMLE hoặc MAP Estimation.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 64, 'page_label': '53'}, page_content='53 CHƯƠNG 4. MAXIMUM LIKELIHOOD VÀ MAXIMUM A POSTERIORI\\n4.2 Maximum likelihood estimation\\n4.2.1 Ý tưởng\\nGiả sử có các điểm dữ liệux1,x2,..., xN. Giả sử thêm rằng ta đã biết các điểm dữ liệu này\\ntuân theo một phân phối nào đó được mô tả bởi bộ tham sốθ.\\nMaximum likelihood estimation là việc đi tìm bộ tham sốθsao cho xác suất sau đây đạt giá\\ntrị lớn nhất:\\nθ= max\\nθ\\np(x1,..., xN|θ) (4.1)\\nBiểu thức (4.1) có ý nghĩa như thế nào và vì sao việc này có lý?\\nGiả sử rằng ta đã biết dạng của mô hình, và mô hình này được mô tả bởi bộ tham sốθ. Như\\nvậy,p(x1|θ) chính là xác suất xảy rasự kiệnx1 biết rằng mô hình được mô tả bởi bộ tham\\nsố θ (đây là một xác suất có điều kiện). Vàp(x1,..., xN|θ) chính là xác suất để toàn bộ các\\nsự kiệnx1,x2,..., xN đồng thời xảy ra, xác suất đồng thời này còn được gọi làlikelihood. Ở\\nđây,likelihood chính là hàm mục tiêu.\\nBởi vì sự việc đã xảy ra, tức dữ liệu huấn luyện bản thân chúng đã như thế, xác suất đồng\\nthời này cần phải càng cao càng tốt. Việc này cũng giống như việc đã biếtkết quả, và ta cần\\nđi tìmnguyên nhân sao cho xác suất xảy ra kết quả càng cao càng tốt. MLE chính là việc\\nđi tìm bộ tham sốθ sao cho Likelihood là lớn nhất. Trong mô hình này ta cũng có một bài\\ntoán tối ưu với hàm mục tiêu làp(x1,..., xN|θ). Lúc này ta không tối thiểu hàm mục tiêu\\nmà cần tối đa nó, vì ta muốn rằng xác suất xảy ra việc này là lớn nhất.\\n4.2.2 Giả sử về sự độc lập và log-likelihood\\nViệc giải trực tiếp bài toán (4.1) thường là phức tạp vì việc đi tìm mô hình xác suất đồng\\nthời cho toàn bộ dữ liệu là ít khi khả thi. Một cách tiếp cận phổ biến là giả sử đơn giản rằng\\ncác điểm dữ liệuxn là độc lập với nhau. Nói cách khác, ta xấp xỉ likelihood trong (4.1) bởi\\np(x1,..., xN|θ) ≈\\nN∏\\nn=1\\np(xn|θ) (4.2)\\n(Nhắc lại rằng hai sự kiệnx,y là độc lập nếu xác suất đồng thời của chúng bằng tích xác suất\\ncủatừngsựkiện: p(x,y) = p(x)p(y).Vàkhilàxácsuấtcóđiềukiện: p(x,y|z) = p(x|z)p(y|z).)\\nLúc đó, bài toán (4.1) có thể được giải quyết bằng cách giải bài toán tối ưu sau:\\nθ= max\\nθ\\nN∏\\nn=1\\np(xn|θ) (3) (4.3)\\nViệc tối ưu một tích thường phức tạp hơn việc tối ưu một tổng, vì vậy việc tối đa hàm mục\\ntiêu thường được chuyển về việc tối đalog của hàm mục tiêu:\\nθ= max\\nθ\\nN∑\\nn=1\\nlog (p(xn|θ)) (4.4)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 65, 'page_label': '54'}, page_content='CHƯƠNG 4. MAXIMUM LIKELIHOOD VÀ MAXIMUM A POSTERIORI 54\\nÔn lại một chút về hai tính chất của hàm logarit: (i)log của một tích bằng tổng của các\\nlog, và (ii) vìlog là một hàm đồng biến, một biểu thức dương sẽ là lớn nhất nếulog của nó\\nlà lớn nhất, và ngược lại.\\n4.2.3 Ví dụ\\nVí dụ 1: phân phối Bernoulli\\nBài toán: giả sử tung một đồng xuN lần và nhận đượcn mặt head. Ước lượng xác suất\\nkhi tung đồng xu nhận được mặthead.\\nLời giải:\\nMột cách trực quan, ta có thể ước lượng được rằng xác suất đó chính làλ = n\\nN. Chúng ta\\ncùng ước lượng giá trị này sử dụng MLE.\\nGiả sử λ là xác suất để nhận được một mặthead. Đặt x1,x2,...,x N là các đầu ra nhận\\nđược, trong đó cón giá trị bằng 1 tương ứng với mặthead và m = N −n giá trị bằng 0\\ntương ứng với mặttail. Ta có thể suy ra ngay rằng\\nN∑\\ni=1\\nxi = n, N −\\nN∑\\ni=1\\nxi = N −n= m (4.5)\\nVì đây là một xác suất của biến ngẫu nhiên nhị phân rời rạc, ta có thể nhận thấy việc nhận\\nđược mặthead hay tail khi tung đồng xu tuân theo phân phối Bernoulli:\\np(xi|λ) = λxi(1 −λ)1−xi (4.6)\\nKhi đó tham số mô hìnhλcó thể được ước lượng bằng việc giải bài toán tối ưu sau đây, với\\ngiả sử rằng kết quả của các lần tung đồng xu là độc lập với nhau:\\nλ= argmax\\nλ\\n[p(x1,x2,...,x N|λ)] = argmax\\nλ\\n[N∏\\ni=1\\np(xi|λ)\\n]\\n(4.7)\\n= argmax\\nλ\\n[N∏\\ni=1\\nλxi(1 −λ)1−xi\\n]\\n= argmax\\nλ\\n[\\nλ\\n∑N\\ni=1 xi(1 −λ)N−∑N\\ni=1 xi\\n]\\n(4.8)\\n= argmax\\nλ\\n[λn(1 −λ)m] = argmax\\nλ\\n[nlog(λ) + mlog(1 −λ)] (4.9)\\ntrong (4.9), ta đã lấylog của hàm mục tiêu. Tới đây, bài toán tối ưu (4.9) có thể được giải\\nbằng cách lấy đạo hàm của hàm mục tiêu bằng 0. Tứcλ là nghiệm của phương trình\\nn\\nλ − m\\n1 −λ = 0 ⇔n\\nλ = m\\n1 −λ ⇔λ= n\\nn+ m = n\\nN (4.10)\\nVậy kết quả ta ước lượng ban đâu là có cơ sở.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 66, 'page_label': '55'}, page_content='55 CHƯƠNG 4. MAXIMUM LIKELIHOOD VÀ MAXIMUM A POSTERIORI\\nVí dụ 2: Categorical distribution\\nMột ví dụ khác phức tạp hơn một chút.\\nBài toán:giả sử tung một viên xúc xắc sáu mặt có xác suất rơi vào các mặt có thể không\\nđều nhau. Giả sử trongN lần tung, số lượng xuất hiện các mặt thứ nhất, thứ hai,..., thứ\\nsáu lần lượt làn1,n2,...,n 6 lần với\\n6∑\\ni=1\\nni = N. Tính xác suất rơi vào mỗi mặt ở lần tung\\ntiếp theo. Giả sử thêm rằngni >0, ∀i= 1,..., 6.\\nLời giải:\\nBài toán này có vẻ phức tạp hơn bài toán trên một chút, nhưng ta cũng có thể dự đoán được\\nước lượng tốt nhất của xác suất rơi vào mặt thứi là λi = ni\\nN.\\nMã hoá mỗi quan sát đầu ra thứi bởi một vector 6 chiềuxi ∈{0,1}6 trong đó các phần\\ntử của nó bằng 0 trừ phần tử tương ứng với mặt quan sát được là bằng 1. Nhận thấy rằng∑N\\ni=1 xj\\ni = nj, ∀j = 1,2,..., 6, trong đóxj\\ni là thành phần thứj của vectorxi.\\nCó thể thấy rằng xác suất rơi vào mỗi mặt tuân theo phân phối categorical với các tham số\\nλj >0,j = 1,2,..., 6. Ta dùngλđể thể hiện cho cả sáu tham số này.\\nVới các tham sốλ, xác suất để sự kiệnxi xảy ra là\\np(xi|λ) =\\n6∏\\nj=1\\nλ\\nxj\\ni\\nj (4.11)\\nKhi đó, vẫn với giả sử về sự độc lập giữa các lần tung xúc xắc, ước lượng bộ tham sốλdựa\\ntrên việc tối đa log-likelihood ta có:\\nλ= argmax\\nλ\\n[N∏\\ni=1\\np(xi|λ)\\n]\\n= argmax\\nλ\\n[N∏\\ni=1\\n6∏\\nj=1\\nλ\\nxj\\ni\\nj\\n]\\n(4.12)\\n= argmax\\nλ\\n[ 6∏\\nj=1\\nλ\\n∑N\\ni=1 xj\\ni\\nj\\n]\\n= argmax\\nλ\\n[ 6∏\\nj=1\\nλ\\nnj\\nj\\n]\\n(4.13)\\n= argmax\\nλ\\n[ 6∑\\nj=1\\nnj log(λj)\\n]\\n(4.14)\\nKhác với bài toán (4.9) một chút, chúng ta không được quên điều kiện∑6\\nj=1 λj = 1. Ta có\\nbài toán tối ưu có ràng buộc sau đây\\nmax\\nλ\\n6∑\\nj=1\\nnj log(λj) thoả mãn:\\n6∑\\nj=1\\nλj = 1 (4.15)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 67, 'page_label': '56'}, page_content='CHƯƠNG 4. MAXIMUM LIKELIHOOD VÀ MAXIMUM A POSTERIORI 56\\nBài toán tối ưu này có thể được giải bằng phương pháp nhân tử Lagrange (xem Phụ lục A).\\nLagrangian của bài toán này là\\nL(λ,µ) =\\n6∑\\nj=1\\nnj log(λj) + µ(1 −\\n6∑\\nj=1\\nλj) (4.16)\\nNghiệm của bài toán là nghiệm của hệ đạo hàm củaL(.) theo từng biến bằng 0\\n∂L(λ,µ)\\n∂λj\\n= nj\\nλj\\n−µ = 0, ∀j = 1,2,..., 6 (4.17)\\n∂L(λ,µ)\\n∂µ = 1 −\\n6∑\\nj=1\\nλj = 0 (4.18)\\nTừ (4.17) ta cóλj = nj\\nµ . Thay vào (4.18),\\n6∑\\nj=1\\nnj\\nµ = 1 ⇒µ=\\n6∑\\nj=1\\nnj = N (4.19)\\nTừ đó ta có ước lượngλj = nj\\nN , ∀j = 1,2,..., 6.\\nQua hai ví dụ trên ta thấy MLE cho hết quả khá hợp lý.\\nVí dụ 3: Univariate normal distribution\\nBài toán:Khi thực hiện một phép đo, giả sử rằng rất khó để có thể đochính xác độ dài\\ncủa một vật. Thay vào đó, người ta thường đo vật đó nhiều lần rồi suy ra kết quả, với giả\\nthiết rằng các phép đo là độc lập với nhau và kết quả mỗi phép đo là một phân phối chuẩn.\\nƯớc lượng chiều dài của vật đó dựa trên các kết quả đo được.\\nLời giải:Vì biết rằng kết quả phép đo tuân theo phân phối chuẩn, ta sẽ cố gắng đi xây\\ndựng phân phối chuẩn đó. Chiều dài của vật có thể được coi là giá trị mà hàm mật độ xác\\nsuất đạt giá trị cao nhất, tức khả năng rơi vào khoảng giá trị xung quanh nó là lớn nhất.\\nTrong phân phối chuẩn, ta biết rằng hàm mật độ xác suất đạt giá trị lớn nhất tại chính kỳ\\nvọng của phân phối đó. Chú ý rằng kỳ vọng của phân phối và kỳ vọng của dữ liệu quan sát\\nđược có thể không chính xác bằng nhau, nhưng rất gần nhau. Nếu ước lượng kỳ vọng của\\nphân phối như cách làm dưới đây sử dụng MLE, ta sẽ thấy rằng kỳ vọng của dữ liệu chính\\nlà đánh giá tốt nhất cho kỳ vọng của phân phối.\\nThật vậy, giả sử các kích thước quan sát được làx1,x2,...,x N. Ta cần đi tìm một phân\\nphối chuẩn, được mô tả bởi một giá trị kỳ vọngµ và phương saiσ2, sao cho các giá trị\\nx1,x2,...,x N là likely nhất. Ta đã biết rằng, hàm mật độ xác suất tạixi của môt phân phối\\nchuẩn có kỳ vọngµ và phương saiσ2 là\\np(xi|µ,σ2) = 1√\\n2πσ2\\nexp\\n(\\n−(xi −µ)2\\n2σ2\\n)\\n(4.20)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 68, 'page_label': '57'}, page_content='57 CHƯƠNG 4. MAXIMUM LIKELIHOOD VÀ MAXIMUM A POSTERIORI\\nVậy, để đánh giáµvà σ, ta sử dụng MLE với giả thiết rằng kết quả các phép đo là độc lập:\\nµ,σ = argmax\\nµ,σ\\n[N∏\\ni=1\\np(xi|µ,σ2)\\n]\\n(4.21)\\n= argmax\\nµ,σ\\n[\\n1\\n(2πσ2)N/2 exp\\n(\\n−\\n∑N\\ni=1(xi −µ)2\\n2σ2\\n)]\\n(4.22)\\n= argmax\\nµ,σ\\n[\\n−Nlog(σ) −\\n∑N\\ni=1(xi −µ)2\\n2σ2 ≜J(µ,σ)\\n]\\n(4.23)\\nTa đã lấylog của hàm bên trong dấu ngoặc vuông của (4.22) để được (4.23), phần hằng số\\ncó chứa2π cũng đã được bỏ đi vì nó không ảnh hưởng tới kết quả.\\nĐể tìmµ và σ, ta giải hệ phương trình đạo hàm củaJ(µ,σ) theo mỗi biến bằng không:\\n∂J\\n∂µ = 1\\nσ2\\nN∑\\ni=1\\n(xi −µ) = 0 (4.24)\\n∂J\\n∂σ = −N\\nσ + 1\\nσ3\\nN∑\\ni=1\\n(xi −µ)2 = 0 (4.25)\\n⇒µ=\\n∑N\\ni=1 xi\\nN , σ 2 =\\n∑N\\ni=1(xi −µ)2\\nN (4.26)\\nKết quả thu được không có gì bất ngờ.\\nVí dụ 4: Multivariate normal distribution\\nBài toán:Giả sử tập dữ liệu ta thu được là các giá trị nhiều chiềux1,..., xN tuân theo\\nphân phối chuẩn. Hãy đánh giá các tham số, vector kỳ vọngµvà ma trận hiệp phương sai\\nΣ của phân phối này dựa trên MLE, giả sử rằng cácx1,..., xN là độc lập.\\nLời giải:Việc chứng minh các công thức\\nµ=\\n∑N\\ni=1 xi\\nN (4.27)\\nΣ = 1\\nN\\nN∑\\ni=1\\n(x −µ)(x −µ)T (4.28)\\nxin được dành lại cho bạn đọc như một bài tập nhỏ. Dưới đây là một vài gợi ý:\\n• Hàm mật độ xác suất của phân phối chuẩn nhiều chiều là\\np(x|µ,Σ) = 1\\n(2π)D/2∥Σ∥1/2 exp\\n(\\n−1\\n2(x −µ)TΣ−1(x −µ)\\n)\\n(4.29)\\nChú ý rằng ma trận hiệp phương saiΣ là xác định dương nên có nghịch đảo.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 69, 'page_label': '58'}, page_content='CHƯƠNG 4. MAXIMUM LIKELIHOOD VÀ MAXIMUM A POSTERIORI 58\\n• Một vài đạo hàm theo ma trận:\\n∇Σ log |Σ|= (Σ−1)T ≜Σ−T (chuyển vị của nghịch đảo) (4.30)\\n∇Σ(xi −µ)TΣ−1(xi −µ) = −Σ−T(xi −µ)(xi −µ)TΣ−T (4.31)\\n(Xem thêm Matrix Calculus, mục D.2.1 và D.2.4 tạihttps://goo.gl/JKg631 .)\\n4.3 Maximum a Posteriori\\n4.3.1 Ý tưởng\\nQuay lại với ví dụ 1 về tung đồng xu. Nếu tung đồng xu 5000 lần và nhận được 1000 lần\\nhead, ta có thể đánh giá xác suất củahead là 1/5 và việc đánh giá này là đáng tin vì số mẫu\\nlà lớn. Nếu tung 5 lần và chỉ nhận được 1 mặthead, theo MLE, xác suất để có một mặthead\\nđược đánh giá là1/5. Tuy nhiên với chỉ 5 kết quả, ước lượng này là không đáng tin, nhiều\\nkhả năng việc đánh giá đã bị overfitting. Khi tập huấn luyện quá nhỏ (low-training) chúng\\nta cần phải quan tâm tới một vài giả thiết của các tham số. Trong ví dụ này, giả thiết của\\nchúng ta là xác suất nhận được mặthead phải gần1/2.\\nMaximum A Posteriori (MAP) ra đời nhằm giải quyết vấn đề này. Trong MAP, chúng ta\\ngiới thiệu một giả thiết biết trước, được gọi làprior, của tham sốθ. Từ giả thiết này, chúng\\nta có thể suy ra các khoảng giá trị và phân bố của tham số.\\nNgược với MLE, trong MAP, chúng ta sẽ đánh giá tham số như là một xác suất có điều kiện\\ncủa dữ liệu:\\nθ= argmax\\nθ\\np(θ|x1,..., xN)\\ued19 \\ued18\\ued17 \\ued1a\\nposterior\\n(4.32)\\nBiểu thức p(θ|x1,..., xN) còn được gọi làxác suất posterior của θ. Chính vì vậy mà việc\\nước lượngθ theo (4.32) được gọi làMaximum A Posteriori.\\nThông thường, hàm tối ưu trong (4.32) khó xác định dạng một cách trực tiếp. Chúng ta\\nthường biết điều ngược lại, tức nếu biết tham số, ta có thể tính được hàm mật độ xác suất\\ncủa dữ liệu. Vì vậy, để giải bải toán MAP, ta thường sử dụng quy tắc Bayes. Bài toán MAP\\nthường được biến đổi thành\\nθ= argmax\\nθ\\np(θ|x1,..., xN) = argmax\\nθ\\n\\uf8ee\\n\\uf8ef\\uf8ef\\uf8f0\\nlikelihood\\n\\ued17 \\ued1a\\ued19 \\ued18\\np(x1,..., xN|θ)\\nprior\\n\\ued17\\ued1a\\ued19\\ued18\\np(θ)\\np(x1,..., xN)\\ued19 \\ued18\\ued17 \\ued1a\\nevidence\\n\\uf8f9\\n\\uf8fa\\uf8fa\\uf8fb (4.33)\\n= argmax\\nθ\\n[p(x1,..., xN|θ)p(θ)] (4.34)\\n= argmax\\nθ\\n[N∏\\ni=1\\np(xi|θ)p(θ)\\n]\\n(4.35)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 70, 'page_label': '59'}, page_content='59 CHƯƠNG 4. MAXIMUM LIKELIHOOD VÀ MAXIMUM A POSTERIORI\\nĐẳng thức (4.33) xảy ra theo quy tắc Bayes. Đẳng thức (4.34) xảy ra vì mẫu số của (4.33)\\nkhông phụ thuộc vào tham sốθ. Đẳng thức (4.35) xảy ra nếu chúng ta giả thiết về sự độc\\nlập giữa cácxi. Chú ý rằng giả thiết độc lập thường xuyên được sử dụng.\\nNhư vậy, điểm khác biệt lớn nhất giữa hai bài toán tối ưu MLE và MAP là việc hàm mục\\ntiêu của MAP có thêmp(θ), tức phân phối củaθ. Phân phối này chính là những thông tin\\nta biết trước vềθ và được gọi làprior. Ta kết luận rằngposterior tỉ lệ thuận với tích\\ncủa likelihood và prior.\\nVậy chọnprior thế nào? chúng ta cùng làm quen với một khái niệm mới:conjugate prior.\\n4.3.2 Conjugate prior\\nNếu phân phối xác suất posteriorp(θ|x1,..., xN) có cùng dạng(same family) với phân phối\\nxác suất p(θ), prior và posterior được gọi làconjugate distributions, và p(θ) được gọi là\\nconjugate prior cho hàm likelihoodp(x1,..., xN|θ). Nghiệm của bài toán MAP và MLE có\\ncấu trúc giống nhau.\\nMột vài cặp cácconjugate distributions1:\\n• Nếu likelihood function là một Gaussian (phân phối chuẩn), và prior cho vector kỳ vọng\\ncũng là một Gaussian, thế thì phân phối posterior cũng là một Gaussian. Ta nói rằng\\nGaussian conjugate với chính nó (hay còn gọi làself-conjugate).\\n• NếulikelihoodfunctionlàmộtGaussianvàpriorchophươngsailàmộtphânphốigamma 2,\\nphân phối posterior cũng là một Gaussian. Ta nói rằng phân phối gamma là conjugate\\nprior cho phương sai của Gassian. Chú ý rằng phương sai có thể được coi là một biến\\ngiúp đođộ chính xáccủa mô hình. Phương sai càng nhỏ thì độ chính xác càng cao.\\n• Phân phối Beta là conjuate của phân phối Bernoulli.\\n• Phân phối Dirichlet là conjugate của phân phối categorical.\\n4.3.3 Hyperparameters\\nXét một ví dụ nhỏ với phân phối Bernoulli với hàm mật độ xác suất:\\np(x|λ) = λx(1 −λ)1−x (4.36)\\nvà conjugate của nó, phân phối Beta, có hàm phân mật độ xác suất:\\np(λ) = Γ(α+ β)\\nΓ(α)Γ(β)λα−1(1 −λ)β−1 (4.37)\\nBỏ qua thừa số hằng số chỉ mang mục đích chuẩn hoá cho tích phân của hàm mật độ xác suất\\nbằng một, ta có thể nhận thấy rằng phần còn lại của phân phối Beta có cùnghọ (family)\\n1 Đọc thêm:Conjugate prior–Wikipedia(https://goo.gl/E2SHbD ).\\n2 Gamma distribution–Wikipedia, (https://goo.gl/kdWd2R .)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 71, 'page_label': '60'}, page_content='CHƯƠNG 4. MAXIMUM LIKELIHOOD VÀ MAXIMUM A POSTERIORI 60\\nvới phân phối Bernoulli. Cụ thể, nếu sử dụng phân phối Beta làmprior cho tham sốλ, và\\nbỏ qua phần thừa số hằng số, posterior sẽ có dạng\\np(λ|x) ∝p(x|λ)p(λ)\\n∝λx+α−1(1 −λ)1−x+β−1 (4.38)\\ntrong đó,∝là ký hiệu củatỉ lệ với.\\nNhận thấy rằng (4.38)vẫn có dạng của một phân phối Bernoulli.Chính vì vậy mà phân\\nphối Beta được gọi là mộtconjugate priorcho phân phối Bernoulli.\\nTrong ví dụ này, tham sốλ phụ thuộc vào hai tham số khác làα và β. Để tránh nhầm lẫn,\\nhai tham số(α,β) được gọi làsiêu tham số (hyperparameters).\\nQuay trở lại ví dụ về bài toán tung đồng xuN lần cónlần nhận được mặthead vàm= N−n\\nlần nhận được mặttail. Nếu sử dụng MLE, ta nhận được ước lượngλ= n/M. Nếu sử dụng\\nMAP với prior là một Beta[α,β] thì kết quả sẽ thay đổi thế nào?\\nBài toán tối ưu MAP:\\nλ= argmax\\nλ\\n[p(x1,...,x N|λ)p(λ)]\\n= argmax\\nλ\\n[(N∏\\ni=1\\nλxi(1 −λ)1−xi\\n)\\nλα−1(1 −λ)β−1\\n]\\n= argmax\\nλ\\n[\\nλ\\n∑N\\ni=1 xi+α−1(1 −λ)N−∑N\\ni=1 xi+β−1\\n]\\n= argmax\\nλ\\n[\\nλn+α−1(1 −λ)m+β−1]\\n(4.39)\\nBài toán tối ưu (4.39) chính là bài toán tối ưu (4.38) với tham số thay đổi một chút. Tương\\ntự như (4.38), nghiệm của (4.39) có thể được suy ra là\\nλ= n+ α−1\\nN + α+ β−2 (4.40)\\nNhờ việc chọn prior phù hợp, ở đây là conjugate prior, posterior và likelihood có dạng giống\\nnhau, khiến cho việc tối ưu bài toán MAP được thuận lợi.\\nViệc còn lại là chọn cặphyperparameters α và β.\\nChúng ta cùng xem lại hình dạng của phân phối Beta và nhận thấy rằng khiα = β >1,\\nhàm mật độ xác suất của phân phối Beta đối xứng qua điểm 0.5 và đạt giá trị cao nhất tại\\n0.5. Xét Hình 4.1, ta nhận thấy rằng khiα= β >1, mật độ xác suất xung quanh điểm 0.5\\nnhận giá trị cao, điều này chứng tỏλ có xu hướng gần với 0.5.\\nNếu ta chọnα= β = 1, ta nhận được phân phối đều vì đồ thị hàm mật độ xác suất là một\\nđường thẳng. Lúc này, xác suất củaλ tại mọi vị trí trong khoảng[0,1] là như nhau. Thực\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 72, 'page_label': '61'}, page_content='61 CHƯƠNG 4. MAXIMUM LIKELIHOOD VÀ MAXIMUM A POSTERIORI\\nHình 4.1: Đồ thị hàm mật độ xác\\nsuất của phân phối Beta khiα= β\\nvà nhận các giá trị khác nhau. Khi\\ncả hai giá trị này lớn, xác suất đểλ\\ngần 0.5 sẽ cao hơn.\\nchất, nếu ta thayα= β = 1 vào (4.40) ta sẽ thu đượcλ= n/N, đây chính là ước lượng thu\\nđược bằng MLE. MLE là một trường hợp đặc biệt của MAP khi prior là một phân phối đều.\\nNếu ta chọnα= β = 2, ta sẽ thu được:λ= n+ 1\\nN + 2. Chẳng hạn khiN = 5,n = 1 như trong\\nví dụ. MLE cho kết quảλ= 1/5, MAP sẽ cho kết quảλ= 2/7, gần với1/2 hơn.\\nNếu chọnα = β = 10 ta sẽ cóλ = (1 + 9)/(5 + 18) = 10 /23. Ta thấy rằng khiα = β và\\ncàng lớn thì ta sẽ thu đượcλ càng gần1/2. Điều này có thể dễ nhận thấy vì prior nhận giá\\ntrị rất cao tại 0.5 khi các siêu tham sốα= β lớn.\\n4.3.4 MAP giúp tránh overfitting\\nViệc chọn các hyperparameter thường được dựa trên thực nghiệm, chẳng hạn bằng cross-\\nvalidation. Việc thử nhiều bộ tham số rồi chọn ra bộ tốt nhất là việc mà các kỹ sư machine\\nlearning thường xuyên phải đối mặt. Cũng giống như việc chọn regularization parameter để\\ntránh overfitting vậy.\\nNếu viết lại bài toán MAP dưới dạng:\\nθ= argmax\\nθ\\np(X|θ)p(θ) (4.41)\\n= argmax\\nλ\\n\\uf8ee\\n\\uf8f0log p(X|θ)\\ued19 \\ued18\\ued17 \\ued1a\\nlikelihood\\n+ logp(θ)\\ued19\\ued18\\ued17\\ued1a\\nprior\\n\\uf8f9\\n\\uf8fb (4.42)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 73, 'page_label': '62'}, page_content='CHƯƠNG 4. MAXIMUM LIKELIHOOD VÀ MAXIMUM A POSTERIORI 62\\nta có thể thấy rằng hàm mục tiêu có dạngL(θ) +λR(θ) giống như trong regularization, với\\nhàm log-likelihood đóng vai trò như hàm mất mátL(θ), và log của prior đóng vai trò như\\nhàm R(θ). Ta có thể nói rằng, MAP chính là một phương pháp giúp tránh overfitting trong\\ncác mô hình machine learning thống kê. MAP đặc biệt hữu ích khi tập huấn luyện là nhỏ.\\n4.4 Tóm tắt\\n• Khi sử dụng các mô hình thống kê machine learning, chúng ta thường xuyên phải ước\\nlượng các tham số của mô hìnhθ, đại diện cho các tham số của các phân phối xác suất.\\nCó hai phương pháp phổ biến được sử dụng để ước lượngθ là Maximum Likelihood\\nEstimation (MLE) và Maximum A Posterior Estimation (MAP).\\n• Với MLE, việc xác định tham sốθ được thực hiện bằng cách đi tìm các tham số sao cho\\nxác suất của tập huấn luyện, hay còn gọi làlikelihood, là lớn nhất:\\nθ= argmax\\nθ\\np(x1,..., xN|θ) (4.43)\\n• Để giải bài toán tối ưu này, giả thiết các dữ liệuxi độc lập thường được sử dụng. Và bài\\ntoán MLP trở thành:\\nθ= argmax\\nθ\\nN∏\\ni=1\\np(xi|θ) (4.44)\\n• Với MAP, các tham số được đánh giá bằng cách tối đaposterior:\\nθ= argmax\\nθ\\np(θ|x1,..., xN) (4.45)\\n• Quy tắc Bayes và giả thiết về sự độc lập của dữ liệu thường được sử dụng:\\nθ= argmax\\nθ\\n[N∏\\ni=1\\np(xi|θ)p(θ)\\n]\\n(4.46)\\nHàm mục tiêu ở đây chính là tích củalikelihood và prior.\\n• Prior thường được chọn dựa trên các thông tin biết trước của tham số, và phân phối\\nđược chọn thường là cácconjugate distribution với likelihood, tức các phân phối khiến\\nviệc nhân thêmprior vẫn giữ được cấu trúc giống nhưlikelihood.\\n• MAP có thể được coi là một phương pháp giúp tránh overfitting. MAP thường mang lại\\nhiệu quả cao hơn MLE với trường hợp có ít dữ liệu huấn luyện.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 74, 'page_label': '63'}, page_content='Phần II\\nTổng quan về machine learning'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 75, 'page_label': '64'}, page_content='Chương 5\\nCác khái niệm cơ bản\\nNội dung của chương này được tham khảo chủ yếu từ Mục 5.1 trong cuốn sáchDeep learning\\n(Goodfellow, 2016).\\nMột thuật toán machine learning là một thuật toán có khả nănghọc tậptừ dữ liệu. Vậy thực\\nsự học tậpở đây có nghĩa như thế nào? Theo Mitchell trong cuốnMachine Learning[M+97],\\nMục 1.1, thì “A computer program is said tolearn from experience E with respect to some\\ntasks T and performance measureP, if its performance at tasks inT, as measured byP,\\nimproves with experienceE. ”\\nTạm dịch:\\nĐịnh nghĩa 5.1: Học (chương trình máy tính)\\nMột chương trình máy tính được gọi làhọc từ kinh nghiệm E để hoàn thànhnhiệm\\nvụ T, với hiệu quả được đo bằngphép đánh giáP, nếu hiệu quả của nó khi thực hiện\\nnhiệm vụT, khi được đánh giá bởiP, cải thiện theo kinh nghiệmE.\\nTrongchươngnày,chúngtasẽđivàotừngkháiniệm task,performance measure,và experience\\nthông qua các ví dụ.\\n5.1 Nhiệm vụ,T\\nCác nhiệm vụ trong machine learning thường được mô tả thông qua việc một hệ thống\\nmachine learning xử lý mộtđiểm dữ liệu(data point) như thế nào. Trong bài toán phân loại\\nảnh, mỗi ảnh là một điểm dữ liệu. Trong bài toán phân nhóm khách hàng, mỗi khách hàng\\nlà một điểm dữ liệu. Trong bài toán xác định một tin nhắn có là rác hay không, mỗi tin\\nnhắn là một điểm dữ liệu. Mỗi điểm dữ liệu bao gồm nhiềuđặc trưng (feature) khác nhau,\\nmỗi feature thường được biểu diễn dưới dạng một con số. Chúng ta thường biểu diễn một'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 76, 'page_label': '65'}, page_content='65 CHƯƠNG 5. CÁC KHÁI NIỆM CƠ BẢN\\nđiểm dữ liệu như một vector1 x ∈Rd trong đó mỗi phần tửxi là một đặc trưng, vector này\\nthường được gọi làvector đặc trưng(feature vector). Ví dụ, trong một bức ảnh, mỗi giá trị\\ncủa một điểm ảnh có thể coi là một đặc trưng, vector chứa toàn bộ giá trị các pixel của ảnh\\ncó thể coi là một vector đặc trưng. Chương 6 sẽ bàn sâu thêm về vector đặc trưng của dữ\\nliệu.\\nRất nhiều nhiệm vụ phức tạp có thể được giải quyết bằng machine learning. Dưới đây là\\nmột trong những bài toán phổ biến nhất của machine learning.\\n5.1.1 Classification\\nClassification, hayphân loại, phân lớp. Đây là một trong những bài toán được nghiên cứu\\nnhiều nhất trong machine learning. Trong bài toán này, chương trình sẽ được yêu cầu chỉ ra\\nnhãn, haylớp (label) của một điểm dữ liệu. Nhãn này thường là một phần tử trong một tập\\nhợp cóC phần tử khác nhau. Mỗi phần tử trong tập hợp này được gọi là mộtlớp (class), và\\nthường được đánh số từ1 đến C. Để giải bài toán này, ta thường phải xây dựng một hàm\\nsố f : Rd →{1,2,...,C }. Khiy= f(x), mô hình gán cho một điểm dữ liệu được mô tả bởi\\nvector đặc trưngx một nhãn được xác định bởi sốy.\\nVí dụ:trong nhận dạng chữ số viết tay, ta có ảnh của hàng nghìn ví dụ của mỗi chữ số\\nđược viết bởi nhiều người khác nhau. Các bức ảnh này cùng với nhãn của chúng được đưa\\nvào một thuật toán machine learning. Sau khi thuật toán nàyhọc được một mô hình, tức\\nmột hàm số mà đầu vào là một bức ảnh và đầu ra là một chữ số, khi nhận được một bức\\nảnh mới mà mô hìnhchưa nhìn thấy bao giờ, nó sẽ dự đoán bức ảnh đó chứa chữ số nào.\\nVí dụ này khá giống với cách học của con người khi còn nhỏ. Ta đưa bảng chữ cái cho một\\nđứa trẻ và chỉ cho chúng đây là chữ A, đây là chữ B. Sau một vài lần được dạy thì trẻ có\\nthể nhận biết được đâu là chữ A, đâu là chữ B mà chúng chưa nhìn thấy bao giờ.\\nCó một biến thể nhỏ ở đầu ra của hàm sốf(x) khi đầu ra không phải là một số mà là một\\nvector y ∈RC trong đó yc chỉ ra xác suất để điểm dữ liệux rơi vào lớp thức. Lớp được\\nchọn cuối cùng là lớp có xác suất rơi vào là cao nhất. Việc sử dụng xác suất này đôi khi rất\\nquan trọng, nó giúp chỉ rađộ chắc chắn(confidence) của mô hình. Nếu xác suất cao nhất\\nlà cao hơn nhiều so với các xác suất còn lại, ta nói mô hình có độ chắn chắn là cao khi phân\\nlớp điểm dữ liệux. Ngược lại, nếu độ chênh lệch giữa xác suất cao nhất và các xác suất tiếp\\ntheo là nhỏ, thì khả năng mô hình đã phân loại nhầm là cao hơn.\\n5.1.2 Regression\\nNếu nhãn không được chia thành các nhóm mà là các giá trị thực (có thể vô hạn) thì bài\\ntoán được gọi làhồi quy, một số tài liệu gọi làtiên lượng (regression). Trong bài toán này,\\nta cần xây dựng một hàm sốf : Rd →R.\\n1 Có những loại dữ liệu không được biểu diễn dưới dạng một vector mà có thể là một ma trận–khi giữ nguyên một\\nbức ảnh trong không gian hai chiều, hoặc mộttensor–mảng nhiều chiều–khi xem các bức ảnh với nhiều channel\\nkhác nhau. Trong cuốn sách này, chúng ta chỉ xét các điểm dữ liệu dưới dạng vector, hoặcvector hoá(vectorization)\\ncác điểm dữ liệu nhiều chiều.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 77, 'page_label': '66'}, page_content='CHƯƠNG 5. CÁC KHÁI NIỆM CƠ BẢN 66\\nVí dụ 1:Ước lượng một căn nhà rộngx m2, cóy phòng ngủ và cách trung tâm thành phố\\nz km sẽ có giá khoảng bao nhiêu?\\nVí dụ 2:Microsoft có một ứng dụng dự đoán giới tính và tuổi dựa trên khuôn mặt (http:\\n//how-old.net/ ). Phần dự đoán giới tính có thể được coi là một thuật toán classification,\\nphần dự đoán tuổi có thể coi là một thuật toán regression. Chú ý rằng phần dự đoán tuổi\\ncũng có thể coi là classification nếu ta coi tuổi là một số nguyên dương không lớn hơn 150,\\nchúng ta sẽ có 150 class (lớp) khác nhau.\\nBài toán regression có thể mở rộng ra việc dự đoán nhiều đầu ra cùng một lúc, khi đó, hàm\\ncần tìm sẽ làf : Rd →Rm. Một ví dụ là bài toánsingle image super resolution, ở đó, hệ\\nthống cần tạo ra một bức ảnh có độ phân giải cao dựa trên một ảnh có độ phân giải thấp\\nhơn. Khi đó, việc dự đoán giá trị của các pixel trong ảnh đầu ra là một bài toán regression\\nvới nhiều đầu ra.\\n5.1.3 Machine translation\\nTrong bài toán này, đầu vào là một câu, đoạn, hay bài văn trong một ngôn ngữ, và chương\\ntrình máy tính được yêu cầu chuyển đổi nó sang một ngôn ngữ khác. Lời giải cho bài toán\\nnày gần đây đã có nhiều bước phát triển vượt bậc dựa trên các thuật toán deep learning.\\n5.1.4 Clustering\\nClustering là bài toánphân nhóm toàn bộ dữ liệuXthành các nhóm nhỏ dựa trên sự liên\\nquan giữa các dữ liệu trong mỗi nhóm.\\nVí dụ:phân nhóm khách hàng dựa trên hành vi mua hàng. Điều này cũng giống như việc\\nta đưa cho một đứa trẻ rất nhiều mảnh ghép với các hình thù và màu sắc khác nhau, ví dụ\\ntam giác, vuông, tròn với màu xanh và đỏ, sau đó yêu cầu trẻ phân chúng thành từng nhóm.\\nMặc dù không cho trẻ biết mảnh nào tương ứng với hình nào hoặc màu nào, nhiều khả năng\\nchúng vẫn có thể phân loại các mảnh ghép theo màu hoặc hình dạng.\\n5.1.5 Completion\\nCompletion là bài toánđiền những giá trị còn thiếu của một điểm dữ liệu. Trong nhiều bài\\ntoán thực tế, việc thu thập toàn bộ thông tin của một điểm dữ liệu, ví dụ khách hàng, là\\nkhông khả thi. Nhiệm vụ của bài toán này là dựa trên mối tương quan giữa các điểm dữ liệu\\nđể dự đoán những giá trị còn thiếu.Các hệ thống khuyến nghị(recommendation system) là\\nmột ví dụ điển hình của loại này.\\nBạn đọc có thể đọc thêm về các bài toánxếp hạng(ranking), thu thập thông tin(information\\nretrieval), giảm nhiễu (denoising), v.v..\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 78, 'page_label': '67'}, page_content='67 CHƯƠNG 5. CÁC KHÁI NIỆM CƠ BẢN\\n5.2 Phép đánh giá,P\\nĐể kiểm tra năng lực của một thuật toán machine learning, chúng ta cần phải thiết kế các\\nphép đánh giá có thể đo đạc được kết quả.\\nThông thường, khi thực hiện một thuật toán machine learning, dữ liệu sẽ được chia thành\\nhai phần riêng biệt:tập huấn luyện(training set) vàtập kiểm thử(test set). Tập huấn luyện\\nsẽ được dùng để tìm các tham số mô hình. Tập kiểm thử được dùng để đánh giá năng lực\\ncủa mô hình tìm được. Có một điểm cần lưu ý rằng khi tìm các tham số mô hình, ta chỉ\\nđược dùng các thông tin trong tập huấn luyện. Việc đánh giá có thể được áp dụng lên cả\\nhai tập hợp. Muốn mô hình thực hiện tốt trên tập kiểm thử thì nó trước hết phải hoạt động\\ntốt trên tập huấn luyện.\\nLưu ý:Ranh giới giữa tập huấn luyện và tập kiểm thử đôi khi không rõ ràng. Các thuật\\ntoán thực tế liên tục được cập nhật dựa trên dữ liệu mới thêm vào, các thuật toán này được\\ngọi là online learning hoặc online training. Phần dữ liệu mới này ban đầu không được hệ\\nthống sử dụng để xây dựng mô hình, nhưng về sau có thể được mô hình sử dụng để cải\\ntiến. Ngược vớionline learninglà offline learning, ở đó hệ thống xây dựng mô hìnhmột lần\\ndựa trên một tập chính là tập huấn luyện. Các điểm dữ liệu không được dùng trong quá\\ntrình xây dựng hệ thống được coi là tập kiểm thử. Trong cuốn sách này, khi không đề cập\\ngì thêm, các thuật toán được ngầm hiểu làoffline learning, trong đótraining setlà tập hợp\\nđược dùng để xây dựng mô hình ban đầu,test set là tập hợp được dùng để đánh giá hiệu\\nquả của mô hình được xây dựng đó.\\n5.3 Kinh nghiệm,E\\nViệc huấn luyện các mô hình machine learning có thể coi là việc cho chúngtrải nghiệmtrên\\ncác tập dữ liệu (dataset)–chính là training set. Các tập dữ liệu khác nhau sẽ cho các mô\\nhình các trải nghiệm khác nhau. Chất lượng của các tập dữ liệu này cũng ảnh hưởng tới\\nhiệu năng của mô hình.\\nDựa trên tính chất của các tập dữ liệu, các thuật toán machine learning có thể phân loại\\nthành hai nhóm chính làhọc không giám sát (unsupervised learning) và học có giám sát\\n(supervised learning).\\nSupervised learning là thuật toán dự đoán đầu ra của một hoặc nhiều dữ liệu mới dựa\\ntrên các cặp (đầu vào, đầu ra) đã biết từ trước. Supervised learning là nhóm phổ biến nhất\\ntrong các thuật toán machine learning.\\nMột cách toán học, supervised learning là khi chúng ra có một tập hợp biến đầu vàoX=\\n{x1,x2,..., xN}và một tập hợp đầu ra tương ứngY= {y1,y2,..., yN}, trong đóxi,yi là\\ncác vector. Các cặp dữ liệu biết trước(xi,yi) ∈X×Y tạo nên tập huấn luyện. Từ tập huấn\\nluyện này, chúng ta cần tạo ra một hàm số ánh xạ mỗi phần tử từ tậpXsang một phần tử\\n(xấp xỉ) tương ứng của tậpY:\\nyi ≈f(xi), ∀i= 1,2,...,N\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 79, 'page_label': '68'}, page_content='CHƯƠNG 5. CÁC KHÁI NIỆM CƠ BẢN 68\\nMục đích là xấp xỉ hàm sốf thật tốt để khi có một dữ liệux mới, chúng ta có thể tính được\\nnhãn tương ứng của nóy = f(x).\\nNgược lại, trongunsupervised learning, chúng ta không biết được kết quả đầu ra mà chỉ\\nbiết các vector đặc trưng của dữ liệu đầu vào. Các thuật toán unsupervised learning sẽ dựa\\nvào cấu trúc của dữ liệu để thực hiện một công việc nào đó, ví dụ như phân nhóm hoặcgiảm\\nsố chiều của dữ liệu(dimentionality reduction). Một cách toán học, unsupervised learning\\nlà khi chúng ta chỉ có dữ liệu đầu vàoXmà không biết đầu raYtương ứng.\\nKhông giống như trong supervised learning, chúng ta không biết câu trả lời chính xác cho\\nmỗi dữ liệu đầu vào trong unsupervised learning. Giống như khi ta học, ta chỉ được đưa cho\\nmột chữ cái mà không nói đó là chữ A hay chữ B. Cụm từkhông giám sát, haykhông ai chỉ\\nbảo (unsupervised) được đặt tên theo nghĩa này.\\nTừ góc độ xác suất thống kê, unsupervised learning trải nghiệm qua rất nhiều ví dụ (các\\nđiểm dữ liệu)x và cố gắng học phân phối xác suấtp(x), hoặc các tính chất của phân phối\\ncủa dữ liệu một cách trực tiếp hoặc gián tiếp. Trong khi đó, supervised learning quan sát các\\nví dụx và các kết quả tương ứngy, sau đó cố gắng học cách dự đoány từ x thông qua việc\\nđánh giá xác suất có điều kiệnp(y|x). Xác suất này có thể diễn đạt bằng lời là biết rằng\\nmột điểm dữ liệu có vector đặc trưng làx, xác suất để đầu ra của nó bằngy là bao nhiêu.\\nRanh giới giữa unsupervised learning và supervised learning đôi khi là không rõ ràng. Thông\\nthường, người ta thường coi các bài classification, regression là supervised learning, các bài\\nclustering haydensity estimation (ước lượng một phân phối) là unsupervised learning.\\nCó những bài toán mà dữ liệu được dùng để huấn luyện bao gồm cả những dữ liệu có nhãn\\nvà chưa được gán nhãn. Các bài toán khi chúng ta có một lượng lớn dữ liệuX nhưng chỉ\\nmột phần trong chúng được gán nhãn được gọi làhọc bán giám sát, haysemi-supervised\\nlearning. Những bài toán thuộc nhóm này nằm giữa hai nhóm được nêu bên trên.\\nMột ví dụ điển hình của nhóm này là chỉ có một phần ảnh hoặc văn bản được gán nhãn\\n(ví dụ bức ảnh về người, động vật hoặc các văn bản khoa học, chính trị) và phần lớn các\\nbức ảnh/văn bản khác chưa được gán nhãn được thu thập từ internet. Thực tế cho thấy rất\\nnhiều các bài toán machine learning thuộc vào nhóm này vì việc thu thập dữ liệu có nhãn\\ntốn rất nhiều thời gian và có chi phí cao. Rất nhiều loại dữ liệu, ví dụ như ảnh y học, thậm\\nchí cần phải có chuyên gia mới gán nhãn được. Ngược lại, dữ liệu chưa có nhãn có thể được\\nthu thập với chi phí thấp từ internet.\\nCó những thuật toán machine learning không luôn trải nghiệm trên một tập dữ liệu cố định.\\nVí dụ, học củng cố (reinforcement learning) trải nghiệm trực tiếp với môi trường xun\\nquanh, liên tục nhận phản hồi từ môi trường để tự cải thiện hành vi của hệ thống trong các\\nmôi trường mới. Các ví dụ điển hình của reinforcement learning là việc huấn luyện cho xe tự\\nlái dựa vào ảnh nhận từ camera và điều khiển tay lái cũng như tốc độc của xe. Reinforcement\\nlearning hiện nay chủ yếu được áp dụng vào các trò chơi, khi mà máy tính có thể mô phỏng\\nđược các trạng thái của môi trường và huấn luyện thuật toán thông qua rất nhiều vòng lặp.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 80, 'page_label': '69'}, page_content='69 CHƯƠNG 5. CÁC KHÁI NIỆM CƠ BẢN\\nVí dụ 1:AlphaGo gần đây nổi tiếng với việc chơi cờ vây thắng cả con người (https://goo.\\ngl/PzKcvP ). Cờ vây được xem là có độ phức tạp cực kỳ cao2 với tổng số nước đi là xấp\\nxỉ 10761, so với cờ vua là10120 và tổng số nguyên tử trong toàn vũ trụ là khoảng1080!! Hệ\\nthống phải chọn ra mộtđường đi nước bướctối ưu trong số hàng nhiều tỉ tỉ lựa chọn, và\\ntất nhiên, việc thử tất cả các lựa chọn là không khả thi. Về cơ bản, AlphaGo bao gồm các\\nthuật toán thuộc cả supervised learning và reinforcement learning. Trong phần supervised\\nlearning, dữ liệu từ các ván cờ do con người chơi với nhau được đưa vào để huấn luyện. Tuy\\nnhiên, mục đích cuối cùng của AlphaGo không phải là chơi như con người mà phải thậm\\nchí thắng cả con người. Vì vậy, sau khihọc xong các ván cờ của con người, AlphaGo tự chơi\\nvới chính nó với hàng triệu ván chơi để tìm ra các nước đi mới tối ưu hơn. Thuật toán trong\\nphần tự chơi này được xếp vào loại reinforcement learning.\\nGần đây, Google DeepMind đã tiến thêm một bước đáng kể với AlphaGo Zero. Hệ thống\\nnày thậm chí không cần học từ các ván cờ của con người. Nó có thể tự chơi với chính mình\\nđể tìm ra các chiến thuật tối ưu. Sau 40 ngày được huấn luyện, nó đã thắng tất cả các con\\nngười và hệ thống khác, bao gồm AlphaGo3.\\nVí dụ 2:Huấn luyện cho máy tính chơi game Mario4. Đây là một chương trình thú vị dạy\\nmáy tính chơi game Mario. Game này đơn giản hơn cờ vây vì tại một thời điểm, người chơi\\nchỉ phải bấm một số lượng nhỏ các nút (di chuyển, nhảy, bắn đạn) hoặc không cần bấm nút\\nnào. Đồng thời, phản ứng của máy cũng đơn giản hơn và lặp lại ở mỗi lần chơi (tại thời\\nđiểm cụ thể sẽ xuất hiện một chướng ngại vật cố định ở một vị trí cố định). Đầu vào của\\nthuật toán là sơ đồ của màn hình tại thời điểm hiện tại, nhiệm vụ của thuật toán là với đầu\\nvào đó, tổ hợp phím nào nên được bấm. Việc huấn luyện này được dựa trên điểm số cho\\nviệc di chuyển được bao xa trong thời gian bao lâu trong game, càng xa và càng nhanh thì\\nđược điểm thưởng càng cao (điểm thưởng này không phải là điểm của trò chơi mà là điểm\\ndo chính người lập trình tạo ra). Thông qua huấn luyện, thuật toán sẽ tìm ra một cách tối\\nđa số điểm trên, qua đó đạt được mục đích cuối cùng là cứu công chúa.\\nReinforcement learning là một lĩnh vực thú vị trong machine learning. Rất tiếc, reinforcement\\nlearning nằm ngoài phạm vi của cuốn sách này.\\n5.4 Hàm mất mát và tham số mô hình\\nMỗi mô hình machine learning được mô tả bởicác tham số mô hình(model parameters).\\nCông việc của một thuật toán machine learning là đi tìm các tham số mô hình phù hợp với\\nmỗi bài toán. Việc đi tìm các tham số mô hình có liên quan mật thiết đến các phép đánh\\ngiá. Mục đích của chúng ta là đi tìm các tham số mô hình sao cho các phép đánh giá cho\\nkết quả tốt nhất. Trong bài toán classification, kết quả tốt có thể được hiểu là ít điểm dữ\\nliệu bị phân lớp sai nhất. Trong bài toán regression, kết quả tốt là khi sự sai lệch giữa đầu\\nra dự đoán và đầu ra thực sự là ít nhất.\\n2 Google DeepMind’s AlphaGo: How it works(https://goo.gl/nDNcCy ).\\n3 AlphaGo Zero: Learning from scratch(https://goo.gl/xtDjoF ).\\n4 MarI/O - Machine Learning for Video Games(https://goo.gl/QekkRz )\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 81, 'page_label': '70'}, page_content='CHƯƠNG 5. CÁC KHÁI NIỆM CƠ BẢN 70\\nQuan hệ giữa một phép đánh giá và các tham số mô hình thường được mô tả thông qua\\nmột hàm số được gọi làhàm mất mát(loss function, haycost function). Hàm mất mát này\\nthường có giá trị nhỏ khi phép đánh giá cho kết quả tốt và ngược lại. Việc đi tìm các tham\\nsố mô hình sao cho phép đánh giá trả về kết quả tốt tương đương với việc tối thiểu hàm\\nmất mát. Như vậy, việc xây dựng một mô hình machine learning chính là việc đi giải một\\nbài toán tối ưu. Quá trình đó có thể được coi là quá trìnhlearning của machine.\\nTập hợp các tham số mô hình thường được ký hiệu bằngθ, hàm mất mát của mô hình\\nthường được ký hiệu làL(θ) hoặc J(θ). Bài toán tối thiểu hàm mất mát để tìm tham số mô\\nhình thường được viết dưới dạng:\\nθ∗= argmin\\nθ\\nL(θ) (5.1)\\nký hiệuargmin\\nθ\\nL(θ) được hiểu là giá trị củaθ để hàm sốL(θ) đạt giá trị nhỏ nhất. Khi sử\\ndụng argmin, chúng ta phải chỉ rõ nó được thực hiện theo các biến số nào bằng cách ghi các\\nbiến số ở dướimin (ở đây làθ). Nếu hàm số chỉ có một biến số, ta có thể bỏ qua biến số đó\\ndưới min. Tuy nhiên, biến số nên được ghi rõ ràng để giảm thiểu sự nhầm lẫn.argmax cũng\\nđược sử dụng một cách tương tự khi ta cần tìm giá trị của các biến số để một hàm số đạt\\ngiá trị lớn nhất.\\nMột hàm sốL(θ) bất kỳ có thể có rất nhiều giá trị củaθ để nó đạt giá trị nhỏ nhất, hoặc\\ncũng có thể nó không chặn dưới. Thậm chí, việc tìm giá trị nhỏ nhất của một hàm số đôi\\nkhi là không khả thi. Trong machine learning cũng như nhiều bài toán tối ưu thực tế, việc\\nchỉ cần tìm ra một bộ tham sốθ làm cho hàm mất mát đạt giá trị nhỏ nhất, hoặc thậm chí\\nđạt một giá trị cực tiểu5, thường mang lại các kết quả khả quan.\\nĐể hiểu rõ bản chất của các thuật toán machine learning, việc nắm vững các kỹ thuật tối\\nưu cơ bản là rất quan trọng. Cuốn sách này có nhiều chương cung cấp các kiến thức cần\\nthiết cho tối ưu, bao gồm tối ưu không ràng buộc (Chương 12) và tối ưu có ràng buộc (xem\\nPhần VII).\\nTrong các chương tiếp theo của cuốn sách này, chúng ta sẽ dần làm quen với các thành phần\\ncơ bản của một hệ thống machine learning.\\n5 Lưu ý rằng cực tiểu trong toán học không có nghĩa là nhỏ nhất.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 82, 'page_label': '71'}, page_content='Chương 6\\nGiới thiệu về feature engineering\\n6.1 Giới thiệu\\nMỗi điểm dữ liệu trong các bài toán machine learning thường được biểu diễn bằng một vector\\nđược gọi làvector đặc trưng(feature vector)1. Hơn nữa, trong cùng một bài toán, các feature\\nvector của tất cả các điểm thường có kích thước như nhau. Điều này là cần thiết vì các phép\\ntoán trong mô hình (cộng, nhân ma trận, vector) yêu cầu đầu vào có cùng kích thước. Khi\\nđó, toàn bộdữ liệu có thể được lưu trong một ma trận mà mỗi hàng hoặc mỗi cột là feature\\nvector của một điểm dữ liệu. Tuy nhiên, trên thực tế, dữ liệu thường ở dạngthô (raw data)\\nvới kích thước khác nhau. Hoặc thậm chí khi kích thước của các điểm là như nhau, việc lựa\\nchọn, tính toán đặc trưng nào phù hợp cho mỗi bài toán là nhiệm vụ quan trọng trước tiên\\ncần được giải quyết.\\nVới các bài toánthị giác máy tính(computer vision), các bức ảnh thường là các ma trận\\nhoặc tensor với kích thước khác nhau. Trong bài toán nhận dạng vật thể trong ảnh, đôi khi\\nta cần làm thêm một bước nữa làxác định vị trí vật thể(object detection), tức là tìm các\\nkhung chứa vật thể cần dự đoán. Ví dụ, trong bài toán nhận dạng khuôn mặt, ta cần tìm\\nđược vị trí các khuôn mặt trong ảnh và cắt ra các khuôn mặt đó trước khi làm các bước\\ntiếp theo. Ngay cả khi đã xác định được các khung chứa các khuôn mặt, ta vẫn phải làm\\nrất nhiều việc vì hình ảnh của khuôn mặt còn phụ thuộc vào góc chụp, ánh sáng, v.v. và rất\\nnhiều yếu tố khác nữa.\\nCác bài toánxử lý ngôn ngữ tự nhiên(natural language processing–NLP) cũng có khó khăn\\ntương tự khi độ dài của các văn bản là khác nhau, thậm chí có những từ rất hiếm gặp hoặc\\nkhông có trong từ điển. Cũng có khi thêm một vài từ vào văn bản mà nội dung của văn bản\\nkhông đổi hoặc hoàn toàn mang nghĩa ngược lại. Hoặc cùng là một câu nói nhưng tốc độ,\\nâm giọng của mỗi người là khác nhau, tại các thời điểm khác nhau là khác nhau.\\n1 Trong các hệ thống deep learning, một bức ảnh hai chiều có thể được trực tiếp đưa vào hệ thống mà không cần\\nqua nhiều bước feature engineering. Cuốn sách này chỉ làm việc với các đặc trưng ở dạng vector cột.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 83, 'page_label': '72'}, page_content='CHƯƠNG 6. GIỚI THIỆU VỀ FEATURE ENGINEERING 72\\nKhi làm việc với các bài toán machine learning thực tế, nhìn chung chúng ta chỉ có được\\ndữ liệu thô chưa qua chỉnh sửa, chọn lọc. Ngoài ra, chúng ta có thể phải tìm cách loại ra\\nnhững dữ liệu nhiễu, và để đưa dữ liệu thô với kích thước, hay số chiều khác nhau về cùng\\nmột chuẩn (cùng là các vector hoặc ma trận). Dữ liệu chuẩn mới này phải đảm bảo giữ được\\nnhững thông tin đặc trưng cho dữ liệu thô ban đầu. Không những thế, tùy vào từng bài\\ntoán, ta cần thiết kế những phép biến đổi để có những đặc trưng phù hợp. Quá trình quan\\ntrọng này được gọi làtrích chọn đặc trưng(feature engineeringhay feature extraction).\\nXin trích một câu nói (xin không dịch) của Andrew Ng2:\\nComing up with features is difficult, time-consuming, requires expert knowledge. “Applied\\nmachine learning” is basically feature engineering.\\nĐể có cái nhìn tổng quan, trong mục tiếp theo, bước feature engineering này sẽ được đặt\\ntrong một bức tranh lớn hơn.\\n6.2 Mô hình chung cho các bài toán Machine Learning\\nPhần lớn các mô hình machine learning có thể được minh hoạ trong Hình 6.1. Có hai bước\\n(phase) lớn trong mỗi bài toán machine learning là bước huấn luyện (training phase) và bước\\nkiểm thử (test phase). Bước huấn luyện sẽ chỉ dùng dữ liệu huấn luyện, bước kiểm thử sẽ\\nchỉ dùng dữ liệu trong tập kiểm thử3.\\n6.2.1 Training phase\\nCó hai khối có nền màu lục cần được thiết kế:\\nKhối thứ nhất,Feature Extraction, có nhiệm vụ tạo ra một vector đặc trưng cho mỗi\\nđiểm dữ liệu đầu vào. Vector đặc trưng này thường có kích thước như nhau, bất kể dữ liệu\\nđầu vào có kích thước như thế nào.\\nĐầu vào của khối Feature Extraction có thể là các yếu tố sau:\\n• Dữ liệu thô ban đầu(raw training input). Dữ liệu thô bao gồm tất cả các thông tin ta\\nbiết về dữ liệu. Ví dụ: dữ liệu thô của một ảnh là giá trị của từng pixel; của một văn\\nbản là từng từ, từng câu; của một file âm thanh là một đoạn tín hiệu; với bài toán dự\\nbáo thời tiết, dữ liệu thô là thông tin về hướng gió, nhiệt độ, độ ẩm,v.v.. Dữ liệu thô này\\nthường không ở dạng vector và không có số chiều như nhau. Thậm chí có thể có số chiều\\nnhư nhau nhưng số chiều quá lớn, chẳng hạn một bức ảnh màu1000 ×1000 pixel sẽ có\\nsố pixel là đã là3 ×106 (ảnh màu thường có ba channel: red, green, blue–RGB). Đây là\\nmột con số quá lớn, không lợi cho lưu trữ và tính toán.\\n2 Feature Engineering– Wikipedia(https://goo.gl/v4e21T )\\n3 Trước khi đánh giá một mô hình trên tập kiểm thử, ta cần đảm bảo rằng mô hình đó đã làm việc tốt trên tập\\nhuấn luyện.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 84, 'page_label': '73'}, page_content='73 CHƯƠNG 6. GIỚI THIỆU VỀ FEATURE ENGINEERING\\nTRAINING PHASE\\nRaw training\\ndata (input)\\nTraining output\\n(ytrain)\\nPrior knowledge\\nabout data\\nFeature\\nExtraction\\n(Feature\\nEngineering)\\nExtracted\\nfeatures\\n(Xtrain)\\n Classiﬁcation,\\nRegression,\\nClustering,...\\nAlgorithms\\nTEST PHASE\\nRaw test\\ndata (input)\\n Feature\\nExtraction\\n(Feature\\nEngineering)\\nExtracted\\nfeatures\\n(Xtest)\\n Classiﬁcation,\\nRegression,\\nClustering,...\\nAlgorithms\\nTest output\\n(ytest)\\nHình 6.1: Mô hình thường gặp trong các bài toán machine learning.\\n• output của training set. Trong các bài toán unsupervised learning, ta không biết\\noutput nên hiển nhiên sẽ không có giá trị này. Trong các bài toán supervised learning, có\\nkhi dữ liệu này cũng không được sử dụng. Ví dụ, nếuraw input đã có cùng số chiều rồi\\nnhưng số chiều quá lớn, ta muốn giảm số chiều của nó thì cách đơn giản nhất làchiếu\\nvector đó xuống một không gian có số chiều nhỏ hơn bằng cách lấy một ma trận ngẫu\\nnhiên nhân với nó vào bên trái. Ma trận này thường là ma trậnbéo, tức có số hàng ít\\nhơn số cột, để đảm bảo số chiều thu được nhỏ hơn số chiều ban đầu. Việc làm này mặc\\ndù làm mất đi thông tin, trong nhiều trường hợp vẫn mang lại hiệu quả vì đã giảm được\\nlượng tính toán ở phần sau. Đôi khima trận chiếukhông phải là ngẫu nhiên mà có thể\\nđược học dựa trên toàn bộ dữ liệu thô ban đầu. Trong nhiều trường hợp khác, dữ liệu\\noutput của tập huấn luyện cũng được sử dụng để tạo ra bộ trích chọn đặc trưng. Trong\\nbài toán classification, việc giữ lại nhiều thông tin không quan trọng bằng việc giữ lại các\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 85, 'page_label': '74'}, page_content='CHƯƠNG 6. GIỚI THIỆU VỀ FEATURE ENGINEERING 74\\nthông tin có ích cho bài toán. Ví dụ, giả sử dữ liệu thô là các hình vuông và hình tam\\ngiác có màu đỏ và xanh. Trong bài toán phân loại đa giác, nếu các nhãn làtam giác và\\nvuông, ta không quan tâm tới màu sắc mà chỉ quan tâm tới số cạnh của đa giác. Ngược\\nlại, trong bài toán phân loại màu, các nhãn làxanh vàđỏ, ta không quan tâm tới số cạnh\\nmà chỉ quan tâm đến màu sắc.\\n• Prior knowledge about data: Các thông tin khác đã biết về loại dữ liệu (ngoài những\\nthông tin về raw input và output).\\nSau khi các tham số mô hình của bộ feature extraction được thiết kế, dữ liệu thô ban đầu\\nđược đưa qua và tạo ra các vector đặc trưng tương ứng được gọi làextracted feature. Những\\nextracted feature này sẽ được đưa vào huấn luyện các thuật toán chính như classification,\\nregression, clustering, v.v. trong khối màu lục phía sau.\\nTrong một số thuật toán cao cấp hơn, việc xây dựng bộ trích chọn đặc trưng và các\\nthuật toán chính (classification, clustering, v.v.) có thể được thực hiện cùng lúc với\\nnhau thay vì từng bước như trên. Các mô hình đó có tên gọi chung là end-to-end. Với\\nsự phát triển của deep learning trong những năm gần đây, người ta cho rằng các hệ\\nthống end-to-end (từ đầu đến cuối) mang lại kết quả tốt hơn nhờ vào việc hai khối\\nphía trên được huấn luyện cùng nhau, bổ trợ lẫn nhau cùng hướng tới mục đích cuối\\ncùng. Thực tế cho thấy, các phương pháp state-of-the-art (các phương pháp hiệu quả\\nnhất) thường là các mô hình end-to-end.\\n6.2.2 Testing phase\\nKhi có dữ liệu thô mới, ta sử dụng bộ trích chọn đặc trưng đã tìm được ở trên để tạo ra\\nvector đặc trưng ứng với dữ liệu thô đó. Vector đặc trưng này được đưa vào thuật toán chính\\nđã tìm được để đưa ra quyết định.\\n6.3 Một số ví dụ về Feature Engineering\\n6.3.1 Trực tiếp lấy dữ liệu thô\\nXét một bài toán phân loại các bức ảnh xám mà mỗi bức ảnh đã có kích thước cố định là\\nm×n pixel. Cách đơn giản nhất để tạo ra vector đặc trưng cho bức ảnh này làkéo dàima\\ntrận các pixel thành một vector cómnphần tử, hay đặc trưng. Khi đó, giá trị mỗi đặc trưng\\nsẽ là một giá trị của một pixel trong bức ảnh ban đầu, thứ tự không quan trọng. Kỹ thuật\\nnày còn được gọi làvector hoá (vectorization).\\nViệc làm đơn giản này đã làm mấtthông tin về không gian(spatial information) giữa các\\nđiểm ảnh vì các pixel gần nhau theo phương ngang trong bức ảnh ban đầu có thể không còn\\ngần nhau trong vector đặc trưng mới nữa. Tuy nhiên, trong nhiều trường hợp, kỹ thuật này\\nvẫn mang lại kết quả khả quan.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 86, 'page_label': '75'}, page_content='75 CHƯƠNG 6. GIỚI THIỆU VỀ FEATURE ENGINEERING\\n6.3.2 Lựa chọn đặc trưng\\nGiả sử rằng các điểm dữ liệu có số đặc trưng khác nhau (do kích thước dữ liệu khác nhau\\nhay do một số đặc trưng mà điểm dữ liệu này có nhưng điểm dữ liệu kia lại không thu thập\\nđược), và số lượng đặc trưng là cực lớn. Chúng ta cầnchọn ra một số lượng nhỏ hơn các đặc\\ntrưng phù hợp với bài toán.\\n6.3.3 Giảm chiều dữ liệu\\nMột phương pháp khác thường được dùng làlàm giảm số chiều dữ liệu (dimensionality\\nreduction) để giảm bộ nhớ và khối lượng tính toán. Việc giảm số chiều này có thể được\\nthực hiện bằng nhiều cách, trong đóchiếu ngẫu nhiên(random projection) là cách đơn giản\\nnhất. Trong phương pháp này, mộtma trận chiếu(projection matrix) ngẫu nhiên được chọn,\\nthường là một ma trận béo–số cột nhiều hơn số hàng, để nhân vào bên trái của từng vector\\nđặc trưng ban đầu để được các vector đặc trưng có số chiều thấp hơn. Cụ thể, giả sử vector\\nđặc trưng ban đầu làx0 ∈RD, nếu ta chọn một ma trận chiếuP ∈Rd×D với d≪D, vector\\nmới x1 = Px0 ∈Rd có số chiều nhỏ hơn số chiều của vectorx0 ban đầu.\\nViệc chọn một ma trận chiếu ngẫu nhiên đôi khi mang lại kết quả tệ không mong muốn vì\\nthông tin có thể bị mất đi quá nhiều. Một phương pháp được sử dụng nhiều để tối thiểu lượng\\nthông tin mất đi có tên là principal component analysis sẽ được trình bày trong Chương 21.\\nLưu ý:Feature engineering không nhất thiết phải làm giảm số chiều dữ liệu, đôi khi vector\\nđặc trưng có thể có có kích thước lớn hơn dữ liệu thô ban đầu.\\n6.3.4 Bag of words\\nChúng ta hẳn đã tự đặt ra các câu hỏi: với một văn bản, vector đặc trưng sẽ có dạng như\\nthế nào? Làm sao đưa các từ, các câu, đoạn văn ở dạngtext trong các văn bản về một vector\\nmà mỗi phần tử là một số?\\nCó một kỹ thuật rất phổ biến trong xử lý văn bản có tên làtúi đựng từ(bag of words–BoW).\\nBắt đầu bằng ví dụ phân loại tin nhắn rác. Ta thấy rằng nếu một tin có chứa các từkhuyến\\nmại, giảm giá, trúng thưởng, miễn phí, quà tặng, tri ân, v.v., nhiều khả năng đó là một tin\\nnhắn rác. Từ đó, phương pháp đầu tiên có thể nghĩ tới làđếm xem trong tin đó có bao nhiêu\\ntừ thuộc vào các từ trên, nếu số lượng này nhiều hơn một ngưỡng nào đó thì ta quyết định\\nđó là tin rác. (Tất nhiên bài toán thực tế phức tạp hơn nhiều khi các từ có thể được viết\\ndưới dạng không dấu, hoặc bị cố tình viết sai chính tả, hoặc dùng ngôn ngữ teen). Với các\\nloại văn bản khác nhau, lượng từ liên quan tới từng chủ đề cũng khác nhau. Từ đó có thể\\ndựa vào số lượng các từ trong từng loại để tạo các vector đặc trưng cho từng văn bản.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 87, 'page_label': '76'}, page_content='CHƯƠNG 6. GIỚI THIỆU VỀ FEATURE ENGINEERING 76\\nXin lấy một ví dụ về hai văn bản đơn giản sau đây4:\\n(1) \"John likes to watch movies. Mary likes movies too.\"\\nvà\\n(2) \"John also likes to watch football games.\"\\nDựatrên haivăn bảnnày,ta códanhsáchcác từđượcsử dụng,được gọi là từ điển(dictionary\\nhoặc codebook) với mườitừ như sau:\\n[\"John\", \"likes\", \"to\", \"watch\", \"movies\", \"also\", \"football\", \"games\", \"Mary\", \"too\"]\\nVới mỗi văn bản, ta sẽ tạo ra một vector đặc trưng có số chiều bằng 10, mỗi phần tử đại\\ndiện cho số từ tương ứng xuất hiện trong văn bản đó. Với hai văn bản trên, ta sẽ có hai\\nvector đặc trưng\\n(1) [1, 2, 1, 1, 2, 0, 0, 0, 1, 1]\\n(2) [1, 1, 1, 1, 0, 1, 1, 1, 0, 0]\\nVăn bản (1) có 1 từ\"John\", 2 từ\"likes\", 0 từ\"also\", 0 từ\"football\", v.v. nên ta thu được\\nvector tương ứng như trên.\\nCó một vài điều cần lưu ý trong BoW:\\n• Với những ứng dụng thực tế,từ điểncó nhiều hơn mười từ rất nhiều, có thể đến cả triệu,\\nnhư vậy vector đặc trưng thu được sẽ rất dài. Một văn bản chỉ có một câu, và một tiểu\\nthuyết nghìn trang đều được biểu diễn bằng các vector có kích thước như nhau.\\n• Có rất nhiều từ trong từ điển không xuất hiện trong một văn bản. Như vậy các vector\\nđặc trưng thu được thường có rất nhiều phần tử bằng không. Các vector có nhiều phần\\ntử bằng không được gọi làvector thưa(sparse vector). Để việc lưu trữ được hiệu quả hơn,\\nta không lưu cả vector đó mà chỉ lưuvị trí của các phần tử khác 0 vàgiá trịtương ứng.\\nChú ý rằng nếu có hơn một nửa số phần tử khác không, việc làm này lại phản tác dụng.\\nTuy nhiên, trường hợp này ít xảy ra vì hiếm có văn bản nào lại chứa tới một nửa từ điển.\\n• Ta xử lý các từ hiếm gặp không nằm trong từ điển như thế nào? Một kỹ thuật thường\\nđược dùng là thêm phần tử<Unknown> vào trong từ điển. Mọi từ không có trong từ điển\\nđều được coi là<Unknown>. Lúc này, kích thước của vector đặc trưng sẽ tăng lên một.\\n• Tuy nhiên, những từ hiếm đôi khi lại mang những thông tin quan trọng nhất mà chỉ loại\\nvăn bản đó có. Đây là một nhược điểm của BoW. Có một phương pháp cải tiến giúp\\n4 Bag of words–Wikipedia(https://goo.gl/rBtZqx )\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 88, 'page_label': '77'}, page_content='77 CHƯƠNG 6. GIỚI THIỆU VỀ FEATURE ENGINEERING\\nkhắc phục nhược điểm này có tên làterm frequency-inverse document frequency(TF-\\nIDF) [SWY75] dùng để xác định tầm quan trọng của một từ trong một văn bản dựa trên\\ntoàn bộ văn bản trong cơ sở dữ liệu5.\\n• Nhược điểm lớn nhất của BoW là nó không mang thông tin về thứ tự của các từ, cũng\\nnhư sự liên kết giữa các câu, các đoạn văn trong văn bản. Thứ tự của các từ trong văn\\nbản thường mang thông tin quan trọng. Ví dụ, ba câu sau đây: “Em yêu anh không?”,\\n“Em không yêu anh”, và “Không, (nhưng) anh yêu em” khi được trích chọn đặc trưng\\nbằng BoW sẽ cho ra ba vector giống hệt nhau, mặc dù ý nghĩa khác hẳn nhau.\\n6.3.5 Bag of words trong computer vision\\nBag of words cũng được áp dụng trong computer vision cho các bức ảnh với cách định nghĩa\\ntừ và từ điển khác. Xét các ví dụ sau:\\nVí dụ 1:Có hai class ảnh, một class là ảnh các khu rừng, một class là ảnh các sa mạc. Giả\\nsử ta biết rằng một bức ảnh chỉ thuộc một trong hai loại này, việc phân loại một bức ảnh\\nlà rừng hay sa mạc một cách trực quan nhất là dựa vào màu sắc. Màu xanh lục nhiều thì\\nlà rừng, màu đỏ và vàng nhiều thì là sa mạc. Vậy chúng ta có thể có một mô hình đơn giản\\nđể trích chọn đặc trưng như sau:\\n• Với một bức ảnh, chuẩn bị một vectorx có số chiều bằng 3, đại diện cho ba màu xanh\\nlục (x1), đỏ (x2), và vàng (x3).\\n• Với mỗi điểm ảnh trong bức ảnh đó, xem nó gần với màu xanh, đỏ hay vàng nhất dựa\\ntrên giá trị của pixel đó. Nếu nó gần điểm xanh nhất, tăngx1 lên một; gần đỏ nhất, tăng\\nx2 lên một; gần vàng nhất, tăngx3 lên một.\\n• Sau khi xem xét tất cả các điểm ảnh, dù cho bức ảnh có kích thước thế nào, ta vẫn thu\\nđược một vector có kích thước bằng ba, mỗi phần tử thể hiện việc có bao nhiêu pixel\\ntrong bức ảnh có màu tương ứng. Vector cuối này còn được gọi làhistogram vectorcủa\\nbức ảnh tương ứng với ba màu xanh, đỏ, vàng. Vector này có thể coi là một đặc trưng\\ntốt trong bài toán phân lớp ảnh rừng hay say mạc.\\nVí dụ 2:Trên thực tế, các bài toán xử lý ảnh không đơn giản như Ví dụ 1 trên đây. Mắt\\nngười thực ra nhạy với các đường nét, hình dáng hơn là màu sắc. Chúng ta có thể nhận biết\\nđược một bức ảnh có cây hay không ngay cả khi bức ảnh đó không có màu. Vì vậy, xem xét\\ngiá trị từng điểm ảnh một không mang lại kết quả khả quan vì lượng thông tin về đường\\nnét bị mất quá nhiều.\\nCó một giải pháp là thay vì xem xét một điểm ảnh, ta xem xét một vùng hình chữ nhật nhỏ\\ntrong ảnh, vùng này còn được gọi làpatch. Các patch này nên đủ lớn để có thể chứa được\\ncác bộ phận có thể mô tả được vật thể trong ảnh. Ví dụ với mặt người, các patch nên đủ\\nlớn để chứa được các phần của khuôn mặt như mắt, mũi, miệng như trong Hình 6.2. Tương\\n5 5 Algorithms Every Web Developer Can Use and Understand, section 5(https://goo.gl/LJW3H1 ).\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 89, 'page_label': '78'}, page_content='CHƯƠNG 6. GIỚI THIỆU VỀ FEATURE ENGINEERING 78\\nHình 6.2:Bag of words cho ảnh chứa mặt người (Nguồn:Bag of visual words model: recognizing\\nobject categories(https://goo.gl/EN2oSM ).\\ntự thế, với ảnh là ô tô, các patch thu được có thể là bánh xe, khung xe, cửa xe, v.v. trên\\nHình 6.3, hàng trên bên phải.\\nMột câu hỏi được đặt ra là, trong xử lý văn bản, hai từ được coi là như nhau nếu nó được\\nbiểu diễn bởi các ký tự giống nhau. Vậy trong xử lý ảnh, hai patch được coi là như nhau khi\\nnào? Khi mọi pixel trong hai patch có giá trị bằng nhau sao?\\nCâu trả lời là không. Xác suất để hai patch giống hệt nhau từng pixel là rất thấp vì có thể\\nmột phần của vật thể trong một patch bị lệch đi vài pixel so với phần đó trong patch kia;\\nhoặc phần vật thể trong patch bị méo, hoặc có độ sáng khác nhau, mặc dù mắt người vẫn\\nnhìn thấy hai patch đórất giống nhau. Vậy thì hai patch được coi là như nhau khi nào? Và\\ntừ điển ở đây được định nghĩa như thế nào?\\nCâu trả lời ngắn cho câu hỏi này là hai patch được coi là gần giống nhau nếu khoảng cách\\nEuclid giữa hai vector tạo bởi hai patch đó là nhỏ. Từ điển sẽ có số từ do ta tự chọn. Số từ\\ntrong từ điển càng cao thì độ sai lệch càng ít, nhưng sẽ nặng về tính toán hơn.\\nCụ thể hơn chúng ta có thể áp dụng một phương pháp phân nhóm đơn giản làK-means\\nclustering (xem Chương 10). Với rất nhiều patch thu được, giả sử ta muốn xây dựng một từ\\nđiển với chỉ khoảng 1000từ. Ta có thể dùngK-means clustering để phân toàn bộ các patch\\nthành 1000 nhóm (bag) khác nhau. Mỗi nhóm gồm các patch gần giống nhau và được mô\\ntả bằng trung bình cộng của tất cả các patch trong nhóm đó (xem Hình 6.3 hàng dưới). Với\\nmột ảnh bất kỳ, ta trích ra các patch từ ảnh đó, tìm xem mỗi patch gần với nhóm nào nhất\\ntrong 1000 nhóm tìm được ở trên và quyết định patch này thuộc nhóm đó. Cuối cùng, ta\\nsẽ thu được một vector đặc trưng có kích thước bằng 1000 mà mỗi phần tử là số lượng các\\npatch trong ảnh rơi vào nhóm tương ứng.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 90, 'page_label': '79'}, page_content='79 CHƯƠNG 6. GIỚI THIỆU VỀ FEATURE ENGINEERING\\nHình 6.3: Bag of Words cho ảnh xe hơi (Nguồn: B. Leibe).\\n6.4 Transfer Learning cho bài toán phân loại ảnh\\n(Giả sử rằng bạn đọc đã có kiến thức nhất định về deep neural network.)\\nNgoài BoW, các phương pháp thường được sử dụng để xây dựng feature vector cho ảnh là\\nscale invariant feature transform–SIFT[Low99],speeded-up robust features–SURF[BTVG06],\\nhistogram of oriented gradients–HOG[DT05], local binary pattern–LBP[Low99], v.v.. Các\\nbộ phân lớp thường được sử dụng là multi-class SVM (Chương 29), softmax regression\\n(Chương 15), sparse coding và discriminative dictionary learning [WYG+09, VMM+16,\\nVM17], random forest[LW+02], v.v..\\nCác feature được tạo bởi các phương pháp nêu trên thường được gọi là cácfeature được tạo\\nthủ công(hand-crafted feature) vì chúng chủ yếu dựa trên các quan sát về đặc tính riêng của\\nảnh. Các phương pháp này cho kết quả khá ấn tượng trong một số trường hợp. Tuy nhiên,\\nchúng vẫn còn nhiều hạn chế vì quá trình tìm ra các feature và các classifier phù hợp vẫn là\\nriêng biệt.\\nNhững năm gần đây, deep learning phát triển cực nhanh dựa trên lượng dữ liệu huấn luyện\\nkhổng lồ và khả năng tính toán ngày càng được cải tiến của các máy tính. Các kết quả cho\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 91, 'page_label': '80'}, page_content='CHƯƠNG 6. GIỚI THIỆU VỀ FEATURE ENGINEERING 80\\nInput Hidden 1 ...\\nFully connected layer\\nsoftmax or multi-class\\nSVM\\nFeature vector\\nSecond to last Output\\nHình 6.4:Mô hình chung cho các bài toán classification sử dụng Deep Learning. Layer cuối cùng\\nthường là một Fully Connected Layer và thường là một Softmax Regression.\\nbài toán phân loại ảnh ngày càng được nâng cao. Bộ cơ sở dữ liệu thường được dùng nhất là\\nImageNet (https://www.image-net.org ) 1.2 triệu ảnh cho 1000 class khác nhau. Rất nhiều\\ncác mô hình deep learning đã giành chiến thắng trong các cuộc thiImageNet large scale vi-\\nsual recognition challenge–ILSVRC: AlexNet [KSH12], ZFNet [ZF14], GoogLeNet [SLJ+15],\\nResNet [HZRS16], VGG [SZ14]. Nhìn chung, các mô hình này là các neural network với rất\\nnhiều layer (xem Chương 16). Các layer phía trước thường là các convolutional layer. Layer\\ncuối cùng là một fully connected layer và thường là một softmax regression (xem Hình 6.4).\\nSố lượng unit ở layer cuối cùng bằng với số lượng class (với ImageNet là 1000). Vì vậy out-\\nput ở layer gần cuối cùng (second to last layer) có thể được coi là feature vector và softmax\\nregression chính là classifier được sử dụng.\\nChính nhờ việc các feature và classifier được huấn luyện cùng nhau thông qua việc tối ưu\\ncác hệ số trong deep network khiến cho các mô hình này đạt kết quả tốt. Tuy nhiên, những\\nmô hình này đều bao gồm rất nhiều layer và các trọng số. Việc huấn luyện dựa trên 1.2M\\nbức ảnh của ImageNet cũng tốn rất nhiều thời gian (2-3 tuần).\\nVới các bài toán dựa trên tập dữ liệu khác với ít dữ liệu hơn, ta có thể không cần xây dựng\\nlại network và huấn luyện nó từ đầu. Thay vào đó, ta có thể sử dụng các mô hình đã được\\nhuấn luyện nêu trên, và sử dụng một vài kỹ thuật khác để giải quyết bài toán. Phương pháp\\nsử dụng các mô hình có sẵn như thế này được gọi làtransfer learning.\\nNhư đã đề cập, toàn bộ các layer trừ output layer có thể được coi là một feature extractor.\\nDựa trên nhận xét rằng các bức ảnh đều có những đặc tính giống nhau nào đó, với cơ sở dữ\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 92, 'page_label': '81'}, page_content='81 CHƯƠNG 6. GIỚI THIỆU VỀ FEATURE ENGINEERING\\nliệu khác, ta cũng có thể sử dụng phần feature extractor này để tạo ra các feature vector.\\nSau đó, ta thay output layer cũng bằng một softmax regression, multi-class SVM (với số\\nlượng unit phù hợp) hoặc các classifier phổ biến khác. Cách làm này có thể tăng độ chính\\nxác phân lớp lên đáng kể so với việc sử dụng cáchand-crafted features.\\nHướng tiếp cận thứ hai là sử dụng các mô hình đã được huấn luyện và cho cập nhật một vài\\nlayer cuối dựa trên dữ liệu mới thêm một vài vòng lặp. Kỹ thuật này được gọi làtinh chỉnh\\n(fine-tuning). Việc này được dựa trên quan sát rằng những layer đầu trong deep network\\nthường giúp trích xuất những đặc tính chung của ảnh (các cạnh, còn được gọi làlow-level\\nfeature), các layer cuối thường mang những đặc trưng riêng của cơ sở dữ liệu (CSDL) (và\\nđược gọi làhigh-level feature). Vì vậy, việc huấn luyện các layer cuối mang nhiều giá trị hơn.\\nDựa trên kích thước và độ tương quan giữa CSDL mới và CSDL gốc (chủ yếu là ImageNet),\\ncó một vài quy tắc để huấn luyện network mới như sau6:\\n• CSDL mới là nhỏ và tương tự như CSDL gốc.Vì CSDL mới nhỏ, việc tiếp tục huấn luyện\\nmô hình có thể dễ dẫn đến hiện tượng overfitting (Chương 8). Cũng vì hai CSDL là tương\\ntự nhau, ta dự đoán rằng các high-level feature của chúng là tương tự nhau. Vì vậy, ta\\nkhông cần huấn luyện lại network mà chỉ cần huấn luyện một classifer dựa trên feature\\nvector ở đầu ra ở layer gần cuối.\\n• CSDL mới là lớn và tương tự như CSDL gốc.Vì CSDL này lớn, overfitting ít có khả năng\\nxảy ra hơn, ta có thể huấn luyện mô hình thêm một một vài vòng lặp. Việc huấn luyện\\ncó thể được thực hiện trên toàn bộ hoặc chỉ một vài layer cuối.\\n• CSDL mới là nhỏ và rất khác với CSDL gốc.Vì CSDL này nhỏ, tốt hơn hết là dùng các\\nclassifier đơn giản để tránh overfitting. Nếu muốn huấn luyện thêm, ta cũng chỉ nên thực\\nhiện trên các layer cuối. Hoặc sử dụng một kỹ thuật khác là coi đầu ra của một layerxa\\nlayer cuối hơn (xa hơn layer gần cuối) làm các feature vector.\\n• CSDL mới là lớn và rất khác CSDL gốc.Thực tế cho thấy, sử dụng các network sẵn có\\ntrên CSDL mới vẫn hữu ích. Trong trường hợp này, ta vẫn có thể sử dụng các network\\nsẵn có như là điểm khởi tạo của network mới, không nên huấn luyện network mới từ đầu.\\nCó một điểm đáng chú ý nữa là khi tiếp tục huấn luyện các network này, ta chỉ nên chọn\\nlearning ratenhỏ để các hệ số mới không đi quá xa so với các hệ số đã được huấn luyện ở\\ncác mô hình trước.\\n6.5 Chuẩn hoá vector đặc trưng\\nCác điểm dữ liệu đôi khi được đo đạc với những đơn vị khác nhau, mét và feet chẳng hạn.\\nHoặc có hai thành phần (của vector dữ liệu) chênh lệch nhau quá lớn, một thành phần có\\nkhoảng giá trị từ 0 đến 1000, thành phần kia chỉ có khoảng giá trị từ 0 đến 1 chẳng hạn.\\nLúc này, chúng ta cần chuẩn hóa dữ liệu trước khi thực hiện các bước tiếp theo.\\n6 Transfer Learning, CS231n(https://goo.gl/VN1g7F )\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 93, 'page_label': '82'}, page_content='CHƯƠNG 6. GIỚI THIỆU VỀ FEATURE ENGINEERING 82\\nChú ý:việc chuẩn hóa này chỉ được thực hiện khi vector dữ liệu đã có cùng chiều.\\nMột vài phương pháp chuẩn hóa thường dùng:\\n6.5.1 Rescaling\\nPhương pháp đơn giản nhất là đưa tất cả các đặc trưng về cùng một khoảng, chẳng hạn\\n[0,1] hoặc [−1,1] tùy thuộc vào ứng dụng. Nếu muốn đưa đặc trưng thứi của một vector\\nđặc trưngx về khoảng[0,1], công thức sẽ là:\\nx′\\ni = xi −min(xi)\\nmax(xi) −min(xi)\\ntrong đó xi và x′\\ni lần lượt là giá trị đặc trưng ban đầu và giá trị đặc trưng sau khi được\\nchuẩn hóa. min(xi),max(xi) là giá trị nhỏ nhất và lớn nhất của đặc trưng thứi xét trên\\ntoàn bộ các điểm dữ liệu của tập huấn luyện.\\n6.5.2 Standardization\\nMột phương pháp khác cũng thường được sử dụng là giả sử mỗi đặc trưng đều có phân phối\\nchuẩn với kỳ vọng là 0 và phương sai là 1. Khi đó, công thức chuẩn hóa sẽ là\\nx′\\ni = xi −¯xi\\nσi\\nvới ¯xi,σi lần lượt là kỳ vọng và độ lệch chuẩn (standard deviation) của đặc trưng đó xét trên\\ntoàn bộ dữ liệu huấn luyện.\\n6.5.3 Scaling to unit length\\nMột lựa chọn khác cũng được sử dụng rộng rãi là chuẩn hóa các thành phần của mỗi vector\\ndữ liệu sao cho toàn bộ vector có độ dài Euclid bằng một. Việc này có thể được thực hiện\\nbằng cách chia mỗi vector đặc trưng choℓ2 norm của nó:\\nx′= x\\n∥x∥2\\n6.6 Đọc thêm\\n1. G. Csurkaet al., Visual categorization with bags of keypoints. Workshop on statistical\\nlearning in computer vision, ECCV. Vol. 1. No. 1-22. 2004 [CDF+04].\\n2. S. Lazebnik et al., Beyond bags of features: Spatial pyramid matching for recognizing\\nnatural scene categories., CVPR 2006 [LSP06]\\n3. Preprocessing data, scikit learn(https://goo.gl/gkCuUp ).\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 94, 'page_label': '83'}, page_content='Chương 7\\nLinear regression\\nTrong chương này, chúng ta cùng làm quen với một trong những thuật toán machine learning\\ncơ bản nhất–linear regression (hồi quy tuyến tính). Qua chương này, bạn đọc sẽ có cái nhìn\\nban đầu về việc xây dựng một hệ thống machine learning. Linear regression là một thuật\\ntoán supervised, ở đó quan hệ giữa đầu vào và đầu ra được mô tả bởi một hàm tuyến tính.\\nThuật toán này còn được gọi làlinear fittinghoặc linear least square.\\n7.1 Giới thiệu\\nXét bài toán ước lượng giá của một căn nhà rộngx1 m2, cóx2 phòng ngủ và cách trung tâm\\nthành phốx3 km. Giả sử ta đã thu thập được số liệu từ 1000 căn nhà trong thành phố đó,\\nliệu rằng khi có một căn nhà mới với các thông số về diện tíchx1, số phòng ngủx2 và khoảng\\ncách tới trung tâmx3, chúng ta có thể dự đoán được giáy của căn nhà đó không? Nếu có\\nthì hàm dự đoány= f(x) sẽ có dạng như thế nào. Ở đây, vector đặc trưngx = [x1,x2,x3]T\\nlà một vector cột chứa thông tin đầu vào, đầu ray là một số vô hướng.\\nMột cách trực quan, ta có thể thấy rằng: (i) diện tích nhà càng lớn thì giá nhà càng cao; (ii)\\nsố lượng phòng ngủ càng lớn thì giá nhà càng cao; (iii) càng xa trung tâm thì giá nhà càng\\ngiảm. Dựa trên quan sát này, ta có thể mô hình quan hệ giữa đầu ra và đầu vào bằng một\\nhàm tuyến tính đơn giản:\\ny≈ˆy= f(x) = w1x1 + w2x2 + w3x3 = xTw (7.1)\\ntrong đów = [w1,w2,w3]T là vector hệ số (hoặc trọng số–weight vector) ta cần đi tìm. Đây\\ncũng chính là tham số mô hình của bài toán. Mối quan hệy≈f(x) như trong (7.1) là một\\nmối quan hệ tuyến tính.\\nBài toán trên đây là bài toán dự đoán giá trị của đầu ra dựa trên vector đặc trưng đầu vào.\\nNgoài ra, giá trị của đầu ra có thể nhận rất nhiều giá trị thực dương khác nhau. Vì vậy,\\nđây là một bài toán regression. Mối quan hệˆy = xTw là một mối quan hệ tuyến tính. Tên\\ngọilinear regressionxuất phát từ đây.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 95, 'page_label': '84'}, page_content='CHƯƠNG 7. LINEAR REGRESSION 84\\nChú ý:\\n1. ylà giá trị thực của đầu ra(ground truth), trong khiˆylà giá trịđầu ra dự đoán(predicted\\noutput) của mô hình linear regression. Nhìn chung,y và ˆy là hai giá trị khác nhau do có\\nsai số mô hình, tuy nhiên, chúng ta mong muốn rằng sự khác nhau này rất nhỏ.\\n2. Linear hay tuyến tính hiểu một cách đơn giản làthẳng, phẳng. Trong không gian hai\\nchiều, một hàm số được gọi làtuyến tính nếu đồ thị của nó có dạng mộtđường thẳng.\\nTrong không gian ba chiều, một hàm số được goi làtuyến tính nếu đồ thị của nó có\\ndạng mộtmặt phẳng. Trong không gian nhiều hơn ba chiều, khái niệmmặt phẳngkhông\\ncòn phù hợp nữa, thay vào đó, một khái niệm khác ra đời được gọi làsiêu mặt phẳng\\n(hyperplane). Các hàm số tuyến tính là các hàm đơn giản nhất, vì chúng thuận tiện trong\\nviệc hình dung và tính toán.\\n7.2 Xây dựng và tối ưu hàm mất mát\\n7.2.1 Sai số dự đoán\\nSau khi đã xây dựng được mô hình dự đoán đầu ra như (7.1), ta cần tìm một phép đánh giá\\nphù hợp với bài toán. Với bài toán regression nói chung, ta mong muốn rằng sự sai kháce\\ngiữa giá trị thựcy và giá trị dự đoánˆy là nhỏ nhất. Nói cách khác, chúng ta muốn giá trị\\nsau đây càng nhỏ càng tốt:\\n1\\n2e2 = 1\\n2(y−ˆy)2 = 1\\n2(y−xTw)2 (7.2)\\nở đây ta lấy bình phương vìe = y−ˆy có thể là một số âm. Việc sai số là nhỏ nhất có thể\\nđược mô tả bằng cách lấy trị tuyệt đối|e|= |y−ˆy|, tuy nhiên, cách làm này ít được sử dụng\\nvì hàm trị tuyệt đối không khả vi tại mọi điểm, không thuật tiện cho việc tối ưu sau này.\\nHệ số 1\\n2 sẽ bị triệt tiêu sau này khi lấy đạo hàm củae theo tham số mô hìnhw.\\n7.2.2 Hàm mất mát\\nĐiều tương tự xảy ra với tất cả các cặp(input, output) (xi,yi),i = 1,2,...,N , vớiN là số\\nlượng dữ liệu quan sát được. Điều chúng ta mong muốn–trung bình sai số là nhỏ nhất–tương\\nđương với việc tìmw để hàm số sau đạt giá trị nhỏ nhất:\\nL(w) = 1\\n2N\\nN∑\\ni=1\\n(yi −xT\\ni w)2 (7.3)\\nHàm số L(w) chính là hàm mất mát của linear regression với tham số mô hìnhθ = w.\\nChúng ta luôn mong muốn rằng sự mất mát là nhỏ nhất, điều này có thể đạt được bằng\\ncách tối thiểu hàm mất mát theow:\\nw∗= argmin\\nw\\nL(w) (7.4)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 96, 'page_label': '85'}, page_content='85 CHƯƠNG 7. LINEAR REGRESSION\\nw∗ là nghiệm cần tìm, đôi khi dấu∗ được bỏ đi và nghiệm có thể được viết gọn lại thành\\nw = argmin\\nw\\nL(w).\\nTrung bình sai số\\nViệc lấy trung bình (hệ số 1\\nN) hay lấy tổng trong hàm mất mát, về mặt toán học,\\nkhông ảnh hưởng tới nghiệm của bài toán. Trong machine learning, các hàm mất mát\\nthường có chứa hệ số tính trung bình theo từng điểm dữ liệu trong tập huấn luyện. Khi\\ntính giá trị của hàm mất mát trên tập kiểm thử, ta cũng tính trung bình lỗi của mỗi\\nđiểm. Việc lấy trung bình này quan trọng vì số lượng điểm dữ liệu trong mỗi tập dữ\\nliệu có thể thay đổi. Việc tính toán mất mát trên từng điểm dữ liệu sẽ hữu ích hơn\\ntrong việc đánh giá chất lượng mô hình sau này. Ngoài ra, việc lấy trung bình cũng\\ngiúp tránh hiện tượng tràn số khi số lượng điểm dữ liệu quá nhiều.\\nTrước khi đi xây dựng nghiệm cho bài toán tối ưu hàm mất mát, ta thấy rằng hàm số này\\ncó thể được viết gọn lại dưới dạng ma trận, vector, và norm như dưới đây:\\nL(w) = 1\\n2N\\nN∑\\ni=1\\n(yi −xT\\ni w)2 = 1\\n2N\\n\\ued79\\ued79\\ued79\\ued79\\ued79\\ued79\\ued79\\ued79\\ued79\\n\\uf8ee\\n\\uf8ef\\uf8ef\\uf8ef\\uf8f0\\ny1\\ny2\\n...\\nyN\\n\\uf8f9\\n\\uf8fa\\uf8fa\\uf8fa\\uf8fb−\\n\\uf8ee\\n\\uf8ef\\uf8ef\\uf8ef\\uf8f0\\nxT\\n1\\nxT\\n2\\n...\\nxT\\nN\\n\\uf8f9\\n\\uf8fa\\uf8fa\\uf8fa\\uf8fbw\\n\\ued79\\ued79\\ued79\\ued79\\ued79\\ued79\\ued79\\ued79\\ued79\\n2\\n2\\n= 1\\n2N∥y −XTw∥2\\n2 (7.5)\\nvới y = [y1,y2,...,y N]T, X = [x1,x2,..., xN]. Như vậyL(w) là một hàm số liên quan tới\\nbình phương củaℓ2 norm.\\n7.2.3 Nghiệm cho bài toán Linear Regression\\nNhận thấy rằng hàm mất mátL(w) có đạo hàm tại mọiw (xem Bảng 2.1). Vậy việc tìm\\ngiá trị tối ưu củaw có thể được thực hiện thông qua việc giải phương trình đạo hàm của\\nL(w) theo w bằng không. Thật may mắn, đạo hàm của hàm mất mát của linear regression\\nrất đơn giản:\\n∇L(w)\\n∇w = 1\\nNX(XTw −y) (7.6)\\nGiải phương trình đạo hàm bằng không:\\n∇L(w)\\n∇w = 0 ⇔XXTw = Xy (7.7)\\nNếu ma trậnXXT khả nghịch, phương trình (7.7) có nghiệm duy nhấtw = (XXT)−1Xy.\\nNếu ma trậnXXT không khả nghịch, phương trình (7.7) sẽ vô nghiệm hoặc có vô số nghiệm.\\nLúc này, một nghiệm đặc biệt của phương trình có thể được xác định dựa vàogiả nghịch đảo\\n(pseudo inverse). Người ta chứng minh được rằng1 với mọi ma trậnX, luôn tồn tại duy nhất\\n1 Least Squares, Pseudo-Inverse, PCA & SVD(https://goo.gl/RoQ6mS )\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 97, 'page_label': '86'}, page_content='CHƯƠNG 7. LINEAR REGRESSION 86\\nmột giá trịw có ℓ2 norm nhỏ nhất giúp tối thiểu∥XTw −y∥2\\nF. Cụ thể,w = (XXT)†Xy,\\ntrong đó(XXT)†là giả nghịch đảo củaXXT. Giả nghịch đảo của một ma trậnA luôn luôn\\ntồn tại, thậm chí cả khi ma trận đó không vuông. KhiA là vuông và khả nghịch thì giả\\nnghịch đảo chính là nghịch đảo. Nghiệm của bài toán tối ưu (7.4) là\\nw = (XXT)†Xy (7.8)\\nHàm số tính giả nghịch đảo của một ma trận bất kỳ có sẵn trong thư viện numpy.\\n7.2.4 Bias trick\\nChú ý rằng quan hệy = xTw là một quan hệ tuyến tính. Linear regression thường để nói\\ntới một quan hệ hơi phức tạp hơn một chút khi có sự xuất hiện của một số hạng tự dob:\\ny= xTw + b (7.9)\\nMối quan hệ này còn được gọi làaffine. Nếub= 0, đường thẳngy = xTw + b luôn đi qua\\ngốc toạ độ. Việc thêm hệ sốb vào sẽ khiến cho mô hình linh hoạt hơn một chút bằng cách\\nbỏ ràng buộc đường thẳng quan hệ giữa đầu ra và đầu vào luôn đi qua gốc toạ độ. Đại lượng\\nb còn được gọi làbias. Đại lượng này cũng có thểhọc đượcnhư vector hệ sốw.\\nĐể ý thấy rằng, nếu coix0 = 1, ta sẽ có:\\ny= xTw + b= w1x1 + w2x2 + ··· + wdxd + bx0 = ¯xT ¯w (7.10)\\ntrong đó ¯x = [x0,x1,x2,...,x N]T và ¯w = [b,w1,w2,...,w N]. Nếu đặt ¯X = [¯x1,¯x2,..., ¯xN]\\nta sẽ có nghiệm của bài toán tối thiểu hàm mất mát:\\n¯w = argmin\\nw\\n1\\n2N∥y −¯XT ¯w∥2\\n2 = ( ¯X ¯XT)†¯Xy (7.11)\\nKỹ thuật thêm một đặc trưng bằng 1 vào vector đặc trưng và ghép biasb vào vector hệ số\\nw như trên còn được gọi làbias trick. Chúng ta sẽ còn gặp lại kỹ thuật này nhiều lần trong\\ncuốn sách này.\\n7.3 Ví dụ trên Python\\n7.3.1 Bài toán\\nXét một ví dụ đơn giản có thể áp dụng linear regression. Chúng ta cũng sẽ so sánh nghiệm của\\nbài toán khi giải theo phương trình (7.11) và nghiệm tìm được khi dùng thư viện scikit-learn\\ncủa Python.\\nXét ví dụ về dự đoán cân nặng dựa theo chiều cao. Xét bảng cân nặng và chiều cao của 15\\nngười trong Bảng 7.1. Dữ liệu của hai người có chiều cao 155 cm và 160 cm được tách ra\\nlàm test set, phần còn lại tạo thành training set.\\nBài toán đặt ra là: liệu có thể dự đoán cân nặng của một người dựa vào chiều cao của họ\\nkhông? (Trên thực tế, tất nhiên là không, vì cân nặng còn phụ thuộc vào nhiều yếu tố khác\\nnữa, thể tích chẳng hạn). Có thể thấy là cân nặng thường tỉ lệ thuận với chiều cao (càng\\ncao càng nặng), nên có thể sử dụng linear regression cho việc dự đoán này.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 98, 'page_label': '87'}, page_content='87 CHƯƠNG 7. LINEAR REGRESSION\\nBảng 7.1: Bảng dữ liệu về chiều cao và cân nặng của 15 người\\nChiều cao (cm)Cân nặng (kg)Chiều cao (cm)Cân nặng (kg)\\n147 49 168 60\\n150 50 170 72\\n153 51 173 63\\n155 52 175 64\\n158 54 178 66\\n160 56 180 67\\n163 58 183 68\\n165 59\\n7.3.2 Hiển thị dữ liệu trên đồ thị\\nTrước tiên, chúng ta khai báo training data:\\nfrom __future__ import print_function\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\n# height (cm), input data, each row is a data point\\nX = np.array([[147, 150, 153, 158, 163, 165, 168, 170, 173, 175, 178, 180, 183]]).T\\n# weight (kg)\\ny = np.array([ 49, 50, 51, 54, 58, 59, 60, 62, 63, 64, 66, 67, 68])\\nCác điểm dữ liệu được minh hoạ bởi các điểm màu đỏ trong Hình 7.1 Ta thấy rằng dữ liệu\\nđược sắp xếp gần như theo một đường thẳng, vậy mô hình linear regression sau đây có khả\\nnăng cho kết quả tốt:\\n(cân nặng) =w_1*(chiều cao) +w_0\\nở đâyw_0 chính là biasb.\\n7.3.3 Nghiệm theo công thức\\nTiếp theo, chúng ta sẽ tính toán các hệ sốw_1 và w_0 dựa vào công thức (7.11). Chú ý: giả\\nnghịch đảo của một ma trậnA trong Python sẽ được tính bằngnumpy.linalg.pinv(A).\\n# Building Xbar\\none = np.ones((X.shape[0], 1))\\nXbar = np.concatenate((one, X), axis = 1) # each point is one row\\n# Calculating weights of the fitting line\\nA = np.dot(Xbar.T, Xbar)\\nb = np.dot(Xbar.T, y)\\nw = np.dot(np.linalg.pinv(A), b)\\n# weights\\nw_0, w_1 = w[0], w[1]\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 99, 'page_label': '88'}, page_content='CHƯƠNG 7. LINEAR REGRESSION 88\\n140 150 160 170 180 190\\nHeight (cm)\\n45\\n50\\n55\\n60\\n65\\n70\\n75Weight (kg)\\nHình 7.1: Phân bố của các\\nđiểm dữ liệu (màu đỏ) và đường\\nthẳng xấp xỉ tìm được bởi linear\\nregression.\\nĐường thẳng mô tả mối quan hệ giữa đầu vào và đầu ra được cho trên Hình 7.1. Ta thấy\\nrằng các điểm dữ liệu màu đỏ nằm khá gần đường thẳng dự đoán màu xanh. Vậy mô hình\\nlinear regression hoạt động tốt với tập dữ liệu huấn luyện. Bây giờ, chúng ta sử dụng mô\\nhình này để dự đoán dữ liệu trong test set:\\ny1 = w_1*155 + w_0\\ny2 = w_1*160 + w_0\\nprint(’Input 155cm, true output 52kg, predicted output %.2fkg’ %(y1) )\\nprint(’Input 160cm, true output 56kg, predicted output %.2fkg’ %(y2) )\\nKết quả:\\nInput 155cm, true output 52kg, predicted output 52.94kg\\nInput 160cm, true output 56kg, predicted output 55.74kg\\nChúng ta thấy rằng kết quả dự đoán khá gần với số liệu thực tế.\\n7.3.4 Nghiệm theo thư viện scikit-learn\\nTiếp theo, chúng ta sẽ sử dụng thư viện scikit-learn để tìm nghiệm.\\nfrom sklearn import datasets, linear_model\\n# fit the model by Linear Regression\\nregr = linear_model.LinearRegression()\\nregr.fit(X, y) # in scikit-learn, each sample is one row\\n# Compare two results\\nprint(\"scikit-learn’s solution : w_1 = \", regr.coef_[0], \"w_0 = \", regr.intercept_)\\nprint(\"our solution : w_1 = \", w[1], \"w_0 = \", w[0])\\nKết quả dưới đây cho thấy rằng hai cách tính cho kết quả như nhau.\\nscikit-learn solution : w_1 = [ 0.55920496] w_0 = [-33.73541021]\\nour solution : w_1 = [ 0.55920496] w_0 = [-33.73541021]\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 100, 'page_label': '89'}, page_content='89 CHƯƠNG 7. LINEAR REGRESSION\\nx\\ny\\nPolynomial regression\\nTrained model\\n(a)\\n140 150 160 170 180 190\\nHeight (cm)\\n50\\n60\\n70\\n80\\n90Weight (kg)\\n (b)\\nHình 7.2: (a) Polynomial regression bậc ba. (b) Linear regression nhạy cảm với nhiễu nhỏ.\\n7.4 Thảo luận\\n7.4.1 Các bài toán có thể giải bằng linear regression\\nHàm số y ≈f(x) = xTw là một hàm tuyến tính theo cảw và x. Trên thực tế, linear\\nregression có thể áp dụng cho các mô hình chỉ cần tuyến tính theow. Ví dụ,\\ny≈w1x1 + w2x2 + w3x2\\n1 + w4 sin(x2) + w5x1x2 + w0 (7.12)\\nlà một hàm tuyến tính theo w và vì vậy cũng có thể được giải bằng linear regression.\\nVới mỗi vector đặc trưng x = [ x1,x2]T, chúng ta tính toán vector đặc trưng mới mới\\n˜x = [x1,x2,x2\\n1,sin(x2),x1x2]T rồi áp dụng linear regression với dữ liệu mới này. Tuy nhiên,\\nviệc tìm ra các hàm sốsin(x2) hay x1x2 là tương đốikhông tự nhiên. Hồi quy đa thức(poly-\\nnomial regression) thường được sử dụng nhiều hơn với các vector đặc trưng mới có dạng\\n[1,x1,x2\\n1,... ]T. Một ví dụ về hồi quy đa thức bậc 3 được thể hiện trong Hình 7.2a.\\n7.4.2 Hạn chế của linear regression\\nHạn chế đầu tiên của linear regression là nó rấtnhạy cảm với nhiễu(sensitive to noise).\\nTrong ví dụ về mối quan hệ giữa chiều cao và cân nặng bên trên, nếu có chỉ một cặp dữ liệu\\nnhiễu (150 cm, 90kg) thì kết quả sẽ sai khác đi rất nhiều (xem Hình 7.2b).\\nVì vậy, trước khi thực hiện linear regression, các nhiễu cần phải được loại bỏ. Bước này được\\ngọi làtiền xử lý(pre-processing). Hoặc hàm mất mát có thể thay đổi một chút để tránh việc\\ntối ưu các nhiễu bằng cách sử dụngHuber loss(https://goo.gl/TBUWzg ). Linear regression\\nvới Huber loss được gọi làHuber regression, được khẳng định làrobust to noise(ít bị ảnh\\nhưởng hơn bởi nhiễu). Xem thêmHuber Regressor, scikit learn(https://goo.gl/h2rKu5 ).\\nHạn chế thứ hai của linear regression là nókhông biễu diễn được các mô hình phức\\ntạp. Mặc dù trong phần trên, chúng ta thấy rằng phương pháp này có thể được áp dụng\\nnếu quan hệ giữaoutcome và input không nhất thiết phải là tuyến tính, nhưng mối quan\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 101, 'page_label': '90'}, page_content='CHƯƠNG 7. LINEAR REGRESSION 90\\nhệ này vẫn đơn giản nhiều so với các mô hình thực tế. Hơn nữa, việc tìm ra các đặc trưng\\nx2\\n1,sin(x2),x1x2 như ở trên là ít khả thi.\\n7.4.3 Ridge regression\\nTrong trường hợpma trậnXXT không khả nghịch, có một kỹ thuật nhỏ để tránh hiện tượng\\nnày là biến đổiXXT một chút để biến nó trở thànhA = XXT + λI với λ là một số dương\\nrất nhỏ vàI là ma trận đơn vị với bậc phù hợp.\\nMa trậnA là khả nghịch vì nó là một ma trận xác định dương. Thật vậy, với mọiw ̸= 0,\\nwTAw = wT(XXT + λI)w = wTXXTw + λwTw = ∥XTw∥2\\n2 + λ∥w∥2\\n2 >0 (7.13)\\nLúc này, nghiệm của bài toán lày = (XXT + λI)−1Xy. Nếu xét hàm mất mát\\nL2(w) = 1\\n2N(∥y −XTw∥2\\n2 + λ∥w∥2\\n2) (7.14)\\nvới phương trình đạo hàm theow bằng không:\\n∇L2(w)\\n∇w = 0 ⇔ 1\\nN(X(XTw −y) + λw) = 0 ⇔(XXT + λI)w = Xy (7.15)\\nTa thấyw = (XXT+λI)−1Xy chính là nghiệm của bài toán tối thiểuL2(w) trong (7.14). Mô\\nhình machine learning với hàm mất mát (7.14) còn được gọi làridge regression. Ngoài việc\\ngiúp cho phương trình đạo hàm theo hệ số bằng không có nghiệm duy nhất, ridge regression\\ncòn giúp cho mô hình tránh được overfitting như chúng ta sẽ thấy ở Chương 8.\\n7.4.4 Phương pháp tối ưu khác\\nLinear regression là một mô hình đơn giản, lời giải cho phương trình đạo hàm bằng không\\ncũng khá đơn giản.Trong hầu hết các trường hợp, chúng ta không thể giải được phương trình\\nđạo hàm bằng không.Tuy nhiên, nếu một hàm mất mát có đạo hàm không quá phức tạp,\\nnó có thể được giải bằng một phương pháp rất hữu dụng có tên là gradient descent. Trên\\nthực tế, một vector đặc trưng có thể có kích thước rất lớn, dẫn đến ma trậnXXT cũng có\\nkích thước lớn và việc tính ma trận nghịch đảo có thể không lợi về mặt tính toán. Gradient\\ndescent sẽ giúp tránh được việc tính ma trận nghịch đảo. Chúng ta sẽ hiểu kỹ hơn về phương\\npháp này trong Chương 12.\\n7.4.5 Đọc thêm\\n1. Simple Linear Regression Tutorial for Machine Learning(https://goo.gl/WRVda8 ).\\n2. Regularization: Ridge Regression and the LASSO(https://goo.gl/uRzN1K ).\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 102, 'page_label': '91'}, page_content='Chương 8\\nOverfitting\\nOverfitting là một hiện tượng không mong muốn thường gặp, người xây dựng mô hình\\nmachine learning cần nắm được các kỹ thuật để tránh hiện tượng này.\\n8.1 Giới thiệu\\nTrong các bài toán supervised learning, chúng ta thường phải đi tìm một mô hình ánh xạ\\ncác vector đặc trưng thành các kết quả tương ứng trong training set. Tức là đi tìm hàm số\\nf sao choyi ≈f(xi), ∀i= 1,2,...,N . Một cách tự nhiên, ta sẽ đi tìm các tham số mô hình\\ncủa f sao cho việc xấp xỉ có sai số càng nhỏ càng tốt. Nói cách khác, mô hình càngkhớp\\n(fit) với dữ liệu càng tốt. Tuy nhiên, sự thật là nếu một mô hìnhquá fit với dữ liệu thì nó\\nsẽ gây phản tác dụng. Hiện tượngquá fitnày trong machine learning được gọi làoverfitting.\\nĐây là một hiện tượng xấu cần tránh. Vì có thể mô hình rấtfit với training set nhưng lại\\nkhông biểu diễn tốt dữ liệu không được nhìn thấy khi huấn luyện. Một mô hình chỉ mô tả\\ntốt training set là mô hình không cótính tổng quát(generalization). Một mô hình tốt là mô\\nhình có tính tổng quát.\\nĐể có cái nhìn đầu tiên về overfitting, chúng ta cùng xem Hình 8.1. Có 50 điểm dữ liệu, ở\\nđó đầu ra bằng một đa thức bậc ba của đầu vào cộng thêm nhiễu. Tập dữ liệu này được\\nchia làm hai phần: 30 điểm dữ liệu màu đỏ là training set, 20 điểm dữ liệu màu vàng là dữ\\nliệu kiểm thử. Đồ thị của đa thức bậc ba này được cho bởi đường nét đứt màu xanh lục. Bài\\ntoán đặt ra là giả sử ta không biết mô hình ban đầu mà chỉ biết các điểm dữ liệu, hãy tìm\\nmột mô hình tốt để mô tả quan hệ giữa đầu vào và đầu ra của dữ liệu đã cho. Giả sử biết\\nthêm rằng mô hình được mô tả bởi một đa thức.\\nNhắc lại đa thức nội suy Lagrange. ChoN cặp điểm dữ liệu(x1,y1),(x2,y2),..., (xN,yN)\\nvới cácxi khác nhau đôi một, luôn tìm được một đa thứcP(.) bậc không vượt quáN −1\\nsao choP(xi) = yi, ∀i= 1,2,...,N .'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 103, 'page_label': '92'}, page_content='CHƯƠNG 8. OVERFITTING 92\\nx\\ny\\nDegree = 2: Underﬁtting\\nTraining samples\\nTest samples\\nPredicted model\\nTrue model\\n(a)\\nx\\ny\\nDegree = 4: Good ﬁt\\nTraining samples\\nTest samples\\nPredicted model\\nTrue model (b)\\nx\\ny\\nDegree = 8: Overﬁtting\\nTraining samples\\nTest samples\\nPredicted model\\nTrue model\\n(c)\\nx\\ny\\nDegree = 16: Overﬁtting\\nTraining samples\\nTest samples\\nPredicted model\\nTrue model (d)\\nHình 8.1: Underfitting và overfitting với polynomial regression.\\nNhư đã đề cập trong Chương 7, với loại dữ liệu này, chúng ta có thể áp dụng polynomial\\nregression với vector đặc trưng làx = [1,x,x 2,x3,...,x d]T cho đa thức bậcd. Điều quan\\ntrọng là cần xác định bậcd của đa thức.\\nRõ ràng là một đa thức bậc không vượt quá 29 có thểfit được hoàn toàn với 30 điểm trong\\ntập training set. Xét một vài giá trịd= 2,4,8,16. Vớid= 2, mô hình không thực sự tốt vì\\nmô hình dự đoán(predicted model) quá khác so vớimô hình thực(true model); thậm chí nó\\ncó xu hướng đi xuống khi mà dữ liệu đang có hướng đi lên. Trong trường hợp này, ta nói mô\\nhình bịunderfitting. Vớid= 8, với các điểm dữ liệu trong training set, mô hình dự đoán và\\nmô hình thực là khá giống nhau. Tuy nhiên, về phía phải, đa thức bậc 8 cho kết quả hoàn\\ntoàn ngược với xu hướng của dữ liệu. Điều tương tự xảy ra trong trường hợpd = 16. Đa\\nthức bậc 16 nàyquá fit training set. Việcquá fit trong trường hợp bậc 16 là không tốt vì\\nmô hình có thể đang cố gắng mô tảnhiễu hơn là dữ liệu. Hiện tượng xảy ra ở hai trường\\nhợp đa thức bậc cao này được gọi làoverfitting. Độ phức tạp của đồ thị trong hai trường\\nhợp này cũng khá lớn, dẫn đến các đường dự đoán không được tự nhiên.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 104, 'page_label': '93'}, page_content='93 CHƯƠNG 8. OVERFITTING\\nVới d= 4, mô hình dự đoán khá giống với mô hình thực. Hệ số bậc cao nhất tìm được rất\\ngần với 01, vì vậy đa thưc bậc bốn này khá gần với đa thức bậc ba ban đầu. Đây chính là\\nmột mô hình tốt.\\nOverfitting là hiện tượng mô hình tìm đượcquá khớp với dữ liệu huấn luyện. Việc này sẽ\\ngây ra hậu quả lớn nếu trong training set có nhiễu. Khi đó, mô hình quá chú trọng vào việc\\nxấp xỉ training set mà quên đi việc quan trọng hơn là tính tổng quát, khiến cho mô hình\\nkhông thực sự mô tả tốt dữ liệu ngoài training set. Overfitting đặc biệt xảy ra khi lượng dữ\\nliệu huấn luyện quá nhỏ hoặc độ phức tạp của mô hình quá cao. Trong ví dụ trên đây, độ\\nphức tạp của mô hình có thể được coi là bậc của đa thức cần tìm.\\nVậy, có những kỹ thuật nào giúp tránh overfitting?\\nTrước hết, chúng ta cần một vài đại lượng để đánh giá chất lượng của mô hình trên training\\nset và test set. Dưới đây là hai đại lượng đơn giản, với giả sửy là đầu ra thực sự (có thể là\\nvector), vàˆ ylà đầu ra dự đoán bởi mô hình.\\nTraining error:Đại lượng này là mức độ sai khác giữa đầu ra thực và đầu ra dự đoán của\\nmô hình, thường là giá trị của hàm mất mát áp dụng lên training data. Hàm mất mát này\\ncần có một thừa số 1\\nNtrain\\nđể tính giá trị trung bình, tức mất mát trung bình trên mỗi điểm\\ndữ liệu. Với các bài toán regression, đại lượng này thường được xác định bởimean squared\\nerror (MSE).\\ntraining error= 1\\n2Ntrain\\n∑\\ntraining set\\n∥y −ˆ y∥2\\n2\\nVới classification, trung bình cộng của cross entropy loss (với softmax regression) hoặc hinge\\nloss (với multi-class SVM) thường được sử dụng.\\nTest error:Tương tự như trên, nhưng mô hình tìm được được áp dụng vào test data. Chú\\ný rằng, khi xây dựng mô hình, ta không được sử dụng thông tin trong tập dữ liệu này. Với\\nregression, đại lượng này thường được định nghĩa bởi\\ntest error= 1\\n2Ntest\\n∑\\ntest set\\n∥y −ˆ y∥2\\n2\\nViệc lấy trung bình là quan trọng vì lượng dữ liệu trong tập huấn luyện và tập kiểm thử có\\nthể chênh lệch rất nhiều.\\nMột mô hình được coi là tốt (fit) nếu cảtraining errorvà test errorđều thấp. Nếutraining\\nerror thấp nhưng test error cao, ta nói mô hình bị overfitting. Nếutraining error cao và\\ntest error cao, ta nói mô hình bị underfitting. Xác suất để xảy ra việctraining error cao\\nnhưng test errorthấp là rất nhỏ. Trong chương này, chúng ta sẽ làm quen với hai kỹ thuật\\nphổ biến giúp tránh overfitting làvalidation và regularization.\\n1 Source code tạihttps://goo.gl/uD9hm1 .\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 105, 'page_label': '94'}, page_content='CHƯƠNG 8. OVERFITTING 94\\nHình 8.2: Lựa chọn mô hình dựa\\ntrên validation error.\\n8.2 Validation\\n8.2.1 Validation\\nMột mô hình là tốt nếu cả training error và test error đều nhỏ. Tuy nhiên, khi xây dựng một\\nmô hìnhchỉ dựa trên training set, làm thế nào để biết được chất lượng của nó trên test set?\\nPhương pháp đơn giản nhất làtrích từ training set ra một tập con nhỏ và thực hiện việc\\nđánh giá mô hình trên tập con nhỏ này. Tập con nhỏđược trích ra từ training setnày\\nđược gọi làvalidation set. Lúc này,training set mới là phần còn lại của training set\\nban đầu. Việc này khá giống với việc chúng ta ôn thi. Giả sử các đề thi của các năm trước\\nlà training set, đề thi năm nay là test set mà ta chưa biết. Khi ôn tập, ta thường chia đề các\\nnăm trước ra hai phần: phần thứ nhất có thể xem lời giải và tài liệu để ôn tập, phần còn lại\\nta tự làm mà không sử dụng tài liệu để tự đánh giá kiến thức của mình. Lúc này, phần thứ\\nnhất đóng vai trò là training set mới, trong khi phần thứ hai chính là validation set. Nếu\\nkết quả bài làm trên phần thứ hai là khả quan, ta có thể tự tin hơn khi vào bài thi thật.\\nLúc này, có ba đại lượng cần được quan tâm:training errortrên training set mới,validation\\nerror được định nghĩa tương tự trên validation set, vàtest errortrên test set. Với khái niệm\\nmới này, ta tìm mô hình sao cho cảtrain eror và validation error đều nhỏ, qua đó có thể\\ndự đoán được rằngtest error cũng nhỏ. Để làm được việc này, ta có thể huấn luyện nhiều\\nmô hình khác nhau dựa trên training set, sau đó áp dụng các mô hình tìm được và tính\\nvalidation error. Mô hình chovalidation errornhỏ nhất sẽ là một mô hình tốt.\\nThông thường, ta bắt đầu từ mô hình đơn giản, sau đó tăng dần độ phức tạp của mô hình.\\nKhi độ phức tạp này tăng lên, training error sẽ có xu hướng nhỏ dần, nhưng điều tương tự\\ncó thể không xảy ra ở validation error. Validation error ban đầu thường giảm dần và đến\\nmột lúc sẽ tăng lên do overfitting xảy ra trên training khi độ phức tạp của mô hình tăng\\nlên. Để chọn ra một mô hình tốt, ta quan sát validation error. Khivalidation errorcó chiều\\nhướng tăng lên thì ta chọn mô hình trước đó.\\nHình 8.2 mô tả ví dụ phía trên với bậc của đa thức tăng từ một đến tám. Validation set là\\n10 điểm được lấy ra ngẫu nhiên từ training set 30 điểm ban đầu. Chúng ta hãy tạm chỉ xét\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 106, 'page_label': '95'}, page_content='95 CHƯƠNG 8. OVERFITTING\\nhai đường màu lam và đỏ, tương ứng với training error và validation error. Khi bậc của đa\\nthức tăng lên, training error có xu hướng giảm. Điều này dễ hiểu vì đa thức bậc càng cao,\\nviệc xấp xỉ càng chính xác. Quan sát đường màu đỏ, khi bậc của đa thức là ba hoặc bốn thì\\nvalidation error thấp, sau đó nó tăng dần lên. Dựa vào validation error, ta có thể xác định\\nđược bậc cần chọn là ba hoặc bốn. Quan sát tiếp đường màu lục, tương ứng với test error,\\nthật là trùng hợp, với bậc bằng ba hoặc bốn, test error cũng đạt giá trị nhỏ nhất, sau đó\\ntăng dần lên. Vậy cách làm này ở đây đã tỏ ra hiệu quả. Và mô hình phù hợp là mô hình\\ncó bậc bằng ba hoặc bốn. Trong ví dụ này, validation set đóng vai trò tìm ra bậc của đa\\nthức, training set đóng vai trò trong việc tìm các hệ số của đa thức với bậc đã biết. Các hệ\\nsố của đa thức chính là cácmodel parameter, trong khi bậc của đa thức có thể được coi là\\nhyperparameter. Cả training set và validation set đều đóng vai trò xây dựng mô hình. Nhắc\\nlại rằng hai tập hợp này được tách ra từ training set ban đầu.\\nViệc không sử dụng test data khi lựa chọn mô hình ở trên nhưng vẫn có được kết quả khả\\nquan vì ta đã giả sử rằng validation data và test data có chung một đặc điểm nào đó (chung\\nphân phối và đều chưa được mô hình nhìn thấy khi huấn luyện). Và khi cả hai đều là chưa\\nđược nhìn thấy,error trên hai tập này sẽ tương đối giống nhau.\\nĐể ý rằng, khi bậc nhỏ (bằng một hoặc hai), cả ba error đều cao, khi đóunderfitting xảy ra.\\n8.2.2 Cross-validation\\nTrong nhiều trường hợp, chúng ta có rất hạn chế số lượng dữ liệu để xây dựng mô hình. Nếu\\nlấy quá nhiều dữ liệu trong training set ra làm dữ liệu validation, phần dữ liệu còn lại của\\ntraining set là không đủ để xây dựng mô hình. Lúc này, validation set phải thật nhỏ để giữ\\nđược lượng dữ liệu cho training đủ lớn. Tuy nhiên, một vấn đề khác nảy sinh. Khi validation\\nset quá nhỏ, hiện tượng overfitting lại có thể xảy ra với training set còn lại. Có giải pháp\\nnào cho tình huống này không?\\nCâu trả lời làcross-validation.\\nCross-validation là một cải tiến của validation với lượng dữ liệu trong validation set là nhỏ\\nnhưng chất lượng mô hình được đánh giá trên nhiều tập validation khác nhau. Một cách\\nthường được sử dụng là chia training set rak tập con không giao nhau, có kích thước gần\\nbằng nhau. Tại mỗi lần, được gọi là mộtrun, một trong số k tập con được lấy ra làm\\nvalidation set. Nhiều mô hình khác nhau sẽ được xây dựng dựa vào hợp củak−1 tập con\\ncòn lại. Mô hình cuối được xác định dựa trên trung bình của các training error và validation\\nerror. Cách làm này còn có tên gọi làk-fold cross-validation.\\nKhi k bằng với số lượng phần tử trong training set ban đầu, tức mỗi tập con có đúng một\\nphần tử, ta gọi kỹ thuật này làleave-one-out.\\nThư viện scikit-learn hỗ trợ rất nhiều phương thức cho phân chia dữ liệu và tính toán\\nerror của các mô hình. Bạn đọc có thể xem thêmCross-validation: evaluating estimator\\nperformance (https://goo.gl/Ars2cr ).\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 107, 'page_label': '96'}, page_content='CHƯƠNG 8. OVERFITTING 96\\nHình 8.3: Early stopping. Đường\\nmàu xanh là training error, màu đỏ\\nlà validation error. Trụcx thể hiện\\nsố lượng vòng lặp, trụcy là giá trị\\nerror. Thuật toán huấn luyện dừng\\nlại tại vòng lặp mà validation error\\nđạt giá trị nhỏ nhất (Nguồn: Over-\\nfitting – Wikipedia).\\n8.3 Regularization\\nMột nhược điểm lớn củacross-validation là số lượng mô hình cần huấn luyện tỉ lệ thuận với\\nk. Điều đáng nói là mô hình polynomial regression như trên chỉ có một tham số liên quan\\nđến độ phức tạp của mô hình cần xác định là bậc của đa thức. Trong các nhiều bài toán,\\nlượng tham số cần xác định thường lớn hơn nhiều, và khoảng giá trị của mỗi tham số cũng\\nrộng hơn nhiều, chưa kể đến việc có những tham số có thể là số thực. Điều này dẫn đến việc\\nhuấn luyện nhiều mô hình là khó khả thi. Có một kỹ thuật giúp số mô hình cần huấn luyện\\ngiảm đi nhiều, thậm chí chỉ một mô hình. Kỹ thuật này có tên gọi làregularization.\\nRegularization, một cách dễ hiểu, là thay đổi mô hình một chút, chấp nhận hy sinh độ chính\\nxác trong training set, nhưng giảm độ phức tạp của mô hình, giúp tránh overfitting trong\\nkhi vẫn giữ được tính tổng quát của nó. Dưới đây là một vài kỹ thuật regularization.\\n8.3.1 Early stopping\\nRất nhiều các mô hình machine learning được xây dựng bằng cách sử dụng các thuật toán\\nlặp cho tới khi hàm mất mát hội tụ để tìm ra nghiệm. Nhìn chung, giá trị hàm mất mát\\ngiảm dần khi số vòng lặp tăng lên. Một giải pháp giúp giảm overfitting là dừng thuật toán\\ntrước khi nó hội tụ. Giải pháp này có tên làearly stopping.\\nVậy dừng khi nào là phù hợp? Một kỹ thuật thường được sử dụng là tách từ training set ra\\nmột validation set như trên. Trong khi huấn luyện, ta tính toán cả training error và validation\\nerror, nếu training error vẫn có xu hướng giảm nhưng validation error có xu hướng tăng lên\\nthì ta dừng thuật toán.\\nHình 8.3 mô tả cách tìm điểmstopping. Chúng ta thấy rằng phương pháp này khá giống với\\nphương pháp tìm bậc của đa thức ở phần trên của bài viết, với độ phức tạp của mô hình có\\nthể được coi là số vòng lặp cần chạy. Số vòng lặp càng cao thì hàm mất mát càng nhỏ, tức\\nmô hình có khả năngquá fit với training set.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 108, 'page_label': '97'}, page_content='97 CHƯƠNG 8. OVERFITTING\\n8.3.2 Thêm số hạng vào hàm mất mát\\nKỹ thuật regularization phổ biến hơn là thêm vào hàm mất mát một số hạng nữa. Số hạng\\nnày thường dùng để đánh giá độ phức tạp của mô hình với giá trị lớn thể hiện mô hình\\nphức tạp.Hàm mất mát mớinày được gọi làregularized loss function, thường được định\\nnghĩa như sau:\\nLreg(θ) = L(θ) + λR(θ)\\nNhắc lại rằngθ được dùng để ký hiệu các tham số trong mô hình.L(θ) là hàm mất mát\\nphụ thuộc vào training set vàθ, R(θ) là số hạngregularization chỉ phụ thuộc vàoθ. Số vô\\nhướng λthường là một số dương nhỏ, còn được gọi làtham số regularization(regularization\\nparameter). Tham số regularization thường được chọn là các giá trị nhỏ để đảm bảo nghiệm\\ncủa bài toán tối ưuLreg(θ) không quá xa nghiệm của bài toán tối ưuL(θ).\\nHai hàm regularization phổ biến làℓ1 norm vàℓ2 norm regularization (viết gọn làℓ1 regu-\\nlarization vàℓ2 regularization). Ví dụ, khi chọnR(w) = ∥w∥2\\n2 cho hàm mất mát của linear\\nregression, chúng ta sẽ đạt được ridge regression. Hàm regularization này khiến các hệ số\\ntrong w không quá lớn, giúp tránh việc đầu ra phụ thuộc quá nhiều vào một đặc trưng\\nnào đó. Trong khi đó, khi chọnR(w) = ∥w∥1, nghiệm w tìm được có xu hướng rất nhiều\\nphần tử bằng không (sparse solution2). Khi thêmℓ1 regularization vào hàm mất mát của\\nlinear regression, chúng ta sẽ thu được LASSO regression. Các thành phần khác không của\\nw tương đương với các đặc trưng quan trọng đóng góp vào việc dự đoán đầu ra. Các đặc\\ntrưng ứng với thành phần bằng không củaw được coi là ít quan trọng. Chính vì vậy, LASSO\\nregression cũng được coi là một phương pháp giúp lựa chọn những đặc trưng hữu ích cho\\nmô hình; nó cũng là một trong các phương phápfeature selection.\\nℓ1 regularization được cho là giúp cho mô hìnhrobust (ít bị ảnh hưởng bởi nhiễu) hơn so với\\nℓ2 regularization. Tuy nhiên, hạn chế củaℓ1 regularization là đạo hàm củaℓ1 norm không\\nxác định tại không (đạo hàm của hàm trị tuyệt đối), dẫn đến việc tìm nghiệm thường tốn\\nthời gian hơn. Trong khi đó, đạo hàm củaℓ2 norm xác định mọi nơi, và trong nhiều trường\\nhợp, ta có thể tìm được công thức nghiệm cho phương trình đạo hàm của (regularized) loss\\nfunction bằng không. Các nghiệm có công thức xác định được gọi làclosed-form solution.\\nTrong neural network, việc sử dụngℓ2 regularization còn được gọi làweight decay[KH92].\\nNgoài ra, gần đây một phương pháp regularization rất hiệu quả cho neural network được sử\\ndụng làdropout [SHK+14].\\n8.4 Đọc thêm\\n1. A. Kroghet al., A simple weight decay can improve generalization.NIPS 1991 [KH92].\\n2. N. Srivastavaet al., Dropout: A Simple Way to Prevent Neural Networks from Overfitting,\\nJournal of Machine Learning Research 15.1 (2014): 1929-1958 [SHK+14].\\n3. Understanding the Bias-Variance Tradeoff(https://goo.gl/yvQv3w ).\\n2 L1 Norm Regularization and Sparsity Explained for Dummies(https://goo.gl/VqPTLh ).\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 109, 'page_label': '98'}, page_content=''),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 110, 'page_label': '99'}, page_content='Phần III\\nKhởi động\\nTrong phần này, chúng ta sẽ làm quen với ba thuật toán machine learning chưa cần nhiều\\ntới tối ưu: k-means clustering cho phân nhóm dữ liệu, k-nearest neighbors cho classification\\nvà regression, naive Bayes classifier cho phân loại văn bản.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 111, 'page_label': '100'}, page_content='Chương 9\\nK-nearest neighbors\\nNếu như con người có kiểu học “nước đến chân mới nhảy” thì machine learning cũng có một\\nthuật toán như vậy.\\n9.1 Giới thiệu\\n9.1.1 K-nearest neighbor\\nK-nearest neighbor (KNN) là một trong những thuật toán supervised learning đơn giản. Khi\\nhuấn luyện, thuật toán nàykhông học một điều gì từ dữ liệu huấn luyện mànhớ lại một\\ncách máy móc toàn bộ dữ liệu đó. Đây cũng là lý do thuật toán này được xếp vào loạilazy\\nlearning, mọi tính toán được thực hiện khi nó cần dự đoán đầu ra của dữ liệu mới. KNN có\\nthể áp dụng được vào cả classification và regression. KNN còn được gọi là một thuật toán\\ninstance-based [AKA91] hay memory-based learning.\\nVới KNN, trong bài toán classification, nhãn của một điểm dữ liệu mới được suy ra trực tiếp\\ntừ K điểm dữ liệu gần nhất trong tập huấn luyện. Nhãn đó có thể được quyết định bằng\\nbầu chọn theo đa số(major voting) trong sốK điểm gần nhất, hoặc nó có thể được suy ra\\nbằng cách đánh trọng số khác nhau cho mỗi trong các điểm gần nhất đó rồi suy ra kết quả.\\nChi tiết sẽ được nêu trong phần tiếp theo. Trong bài toán regresssion, đầu ra của một điểm\\ndữ liệu sẽ bằng chính đầu ra của điểm dữ liệu đã biết gần nhất (trong trường hợpK = 1),\\nhoặc là trung bình có trọng số của đầu ra của những điểm gần nhất, hoặc bằng một mối\\nquan hệ dựa trên các điểm gần nhất đó và khoảng cách tới chúng.\\nMột cách ngắn gọn, KNN là thuật toán đi tìm đầu ra của một điểm dữ liệu mới bằng cách\\nchỉ dựa trên thông tin củaK điểm dữ liệu gần nhất trong tập huấn luyện.\\nHình 9.1 mô tả một bài toán phân lớp với ba class: đỏ, lam, lục. Các hình tròn nhỏ với màu\\nkhác nhau thể hiện dữ liệu huấn luyện của các class khác nhau. Các vùng màu nền khác\\nnhau thể hiệnlãnh thổ của mỗi class. Tại một điểm bất kỳ, class của nó được xác định dựa\\ntrên class của điểm gần nó nhất trong trong tập huấn luyện. Trong hình này, có một vài'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 112, 'page_label': '101'}, page_content='101 CHƯƠNG 9. K-NEAREST NEIGHBORS\\nHình 9.1: Ví dụ về 1NN. Các hình tròn\\nlà các điểm dữ liệu huấn luyện. Các hình\\nkhácmàuthểhiệncáclớpkhácnhau.Các\\nvùng nền thể hiện các điểm được phân\\nloại vào lớp có màu tương ứng khi sử\\ndựng 1NN (Nguồn: K-nearest neighbors\\nalgorithm – Wikipedia).\\nvùng nhỏ xem lẫn vào các vùng lớn hơn khác màu. Ví dụ có một điểm màu lục ở gần góc 11\\ngiờ nằm giữa hai vùng lớn với nhiều dữ liệu màu đỏ và lam. Điểm này rất có thể là nhiễu.\\nViệc này nhiều khả năng sẽ dẫn đến việc phân lớp sai cho một điểm dữ liệu kiểm thử rơi\\nvào khu vực này.\\nKNN là một ví dụ rõ nhất của overfitting. Với mô hình này, mọi điểm trong tập huấn luyện\\nđều được mô hình mô tả một cách chính xác, vì vậy, nó rất nhạy cảm với nhiễu.\\nMặc dù có nhiều hạn chế, KNN vẫn là một giải pháp đầu tiên nên nghĩ tới khi giải quyết\\nmột bài toán machine learning.Khi làm các bài toán machine learning nói chung, không có\\nmô hình đúng hay sai, chỉ có mô hình cho kết quả tốt hơn. Chúng ta luôn cần một mô hình\\nđơn giản để giải quyết bài toán, sau đó dần dần tìm cách tăng chất lượng của mô hình.\\n9.2 Phân tích toán học\\nKNN là một thuật toánlazy learning, không có hàm mất mát nào và bài toán tối ưu nào\\nphải thực hiện trong quá trình huấn luyện. Mọi tính toán được thực hiện ở bước kiểm thử.\\nVì KNN ra quyết định dựa trên các điểm gần nhất nên có hai vấn đề ta cần lưu tâm. Thứ\\nnhất, khoảng cách được định nghĩa như thế nào. Thứ hai, cần phải tính toán khoảng cách\\nnhư thế nào cho hiệu quả.\\nVới vấn đề thứ nhất, mỗi điểm dữ liệu được thể hiện bằng một vector đặc trưng, khoảng\\ncách giữa hai điểm chính là khoảng cách giữa hai vector đó. Để đo khoảng cách trong không\\ngian nhiều chiều, norm (xem Mục 1.14) thường được sử dụng, và norm phổ biến nhất làℓ2\\nnorm, chính là khoảng cách Euclid quen thuộc.\\nTa cần lưu ý tới vấn đề thứ hai hơn, đặc biệt vớicác bài toán với tập huấn luyện lớn và\\nvector đặc trưng có kích thước lớn(large-scale problem). Giả sử các vector đặc trưng huấn\\nluyện là các cột của ma trậnX ∈Rd×N với dvà N lớn, KNN sẽ phải tính toán khoảng cách\\ntừ một điểm dữ liệu mớiz ∈Rd đến toàn bộN điểm dữ liệu đã cho và chọn raK khoảng\\ncách nhỏ nhất. Nếu không có một cách tính hiệu quả, khối lượng tính toán ở đây sẽ rất lớn.\\nĐây cũng là cái giá phải trả cho việclazy learning.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 113, 'page_label': '102'}, page_content='CHƯƠNG 9. K-NEAREST NEIGHBORS 102\\nTiếp theo, chúng ta cùng thực hiện một vài phân tích toán học để tìm ra cách tính các\\nkhoảng cách một cách hiệu quả.\\nKhoảng cách từ một điểm tới từng điểm trong một tập hợp\\nKhoảng cách Euclid từ một điểmz tới một điểmxi trong tập huấn luyện được định nghĩa\\nbởi ∥z−xi∥2. Vì trong cách tính này có một bước phải tính căn bậc hai nên người ta thường\\ntính ∥z −xi∥2\\n2. Nếu việc tính khoảng cách chỉ để phục vụ việc sắp xếp thì ta không cần tính\\ncăn bậc hai sau bước này nữa. Để ý rằng\\n∥z −xi∥2\\n2 = (z −xi)T(z −xi) = ∥z∥2\\n2 + ∥xi∥2\\n2 −2xT\\ni z (9.1)\\nTừ đây, nếu nhiệm vụ chỉ là tìm raxi gần vớiz nhất, số hạng đầu tiên có thể được bỏ qua.\\nHơn nữa, nếu có nhiều điểm dữ liệu trong tập kiểm thử, các giá trị∥xi∥2\\n2 có thể được tính\\nvà lưu trước vào bộ nhớ. Khi đó, ta chỉ cần tính các tích vô hướngxT\\ni z.\\nĐể thấy rõ hơn, chúng ta cùng làm một ví dụ trên Python. Trước hết, chọnd và N là các\\ngiá trị lớn và khai báo ngẫu nhiênX và z. Lưu ý rằng vì dữ liệu trong Python thường được\\nlưu ở dạng hàng, khi lập trình ta cần thay đổi một chút.\\nfrom __future__ import print_function\\nimport numpy as np\\nfrom time import time # for comparing runing time\\nd, N = 1000, 10000 # dimension, number of training points\\nX = np.random.randn(N, d) # N d-dimensional points\\nz = np.random.randn(d)\\nTiếp theo, ta viết ba hàm số:\\n1. dist_pp(z, x) tính bình phương khoảng cách Euclid giữa hai vectorz vàx. Hàm này thực\\nhiện cách tính trực tiếp, tức tính hiệu rồi lấy bình phươngℓ2 norm của vector hiệu.\\n2. dist_ps_naive(z, X) tính bình phương khoảng cách giữaz và mỗihàng của X. Trong hàm\\nnày, các khoảng cách được tính dựa trên việc tính từng cặpdist_pp(z, X[i]).\\n3. dist_ps_fast(z, X) tính bình phương khoảng cách giữaz và mỗihàng của X, tuy nhiên,\\nkết quả được tính dựa trên đẳng thức (9.1). Khi có nhiều điểm dữ liệu được lưu trong\\nX, ta cần tính tổng bình phương các phần tử của mỗi điểm dữ liệu và tính tíchXTz.\\nĐoạn code dưới đây thể hiện cách tính khoảng cách từ một điểmz tới một tập hợp điểmX\\nbằng hai cách. Kết quả và thời gian chạy của mỗi hàm cũng được in ra để so sánh.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 114, 'page_label': '103'}, page_content='103 CHƯƠNG 9. K-NEAREST NEIGHBORS\\n# naively compute square distance between two vector\\ndef dist_pp(z, x):\\nd = z - x.reshape(z.shape) # force x and z to have the same dims\\nreturn np.sum(d*d)\\n# from one point to each point in a set, naive\\ndef dist_ps_naive(z, X):\\nN = X.shape[0]\\nres = np.zeros((1, N))\\nfor i in range(N):\\nres[0][i] = dist_pp(z, X[i])\\nreturn res\\n# from one point to each point in a set, fast\\ndef dist_ps_fast(z, X):\\nX2 = np.sum(X*X, 1) # square of l2 norm of each ROW of X\\nz2 = np.sum(z*z) # square of l2 norm of z\\nreturn X2 + z2 - 2*X.dot(z) # z2 can be ignored\\nt1 = time()\\nD1 = dist_ps_naive(z, X)\\nprint(’naive point2set, running time:’, time() - t1, ’s’)\\nt1 = time()\\nD2 = dist_ps_fast(z, X)\\nprint(’fast point2set , running time:’, time() - t1, ’s’)\\nprint(’Result difference:’, np.linalg.norm(D1 - D2))\\nKết quả:\\nnaive point2set, running time: 0.0932548046112 s\\nfast point2set , running time: 0.0514178276062 s\\nResult difference: 2.11481965531e-11\\nKết quả chỉ ra rằng hàm dist_ps_fast(z, X) chạy nhanh hơn gần gấp đôi so với hàm\\ndist_ps_naive(z, X) (số này còn lớn hơn nữa khi kích thước dữ liệu tăng lên). Quan trọng\\nhơn, sự chênh lệch của kết quả hai phép tính là một số rất nhỏ. Điều này chỉ ra rằng\\ndist_ps_fast(z, X) nên được ưu tiên hơn.\\nKhoảng cách giữa từng cặp điểm trong hai tập hợp\\nThông thường, ta không những phải tính khoảng cách từ một điểmz tới tập hợp các điểm\\nX, mà thường xuyên còn phải tính khoảng cách giữa nhiều điểmZ tới X. Nói đúng hơn, ta\\nphải tính từng cặp khoảng cách giữa mỗi điểm trong tập kiểm thử và một điểm trong tập\\nhuấn luyện. Nếu mỗi tập có 1000 phần tử, ta sẽ phải tính một triệu khoảng cách–là một số\\nrất lớn. Nếu không có một phương pháp tính hiệu quả, thời gian thực hiện sẽ là rất lớn.\\nDưới đây là đoạn code thực hiện cách tính bình phương khoảng cách giữa các cặp điểm trong\\nhai tập điểm sử dụng hai phương pháp khác nhau. Phương pháp thứ nhất sử dụng một vòng\\nfor tính khoảng cách từ từng điểm trong tập thứ nhất đến tất cả các điểm trong tập thứ\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 115, 'page_label': '104'}, page_content='CHƯƠNG 9. K-NEAREST NEIGHBORS 104\\nhai sử dụng hàmdist_ps_fast(z, X) ở trên. Phương pháp thứ hai tiếp tục sử dụng (9.1) cho\\ntrường hợp tổng quát.\\nM = 100\\nZ = np.random.randn(M, d)\\n# from each point in one set to each point in another set, half fast\\ndef dist_ss_0(Z, X):\\nM = Z.shape[0]\\nN = X.shape[0]\\nres = np.zeros((M, N))\\nfor i in range(M):\\nres[i] = dist_ps_fast(Z[i], X)\\nreturn res\\n# from each point in one set to each point in another set, fast\\ndef dist_ss_fast(Z, X):\\nX2 = np.sum(X*X, 1) # square of l2 norm of each ROW of X\\nZ2 = np.sum(Z*Z, 1) # square of l2 norm of each ROW of Z\\nreturn Z2.reshape(-1, 1) + X2.reshape(1, -1) - 2*Z.dot(X.T)\\nt1 = time()\\nD3 = dist_ss_0(Z, X)\\nprint(’half fast set2set running time:’, time() - t1, ’s’)\\nt1 = time()\\nD4 = dist_ss_fast(Z, X)\\nprint(’fast set2set running time’, time() - t1, ’s’)\\nprint(’Result difference:’, np.linalg.norm(D3 - D4))\\nKết quả:\\nhalf fast set2set running time: 4.33642292023 s\\nfast set2set running time 0.0583250522614 s\\nResult difference: 9.93586539607e-11\\nĐiều này chỉ ra rằng hai cách tính cho kết quả chênh lệch nhau không đáng kể. Trong khi\\nđó dist_ss_fast(Z, X) chạy nhanh hơndist_ss_0(Z, X) nhiều lần.\\nKhi làm việc trên python, chúng ta có thể sử dụng hàmcdist (https://goo.gl/vYMnmM )\\ntrong scipy.spatial.distance, hoặc hàmpairwise_distances (https://goo.gl/QK6Zyi ) trong\\nsklearn.metrics.pairwise. Các hàm này giúp tính khoảng cách từng cặp điểm trong hai tập\\nhợp khá hiệu quả. Phần còn lại của chương này sẽ trực tiếp sử dụng thư viện scikit-learn\\ncho KNN. Việc viết lại thuật toán này không quá phức tạp khi đã có một hàm tính khoảng\\ncách hiệu quả.\\nNếu thực hiện trên GPU, bạn đọc có thể tham khảo thêm bài báo [JDJ17] và source code\\ncủa nó tạihttps://github.com/facebookresearch/faiss .\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 116, 'page_label': '105'}, page_content='105 CHƯƠNG 9. K-NEAREST NEIGHBORS\\nHình 9.2: Ba loại hoa lan trong bộ cơ sở dữ liệu hoa Iris.\\n9.3 Ví dụ trên cơ sở dữ liệu Iris\\n9.3.1 Bộ cơ sở dữ liệu hoa Iris (Iris flower dataset).\\nIris flower dataset (https://goo.gl/eUy83R ) là một bộ dữ liệu nhỏ. Bộ dữ liệu này bao gồm\\nthông tin của ba class hoa Iris (một loài hoa lan) khác nhau: Iris setosa, Iris virginica và Iris\\nversicolor. Mỗi class có 50 bông hoa với dữ liệu là bốn thông tin: chiều dài, chiều rộng đài\\nhoa (sepal), và chiều dài, chiều rộng cánh hoa (petal). Hình 9.2 là ví dụ về hình ảnh của ba\\nloại hoa. Chú ý rằng các điểm dữ liệu không phải là các bức ảnh mà chỉ là một vector đặc\\ntrưng bốn chiếu gồm bốn thông tin ở trên.\\n9.3.2 Thí nghiệm\\nTrong phần này, chúng ta sẽ tách 150 điểm dữ liệu trong Iris flower dataset ra thành hai tập\\nhuấn luyện và kiểm thử. KNN sẽ dựa vào trông tin trong tập huấn luyện để dự đoán xem\\nmỗi dữ liệu trong tập kiểm thử tương ứng với loại hoa nào. Dữ liệu được dự đoán này sẽ\\nđược đối chiếu với dữ liệu thật để đánh giá hiệu quả của KNN.\\nTrước tiên, chúng ta cần khai báo vài thư viện. Iris flower dataset có sẵn trong thư viện\\nscikit-learn.\\nfrom __future__ import print_function\\nimport numpy as np\\nfrom sklearn import neighbors, datasets\\nfrom sklearn.model_selection import train_test_split # for splitting data\\nfrom sklearn.metrics import accuracy_score # for evaluating results\\nTiếp theo, ta sẽ load cơ sở dữ liệu này và chọn ra ngẫu nhiên 130 mẫu làm test set, 20 mẫu\\ncòn lại được dùng làm training set.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 117, 'page_label': '106'}, page_content='CHƯƠNG 9. K-NEAREST NEIGHBORS 106\\nnp.random.seed(7)\\niris = datasets.load_iris()\\niris_X = iris.data\\niris_y = iris.target\\nprint(’Labels:’, np.unique(iris_y))\\n# split train and test\\nX_train, X_test, y_train, y_test = train_test_split(iris_X, iris_y, test_size=130)\\nprint(’Train size:’, X_train.shape[0], ’, test size:’, X_test.shape[0])\\nLabels: [0 1 2]\\nTrain size: 20 , test size: 130\\nDòng np.random.seed(7) để đảm bảo rằng khi các bạn chạy lại các đoạn code này cũng nhận\\nđược kết quả tương tự. Có thể thay 7 bằng một số tự nhiên bất kỳ 32 bit.\\nKết quả với 1NN\\nTới đây, ta trực tiếp sử dụng thư viện scikit-learn cho KNN. Xét ví dụ đầu tiên vớiK = 1.\\nmodel = neighbors.KNeighborsClassifier(n_neighbors = 1, p = 2)\\nmodel.fit(X_train, y_train)\\ny_pred = model.predict(X_test)\\nprint(\"Accuracy of 1NN: %.2f %%\" %(100*accuracy_score(y_test, y_pred)))\\nKết quả:\\nAccuracy of 1NN: 92.31 %\\nKết quả thu được là 92.31% (tỉ lệ các mẫu được phân loại chính xác). Ở đây,n_neighbors = 1\\nchỉ ra rằng ta chỉ lấy một điểm gần nhất, tứcK = 1, p = 2 chính làℓ2 norm ta đã chọn để\\ntính khoảng cách. Bạn đọc có thể thử vớip = 1 tương ứng với khoảng cáchℓ1 norm.\\nKết quả với 7NN\\nNhư đã đề cập, 1NN rất dễ gây ra hiện tượng overfitting. Để giảm thiểu việc này, ta có thể\\ntăng lượng điểm lân cận lên, ví dụ bảy điểm, và xem xét trong bảy điểm gần nhất, đa số\\nchúng thuộc vào class nào.\\nmodel = neighbors.KNeighborsClassifier(n_neighbors = 7, p = 2)\\nmodel.fit(X_train, y_train)\\ny_pred = model.predict(X_test)\\nprint(\"Accuracy of 7NN with major voting: %.2f %%\" %(100*accuracy_score(y_test,\\n% y_pred)))\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 118, 'page_label': '107'}, page_content='107 CHƯƠNG 9. K-NEAREST NEIGHBORS\\nKết quả:\\nAccuracy of 7NN with major voting: 93.85 %\\nTa nhận thấy rằng độ chính xác đã tăng lên khi ta dự đoán dựa trên nhiều lân cận hơn.\\nĐánh trọng số cho các điểm lân cận\\nTrong kỹ thuật major voting bên trên, mỗi trong bảy điểm gần nhất được coi là có vai trò\\nnhư nhau và giá trịlá phiếu của mỗi điểm này là như nhau. Như thế có thể không công\\nbằng, vì những điểm gần hơn cần có trọng số cao hơn. Vì vậy, ta sẽ đánh trọng số khác\\nnhau cho mỗi trong bảy điểm gần nhất này. Cách đánh trọng số phải thoải mãn điều kiện là\\nmột điểm càng gần điểm kiểm thử phải được đánh trọng số càng cao. Cách đơn giản nhất\\nlà lấy nghịch đảo của khoảng cách này.Trong trường hợp test data trùng với một điểm dữ\\nliệu trong training data, tức khoảng cách bằng 0, ta lấy luôn đầu ra của điểm training data.\\nScikit-learn giúp chúng ta đơn giản hóa việc này bằng cách gán thuộc tínhweights = ’\\ndistance’. (Giá trị mặc định củaweights là ’uniform’, tương ứng với việc coi tất cả các điểm\\nlân cận có giá trị như nhau như ở trên).\\nmodel = neighbors.KNeighborsClassifier(n_neighbors = 7, p = 2, weights = ’distance’)\\nmodel.fit(X_train, y_train)\\ny_pred = model.predict(X_test)\\nprint(\"Accuracy of 7NN (1/distance weights): %.2f %%\"(100*accuracy_score(y_test,\\ny_pred)))\\nKết quả:\\nAccuracy of 7NN (1/distance weights): 94.62 %\\nĐộ chính xác tiếp tục được tăng lên.\\nK-nearest neighbors với trọng số tự định nghĩa\\nNgoài 2 phương pháp đánh trọng số weights = ’uniform’ và weights = ’distance’ ở trên,\\nscikit-learn còn cung cấp cho chúng ta một cách để đánh trọng số một cách tùy chọn. Ví dụ,\\nmột cách đánh trọng số phổ biến khác thường được dùng là\\nwi = exp\\n(−∥z −xi∥2\\n2\\nσ2\\n)\\ntrong đó wi là trọng số của điểm gần thứi (xi) của điểm dữ liệu đang xétz, σ là một số\\ndương. Hàm số này cũng thỏa mãn điều kiện điểm càng gầnx thì trọng số càng cao (cao\\nnhất bằng 1). Với hàm số này, chúng ta có thể lập trình như sau:\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 119, 'page_label': '108'}, page_content='CHƯƠNG 9. K-NEAREST NEIGHBORS 108\\ndef myweight(distances):\\nsigma2 = .4 # we can change this number\\nreturn np.exp(-distances**2/sigma2)\\nmodel = neighbors.KNeighborsClassifier(n_neighbors = 7, p = 2, weights = myweight)\\nmodel.fit(X_train, y_train)\\ny_pred = model.predict(X_test)\\nprint(\"Accuracy of 7NN (customized weights): %.2f %%\"\\n(100*accuracy_score(y_test, y_pred)))\\nKết quả:\\nAccuracy of 7NN (customized weights): 95.38 %\\nKết quả tiếp tục tăng lên một chút. Với từng bài toán, chúng ta có thể thay các thuộc tính\\ncủa KNN bằng các giá trị khác nhau và chọn ra giá trị tốt nhất thông qua cross-validation.\\n9.4 Thảo luận\\n9.4.1 KNN cho Regression\\nVới bài toán regression, chúng ta cũng hoàn toàn có thể sử dụng phương pháp tương tự: đầu\\nra của một điểm được xác định dựa trên đầu ra của các điểm lân cận và khoảng cách tới\\nchúng. Giả sửx1,..., xK là K điểm lân cận của một điểm dữ liệuz với đầu ra tương ứng\\nlà y1,...,y K. Giả sử các trọng số ứng với các lân cận này tính được làw1,...,w K. Kết quả\\ndự đoán đầu ra củaz có thể được xác định bởi\\nw1y1 + w2y2 + ··· + wKwK\\nw1 + w2 + ··· + wK\\n(9.2)\\nHình 9.3 là một ví dụ về KNN cho regression vớiK = 5, sử dụng hai cách đánh trọng số\\nkhác nhau. Ta có thể thấy rằngweights = ’distance’ có xu hướng gây ra overfitting.\\n9.4.2 Ưu điểm của KNN\\n1. Độ phức tạp tính toán của quá trình huấn luyện là bằng 0.\\n2. Việc dự đoán kết quả của dữ liệu mới rất đơn giản (sau khi đã xác định được các điểm\\nlân cận).\\n3. Không cần giả sử về phân phối của các class.\\n9.4.3 Nhược điểm của KNN\\n1. KNN rất nhạy cảm với nhiễu khi K nhỏ.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 120, 'page_label': '109'}, page_content='109 CHƯƠNG 9. K-NEAREST NEIGHBORS\\nHình 9.3: KNN cho bài toán Regression (Nguồn: Nearest neighbors regression–scikit-learn–\\nhttps://goo.gl/9VyBF3 ).\\n2. Như đã nói, KNN là một thuật toán mà mọi tính toán đều nằm ở khâu kiểm thử. Trong\\nđó việc tính khoảng cách tớitừng điểm dữ liệu trong tập huấn luyện tốn rất nhiều thời\\ngian, đặc biệt là với các cơ sở dữ liệu có số chiều lớn và có nhiều điểm dữ liệu. Với K\\ncàng lớn thì độ phức tạp cũng sẽ tăng lên. Ngoài ra, việc lưu toàn bộ dữ liệu trong bộ\\nnhớ cũng ảnh hưởng tới hiệu năng của KNN.\\n9.4.4 Đọc thêm\\n1. Tutorial To Implement k-Nearest Neighbors in Python From Scratch(https://goo.gl/\\nJ78Qso).\\n2. Source code cho chương này có thể được tìm thấy tạihttps://goo.gl/asF58Q .\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 121, 'page_label': '110'}, page_content='Chương 10\\nK-means clustering\\n10.1 Giới thiệu\\nChúng ta đã làm quen với linear regression, một mô hình đơn giản trong supervised learning.\\nTrong chương này, một mô hình đơn giản khác trong unsupervised learning sẽ được trình\\nbày. Thuật toán này có tên làphân nhómK-means (K-means clustering).\\nTrong K-means clustering, chúng ta không biết nhãn của từng điểm dữ liệu. Mục đích là\\nlàm thể nào để phân dữ liệu thành các cụm (cluster) khác nhau sao cho dữ liệu trong cùng\\nmột cụm có những tính chất giống nhau.\\nVí dụ:Một công ty muốn tạo ra một chính sách ưu đãi cho những nhóm khách hàng khác\\nnhau dựa trên sự tương tác giữa mỗi khách hàng với công ty đó (số năm là khách hàng; số\\ntiền khách hàng đã chi trả cho công ty; độ tuổi; giới tính; thành phố; nghề nghiệp; v.v.).\\nGiả sử công ty đó có rất nhiều dữ liệu của rất nhiều khách hàng nhưng chưa làm công việc\\nphâm nhóm khách hàng.K-means clustering là một thuật toán có thể giúp thực hiện công\\nviệc này. Sau khi đã phân ra được từng nhóm, nhân viên công ty đó có thể lựa chọn ra một\\nvài khách hàng trong mỗi nhóm để quyết định xem mỗi nhóm tương ứng với nhóm khách\\nhàng nào. Phần việc cuối cùng này cần sự can thiệp của con người, nhưng lượng công việc\\nđã được rút gọn đi rất nhiều.\\nMột định nghĩa đơn giản của nhóm/cụm (cluster) là tập hợp các điểm có các vector đặc\\ntrưng gần nhau. Việc đo khoảng cách giữa các vector thường được thực hiện dựa trên norm,\\ntrong đó khoảng cách Euclid, tứcℓ2 norm, được sử dụng phổ biến hơn cả.\\nHình 10.1 là một ví dụ về dữ liệu được phân vào ba cluster1. Giả sử mỗi cluster có một điểm\\nđại diện (centroid) màu vàng, và nhóm của mỗi điểm được xác định qua việc nó gần với\\ncentroid nào nhất trong ba centroid. Tới đây, chúng ta có một bài toán thú vị:Trên một vùng\\n1 Để cho thống nhất, từcluster sẽ được sử dụng thay thế cho nhóm/cụm. Các thuật ngữ tiếng Anh từ đây cũng\\nđược sử dụng thường xuyên hơn.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 122, 'page_label': '111'}, page_content='111 CHƯƠNG 10. K-MEANS CLUSTERING\\n2\\n 0 2 4 6 8 10\\n2\\n0\\n2\\n4\\n6\\n8\\n10\\nHình 10.1: Ví dụ với ba cụm dữ\\nliệu trong không gian hai chiều.\\nbiển hình vuông lớn có ba đảo hình vuông, tam giác, và tròn màu vàng như tròn Hình 10.1.\\nMột điểm trên biển được gọi là thuộc lãnh hải của một đảo nếu nó nằm gần đảo này hơn so\\nvới hai đảo kia. Hãy xác định ranh giới lãnh hải giữa các đảo.\\nCũng trên Hình 10.1, các vùng với màu nền khác nhau biểu diễn lãnh hải của mỗi đảo.\\nChúng ta thấy rằng đường phân định giữa các lãnh hải là các đường thẳng. Chính xác hơn,\\nchúng là các đường trung trực của các cặp đảo gần nhau. Vì vậy, lãnh hải của một đảo sẽ là\\nmột hình đa giác. Cách phân chia dựa trên khoảng cách tới điểm gần nhất này trong toán\\nhọc được gọi là Voronoi diagram2. Trong không gian ba chiều, lấy ví dụ là các hành tinh,\\nlãnh không của mỗi hành tinh sẽ là một đa diện. Trong không gian nhiều chiều hơn, chúng\\nta sẽ có nhữngsiêu đa diện(hyperpolygon).\\nQuay lại với bài toán phân nhóm và cụ thể là thuật toánK-means clustering, chúng ta cùng\\nthảo luận cơ sở toán học, cách xây dựng và tối ưu hàm mất mát của nó.\\n10.2 Phân tích toán học\\nMục đích cuối cùng của thuật toánK-means clustering là từ dữ liệu đầu vào và số lượng\\nnhóm cần tìm, hãy xác định centroid của mỗi nhóm và phân các điểm dữ liệu vào các nhóm\\ntương ứng. Giả sử thêm rằng mỗi điểm dữ liệu chỉ thuộc vào đúng một nhóm.\\nGiả sửN điểm dữ liệu trong training set được ghép lại thànhX = [x1,x2,..., xN] ∈Rd×N\\nvàK <N là số cluster được xác định trước. Ta cần tìm các centroidm1,m2,..., mK ∈Rd×1\\nvà label của mỗi điểm dữ liệu. Ở đây, mỗi cluster được đại diển bởi một label, thường là một\\nsố tự nhiên từ 1 đếnK. Nhắc lại rằng các điểm dữ liệu trong bài toánK-means clustering\\nban đầu không có label cụ thể, nhiệm vụ của ta là đi tìm label của chúng sao cho các điểm\\ncó cùng label nằm gần nhau, tạo thành một cluster.\\n2 Vonoroi diagram–Wikipedia(https://goo.gl/xReCW8 ).\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 123, 'page_label': '112'}, page_content='CHƯƠNG 10. K-MEANS CLUSTERING 112\\nVới mỗi điểm dữ liệuxi, ta cần tìm labelyi = kcủa nó, ở đâyk∈{1,2,...,K }. Một kỹ thuật\\nkhác khác thường được dùng để biểu diễn label này có tên làone-hot coding. Mỗi labelkđược\\nthay thế bằng mộtvector hàngyi ∈R1×K–được gọi làlabel vector, trong đó tất cả các phần\\ntử củayi bằng 0, ngoại trừ phần tử ở vị trí thứk bằng 1. Cụ thể,yij = 0, ∀j ̸= k,yik = 1.\\nKhi chồng các vectoryi lên nhau, ta được một ma trận labelY ∈RN×K. Nhắc lại rằngyij là\\nphần tử hàng thứi, cột thứj của ma trậnY, và nó cũng chính là phần tử thứj của vector\\nyi. Ví dụ, nếu một điểm dữ liệu có label vector là[1,0,0,..., 0] thì nó thuộc vào cluster thứ\\nnhất, là [0,1,0,..., 0] thì nó thuộc vào cluster thứ hai, v.v. Ràng buộc củayi có thể viết\\ndưới dạng toán học như sau:\\nyij ∈{0,1}, ∀i,j;\\nK∑\\nj=1\\nyij = 1, ∀i (10.1)\\n10.2.1 Hàm mất mát và bài toán tối ưu\\nNếu gọi mk ∈Rd là centroid của mỗi cluster và thay thế tất cả các điểm được phân vào\\ncluster này bởimk, một điểm dữ liệuxi được phân vào clusterk sẽ bị sai số là(xi −mk).\\nChúng ta mong muốn vector sai số này gần với vector không, tứcxi gần vớimk. Một đại\\nlượng đơn giản giúp đo khoảng cách giữa hai điểm là (bình phương) khoảng cách Euclid\\n∥xi −mk∥2\\n2. Hơn nữa, vìxi được phân vào clusterk nên yik = 1,yij = 0, ∀j ̸= k. Khi đó,\\nbiểu thức khoảng cách Euclid có thể được viết lại thành\\n∥xi −mk∥2\\n2 = yik∥xi −mk∥2\\n2 =\\nK∑\\nj=1\\nyij∥xi −mj∥2\\n2 (10.2)\\nNhư vậy, sai số trung bình cho toàn bộ dữ liệu sẽ là:\\nL(Y,M) = 1\\nN\\nN∑\\ni=1\\nK∑\\nj=1\\nyij∥xi −mj∥2\\n2 (10.3)\\nTrong đó M = [ m1,m2,..., mK] ∈Rd×K là ma trận tạo bởiK centroid. Hàm mất mát\\ntrong bài toánK-means clustering làL(Y,M) với ràng buộc như được nêu trong (10.1).\\nTóm lại, bài toán cần tối ưu là\\nY,M = argmin\\nY,M\\n1\\nN\\nN∑\\ni=1\\nK∑\\nj=1\\nyij∥xi −mj∥2\\n2\\nthoả mãn:yij ∈{0,1}, ∀i,j;\\nK∑\\nj=1\\nyij = 1, ∀i\\n(10.4)\\n10.2.2 Thuật toán tối ưu hàm mất mát\\nBài toán (10.4) là một bài toán khó tìmđiểm tối ưuvì nó có thêm các điều kiện ràng buộc.\\nBài toán này thuộc loại mix-integer programming (điều kiện biến là số nguyên) - là loại rất\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 124, 'page_label': '113'}, page_content='113 CHƯƠNG 10. K-MEANS CLUSTERING\\nkhó tìm nghiệm tối ưu toàn cục.Tuy nhiên, trong một số trường hợp chúng ta vẫn có thể\\ntìm được phương pháp để tìm được nghiệm gần đúng. Một kỹ thuật đơn giản và phổ biến\\nđể giải bài toán (10.4) là xen kẽ giảiY và M khi biến còn lại được cố định tới khi hàm mất\\nmát hội tụ. Chúng ta sẽ lần lượt giải quyết hai bài toán sau.\\nCố địnhM, tìmY\\nGiả sử đã tìm được các centroid, hãy tìm các label vector để hàm mất mát đạt\\ngiá trị nhỏ nhất.Điều này tương đương với việc tìm cluster cho mỗi điểm dữ liệu. Khi\\ncác centroid là cố định, bài toán tìm label vector cho toàn bộ dữ liệu có thể được chia nhỏ\\nthành bài toán tìm label vector cho từng điểm dữ liệuxi như sau:\\nyi = argmin\\nyi\\n1\\nN\\nK∑\\nj=1\\nyij∥xi −mj∥2\\n2\\nthoả mãn:yij ∈{0,1}, ∀i,j;\\nK∑\\nj=1\\nyij = 1, ∀i\\n(10.5)\\nVì chỉ có một phần tử của label vectoryi bằng 1 nên bài toán (10.5) chính là bài toán đi\\ntìm centroid gần điểmxi nhất: j = argminj ∥xi −mj∥2\\n2.\\nVì ∥xi −mj∥2\\n2 chính là bình phương khoảng cách Euclid từ điểmxi tới centroidmj, ta có\\nthể kết luận rằngmỗi điểmxi thuộc vào cluster có centroid gần nó nhất! Từ đó ta\\ncó thể suy ra label vector của từng điểm dữ liệu.\\nCố địnhY, tìmM\\nGiả sử đã tìm được cluster cho từng điểm, hãy tìm centroid mới cho mỗi cluster\\nđể hàm mất mát đạt giá trị nhỏ nhất.\\nMột khi label vector cho từng điểm dữ liệu đã được xác định, bài toán tìm centroid cho mỗi\\ncluster được rút gọn thành\\nmj = argmin\\nmj\\n1\\nN\\nN∑\\ni=1\\nyij∥xi −mj∥2\\n2. (10.6)\\nTới đây, ta có thể tìm nghiệm bằng phương pháp giải phương trình đạo hàm bằng không, vì\\nhàm cần tối ưu là một hàm liên tục và có đạo hàm xác định tại mọi điểmmj. Đặtl(mj) là\\nhàm bên trong dấuargmin trong 10.6, ta cần giải phương trình\\n∇mj l(mj) = 2\\nN\\nN∑\\ni=1\\nyij(mj −xi) = 0 ⇔mj\\nN∑\\ni=1\\nyij =\\nN∑\\ni=1\\nyijxi ⇔mj =\\n∑N\\ni=1 yijxi\\n∑N\\ni=1 yij\\n(10.7)\\nNếu để ý một chút, chúng ta sẽ thấy rằng mẫu số chính là phép đếmsố lượng các điểm dữ\\nliệu trong clusterj. Còn tử số chính làtổng các điểm dữ liệutrong clusterj. Nói cách khác,\\nmj là trung bình cộng (mean) của các điểm trong clusterj.\\nTên gọiK-means clusteringcũng xuất phát từ đây.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 125, 'page_label': '114'}, page_content='CHƯƠNG 10. K-MEANS CLUSTERING 114\\n10.2.3 Tóm tắt thuật toán\\nTới đây, ta có thể tóm tắt thuật toán K-means clustering như sau.\\nThuật toán 10.1:K-means clustering\\nĐầu vào:Ma trận dữ liệuX ∈Rd×N và số lượng cluster cần tìmK <N.\\nĐầu ra:Ma trận các centroidM ∈Rd×K và ma trận labelY ∈RN×K.\\n1. Chọn K điểm bất kỳ trong training set làm các centroid ban đầu.\\n2. Phân mỗi điểm dữ liệu vào cluster có centroid gần nó nhất.\\n3. Nếu việc phân nhóm dữ liệu vào từng cluster ở bước 2 không thay đổi so với vòng\\nlặp trước nó thì ta dừng thuật toán.\\n4. Cập nhật centroid cho từng cluster bằng cách lấy trung bình cộng của tất các các\\nđiểm dữ liệu đã được gán vào cluster đó sau bước 2.\\n5. Quay lại bước 2.\\nThuật toán này được đảm bảo sẽ hội tụ sau một số hữu hạn vòng lặp. Thật vậy, vì hàm mất\\nmát là một số dương và sau mỗi bước 2 hoặc 3, giá trị của hàm mất mát bị giảm đi. Vậy,\\ndãy số biểu diễn giá trị của hàm mất mát sau mỗi bước là một đại lượng không tăng và bị\\nchặn dưới, điều này chỉ ra rằng dãy số này phải hội tụ. Để ý thêm nữa, số lượng cách phân\\nnhóm cho toàn bộ dữ liệu là hữu hạn (khi số clusterK là cố định) nên đến một lúc nào đó,\\nhàm mất mát sẽ không thể thay đổi, và chúng ta có thể dừng thuật toán tại đây.\\nNếu tồn tại một cluster không chứa điểm nào, mẫu số trong (10.7) sẽ bằng không, và phép\\nchia sẽ không thực hiện được. Vì vậy,K điểm bất kỳ trong training set được chọn làm các\\ncentroid ban đầu ở Bước 1. để đảm bảo rằng mỗi cluster có ít nhất một điểm. Trong quá\\ntrình huấn luyện, nếu tồn tại một cluster không chứa điểm nào, có hai cách giải quyết. Cách\\nthứ nhất là bỏ đi cluster đó và giảmK đi một. Cách thứ hai là thay centroid của cluster đó\\nbằng một điểm bất kỳ trong training set, chẳng hạn, điểm xa centroid hiện tại của nó nhất.\\n10.3 Ví dụ trên Python\\n10.3.1 Giới thiệu bài toán\\nChúng ta sẽ làm một ví dụ đơn giản. Trước hết, ta tạo centroid và dữ liệu cho từng cluster\\nbằng cách lấy mẫu theo phân phối chuẩn có kỳ vọng là centroid của cluster đó và ma trận\\nhiệp phương sai là ma trận đơn vị. Ở đây, hàmcdist trong scipy.spatial.distance được dùng\\nđể tính khoảng cách giữa các cặp điểm trong hai tập hợp một cách hiệu quả3.\\nDữ liệu được tạo bằng cách lấy ngẫu nhiên 500 điểm cho mỗi cluster theo phân phối chuẩn\\ncó kỳ vọng lần lượt là(2, 2), (8, 3) và (3, 6), ma trận hiệp phương sai giống nhau và là\\nma trận đơn vị.\\n3 việc xây dựng hàm số này không sử dụng thư viện đã được thảo luận kỹ trong Chương 9\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 126, 'page_label': '115'}, page_content='115 CHƯƠNG 10. K-MEANS CLUSTERING\\nfrom __future__ import print_function\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\nfrom scipy.spatial.distance import cdist\\nimport random\\nnp.random.seed(18)\\nmeans = [[2, 2], [8, 3], [3, 6]]\\ncov = [[1, 0], [0, 1]]\\nN = 500\\nX0 = np.random.multivariate_normal(means[0], cov, N)\\nX1 = np.random.multivariate_normal(means[1], cov, N)\\nX2 = np.random.multivariate_normal(means[2], cov, N)\\nX = np.concatenate((X0, X1, X2), axis = 0)\\nK = 3 # 3 clusters\\noriginal_label = np.asarray([0]*N + [1]*N + [2]*N).T\\n10.3.2 Các hàm số cần thiết choK-means clustering\\nTrước khi viết thuật toán chínhK-means clustering, ta cần viết một số hàm phụ trợ:\\n1. kmeans_init_centroids để khởi tạo các centroids ban đầu.\\n2. kmeans_asign_labels để tìm label mới cho các điểm khi cố định các centroid.\\n3. kmeans_update_centroids để cập nhật các centroid khi biết label của mỗi điểm dữ liệu.\\n4. has_converged để kiểm tra điều kiện dừng của thuật toán.\\ndef kmeans_init_centroids(X, k):\\n# randomly pick k rows of X as initial centroids\\nreturn X[np.random.choice(X.shape[0], k, replace=False)]\\ndef kmeans_assign_labels(X, centroids):\\n# calculate pairwise distances btw data and centroids\\nD = cdist(X, centroids)\\n# return index of the closest centroid\\nreturn np.argmin(D, axis = 1)\\ndef has_converged(centroids, new_centroids):\\n# return True if two sets of centroids are the same\\nreturn (set([tuple(a) for a in centroids]) ==\\nset([tuple(a) for a in new_centroids]))\\ndef kmeans_update_centroids(X, labels, K):\\ncentroids = np.zeros((K, X.shape[1]))\\nfor k in range(K):\\n# collect all points that are assigned to the k-th cluster\\nXk = X[labels == k, :]\\ncentroids[k,:] = np.mean(Xk, axis = 0) # then take average\\nreturn centroids\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 127, 'page_label': '116'}, page_content='CHƯƠNG 10. K-MEANS CLUSTERING 116\\nPhần chính củaK-means clustering:\\ndef kmeans(X, K):\\ncentroids = [kmeans_init_centroids(X, K)]\\nlabels = []\\nit = 0\\nwhile True:\\nlabels.append(kmeans_assign_labels(X, centroids[-1]))\\nnew_centroids = kmeans_update_centroids(X, labels[-1], K)\\nif has_converged(centroids[-1], new_centroids):\\nbreak\\ncentroids.append(new_centroids)\\nit += 1\\nreturn (centroids, labels, it)\\nÁp dụng thuật toán vừa viết vào dữ liệu ban đầu, hiển thị kết quả cuối cùng.\\n(centroids, labels, it) = kmeans(X, K)\\nprint(’Centers found by our algorithm:\\\\n’, centroids[-1])\\nkmeans_display(X, labels[-1])\\nKết quả:\\nCenters found by our algorithm:\\n[[ 1.9834967 1.96588127]\\n[ 3.02702878 5.95686115]\\n[ 8.07476866 3.01494931]]\\nHình 10.2 minh hoạ thuật toánK-means clustering trên tập dữ liệu này sau một số vòng\\nlặp. Ta nhận thấy rằng centroid và các vùnglãnh thổ của chúng thay đổi qua các vòng lặp\\nvà hội tụ sau chỉ sáu vòng lặp. Từ kết quả này chúng ta thấy rằng thuật toánK-means\\nclustering làm việc khá thành công, các centroid tìm được gần với các centroid ban đầu,\\nvà các nhóm dữ liệu được phân ra gần như hoàn hảo (một vài điểm gần ranh giới giữa hai\\ncluster xanh có thể đã lẫn vào nhau).\\n10.3.3 Kết quả tìm được bằng thư viện scikit-learn\\nĐể kiểm tra thêm, chúng ta hãy so sánh kết quả trên với kết quả thu được bằng cách sử\\ndụng thư việnscikit−learn.\\nfrom sklearn.cluster import KMeans\\nmodel = KMeans(n_clusters=3, random_state=0).fit(X)\\nprint(’Centers found by scikit-learn:’)\\nprint(model.cluster_centers_)\\npred_label = model.predict(X)\\nkmeans_display(X, pred_label)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 128, 'page_label': '117'}, page_content='117 CHƯƠNG 10. K-MEANS CLUSTERING\\n2\\n 0 2 4 6 8 10\\n2\\n0\\n2\\n4\\n6\\n8\\n10\\niteration: 1/6\\n(a)\\n2\\n 0 2 4 6 8 10\\n2\\n0\\n2\\n4\\n6\\n8\\n10\\niteration: 2/6 (b)\\n2\\n 0 2 4 6 8 10\\n2\\n0\\n2\\n4\\n6\\n8\\n10\\niteration: 3/6 (c)\\n2\\n 0 2 4 6 8 10\\n2\\n0\\n2\\n4\\n6\\n8\\n10\\niteration: 4/6\\n(d)\\n2\\n 0 2 4 6 8 10\\n2\\n0\\n2\\n4\\n6\\n8\\n10\\niteration: 5/6 (e)\\n2\\n 0 2 4 6 8 10\\n2\\n0\\n2\\n4\\n6\\n8\\n10\\niteration: 6/6 (f)\\nHình 10.2: Thuật toánK-means clustering qua các vòng lặp.\\nKết quả:\\nCentroids found by scikit-learn:\\n[[ 8.0410628 3.02094748]\\n[ 2.99357611 6.03605255]\\n[ 1.97634981 2.01123694]]\\nTa nhận thấy rằng các centroid tìm được cũng rất gần với kết quả kỳ vọng. Từ các centroid\\nnày, cluster của mỗi điểm dữ liệu cũng dễ dàng được suy ra.\\nTiếp theo, chúng ta cùng xem xét ba ứng dụng đơn giản củaK-means clustering.\\n10.4 Phân nhóm chữ số viết tay\\n10.4.1 Bộ cơ sở dữ liệu MNIST\\nMNIST [LCB10] là bộ cơ sở dữ liệu lớn nhất về chữ số viết tay và được sử dụng trong hầu\\nhết các thuật toán phân lớp hình ảnh. MNIST bao gồm hai tập con: training set có tổng\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 129, 'page_label': '118'}, page_content='CHƯƠNG 10. K-MEANS CLUSTERING 118\\nHình 10.3: 200\\nmẫu ngẫu nhiên\\ntrong bộ cơ sở dữ\\nliệu MNIST.\\nHình 10.4:Ví dụ về\\nchữ số 7 và giá trị\\ncác pixel của nó.\\ncộng 60 nghìn mẫu khác nhau về chữ số viết tay từ 0 đến 9, test set có 10 nghìn mẫu khác\\nnhau. Tất cả đều đã được gán nhãn. Hình 10.3 hiển thị 200 mẫu được trích ra từ MNIST.\\nMỗi bức ảnh là một ảnh xám (chỉ có một channel), có kích thước28 ×28 pixel (tổng cộng\\n784 pixel). Mỗi pixel mang một giá trị là một số tự nhiên từ 0 đến 255. Các pixel màu đen\\ncó giá trị bằng không, các pixel càng trắng thì có giá trị càng cao, nhưng không quá 255.\\nHình 10.4 là một ví dụ về chữ số 7 và giá trị các pixel của nó.Vì mục đích hiển thị ma trận\\npixel ở bên phải, bức ảnh kích thước28 ×28 ban đầu đã được resize về kích thước14 ×14.\\n10.4.2 Bài toán phân nhóm giả định\\nBài toán: Giả sử rằng ta không biết nhãn của các chữ số này, hãy phân các bức\\nảnh gần giống nhau về một nhóm.\\nBài toán này có thể được giải quyết bằng K-means clustering.\\nMỗi bức ảnh được coi là một điểm dữ liệu. Vector đặc trưng của một bức ảnh đơn giản là\\nvector cột cỡ784 ×1 thu được bằng cáchchồng các cột của bức ảnh ban đầu lên nhau.\\n10.4.3 Làm việc trên Python\\nĐể tải về MNIST, chúng ta có thể dùng trực tiếp một hàm số trong scikit-learn như sau.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 130, 'page_label': '119'}, page_content='119 CHƯƠNG 10. K-MEANS CLUSTERING\\nfrom __future__ import print_function\\nimport numpy as np\\nfrom sklearn.datasets import fetch_mldata\\ndata_dir = ’../../data’ # path to your data folder\\nmnist = fetch_mldata(’MNIST original’, data_home=data_dir)\\nprint(\"Shape of minst data:\", mnist.data.shape)\\nKết quả:\\nShape of minst data: (70000, 784)\\nshape của ma trận dữ liệumnist.data là (70000, 784) tức có 70000 mẫu, mỗi mẫu có kích\\nthước 784. Chú ý rằng trong scikit-learn, mỗi điểm dữ liệu thường được lưu dưới dạng một\\nvector hàng. Tiếp theo, chúng ta lấy ra ngẫu nhiên 10000 mẫu và thực hiện K-means cluster\\ntrên tập con này.\\nfrom sklearn.cluster import KMeans\\nfrom sklearn.neighbors import NearestNeighbors\\nK = 10 # number of clusters\\nN = 10000\\nX = mnist.data[np.random.choice(mnist.data.shape[0], N)]\\nkmeans = KMeans(n_clusters=K).fit(X)\\npred_label = kmeans.predict(X)\\nSau khi thực hiện đoạn code trên, các centroid được lưu trong biếnkmeans.cluster_centers_,\\nlabel của mỗi điểm dữ liệu được lưu trong biếnpred_label. Hình 10.5 hiển thị các centroid\\ntìm được và 20 mẫu ngẫu nhiên được phân vào mỗi cluster tương ứng. Mỗi hàng tương ứng\\nvới một cluster, cột đầu tiên có nền xanh bên trái là các centroid tìm được (màu đỏ hơn là\\ncác pixel có giá trị cao hơn). Chúng ta thấy rằng các centroid đều hoặc là giống với một chữ\\nsố nào đó, hoặc là kết hợp của hai/ba chữ số nào đó. Ví dụ, centroid ở hàng thứ 4 là sự kết\\nhợp của các số 4, 7, 9; ở hàng thứ 7 là kết hợp của chữ số 7, 8 và 9.\\nQuan sát thấy các bức ảnh lấy ra ngẫu nhiên từ mỗi cluster trông không thực sự giống nhau.\\nLý do có thể là những bức ảnh này ở xa các centroid mặc dù centroid đó đã là gần nhất.\\nNhư vậy K-means clustering làm việc chưa thực sự tốt trong trường hợp này. Tuy nhiên,\\nchúng ta vẫn có thể khai thác một số thông tin hữu ích sau khi thực hiện thuật toán này.\\nThay vì chọn ngẫu nhiên các bức ảnh trong mỗi cluster, ta chọn 20 bức ảnh gần centroid\\ncủa mỗi cluster nhất, vì càng gần centroid thì độ tin cậy càng cao. Hãy quan sát Hình 10.6.\\nTa có thể thấy dữ liệu trong mỗi hàng khá giống nhau và giống với centroid ở cột đầu tiên\\nbên trái. Có một vài quan sát thú vị có thể rút ra từ đây:\\n1. Có hai kiểu viết chữ số 1–thẳng và chéo. VàK-means clustering nghĩ rằng đó là hai chữ\\nsố khác nhau. Điều này là dễ hiểu vìK-means clustering là một thuật toán unsupervised\\nlearning. Nếu có sự can thiệp của con người, chúng có thể được nhóm lại thành một.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 131, 'page_label': '120'}, page_content='CHƯƠNG 10. K-MEANS CLUSTERING 120\\nHình 10.5: Hiển thị\\ncác centroid (cột đầu)\\nvà 20 điểmngẫu nhiên\\nđược phân vào từng\\ncluster. Các chữ số trên\\nmỗi hàng thuộc vào\\ncùng một cluster.\\nHình 10.6: Hiển thị\\ncác centroid (cột đầu)\\nvà20điểm gầncentroid\\nnhất được phân vào\\ntừng cluster. Các chữ\\nsố trên mỗi hàng thuộc\\nvào cùng một cluster.\\n2. Ở hàng thứ chín, chữ số 4 và 9 được phân vào cùng một cluster. Sự thật là hai chữ số\\nnày khá giống nhau. Điều tương tự xảy ra đối với hàng thứ bảy với các chữ số 7, 8, 9.\\nK-means clustering có thể được áp dụng để tiếp tục phân nhỏ các cluster đó.\\nTrong clustering có một kỹ thuật thường được sử dụng làclustering phân tầng(hierarchical\\nclustering [Ble08]). Có hai loại hierachical clustering:\\n• Agglomerative tức “đi từ dưới lên”. Ban đầu coi một vài điểm dữ liệu gần nhau là một\\ncluster, sau đó các cặp cluster gần giống nhau được gộp lại làm một cluster lớn hơn. Ở\\nđây, sự giống nhau của hai cluster có thể được xác định dựa trên khoảng cách giữa hai\\ncentroid tương ứng. Cụ thể hơn, ban đầu ta chọnK là một số lớn gần bằng số điểm dữ\\nliệu. Sau khi thực hiệnK-means clustering lần đầu, các cluster gần nhau được ghép lại\\nthành một cluster. Sau bước này, ta được một số lượng cluster nhỏ hơn. Ta tiếp tục làm\\nK-means clustering với điểm khởi tạo là centroid của các nhóm vừa thu được. Lặp lại\\nquá trình này đến khi nhận được kết quả chấp nhận được.\\n• Divisive tức “đi từ trên xuống”. Ban đầu coi tất cả các điểm dữ liệu thuộc cùng một\\ncluster, sau đó chia nhỏ mỗi cluster bằng một thuật toán clustering nào đó. Việc này có\\nthể được thực hiện bằng cách ban đầu chọn một sốK nhỏ làm số lượng cluster, sau đó\\ntrong mỗi cluster thu được, ta tiếp tục làmK-means clustering. Tiếp tục quá trình cho\\ntới khi được kết quả chấp nhận được.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 132, 'page_label': '121'}, page_content='121 CHƯƠNG 10. K-MEANS CLUSTERING\\nHình 10.7: Ảnh:Trọng Vũ(https:\\n//goo.gl/9D8aXW ) .\\n10.5 Tách vật thể trong ảnh\\nK-means clustering có thể được áp dụng vào một bài toán xử lý ảnh khác, bài toántách vật\\nthể trong ảnh(object segmentation). Cho bức ảnh như trong Hình 10.7, hãy xây dựng một\\nthuật toán tự động nhận ra vùng khuôn mặt và tách nó ra.\\nBức ảnh có ba màu chủ đạo: hồng ở khăn và môi; đen ở mắt, tóc, và hậu cảnh; màu da ở\\nvùng còn lại của khuôn mặt. Ảnh này khá rõ nét và các vùng được phân biệt rõ ràng bởi\\nmàu sắc nên chúng ta có thể áp dụng thuật toán K-means clustering. Thuật toán này sẽ\\nphân các pixel ảnh thành ba cluster, cluster chứa phần khuôn mặt có thể được chọn, có thể\\nbằng tay.\\nĐây là một bức ảnh màu, mỗi điểm ảnh sẽ được biểu diễn bởi ba giá trị tương ứng với màu\\nRed, Green, và Blue, mỗi giá trị này cũng là một số tự nhiên không vượt quá 255. Nếu coi\\nmỗi pixel là một điểm dữ liệu mô tả bởi một vector ba chiều chứa các giá trị này, sau đó áp\\ndụng thuật toán K-means clustering, chúng ta có thể có kết quả mong muốn.\\n10.5.1 Làm việc trên Python\\nKhai báo thư viện và load bức ảnh:\\nimport matplotlib.image as mpimg\\nimport matplotlib.pyplot as plt\\nimport numpy as np\\nfrom sklearn.cluster import KMeans\\nimg = mpimg.imread(’girl3.jpg’)\\nplt.imshow(img)\\nimgplot = plt.imshow(img)\\nplt.axis(’off’)\\nplt.show()\\nBiến đổi bức ảnh thành 1 ma trận mà mỗi hàng là 1 pixel với 3 giá trị màu\\nX = img.reshape((img.shape[0]*img.shape[1], img.shape[2]))\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 133, 'page_label': '122'}, page_content='CHƯƠNG 10. K-MEANS CLUSTERING 122\\nHình 10.8:Kết quả nhận được sau\\nkhi thực hiện K-means clustering\\ncho các điểm dữ liệu. Có ba clus-\\nter tương ứng với ba màu đỏ, hồng,\\nđen.\\nPhần còn lại của source code có thể được tìm thấy tạihttps://goo.gl/Tn6Gec .\\nSau khi tìm được các cluster, giá trị của mỗi pixel được thay bằng giá trị của centroid tương\\nứng. Kết quả được minh hoạ trên Hình 10.8. Ba màu đỏ, đen, và màu da đã được phân nhóm\\nkhá thành công. Và khuôn mặt có thể được tách ra từ phần có màu da (và vùng bên trong\\nnó). Như vậy,K-means clustering tạo ra một kết quả chấp nhận được cho bài toán này.\\n10.6 Image Compression (nén ảnh và nén dữ liệu nói chung)\\nTrước hết, xét đoạn code dưới đây.\\nfor K in [5, 10, 15, 20]:\\nkmeans = KMeans(n_clusters=K).fit(X)\\nlabel = kmeans.predict(X)\\nimg4 = np.zeros_like(X)\\n# replace each pixel by its centroid\\nfor k in range(K):\\nimg4[label == k] = kmeans.cluster_centroids_[k]\\n# reshape and display output image\\nimg5 = img4.reshape((img.shape[0], img.shape[1], img.shape[2]))\\nplt.imshow(img5, interpolation=’nearest’)\\nplt.axis(’off’)\\nplt.show()\\nGiải thích: Để ý thấy rằng mỗi một pixel có thể nhận một trong số2563 = 16,777,216 (16\\ntriệu màu). Đây là một số rất lớn (tương đương với 24 bit cho một điểm ảnh). Nếu ta muốn\\nlưu mỗi điểm ảnh với một số bit nhỏ hơn và chấp nhận mất dữ liệu ở một mức nào đó,\\nK-means clustering là một giải pháp đơn giản cho việc này. Trong bài toán segmentation\\nphía trên, có ba cluster, và mỗi một điểm ảnh sau khi xử lý sẽ được biểu diễn bởi một số\\ntương ứng với một cluster. Tuy nhiên, chất lượng bức ảnh rõ ràng đã giảm đi nhiều. Trong\\nđoạn code trên đây, ta đã làm một thí nghiệm nhỏ với số lượng cluster được tăng lên 5, 10,\\n15, 20. Sau khi tìm được centroid cho mỗi cluster, giá trị của một điểm ảnh được thay bằng\\ngiá trị của centroid tương ứng. Kết quả được cho trên Hình 10.9. Ta có thể quan sát thấy\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 134, 'page_label': '123'}, page_content='123 CHƯƠNG 10. K-MEANS CLUSTERING\\nHình 10.9: Chất lượng nén ảnh với số lượng cluster khác nhau.\\nrằng khi số lượng cluster tăng lên, chất lượng bức ảnh đã được cải thiện. Để nén bức ảnh\\nnày, ta chỉ cần lưuK centroid tìm được và label của mỗi điểm ảnh.\\n10.7 Thảo luận\\n10.7.1 Hạn chế củaK-means clustering\\n• Số lượng clusterK cần được xác định trước.Trong thực tế, nhiều trường hợp chúng\\nta không xác định được giá trị này. Bạn đọc có thể tham khảo một cách giúp xác định\\ngiá trịK này có tên là elbow method (https://goo.gl/euYhpK ).\\n• Nghiệm cuối cùng phụ thuộc vào các centroid được khởi tạo ban đầu.Trong\\nthuật toán này, hàm khởi tạokmeans_init_centroids chọn ngẫu nhiênK điểm từ tập dữ\\nliệu làm các centroid ban đầu. Thêm nữa, thuật toánK-means clustering không đảm\\nbảo tìm được nghiệm tối ưu toàn cục, nên nghiệm cuối cùng phụ thuộc rất nhiều vào\\ncác centroid được khởi tạo ban đầu. Hình 10.10 thể hiện các kết quả khác nhau khi các\\ncentroid được khởi tạo khác nhau. Ta cũng thấy rằng trường hợp (a) và (b) cho kết quả\\ntốt, trong khi kết quả thu được ở trường hợp (c) không thực sự tốt. Một điểm nữa có thể\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 135, 'page_label': '124'}, page_content='CHƯƠNG 10. K-MEANS CLUSTERING 124\\n2\\n 0 2 4 6 8 10\\n2\\n0\\n2\\n4\\n6\\n8\\n10\\niteration: 8/8\\n(a)\\n2\\n 0 2 4 6 8 10\\n2\\n0\\n2\\n4\\n6\\n8\\n10\\niteration: 14/14 (b)\\n2\\n 0 2 4 6 8 10\\n2\\n0\\n2\\n4\\n6\\n8\\n10\\niteration: 20/20 (c)\\nHình 10.10: Các giá trị khởi tạo ban đầu khác nhau dẫn đến các nghiệm khác nhau.\\nrút ra là số lượng vòng lặp tới khi thuật toán hội tụ cũng khác nhau. Trường hợp (a) và\\n(b) cùng cho kết quả tốt nhưng (b) chạy trong thời gian gần gấp đôi. Một kỹ thuật giúp\\nhạn chế nghiệm xấu như trường hợp (c) là chạy thuật toánK-means clustering nhiều lần\\nvới các centroid được khởi tạo khác nhau và chọn ra lần chạy cho giá trị hàm mất mát\\nthấp nhất4. Ngoài ra, [KA04], Kmeans++ [AV07,BMV+12] cũng là một vài thuật toán\\nnổi tiếng giúp chọn các centroid ban đầu.\\n• Các cluster cần có số lượng điểm gần bằng nhau. Hình 10.11a minh hoạ kết quả\\nkhi các cluster có số lượng điểm chênh lệch. Trong trường hợp này, nhiều điểm lẽ ra thuộc\\ncluster xanh lam đã bị phân nhầm vào cluster xanh lục.\\n• Các cluster cần có dạng hình tròn (cầu)Khi các cluster vẫn tuân theo phân phối\\nchuẩn nhưng ma trận hiệp phương sai không tỉ lệ với ma trận đơn vị, các cluster sẽ\\ncó dạng không phải là tròn (hoặc cầu trong không gian nhiều chiều). Khi đó,K-means\\nclustering cũng không hoạt động hiệu quả. Lý do chính là vìK-means clustering quyết\\nđịnh cluster của một điểm dữ liệu dựa trên khoảng cách Euclid của nó tới các centroid.\\nTrong trường hợp này, Gaussian mixture models (GMM) [Rey15] có thể cho kết quả tốt\\nhơn5. Trong GMM, mỗi cluster được giả sử tuân theo một phân phối chuẩn với ma trận\\nhiệp phương sai không nhất thiết tỉ lệ với ma trận đơn vị. Ngoài các centroid, các ma\\ntrận hiệp phương sai cũng là các biến cần tối ưu trong GMM.\\n• Khi một cluster bị bao bọc bởi một cluster khácHình 10.12 là một ví dụ kinh điển\\nvề việcK-means clustering không thể phân cụm dữ liệu. Một cách tự nhiên, chúng ta sẽ\\nphân dữ liệu ra thành bốn cluster: mắt trái, mắt phải, miệng, xung quanh mặt. Nhưng\\nvì mắt và miệng nằm trong khuôn mặt nênK-means clustering cho kết quả không chính\\nxác. Với dữ liệu như trong ví dụ này, spectral clustering [VL07,NJW02] sẽ cho kết quả tốt\\nhơn. Spectral clustering cũng coi các điểm gần nhau tạo thành một cluster, nhưng không\\ngiả sử về một centroid chung cho cả cluster. Spectral clustering được thực hiện dựa trên\\n4 KMeans–scikit-learn (https://goo.gl/5KavVn ).\\n5 Đọc thêm:Gaussian mixture models–Wikipedia(https://goo.gl/GzdauR ).\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 136, 'page_label': '125'}, page_content='125 CHƯƠNG 10. K-MEANS CLUSTERING\\n2\\n 0 2 4 6 8 10\\n2\\n0\\n2\\n4\\n6\\n8\\n10\\niteration: 17/17\\n(a)\\n2\\n 0 2 4 6 8 10\\n2\\n0\\n2\\n4\\n6\\n8\\n10\\niteration: 6/6 (b)\\nHình 10.11: K-means clustering hoạt động không thực sự tốt trong trường hợp các cluster có\\nsố lượng phần tử chênh lệch hoặc các cluster không có dạng hình tròn (cầu).\\nHình 10.12: Một ví dụ về việc\\nK-means clustering phân nhóm\\nsai.\\nmột đồ thị vô hướng với đỉnh là các điểm dữ liệu và cạnh được nối giữa các điểm gần\\nnhau, mỗi cạnh được đánh trọng số là một hàm của khoảng cách giữa hai điểm.\\n10.7.2 Các ứng dụng khác củaK-means clustering\\nMặc dù có những hạn chế,K-means clustering vẫn cực kỳ quan trọng trong machine learning\\nvà là nền tảng cho nhiều thuật toán phức tạp khác. Dưới đây là một vài ứng dụng khác của\\nK-means clustering.\\n1. Cách thay một điểm dữ liệu bằng centroid tương ứng là một trong số các kỹ thuật có\\ntên chung làVector Quantization – VQ[AM93]). Không chỉ trong nén dữ liệu, VQ còn\\nđược kết hợp với Bag-of-Words [LSP06] áp dụng rộng rãi trong các thuật toán xây dựng\\nvector đặc trưng cho các bài toán phân loại.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 137, 'page_label': '126'}, page_content='CHƯƠNG 10. K-MEANS CLUSTERING 126\\n2. Ngoài ra, VQ còn được áp dụng trong các bài toán tìm kiếm trong cơ sở dữ liệu lớn.\\nKhi lượng điểm dữ liệu rất lớn, việc tìm kiếm trở nên cực kỳ quan trọng. Khó khăn\\nchính của việc này là làm thế nào có thể tìm kiếm một cách nhanh chóng trong lượng\\ndữ liệu khổng lồ đó. Ý tưởng cơ bản là sử dụng các thuật toán clustering để phân các\\nđiểm dữ liệu thành nhiều nhóm nhỏ và xấp xỉ mỗi điểm dữ liệu bằng centroid tương\\nứng. Khi tìm điểm gần nhất của một điểmtruy vấn (query), thay vì tính khoảng cách\\ngiữa điểm truy vấn đó đến từng điểm trong cơ sở dữ liệu, ta sẽ chỉ cần tính khoảng\\ncách từ điểm đó tới các centroid (số lượng nhỏ hơn). Sau đó trả về các điểm được\\nphân vào centroid đó. Bạn đọc có thể đọc thêm các bài báo nổi tiếng gần đây về vấn\\nđề này: Product Quantization [JDS11], Cartesian k-means [NF13,JDJ17], Composite\\nQuantization [ZDW14], Additive Quantization [BL14].\\nSource code cho chương này có thể được tìm thấy tạihttps://goo.gl/QgW5f2 .\\n10.7.3 Đọc thêm\\n1. Clustering documents using k-means–scikit-learn(https://goo.gl/y4xsy2 ).\\n2. Voronoi Diagram - Wikipedia(https://goo.gl/v8WQEv ).\\n3. Cluster centroid initialization algorithm for K-means clustering(https://goo.gl/hBdody ).\\n4. Visualizing K-Means Clustering(https://goo.gl/ULbpUM ).\\n5. Visualizing K-Means Clustering - Standford(https://goo.gl/idzR2i ).\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 138, 'page_label': '127'}, page_content='Chương 11\\nNaive Bayes classifier\\n11.1 Naive Bayes classifier\\nXét các bài toán phân lớp vớiC class khác nhau. Thay vì tìm ra chính xác label của mỗi\\nđiểm dữ liệux ∈Rd, ta có thể đi tìm xác suất để đầu ra đó rơi vào mỗi class:p(y = c|x),\\nhoặc viết gọn thànhp(c|x). Biểu thức này được hiểu là xác suất để đầu ra là classc biết\\nrằng đầu vào là vectorx. Biểu thức này, nếu tính được, có thể giúp xác định class của mỗi\\nđiểm dữ liệu bằng cách chọn ra class có xác suất rơi vào cao nhất:\\nc= argmax\\nc∈{1,...,C}\\np(c|x) (11.1)\\nBiểu thức trong dấuargmax ở = (11.1) nhìn chung khó có cách tính trực tiếp. Thay vào đó,\\nquy tắc Bayes thường được sử dụng:\\nc= argmax\\nc\\np(c|x) = argmax\\nc\\np(x|c)p(c)\\np(x) = argmax\\nc\\np(x|c)p(c) (11.2)\\nDấu bằng thứ hai xảy ra theo quy tắc Bayes, dấu bằng thứ ba xảy ra vìp(x) ở mẫu số\\nkhông phụ thuộc vàoc. Tiếp tục quan sát,p(c) có thể được hiểu là xác suất để một điểmbất\\nkỳ rơi vào classc. Nếu training set lớn, nó có thể được xác định bằng maximum likelihood\\nestimation (MLE)–là tỉ lệ giữa số điểm thuộc classc và số điểm trong training set. Nếu\\ntraining set nhỏ, giá trị này có thể được ước lượng bằng maximum a posteriori (MAP). Cách\\nthứ nhất thường được sử dụng nhiều hơn.\\nThành phần còn lạip(x|c), tức phân phối của các điểm dữ liệu trong classc, thường rất khó\\ntính toán vìx là một biến ngẫu nhiên nhiều chiều. Để có thể ước lượng được phân phối đó,\\ntraining set phải rất lớn. Để giúp cho việc tính toán được đơn giản, người ta thường giả sử\\nrằng các thành phần của biến ngẫu nhiênx là độc lập với nhau khi đã biếtc:\\np(x|c) = p(x1,x2,...,x d|c) =\\nd∏\\ni=1\\np(xi|c) (11.3)'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 139, 'page_label': '128'}, page_content='CHƯƠNG 11. NAIVE BAYES CLASSIFIER 128\\nGiả thiết các chiều của dữ liệu độc lập với nhau là quá chặt và trên thực tế, ít khi tìm được\\ndữ liệu mà các thành phần hoàn toàn độc lập với nhau. Tuy nhiên, giả thiếtngây thơ(naive)\\nnày đôi khi mang lại những kết quả tốt bất ngờ. Giả thiết về sự độc lập của các chiều dữ\\nliệu này được gọi lànaive Bayes. Cách xác định label của dữ liệu dựa trên giả thiết này có\\ntên lànaive Bayes classifier (NBC).\\nNBC, nhờ vào tính đơn giản một cáchngây thơ, có tốc độ huấn luyện và kiểm thử rất nhanh.\\nViệc này giúp nó mang lại hiệu quả cao trong các bài toán large-scale.\\nỞ bước huấn luyện, các phân phốip(c) và p(xi|c),i = 1,...,d sẽ được xác định dựa vào dữ\\nliệu huấn luyện. Việc xác định các giá trị này có thể có thể dựa vào MLE hoặc MAP.\\nỞ bước kiểm thử, label của một điểm dữ liệu mớix được xác đinh bởi\\nc= argmax\\nc∈{1,...,C}\\np(c)\\nd∏\\ni=1\\np(xi|c) (11.4)\\nKhi d lớn và các xác suất nhỏ, biểu thức ở vế phải của (11.4) là một số rất nhỏ, khi tính\\ntoán có thể gặp sai số. Để giải quyết việc này, (11.4) thường được viết lại dưới dạng tương\\nđương bằng cách lấylog của vế phải:\\nc= argmax\\nc∈{1,...,C}\\n(\\nlog(p(c)) +\\nd∑\\ni=1\\nlog(p(xi|c))\\n)\\n(11.5)\\nViệc này không ảnh hưởng tới kết quả vìlog là một hàm đồng biến trên tập các số dương.\\nSự đơn giản của NBC mang lại hiệu quả đặc biệt trong các bài toán phân loại văn bản, ví\\ndụ bài toán lọc tin nhắn hoặc email rác. Trong phần sau của chương này, chúng ta cùng xây\\ndựng một bộ lọc email rác tiếng Anh đơn giản. Cả việc huấn luyện và kiểm thử của NBC\\nlà cực kỳ nhanh khi so với các phương pháp phân loại phức tạp khác. Việc giả sử các thành\\nphần trong dữ liệu là độc lập với nhau khiến cho việc tính toán mỗi phân phốip(xi|c) không\\nmất nhiều thời gian.\\nViệc tính toánp(xi|c) phụ thuộc vào loại dữ liệu. Có ba loại phân bố xác suất thường được\\nsử dụng phổ làGaussian naive Bayes, multinomial naive Bayes, vàBernoulli Naive. Chúng\\nta cùng xem xét vào từng loại.\\n11.2 Các phân phối thường dùng trong NBC\\n11.2.1 Gaussian naive Bayes\\nMô hình này được sử dụng chủ yếu trong loại dữ liệu mà các thành phần là các biến liên\\ntục. Với mỗi chiều dữ liệui và một classc, xi tuân theo một phân phối chuẩn có kỳ vọng\\nµci và phương saiσ2\\nci:\\np(xi|c) = p(xi|µci,σ2\\nci) = 1√\\n2πσ2\\nci\\nexp\\n(\\n−(xi −µci)2\\n2σ2\\nci\\n)\\n(11.6)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 140, 'page_label': '129'}, page_content='129 CHƯƠNG 11. NAIVE BAYES CLASSIFIER\\nTrong đó, bộ tham sốθ = {µci,σ2\\nci}được xác định bằng MLE dựa trên các điểm trong\\ntraining set thuộc classc.\\n11.2.2 Multinomial naive Bayes\\nMô hình này chủ yếu được sử dụng trong phân loại văn bản mà vector đặc trưng được xây\\ndựng dựa trên ý tưởng bag of words (BoW). Lúc này, mỗi văn bản được biểu diễn bởi một\\nvector có độ dàidchính là số từ trong từ điển. Giá trị của thành phần thứitrong mỗi vector\\nchính là số lần từ thứixuất hiện trong văn bản đó. Khi đó,p(xi|c) tỉ lệ với tần suất từ thứ\\ni (hay đặc trưng thứi cho trường hợp tổng quát) xuất hiện trong các văn bản của classc.\\nGiá trị này có thể được tính bằng\\nλci = p(xi|c) = Nci\\nNc\\n(11.7)\\nTrong đó:\\n• Nci là tổng số lần từ thứi xuất hiện trong các văn bản của classc. Nó chính là tổng của\\ntất cả các đặc trưng thứi của các vector đặc trưng ứng với classc.\\n• Nc là tổng số từ (kể cả lặp) xuất hiện trong classc. Nói cách khác, nó bằng tổng độ dài\\ncủa toàn bộ các văn bản thuộc vào classc. Có thể suy ra rằngNc = ∑d\\ni=1 Nci, từ đó∑d\\ni=1 λci = 1. Ở đâyd là số từ trong từ điển.\\nCách tính này có một hạn chế là nếu có một từ mới chưa bao giờ xuất hiện trong classc\\nthì biểu thức (11.7) sẽ bằng không, dẫn đến vế phải của (11.4) bằng không bất kể các giá\\ntrị còn lại có lớn thế nào (xem thêm ví dụ ở mục sau). Để giải quyết việc này, một kỹ thuật\\nđược gọi làLaplace smoothingđược áp dụng:\\nˆλci = Nci + α\\nNc + dα (11.8)\\nvới α là một số dương, thường bằng 1, để tránh trường hợp tử số bằng không. Mẫu số được\\ncộng vớidαđể đảm bảo tổng xác suất∑d\\ni=1\\nˆλci = 1. Như vậy, mỗi classcsẽ được mô tả bởi\\nmột bộ các số dương có tổng bằng 1:ˆλc = {ˆλc1,..., ˆλcd}.\\n11.2.3 Bernoulli Naive Bayes\\nMô hình này được áp dụng cho các loại dữ liệu mà mỗi thành phần là một giá trị nhị phân–\\nbằng 0 hoặc 1. Ví dụ, cũng với loại văn bản nhưng thay vì đếm tổng số lần xuất hiện của\\nmột từ trong văn bản, ta chỉ cần quan tâm từ đó có xuất hiện hay không.\\nKhi đó,p(xi|c) được tính bằng:\\np(xi|c) = p(i|c)xi + (1 −p(i|c))(1 −xi) (11.9)\\nvới p(i|c) có thể được hiểu là xác suất từ thứi xuất hiện trong các văn bản của classc.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 141, 'page_label': '130'}, page_content='CHƯƠNG 11. NAIVE BAYES CLASSIFIER 130\\n11.3 Ví dụ\\n11.3.1 Bắc hay Nam\\nGiả sử trong training set có các văn bản d1, d2, d3, d4 như trong Bảng 11.1. Mỗi văn bản\\nnày thuộc vào một trong hai lớp: B (Bắc) hoặc N (Nam). Hãy xác định lớp của văn bản d5.\\nBảng 11.1: Ví dụ về nội dung của các văn bản trong bài toán Bắc hay Nam\\nVăn bảnNội dung Lớp\\nTập huấn luyện\\nd1 hanoi pho chaolong hanoi B\\nd2 hanoi buncha pho omai B\\nd3 pho banhgio omai B\\nd4 saigon hutiu banhbo pho N\\nKiểm thử d5 hanoi hanoi buncha hutiu ?\\nTa có thể dự đoán rằng d5 thuộc classBắc.\\nBài toán này có thể được giải quyết bằng NBC sử dụng multinomial Naive Bayes hoặc\\nBernoulli naive Bayes. Chúng ta sẽ cùng làm ví dụ với mô hình thứ nhất và triển khai code\\ncho cả hai mô hình. Việc mô hình nào tốt hơn phụ thuộc vào mỗi bài toán. Chúng ta có thể\\nthử cả hai để chọn ra mô hình tốt hơn.\\nNhận thấy rằng ở đây có hai lớp B và N, ta cần đi tìmp(B) và p(N) dựa trên tần số xuất\\nhiện của mỗi class trong tập training. Ta sẽ có\\np(B) = 3\\n4, p (N) = 1\\n4 (11.10)\\nTập hợp toàn bộ các từ trong các văn bản, hay còn gọi là từ điển, là\\nV = {hanoi, pho, chaolong, buncha, omai, banhgio, saigon, hutiu, banhbo}\\nTổng cộng số phần tử trong từ điển là|V|= 9.\\nHình 11.1 minh hoạ quá trình huấn luyện và kiểm thử cho bài toán này khi sử dụng Multi-\\nnomial naive Bayes, trong đó Laplace smoothing được sử dụng vớiα= 1. Chú ý, hai giá trị\\ntìm được 1.5 ×10−4 và 1.75 ×10−5 không phải là hai xác suất cần tìm mà chỉ là hai đại\\nlượng tỉ lệ thuậnvới hai xác suất đó. Để tính cụ thể, ta có thể làm như sau\\np(B|d5) = 1.5 ×10−4\\n1.5 ×10−4 + 1.75 ×10−5 ≈0.8955, p (N|d5) = 1 −p(B|d5) ≈0.1045 (11.11)\\nNhư vậy xác suất để d5 rơi vào class B là 89.55%, vào class N là 10.45%. Bạn đọc có thể tự\\ntính với ví dụ khác: d6 = pho hutiu banhbo. Nếu tính toán đúng, ta sẽ thu được\\np(B|d6) ≈0.29, p (N|d6) ≈0.71 (11.12)\\nvà suy ra d6 thuộc vào class N.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 142, 'page_label': '131'}, page_content='131 CHƯƠNG 11. NAIVE BAYES CLASSIFIER\\nclass = B\\nhanoi pho chaolongbunchaomai banhgiosaigon hutiu banhbo\\nd= |V|= 9\\n2 1 1 0 0 0 0 0 0\\n1 1 0 1 1 0 0 0 0\\n0 1 0 0 1 1 0 0 0\\n3 3 1 1 2 1 0 0 0\\n4/20 4/20 2/20 2/20 3/20 2/20 1/20 1/20 1/20\\n⇒NB = 11\\n(20 =NB + |V|)\\nd1: x1\\nd2: x2\\nd3: x3\\nTotal\\n⇒ˆλB\\nclass = N\\n0 1 0 0 0 0 1 1 1\\n1/13 2/13 1/13 1/13 1/13 1/13 2/13 2/13 2/13\\nd4: x4 ⇒NN = 4\\n(13 =NN + |V|)⇒ˆλN\\nd5: x5 = [2,0,0,1,0,0,0,1,0]\\np(B|d5) ∝p(B) ∏d\\ni=1 p(xi|B)\\n= 3\\n4\\n(4\\n20\\n)2 2\\n20\\n1\\n20 ≈1.5 ×10−4\\np(N|d5) ∝p(N) ∏d\\ni=1 p(xi|N)\\n= 1\\n4\\n(1\\n13\\n)2 1\\n13\\n2\\n13 ≈1.75 ×10−5\\n⇒p(x5|B) >p(x5|N) ⇒d5 ∈class(B)\\nTRAINING TEST\\nHình 11.1: Minh hoạ NBC với Multinomial naive Bayes cho bài toánBắc hay Nam.\\n11.3.2 Naive Bayes Classifier với thư viện scikit-learn\\nĐể kiểm tra lại các phép tính toán phía trên, chúng ta cùng giải quyết bài toán này bằng\\nsikit-learn. Ở đây, dữ liệu huấn luyện và kiểm thử đã được đưa về dạng vector đặc trưng sử\\ndụng BoW.\\nfrom __future__ import print_function\\nfrom sklearn.naive_bayes import MultinomialNB\\nimport numpy as np\\n# train data\\nd1 = [2, 1, 1, 0, 0, 0, 0, 0, 0]\\nd2 = [1, 1, 0, 1, 1, 0, 0, 0, 0]\\nd3 = [0, 1, 0, 0, 1, 1, 0, 0, 0]\\nd4 = [0, 1, 0, 0, 0, 0, 1, 1, 1]\\ntrain_data = np.array([d1, d2, d3, d4])\\nlabel = np.array([’B’, ’B’, ’B’, ’N’])\\n# test data\\nd5 = np.array([[2, 0, 0, 1, 0, 0, 0, 1, 0]])\\nd6 = np.array([[0, 1, 0, 0, 0, 0, 0, 1, 1]])\\n## call MultinomialNB\\nmodel = MultinomialNB()\\n# training\\nmodel.fit(train_data, label)\\n# test\\nprint(’Predicting class of d5:’, str(model.predict(d5)[0]))\\nprint(’Probability of d6 in each class:’, model.predict_proba(d6))\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 143, 'page_label': '132'}, page_content='CHƯƠNG 11. NAIVE BAYES CLASSIFIER 132\\nKết quả:\\nPredicting class of d5: B\\nProbability of d6 in each class: [[ 0.29175335 0.70824665]]\\nKết quả này nhất quán với những kết quả được tính bằng tay ở trên.\\nNếu sử dụng Bernoulli naive Bayes, chúng ta cần thay đổi một chút về feature vector. Lúc\\nnày, các giá trị khác không sẽ đều được đưa về 1 vì ta chỉ quan tâm đến việc từ đó có xuất\\nhiện trong văn bản hay không.\\nfrom __future__ import print_function\\nfrom sklearn.naive_bayes import BernoulliNB\\nimport numpy as np\\n# train data\\nd1 = [1, 1, 1, 0, 0, 0, 0, 0, 0]\\nd2 = [1, 1, 0, 1, 1, 0, 0, 0, 0]\\nd3 = [0, 1, 0, 0, 1, 1, 0, 0, 0]\\nd4 = [0, 1, 0, 0, 0, 0, 1, 1, 1]\\ntrain_data = np.array([d1, d2, d3, d4])\\nlabel = np.array([’B’, ’B’, ’B’, ’N’]) # 0 - B, 1 - N\\n# test data\\nd5 = np.array([[1, 0, 0, 1, 0, 0, 0, 1, 0]])\\nd6 = np.array([[0, 1, 0, 0, 0, 0, 0, 1, 1]])\\n## call MultinomialNB\\nmodel = BernoulliNB()\\n# training\\nmodel.fit(train_data, label)\\n# test\\nprint(’Predicting class of d5:’, str(model.predict(d5)[0]))\\nprint(’Probability of d6 in each class:’, model.predict_proba(d6))\\nKết quả:\\nPredicting class of d5: B\\nProbability of d6 in each class: [[ 0.16948581 0.83051419]]\\nTa thấy rằng, với bài toán nhỏ này, cả hai mô hình đều cho kết quả giống nhau (xác suất\\ntìm được khác nhau nhưng không ảnh hưởng tới quyết định cuối cùng).\\n11.3.3 Naive Bayes Classifier cho bài toán spam filtering\\nTiếp theo, chúng ta cùng làm việc với một bộ cơ sở dữ liệu lớn hơn. Dữ liệu trong ví dụ\\nnày được lấy trongExercise 6: Naive Bayes–Machine Learning, Andrew Ng(https://goo.\\ngl/kbzR3d ). Trong ví dụ này, dữ liệu đã được xử lý, và là một tập con của cơ sở dữ liệu\\nLing-Spam dataset(https://goo.gl/whHCd9 ).\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 144, 'page_label': '133'}, page_content='133 CHƯƠNG 11. NAIVE BAYES CLASSIFIER\\nMô tả dữ liệuTập dữ liệu này bao gồm tổng cộng 960 email tiếng Anh, được tách thành\\ntraining set và test set theo tỉ lệ 700:260 với 50% trong mỗi tập là các spam email.\\nDữ liệu trong cơ sở dữ liệu này đã được xử lý khá đẹp. Các quy tắc xử lý như sau1:\\n1. Loại bỏstop words: Những từ xuất hiện thường xuyên như ‘and’, ‘the’, ‘of’, v.v. được\\nloại bỏ vì chúng xuất hiện ở cả hai loại, không ảnh hưởng nhiều đến việc quyết định.\\n2. Lemmatization:Nhữngtừcócùnggốcđượcđưavềcùngloại.Vídụ,‘include’,‘includes’,\\n‘included’ đều được đưa chung về ‘include’. Tất cả các từ cũng đã được đưa về dạng ký\\ntự thường (không phải HOA).\\n3. Loại bỏnon-words: các chữ số, dấu câu, và các ký tự đặc biệt đã được loại bỏ.\\nDưới đây là một ví dụ của một email không phải spam,trước khi được xử lý.\\nSubject: Re: 5.1344 Native speaker intuitions\\nThe discussion on native speaker intuitions has been extremely interesting, but\\nI worry that my brief intervention may have muddied the waters. I take it that\\nthere are a number of separable issues. The first is the extent to which a\\nnative speaker is likely to judge a lexical string as grammatical or\\nungrammatical per se. The second is concerned with the relationships between\\nsyntax and interpretation (although even here the distinction may not be\\nentirely clear cut).\\nvà sau khi được xử lý:\\nre native speaker intuition discussion native speaker intuition extremely\\ninterest worry brief intervention muddy waters number separable issue first\\nextent native speaker likely judge lexical string grammatical ungrammatical\\nper se second concern relationship between syntax interpretation although\\neven here distinction entirely clear cut\\nVà dưới đây là một ví dụ vềspam email sau khi được xử lý.\\nfinancial freedom follow financial freedom work ethic extraordinary desire earn\\nleast per month work home special skills experience required train personal\\nsupport need ensure success legitimate homebased income opportunity put back\\ncontrol finance life ve try opportunity past fail live promise\\nChúng ta thấy rằng trong đoạn này có các từ như:financial, extraordinary, earn, opportunity,\\nv.v. là những từ thường thấy trong các email spam.\\nTrong ví dụ này, chúng ta sẽ sử dụng Multinomial Naive Bayes.\\n1 Bạn đọc có thể tham khảo thư việnNLTK (http://www.nltk.org/ ) cho các công việc xử lý dữ liệu này.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 145, 'page_label': '134'}, page_content='CHƯƠNG 11. NAIVE BAYES CLASSIFIER 134\\nĐể cho bài toán được đơn giản hơn, chúng ta sẽ tiếp tục sử dụng dữ liệu đã được xử lý, có\\nthể được download tạihttps://goo.gl/CSMxHU . Trong folder sau khi giải nén, chúng ta sẽ\\nthấy các file:\\ntest-features.txt\\ntest-labels.txt\\ntrain-features-50.txt\\ntrain-features-100.txt\\ntrain-features-400.txt\\ntrain-features.txt\\ntrain-labels-50.txt\\ntrain-labels-100.txt\\ntrain-labels-400.txt\\ntrain-labels.txt\\ntương ứng với các file chứa dữ liệu của training set và test set. Filetrain−features−50.txt\\nchứa dữ liệu của training set thu gọn với chỉ tổng cộng 50 email. Mỗi filelabels.txt chứa\\nnhiều dòng, mỗi dòng là một ký tự 0 hoặc 1 thể hiện email lànon-spam hoặc spam.\\nMỗi filefeatures.txt chứa nhiều dòng, mỗi dòng có 3 số, chẳng hạn:\\n1 564 1\\n1 19 2\\nTrong đó, số đầu tiên là chỉ số của email, bắt đầu từ 1; số thứ hai là thứ tự của từ trong từ\\nđiển (tổng cộng 2500 từ); số thứ ba là số lượng của từ đó trong email đang xét. Dòng đầu\\ntiên nói rằng trong email thứ nhất, từ thứ 564 trong từ điển xuất hiện một lần. Cách lưu\\ndữ liệu như thế này giúp tiết kiệm bộ nhớ vì một email thường không chứa hết tất cả các\\ntừ trong từ điển mà chỉ chứa một lượng nhỏ, ta chỉ cần lưu các giá trị khác không.\\nNếu biểu diễn mỗi email bằng một vector hàng có độ dài bằng độ dài từ điển (2500) thì\\ndòng thứ nhất nói rằng đặc trưng thứ 564 của vector này bằng 1. Tương tự, đặc trưng thứ\\n19 của vector này bằng 2. Nếu không xuất hiện, các thành phần khác được mặc định bằng\\n0. Dựa trên các thông tin này, chúng ta có thể tiến hành lập trình với thư viện sklearn.\\nKhai báo thư viện và đường dẫn tới files:\\nfrom __future__ import print_function\\nimport numpy as np\\nfrom scipy.sparse import coo_matrix # for sparse matrix\\nfrom sklearn.naive_bayes import MultinomialNB, BernoulliNB\\nfrom sklearn.metrics import accuracy_score # for evaluating results\\n# data path and file name\\npath = ’ex6DataPrepared/’\\ntrain_data_fn = ’train-features.txt’\\ntest_data_fn = ’test-features.txt’\\ntrain_label_fn = ’train-labels.txt’\\ntest_label_fn = ’test-labels.txt’\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 146, 'page_label': '135'}, page_content='135 CHƯƠNG 11. NAIVE BAYES CLASSIFIER\\nTiếp theo ta cần viết hàm số đọc dữ liệu từ filedata_fn với label tương ứng được lưu trong\\nlabel_fn. Chú ý rằng số lượng từ trong từ điển là 2500.\\nDữ liệu sẽ được lưu trong một ma trận mà mỗi hàng là một vector đặc trưng của email. Ma\\ntrận này là một ma trận sparse nên chúng ta sẽ sử dụng hàmscipy.sparse.coo_matrix.\\nnwords = 2500\\ndef read_data(data_fn, label_fn):\\n## read label_fn\\nwith open(path + label_fn) as f:\\ncontent = f.readlines()\\nlabel = [int(x.strip()) for x in content]\\n## read data_fn\\nwith open(path + data_fn) as f:\\ncontent = f.readlines()\\n# remove ’\\\\n’ at the end of each line\\ncontent = [x.strip() for x in content]\\ndat = np.zeros((len(content), 3), dtype = int)\\nfor i, line in enumerate(content):\\na = line.split(’ ’)\\ndat[i, :] = np.array([int(a[0]), int(a[1]), int(a[2])])\\n# remember to -1 at coordinate since we’re in Python\\ndata = coo_matrix((dat[:, 2], (dat[:, 0] - 1, dat[:, 1] - 1)),\\\\\\nshape=(len(label), nwords))\\nreturn (data, label)\\nĐoạn code dưới đây giúp lấy dữ liệu huấn luyện và kiểm thử, sau đó tiến hành phân lớp sử\\ndụng MultinomialNB.\\n(train_data, train_label) = read_data(train_data_fn, train_label_fn)\\n(test_data, test_label) = read_data(test_data_fn, test_label_fn)\\nclf = MultinomialNB()\\nclf.fit(train_data, train_label)\\ny_pred = clf.predict(test_data)\\nprint(’Training size = %d, accuracy = %.2f%%’ % \\\\\\n(train_data.shape[0],accuracy_score(test_label, y_pred)*100))\\nKết quả:\\nTraining size = 700, accuracy = 98.08%\\nVậy là có tới 98.08% các email được phân loại đúng. Chúng ta tiếp tục thử với các bộ dữ\\nliệu training nhỏ hơn.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 147, 'page_label': '136'}, page_content='CHƯƠNG 11. NAIVE BAYES CLASSIFIER 136\\ntrain_data_fn = ’train-features-100.txt’\\ntrain_label_fn = ’train-labels-100.txt’\\ntest_data_fn = ’test-features.txt’\\ntest_label_fn = ’test-labels.txt’\\n(train_data, train_label) = read_data(train_data_fn, train_label_fn)\\n(test_data, test_label) = read_data(test_data_fn, test_label_fn)\\nclf = MultinomialNB()\\nclf.fit(train_data, train_label)\\ny_pred = clf.predict(test_data)\\nprint(’Training size = %d, accuracy = %.2f%%’ % \\\\\\n(train_data.shape[0],accuracy_score(test_label, y_pred)*100))\\ntrain_data_fn = ’train-features-50.txt’\\ntrain_label_fn = ’train-labels-50.txt’\\ntest_data_fn = ’test-features.txt’\\ntest_label_fn = ’test-labels.txt’\\n(train_data, train_label) = read_data(train_data_fn, train_label_fn)\\n(test_data, test_label) = read_data(test_data_fn, test_label_fn)\\nclf = MultinomialNB()\\nclf.fit(train_data, train_label)\\ny_pred = clf.predict(test_data)\\nprint(’Training size = %d, accuracy = %.2f%%’ % \\\\\\n(train_data.shape[0],accuracy_score(test_label, y_pred)*100))\\nKết quả:\\nTraining size = 100, accuracy = 97.69%\\nTraining size = 50, accuracy = 97.31%\\nTa thấy rằng thậm chí khi training set là rất nhỏ, 50 email tổng cộng, kết quả đạt được đã\\nrất ấn tượng.\\nNếu bạn muốn tiếp tục thử mô hìnhBernoulliNB:\\nclf = BernoulliNB(binarize = .5)\\nclf.fit(train_data, train_label)\\ny_pred = clf.predict(test_data)\\nprint(’Training size = %d, accuracy = %.2f%%’ % \\\\\\n(train_data.shape[0],accuracy_score(test_label, y_pred)*100))\\nKết quả:\\nTraining size = 50, accuracy = 69.62%\\nTa thấy rằng trong bài toán này,MultinomialNB hoạt động hiệu quả hơn.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 148, 'page_label': '137'}, page_content='137 CHƯƠNG 11. NAIVE BAYES CLASSIFIER\\n11.4 Thảo luận\\n11.4.1 Tóm tắt\\n• Naive Bayes classifiers (NBC) thường được sử dụng trong các bài toán phân loại văn bản.\\n• NBC có thời gian huấn luyện và kiểm thử rất nhanh. Điều này có được là do giả sử về\\ntính độc lập giữa các thành phần.\\n• Nếu giả sử về tính độc lập được thoả mãn (dựa vào bản chất của dữ liệu), NBC được cho\\nlà cho kết quả tốt hơn so với support vector machine (Phần VIII) và logistic regression\\n(Chương 14) khi có ít dữ liệu huấn luyện.\\n• NBC có thể hoạt động với các vector đặc trưng mà một phần là liên tục (sử dụng Gaussian\\nNaive Bayes), phần còn lại ở dạng rời rạc (sử dụng Multinomial hoặc Bernoulli). Chính\\nsự độc lập giữa các đặc trưng khiến NBC có khả năng này.\\n• Khi sử dụng Multinomial Naive Bayes, Laplace smoothing thường được sử dụng để tránh\\ntrường hợp một từ trong dữ liệu kiểm thử chưa xuất hiện trong training set.\\n• Source code trong chương này có thể được tìm thấy tại đây.\\n11.4.2 Đọc thêm\\n1. Text Classification and Naive Bayes - Stanford(https://goo.gl/HcefLX ).\\n2. 6 Easy Steps to Learn Naive Bayes Algorithm (with code in Python)(https://goo.gl/\\nodQaaY).\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 149, 'page_label': '138'}, page_content=''),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 150, 'page_label': '139'}, page_content='Phần IV\\nNeural networks'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 151, 'page_label': '140'}, page_content='Chương 12\\nGradient descent\\n12.1 Giới thiệu\\nHình 12.1 mô tả sự biến thiên của hàm sốf(x) = 1\\n2 (x−1)2 −2. Điểm màu xanh lục là một\\nđiểm cực tiểu(local minimum), và cũng là điểm làm cho hàm số đạt giá trị nhỏ nhất (global\\nminimum). Global minimum là một trường hợp đặc biệt của local minimum.\\nGiả sử ta đang quan tâm đến một hàm số một biến có đạo hàm mọi nơi. Cùng ôn lại một\\nvài điểm cơ bản:\\n1. Điểm local minimumx∗của hàm số là điểm có đạo hàmf′(x∗) bằng không. Hơn thế nữa,\\ntrong lân cận của nó, đạo hàm của các điểm phía bên tráix∗ là không dương, đạo hàm\\ncủa các điểm phía bên phảix∗ là không âm.\\n2. Đường tiếp tuyến với đồ thị hàm số đó tại một điểm bất kỳ có hệ số góc chính bằng đạo\\nhàm của hàm số tại điểm đó.\\nTrong Hình 12.1, các điểm bên trái của điểm local minimum màu xanh lục có đạo hàm âm,\\ncác điểm bên phải có đạo hàm dương. Và đối với hàm số này, càng xa về phía trái của điểm\\nlocal minimum thì đạo hàm càng âm, càng xa về phía phải thì đạo hàm càng dương.\\nTrong machine learning nói riêng và toán tối ưu nói chung, chúng ta thường xuyên phải tìm\\ncác giá trị lớn nhất hoặc nhỏ nhất của một hàm số. Nếu chỉ xét riêng các hàm khả vi liên\\ntục, việc giải phương trình đạo hàm bằng không thường rất phức tạp hoặc có thể ra vô số\\nnghiệm. Thay vào đó, người ta thường cố gắng tìm các điểm local minimum, và ở một mức\\nđộ nào đó, coi đó là một nghiệm cần tìm của bài toán.\\nCác điểm local minimum là nghiệm của phương trình đạo hàm bằng không (ta vẫn đang giả\\nsử rằng các hàm này liên tục và khả vi). Nếu bằng một cách nào đó có thể tìm được toàn bộ\\n(hữu hạn) các điểm cực tiểu, ta chỉ cần thay từng điểm local minimum đó vào hàm số rồi\\ntìm điểm làm cho hàm có giá trị nhỏ nhất. Tuy nhiên, trong hầu hết các trường hợp, việc'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 152, 'page_label': '141'}, page_content='141 CHƯƠNG 12. GRADIENT DESCENT\\nx\\nf\\n′\\n( x )\\nf ( x )\\n−∞ 1 + ∞\\n0− +\\n+ ∞ + ∞\\n-2\\nf ( x ) =\\n1\\n2\\n( x − 1)\\n2\\n− 2\\nx\\n∗\\nHình 12.1:Khảo sát sự biến thiên\\ncủa một đa thức bậc hai.\\ngiải phương trình đạo hàm bằng không là bất khả thi. Nguyên nhân có thể đến từ sự phức\\ntạp của dạng của đạo hàm, từ việc các điểm dữ liệu có số chiều lớn, hoặc từ việc có quá\\nnhiều điểm dữ liệu. Thực tế cho thấy, trong nhiều bài toán machine learning, các nghiệm\\nlocal minimum thường đã cho kết quả tốt, đặc biệt là trong neural networks.\\nHướng tiếp cận phổ biến nhất để giải quyết các bài toán tối ưu là xuất phát từ một điểm\\nđược coi làgần với nghiệm của bài toán, sau đó dùng một phép toán lặp đểtiến dần đến\\nđiểm cần tìm, tức đến khi đạo hàm gần với không. Gradient descent (GD) và các biến thể\\ncủa nó là một trong những phương pháp được dùng nhiều nhất.\\n12.2 GD cho hàm một biến\\nXét các hàm số một biếnf : R →R. Quay trở lại Hình 12.1 và một vài quan sát đã nêu.\\nGiả sửxt là điểm tìm được sau vòng lặp thứt. Ta cần tìm một thuật toán để đưaxt về càng\\ngần x∗ càng tốt. Có hai quan sát sau đây:\\n1. Nếu đạo hàm của hàm số tạixt là dương (f′(xt) >0) thìxt nằm về bên phải so vớix∗,\\nvà ngược lại. Để điểm tiếp theoxt+1 gần vớix∗ hơn, chúng ta cần di chuyểnxt về phía\\nbên trái, tức về phíaâm. Nói các khác,ta cần di chuyển ngược dấu với đạo hàm:\\nxt+1 = xt + ∆ (12.1)\\nTrong đó∆ là một đại lượng ngược dấu với đạo hàmf′(xt).\\n2. xt càng xa x∗ về phía bên phải thìf′(xt) càng lớn hơn 0 (và ngược lại). Vậy, lượng di\\nchuyển ∆, một cách tự nhiên nhất, là tỉ lệ thuận với−f′(xt).\\nHai nhận xét phía trên cho chúng ta một cách cập nhật đơn giản là\\nxt+1 = xt −ηf′(xt) (12.2)\\nTrong đóη là một số dương được gọi làtốc độ học(learning rate). Dấu trừ thể hiện việc\\nchúng ta phảiđi ngượcvới đạo hàm1. Các quan sát đơn giản phía trên, mặc dù không phải\\nđúng trong tất cả các trường hợp, là nền tảng cho rất nhiều phương pháp tối ưu.\\n1 Đây chính là lý do phương pháp này được gọi là gradient descent–descent nghĩa làđi ngược\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 153, 'page_label': '142'}, page_content='CHƯƠNG 12. GRADIENT DESCENT 142\\n12.2.1 Ví dụ đơn giản với Python\\nXét hàm sốf(x) = x2 + 5 sin(x) với đạo hàmf′(x) = 2x+ 5 cos(x). Giả sử bắt đầu từ một\\nđiểm x0 nào đó, tại vòng lặp thứt, chúng ta sẽ cập nhật như sau:\\nxt+1 = xt −η(2xt + 5 cos(xt)) (12.3)\\nKhi thực hiện trên Python, ta cần viết các hàm số2:\\n1. grad để tính đạo hàm.\\n2. cost để tính giá trị của hàm số. Hàm này không sử dụng trong thuật toán nhưng thường\\nđược dùng để kiểm tra việc tính đạo hàm có đúng không hoặc để xem giá trị của hàm số\\ncó giảm theo mỗi vòng lặp hay không.\\n3. myGD1 là phần chính thực hiện thuật toán GD nêu phía trên. Đầu vào của hàm số này là\\nlearning rate và điểm xuất phát. Thuật toán dừng lại khi đạo hàm có độ lớn đủ nhỏ.\\ndef grad(x):\\nreturn 2*x+ 5*np.cos(x)\\ndef cost(x):\\nreturn x**2 + 5*np.sin(x)\\ndef myGD1(x0, eta):\\nx = [x0]\\nfor it in range(100):\\nx_new = x[-1] - eta*grad(x[-1])\\nif abs(grad(x_new)) < 1e-3: # just a small number\\nbreak\\nx.append(x_new)\\nreturn (x, it)\\nĐiểm xuất phát khác nhau\\nSau khi đã có các hàm cần thiết, chúng ta thử tìm nghiệm với các điểm khởi tạo khác nhau\\nlà x0 = −5 và x0 = 5, với cùng learning rateη= 0.1.\\n(x1, it1) = myGD1(-5, .1)\\n(x2, it2) = myGD1(5, .1)\\nprint(’Solution x1 = %f, cost = %f, after %d iterations’%(x1[-1], cost(x1[-1]), it1))\\nprint(’Solution x2 = %f, cost = %f, after %d iterations’%(x2[-1], cost(x2[-1]), it2))\\nKết quả:\\nSolution x1 = -1.110667, cost = -3.246394, after 11 iterations\\nSolution x2 = -1.110341, cost = -3.246394, after 29 iterations\\n2 Giả sử rằng các thư viện đã được khai báo đầy đủ\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 154, 'page_label': '143'}, page_content='143 CHƯƠNG 12. GRADIENT DESCENT\\n−5 0 5\\niter 0/11, grad = -8.582\\n0\\n10\\n20\\n30\\n−5 0 5\\niter 1/11, grad = -10.984\\n0\\n10\\n20\\n30\\n−5 0 5\\niter 2/11, grad = -11.063\\n0\\n10\\n20\\n30\\n−5 0 5\\niter 3/11, grad = -5.665\\n0\\n10\\n20\\n30\\n−5 0 5\\niter 4/11, grad = -1.747\\n0\\n10\\n20\\n30\\n−5 0 5\\niter 5/11, grad = -0.561\\n0\\n10\\n20\\n30\\n−5 0 5\\niter 7/11, grad = -0.066\\n0\\n10\\n20\\n30\\n−5 0 5\\niter 11/11, grad = -0.001\\n0\\n10\\n20\\n30\\n.\\nHình 12.2: Nghiệm tìm được qua các vòng lặp vớix0 = −5,η = 0.1\\nVậy là với các điểm xuất phát khác nhau, thuật toán tìm được nghiệm gần giống nhau, mặc\\ndù với tốc độ hội tụ khác nhau. Hình 12.2 và Hình 12.3 thể hiện vị trí của nghiệm và đạo\\nhàm qua các vòng lặp với cùng learning rateη = .1 nhưng điểm khởi tạo khác nhau tại−5\\nvà 5.\\nHình 12.2 tương ứng vớix0 = −5, cho thấy nghiệm hội tụ nhanh hơn, vì điểm ban đầux0\\ngần với nghiệmx∗≈−1 hơn. Hơn nữa,đường đi tới nghiệm khá suôn sẻ với đạo hàm luôn\\nâm và càng gần nghiệm thì đạo hàm càng nhỏ.\\nTrong Hình 12.3 tương ứng vớix0 = 5, đường đi của nghiệm có chứa một khu vực có đạo\\nhàm khá nhỏ gần điểm có hoành độ bằng 2.5. Điều này khiến cho thuật toánla cà ở đây\\nkhá lâu. Khi vượt qua được điểm này thì mọi việc diễn ra rất tốt đẹp. Các điểm không phải\\nlà điểm cực tiểu nhưng có đạo hàm gần bằng không rất dễ gây ra hiện tượng nghiệm bịbẫy\\n(trapped) tại đây vì đạo hàm nhỏ khiến nó không thay đổi nhiều ở vòng lặp tiếp theo. Chúng\\nta sẽ thấy một kỹ thuật khác giúpthoát được những chiếc bẫy này.\\nLearning rate khác nhau\\nTốc độ hội tụ của GD không những phụ thuộc vào điểm xuất phát mà còn phụ thuộc vào\\nlearning rate. Hình 12.4 và Hình 12.5 thể hiện vị trí của nghiệm qua các vòng lặp với cùng\\nđiểm khởi tạox0 = −5 nhưng learning rate khác nhau. Ta quan sát thấy hai điều:\\n1. Vớilearning ratenhỏ η = 0.01 (Hình 12.4), tốc độ hội tụ rất chậm. Trong ví dụ này ta\\nchọn tối đa 100 vòng lặp nên thuật toán dừng lại trước khi tớiđích, mặc dù đã rất gần.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 155, 'page_label': '144'}, page_content='CHƯƠNG 12. GRADIENT DESCENT 144\\n−5 0 5\\niter 0/29, grad = 11.418\\n0\\n10\\n20\\n30\\n−5 0 5\\niter 3/29, grad = 1.517\\n0\\n10\\n20\\n30\\n−5 0 5\\niter 6/29, grad = 0.925\\n0\\n10\\n20\\n30\\n−5 0 5\\niter 10/29, grad = 0.983\\n0\\n10\\n20\\n30\\n−5 0 5\\niter 15/29, grad = 2.341\\n0\\n10\\n20\\n30\\n−5 0 5\\niter 20/29, grad = 4.739\\n0\\n10\\n20\\n30\\n−5 0 5\\niter 25/29, grad = 0.071\\n0\\n10\\n20\\n30\\n−5 0 5\\niter 29/29, grad = 0.001\\n0\\n10\\n20\\n30\\n.\\nHình 12.3: Nghiệm tìm được qua các vòng lặp vớix0 = 5,η = 0.1\\n−5 0 5\\niter 0/100, grad = -8.582\\n0\\n10\\n20\\n30\\n−5 0 5\\niter 10/100, grad = -11.230\\n0\\n10\\n20\\n30\\n−5 0 5\\niter 20/100, grad = -10.584\\n0\\n10\\n20\\n30\\n−5 0 5\\niter 30/100, grad = -6.175\\n0\\n10\\n20\\n30\\n−5 0 5\\niter 50/100, grad = -1.476\\n0\\n10\\n20\\n30\\n−5 0 5\\niter 70/100, grad = -0.368\\n0\\n10\\n20\\n30\\n−5 0 5\\niter 90/100, grad = -0.095\\n0\\n10\\n20\\n30\\n−5 0 5\\niter 100/100, grad = -0.049\\n0\\n10\\n20\\n30\\nHình 12.4: Nghiệm tìm được qua các vòng lặp với điểm xuất phátx0 = −5, learning rate\\nη= 0.01.\\nTrong thực tế, khi việc tính toán trở nên phức tạp,learning ratequá thấp sẽ ảnh hưởng\\ntới tốc độ của thuật toán rất nhiều, thậm chí không bao giờ tới được đích.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 156, 'page_label': '145'}, page_content='145 CHƯƠNG 12. GRADIENT DESCENT\\n−5 0 5\\niter 0/100, grad = -8.582\\n0\\n10\\n20\\n30\\n−5 0 5\\niter 1/100, grad = 2.376\\n0\\n10\\n20\\n30\\n−5 0 5\\niter 2/100, grad = -5.398\\n0\\n10\\n20\\n30\\n−5 0 5\\niter 3/100, grad = 5.081\\n0\\n10\\n20\\n30\\n−5 0 5\\niter 50/100, grad = -8.114\\n0\\n10\\n20\\n30\\n−5 0 5\\niter 70/100, grad = 4.663\\n0\\n10\\n20\\n30\\n−5 0 5\\niter 90/100, grad = -7.038\\n0\\n10\\n20\\n30\\n−5 0 5\\niter 100/100, grad = 4.761\\n0\\n10\\n20\\n30\\n.\\nHình 12.5: Nghiệm tìm được qua các vòng lặp vớix0 = −5,η = 0.5\\n2. Vớilearning ratelớn η= 0.5 (Hình 12.5), thuật toán tiến rất nhanh tớigần đíchsau vài\\nvòng lặp. Tuy nhiên, thuật toán không hội tụ được vì sự thay đổi vị trí của nghiệm sau\\nmỗi vòng lặp là quá lớn, khiến nó cứquẩn quanh ở đích mà vẫn không tới được đích.\\nViệc lựa chọnlearning rate rất quan trọng. Việc này phụ thuộc nhiều vào từng bài toán\\nvà phải làm một vài thí nghiệm để chọn ra giá trị tốt nhất. Ngoài ra, tùy vào một số bài\\ntoán, GD có thể làm việc hiệu quả hơn bằng cách chọn ralearning ratephù hợp hoặc chọn\\nlearning ratekhác nhau ở mỗi vòng lặp, thường là giảm dần.\\n12.3 GD cho hàm nhiều biến\\nGiả sử ta cần tìm global minimum cho hàmf(θ) trong đóθ là tập hợp các tham số cần tối\\nưu. Đạo hàm của hàm số đó tại một điểmθ bất kỳ được ký hiệu là∇θf(θ). Tương tự như\\nhàm một biến, thuật toán GD cho hàm nhiều biến cũng bắt đầu bằng một điểm dự đoánθ0,\\nsau đó, ở vòng lặp thứt, quy tắc cập nhật là\\nθt+1 = θt −η∇θf(θt) (12.4)\\nHoặc viết dưới dạng đơn giản hơn:θ←θ−η∇θf(θ).\\nQuay lại với bài toán linear regression\\nTrong mục này, chúng ta quay lại với bài toán linear regression và thử tối ưu hàm mất mát\\ncủa nó bằng thuật toán GD.\\nNhắc lại hàm mất mát của linear regression và đạo hàm theow lần lượt là\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 157, 'page_label': '146'}, page_content='CHƯƠNG 12. GRADIENT DESCENT 146\\n0.0 0.2 0.4 0.6 0.8 1.0\\n0\\n2\\n4\\n6\\n8\\n10\\nHình 12.6: Nghiệm của bài toán\\nlinear regression (đường thằng màu\\nvàng) tìm được bằng thư viện\\nscikit-learn.\\nL(w) = 1\\n2N∥y −XTw∥2\\n2; ∇wL(w) = 1\\nNX(XTw −y) (12.5)\\nSau đây là ví dụ trên Python và một vài lưu ý khi lập trình\\nTrước hết, chúng ta tạo 1000 điểm dữ liệu được chọngần với đường thẳngy= 4 + 3x:\\nfrom sklearn.linear_model import LinearRegression\\nX = np.random.rand(1000)\\ny = 4 + 3 * X + .5*np.random.randn(1000) # noise added\\nmodel = LinearRegression()\\nmodel.fit(X.reshape(-1, 1), y.reshape(-1, 1))\\nw, b = model.coef_[0][0], model.intercept_[0]\\nsol_sklearn = np.array([b, w])\\nprint(sol_sklearn)\\nKết quả:\\nSolution found by sklearn: [ 3.94323245 3.12067542]\\nCác điểm dữ liệu và đường thẳng tìm được bằng linear regression có phương trìnhy ≈\\n3.94 + 3.12x được minh hoạ trong Hình 12.6. Nghiệm tìm được rất gần với mong đợi.\\nTiếp theo, ta sẽ thực hiện tìm nghiệm của linear regression sử dụng GD. Ta cần viết hàm\\nmất mát và đạo hàm theow. Chú ý rằng ở đâyw đã bao gồm cả bias.\\ndef grad(w):\\nN = Xbar.shape[0]\\nreturn 1/N * Xbar.T.dot(Xbar.dot(w) - y)\\ndef cost(w):\\nN = Xbar.shape[0]\\nreturn .5/N*np.linalg.norm(y - Xbar.dot(w))**2\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 158, 'page_label': '147'}, page_content='147 CHƯƠNG 12. GRADIENT DESCENT\\nVới các hàm phức tạp, khi tính xong đạo hàm chúng ta cần kiểm tra đạo hàm thông qua\\nnumerical gradient (xem Mục 2.6). Trường hợp này tương đối đơn giản, việc kiểm tra đạo\\nhàm xin giành lại cho bạn đọc. Dưới đây là thuật toán GD cho bài toán.\\ndef myGD(w_init, grad, eta):\\nw = [w_init]\\nfor it in range(100):\\nw_new = w[-1] - eta*grad(w[-1])\\nif np.linalg.norm(grad(w_new))/len(w_new) < 1e-3:\\nbreak\\nw.append(w_new)\\nreturn (w, it)\\none = np.ones((X.shape[0],1))\\nXbar = np.concatenate((one, X.reshape(-1, 1)), axis = 1)\\nw_init = np.array([[2], [1]])\\n(w1, it1) = myGD(w_init, grad, 1)\\nprint(’Sol found by GD: w = ’, w1[-1].T, ’,\\\\nafter %d iterations.’ %(it1+1))\\nKết quả:\\nSol found by GD: w = [ 3.99026984 2.98702942] ,\\nafter 49 iterations.\\nSau 49 vòng lặp, thuật toán đã hội tụ với một nghiệm khá gần với nghiệm tìm được theo\\nsklearn. Hình 12.7 mô tả đường đi của nghiệm với cùng điểm khởi tạo nhưng với learning\\nrate khác nhau. Các điểm màu lam là các điểm xuất phát. Các điểm màu lục là nghiệm tìm\\nđược bằng thư viện scikit-learn. Các điểm màu đỏ là nghiệm qua các vòng lặp trung gian.\\nTa thấy rằng khieta= 1, thuật toán hội tụ tới (rất gần) nghiệm theo thư viện sau 49 vòng\\nlặp. Với learning rate nhỏ hơn,η= 0.1, sau hơn 100 vòng lặp, nghiệm vẫn còn cách xa đích.\\nNhư vậy, việc chọn learning rate hợp lý là rất quan trọng.\\nỞ đây, chúng ta cùng làm quen với một khái niệm quan trọng:đường đồng mức(level sets).\\nTa thường gặp khái niệmđường đồng mức trong các bản đồ tự nhiên. Các điểm có cùng\\nđộ cao so với mực nước biển thường được nối với nhau. Với các ngọn núi, đường đồng mức\\nthường là các đường kín bao quanh đỉnh núi. Khái niệm tương tự cũng được sử dụng trong\\ntối ưu.Đường đồng mứchay level setscủa một hàm số là tập hợp các điểm làm cho hàm số\\ncó cùng giá trị. Tưởng tượng một hàm số với hai biến, đồ thị của nó là mộtbề mặt(surface)\\ntrong không gian ba chiều. Đường đồng mức có thể được xác định bằng cáchcắt bề mặt này\\nbằng một mặt phẳng song song với đáy và lấy giao điểm của chúng. Với dữ liệu hai chiều,\\nhàm mất mát của linear regression là một hàm bậc hai của hai thành phần trong vector hệ\\nsố w. Đồ thị của nó là một bề mặt parabolic. Vì vậy, các đường đồng mức của hàm này là\\ncác đường ellipse có cùng tâm như trên Hình 12.7. Tâm này chính là đáy của parabolic và là\\ngiá trị nhỏ nhất của hàm mất mát. Các đường đồng mức được biểu diễn bởi các màu khác\\nnhau với màu từ lam đậm đến lục, vàng, cam, đỏ, đỏ đậm thể hiện giá trị tăng dần.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 159, 'page_label': '148'}, page_content='CHƯƠNG 12. GRADIENT DESCENT 148\\n2 3 4 5 6\\n0.5\\n1.0\\n1.5\\n2.0\\n2.5\\n3.0\\n3.5\\n4.0\\n4.5\\n51 iterations\\n(a) η= 1.\\n2 3 4 5 6\\n0.5\\n1.0\\n1.5\\n2.0\\n2.5\\n3.0\\n3.5\\n4.0\\n4.5\\n101 iterations (b) η= 0.1.\\nHình 12.7: Đường đi nghiệm của linear regression với các learning rate khác nhau.\\n12.4 GD với momentum\\nTrước hết, cùng nhắc lại thuật toán GD để tối ưu hàm mất mátJ(θ):\\n1. Dự đoán một điểm khởi tạoθ= θ0.\\n2. Cập nhậtθ đến khi đạt được kết quả chấp nhận được:\\nθ←θ−η∇θJ(θ) (12.6)\\nvới ∇θJ(θ) là đạo hàm của hàm mất mát tạiθ.\\nGradient dưới góc nhìn vật lý\\nThuật toán GD thường được ví với tác dụng của trọng lực lên một hòn bi đặt trên một mặt\\ncó dạng một thung lũng như Hình 12.8a. Bất kể ta đặt hòn bi ở A hay B thì cuối cùng hòn\\nbi cũng sẽ lăn xuống và kết thúc ở vị trí C.\\nTuy nhiên, nếu như bề mặt có hai đáy thung lũng như Hình 12.8b thì tùy vào việc đặt bi ở\\nA hoặc B, vị trí cuối cùng tương ứng của bi sẽ ở C hoặc D (giả sử rằng ma sát đủ lớn và đà\\nchưa quá lớn khiến bi không thể vượt dốc). Điểm D chính là một điểm local minimum.\\nNếu suy nghĩ một cách vật lý hơn, vẫn trong Hình 12.8b, nếu vận tốc ban đầu của bi khi ở\\nđiểm B đủ lớn, khi bi lăn đến điểm D, theođà, bi có thể tiếp tục di chuyển lên dốc phía bên\\ntrái của D. Và nếu giả sử vận tốc ban đầu lớn hơn nữa, bi có thể vượt dốc tới điểm E rồi lăn\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 160, 'page_label': '149'}, page_content='149 CHƯƠNG 12. GRADIENT DESCENT\\nHình 12.8: So sánh GD với các hiện tượng vật lý.\\nxuống C như trong Hình 12.8c. Dựa trên quan sát này, một thuật toán được ra đời nhằm\\ngiúp GD thoát được các local minimum. Thuật toán đó có tên làmomentum (tức theo đà).\\nGD với momentum\\nLàm thế nào để biểu diễnmomentum dưới dạng toán học?\\nTrong GD, chúng ta cần tính lượng thay đổi ở thời điểmtđể cập nhật vị trí mới cho nghiệm\\n(tức hòn bi). Nếu chúng ta coi đại lượng này như vận tốcvt trong vật lý, vị trí mới củahòn\\nbi sẽ làθt+1 = θt−vt, với giả sử rằng mỗi vòng lặp là một đơn vị thời gian. Dấu trừ thể hiện\\nviệc phải di chuyển ngược với đạo hàm. Việc tiếp theo là tính đại lượngvt sao cho nó vừa\\nmang thông tin củađộ dốc(tức đạo hàm), vừa mang thông tin củađà, tức vận tốc trước đó\\nvt−1 (với giả sử rằng vận tốc ban đầuv0 = 0). Một cách đơn giản nhất, ta có thể lấy tổng\\ncó trọng số của chúng:\\nvt = γvt−1 + η∇θJ(θ) (12.7)\\nTrong đóγ thường được chọn là một giá trị nhỏ hơn gần bằng một, thường là khoảng 0.9,\\nvt−1 là vận tốc tại thời điểm trước đó,∇θJ(θ) chính là độ dốc của điểm trước đó. Sau đó,\\nvị trí mới củahòn bi được xác định bởi\\nθ←θ−vt = θ−η∇θJ(θ) −γvt−1 (12.8)\\nSự khác nhau giữa GD thông thường và GD với momentem chỉ nằm ở thành phần cuối cùng\\ncủa (12.8). Thuật toán đơn giản này tỏ ra rất hiệu quả trong các bài toán thực tế. Dưới đây\\nlà một ví dụ trong không gian một chiều. Xét một hàm đơn giản có hai điểm local minimum,\\ntrong đó một điểm là global minimum\\nf(x) = x2 + 10 sin(x) (12.9)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 161, 'page_label': '150'}, page_content='CHƯƠNG 12. GRADIENT DESCENT 150\\n−5 0 5\\niter 0/4, grad = 12.837\\n−10\\n0\\n10\\n20\\n30\\n−5 0 5\\niter 1/4, grad = -0.961\\n−10\\n0\\n10\\n20\\n30\\n−5 0 5\\niter 2/4, grad = -0.208\\n−10\\n0\\n10\\n20\\n30\\n−5 0 5\\niter 4/4, grad = -0.006\\n−10\\n0\\n10\\n20\\n30\\nHình 12.9: GD thông thường.\\n−5 0 5\\niter 0/100, grad = 12.837\\n−10\\n0\\n10\\n20\\n30\\n−5 0 5\\niter 1/100, grad = -0.961\\n−10\\n0\\n10\\n20\\n30\\n−5 0 5\\niter 2/100, grad = -3.535\\n−10\\n0\\n10\\n20\\n30\\n−5 0 5\\niter 10/100, grad = 9.845\\n−10\\n0\\n10\\n20\\n30\\n−5 0 5\\niter 20/100, grad = -10.917\\n−10\\n0\\n10\\n20\\n30\\n−5 0 5\\niter 50/100, grad = 2.289\\n−10\\n0\\n10\\n20\\n30\\n−5 0 5\\niter 75/100, grad = -0.462\\n−10\\n0\\n10\\n20\\n30\\n−5 0 5\\niter 100/100, grad = -0.044\\n−10\\n0\\n10\\n20\\n30\\nHình 12.10: GD với momentum.\\nvới đạo hàmf′(x) = 2x+ 10 cos(x). Hình 12.9 thể hiện đường đi của nghiệm cho bài toán\\nnày khi không sử dụng momentum. Ta thấy rằng thuật toán hội tụ nhanh chóng sau chỉ bốn\\nvòng lặp. Tuy nhiên, nghiệm dừng lại ở một điểm local minimum. Trong khi đó, Hình 12.10\\nthể hiện đường đi của nghiệm khi có sử dụng momentum. Chúng ta thấy rằnghòn bi vượt\\nđược dốc thứ nhất nhờ cóđà, theo quán tính tiếp tục vượt qua điểm global minimum, nhưng\\nquay trở lại điểm này sau 50 vòng lặp rồi chuyển động chậm dần quanh đó tới khi dừng hẳn\\nở vòng lặp thứ 100. Ví dụ này cho thấy momentum thực sự đã giúp nghiệm thoát được khu\\nvực local minimum.\\nNếu biết trước điểmđặt bi ban đầutheta, đạo hàm của hàm mất mát tại một điểm bất kỳ\\ngrad(theta), lượng thông tin lưu trữ từ vận tốc trước đógamma và learning rateeta, chúng ta\\ncó thể viết hàmGD_momentum như sau.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 162, 'page_label': '151'}, page_content='151 CHƯƠNG 12. GRADIENT DESCENT\\nθt−1 gradient step−η∇θJ(θt−1)\\nmomentum\\n−γv\\nt−1\\ncập nhật\\nθt = θt−1−γvt−1−η∇θJ(θt−1)\\n(a) Momentum gradient descent. (b) Nesterov accelerated gradient.\\nθt−1\\ngradient step:\\n−η∇θJ(θt−1 −γvt−1)\\nmomentum\\n−γv\\nt−1\\ncập nhậtθt =\\nθt−1−γvt−1−η∇θJ(θt−1 −γvt−1)\\nToạ độ điểm tính đạo hàm khác đi một chút\\nHình 12.11: Ý tưởng của Nesterov accelerated gradient.\\ndef GD_momentum(grad, theta_init, eta, gamma):\\n# Suppose we want to store history of theta\\ntheta = [theta_init]\\nv_old = np.zeros_like(theta_init)\\nfor it in range(100):\\nv_new = gamma*v_old + eta*grad(theta[-1])\\ntheta_new = theta[-1] - v_new\\nif np.linalg.norm(grad(theta_new))/np.array(theta_init).size < 1e-3:\\nbreak\\ntheta.append(theta_new)\\nv_old = v_new\\nreturn theta\\n12.5 Nesterov accelerated gradient\\nMomentum giúphòn bivượt qua đượcdốc local minimum. Tuy nhiên, có một hạn chế chúng\\nta có thể thấy trong ví dụ trên: khi tới gầnđích, momemtum vẫn mất khá nhiều thời gian\\ntrước khi dừng lại, cũng chính vì cóđà. Một kỹ thuật có tênNesterov accelerated gradient\\n(NAG) [Nes07] giúp cho thuật toán momentum GD hội tụ nhanh hơn.\\nÝ tưởng chính\\nÝ tưởng trung tâm của thuật toán làdự đoán vị trí của nghiệm trước một bước. Cụ thể, nếu\\nsử dụng số hạngmomentum γvt−1 để cập nhật thì ta có thểxấp xỉ được vị trí tiếp theo của\\nnghiệm là θ−γvt−1. Vậy, thay vì sử dụng gradient của điểm hiện tại, NAGđi trước một\\nbước, sử dụng gradient của điểmđược dự đoán làvị trí tiếp theo. Ý tưởng này được thể hiện\\ntrên Hình 12.11.\\n• Với momentum thông thường,lượng thay đổilà tổng của hai vector: momentum vector\\nvà gradient ở thời điểm hiện tại.\\n• Với Nesterove momentum,lượng thay đổi là tổng của hai vector: momentum vector và\\ngradient của điểm được dự đoán là vị trí tiếp theo.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 163, 'page_label': '152'}, page_content='CHƯƠNG 12. GRADIENT DESCENT 152\\nSự khác nhau giữa momentum và NAG nằm ở điểm lấy đạo hàm. Ở momentum, điểm được\\nlấy đạo hàm chính là vị trí hiện tại của nghiệm. Ở NAG, điểm được lấy đạo hàm là điểmcó\\nđược nếu sử dụng momentum.\\nCông thức cập nhật\\nCông thức cập nhật của NAG được cho như sau:\\nvt = γvt−1 + η∇θJ(θ−γvt−1) (12.10)\\nθ←θ−vt (12.11)\\nĐoạn code dưới đây là hàm cho NAG.\\ndef GD_NAG(grad, theta_init, eta, gamma):\\ntheta = [theta_init]\\nv = [np.zeros_like(theta_init)]\\nfor it in range(100):\\nv_new = gamma*v[-1] + eta*grad(theta[-1] - gamma*v[-1])\\ntheta_new = theta[-1] - v_new\\nif np.linalg.norm(grad(theta_new))/np.array(theta_init).size < 1e-3:\\nbreak\\ntheta.append(theta_new)\\nv.append(v_new)\\nreturn theta\\nVí dụ minh họa\\nChúng ta cùng áp dụng cả GD với momentum và GD với NAG cho bài toán linear regression\\nđề cập ở trên. Hình 12.12 thể hiện đường đi của nghiệm khi sử dụng hai phương pháp này.\\nHình 12.12a là đường đi của nghiệm với phương pháp momentum. Nghiệm đi kházigzag và\\nmất nhiều vòng lặp hơn. Hình 12.12b là đường đi của nghiệm với phương pháp NAG, nghiệm\\nhội tụ nhanh hơn, và đường đi ítzigzag hơn.\\n12.6 Stochastic gradient descent\\n12.6.1 Batch gradient descent\\nThuật toán GD được đề cập từ đầu chương tới hiện tại còn được gọi làbatch GD. Batch ở\\nđây được hiểu làtất cả, tức khi cập nhật các tham sốθ, chúng ta sử dụngtất cảcác điểm\\ndữ liệu xi. Hạn chế của việc này là khi lượng cơ sở dữ liệu lớn, có thể tới hàng triệu, việc\\ntính toán đạo hàm trên toàn bộ dữ liệu tại mỗi vòng lặp sẽ tốn rất nhiều thời gian.\\nOnline learninglà khi cơ sở dữ liệu được cập nhật liên tục, mỗi lần tăng thêm vài điểm dữ\\nliệu mới, yêu cầu cập nhật mô hình mới. Kéo theo đó là mô hình cũng phải được thay đổi\\nmột chút để phù hợp với dữ liệu mới. Nếu làm theo batch GD, tức tính lại đạo hàm của hàm\\nmất mát tại tất cả các điểm dữ liệu, độ phức tạp tính toán sẽ rất cao. Lúc đó, thuật toán\\ncó thể không còn mang tínhonline nữa do mất quá nhiều thời gian tính toán.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 164, 'page_label': '153'}, page_content='153 CHƯƠNG 12. GRADIENT DESCENT\\n2 3 4 5 6\\n0.5\\n1.0\\n1.5\\n2.0\\n2.5\\n3.0\\n3.5\\n4.0\\n4.5\\n101 iterations\\n(a) GD với momentum.\\n2 3 4 5 6\\n0.5\\n1.0\\n1.5\\n2.0\\n2.5\\n3.0\\n3.5\\n4.0\\n4.5\\n28 iterations (b) GD với NAG.\\nHình 12.12: Đường đi của nghiệm cho bài toán linear regression với hai phương pháp gradient\\ndescent khác nhau. NAG cho nghiệm mượt hơn và nhanh hơn.\\nMột thuật toán đơn giản hơn, chấp nhận việc có sai số một chút nhưng lại lợi ích tính toán\\ncao, thường được sử dụng có tên gọi làstochastic gradient descent(SGD).\\n12.6.2 Stochastic gradient descent\\nTrong SGD, tại một thời điểm (vòng lặp–iteration), ta chỉ tính đạo hàm của hàm mất mát\\ndựa trênchỉ mộtđiểm dữ liệuxi rồi cập nhậtθdựa trên đạo hàm này. Chú ý rằng hàm mất\\nmát thường được lấy trung bình trên mỗi điểm dữ liệu nên đạo hàm tại một điểm cũngđược\\nkỳ vọnglà khá gần với đạo hàm của hàm mất mát trên mọi điểm dữ liệu. Sau khi duyệt qua\\ntất cả các điểm dữ liệu, thuật toán lặp lại quá trình trên. Biến thể đơn giản này trên thực\\ntế làm việc rất hiệu quả.\\nepoch\\nMỗi lần duyệt một lượt quatất cả các điểm trên toàn bộ dữ liệu được gọi là mộtepoch (số\\nnhiều epoches). Với GD thông thường, mỗi epoch ứng với một lần cập nhậtθ. Với SGD, mỗi\\nepoch ứng vớiN lần cập nhậtθ với N là số điểm dữ liệu. Nhìn vào một mặt, việc cập nhật\\ntừng điểm một như thế này có thể làm giảm đi tốc độ thực hiện một epoch. Nhưng nhìn vào\\nmột mặt khác, với SGD, nghiệm có thể hội tụ sau vài epoch. Vì vậy, SGD phù hợp với các\\nbài toán có lượng cơ sở dữ liệu lớn và các bài toán yêu cầu mô hình thay đổi liên tục như\\nonline learning. Với một mô hình đã được huấn luyện từ trước, khi có thêm dữ liệu, ta có\\nthể chỉ cần chạy thêm một vài epoch nữa là đã có nghiệm hội tụ.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 165, 'page_label': '154'}, page_content='CHƯƠNG 12. GRADIENT DESCENT 154\\n0 500 1000 1500 2000 2500\\nnumber of iterations\\n4\\n5\\n6\\n7\\n8\\n9loss function\\nHình 12.13: Ví dụ về giá\\ntrị hàm mất mát sau mỗi\\niteration khi sử dụng mini-\\nbatch gradient descent. Hàm\\nmất mátnhảy lên nhảy xuống\\n(fluctuate) sau mỗi lần cập\\nnhật nhưng nhìn chung giảm\\ndần và có xu hướng hội tụ.\\nThứ tự lựa chọn điểm dữ liệu\\nMột điểm cần lưu ý đó là sau mỗi epoch, chúng ta cầnxáo trộn(shuffle) thứ tự của các dữ\\nliệu để đảm bảo tính ngẫu nhiên. Việc này cũng ảnh hưởng tới hiệu năng của SGD. Đây\\ncũng chính là lý do thuật toán này có chứa từstochastic (ngẫu nhiên).\\nMột cách toán học, quy tắc cập nhật của SGD là\\nθ←θ−η∇θJ(θ; xi,yi) (12.12)\\ntrong đóJ(θ; xi,yi) ≜Ji(θ) là hàm mất mát với chỉ một điểm dữ liệu thứi. Các thuật toán\\nbiến thể của GD như momentum hay NAG hoàn toàn có thể được áp dụng vào SGD.\\n12.6.3 Mini-batch gradient descent\\nKhác với SGD, mini-batch sử dụng một số lượngk lớn hơn một (nhưng vẫn nhỏ hơn tổng\\nsố điểm dữ liệuN rất nhiều) để cập nhật ở mỗiiteration. Giống với SGD, mini-batch GD\\nbắt đầu mỗi epoch bằng việc xáo trộn ngẫu nhiên dữ liệu rồi chia toàn bộ dữ liệu thành các\\nmini-batch, mỗi mini-batch có k điểm dữ liệu (trừ mini-batch cuối có thể có ít hơn nếuN\\nkhông chia hết chok). Ở mỗi vòng lặp, thuật toán này lấy ra một mini-batch để tính toán\\nđạo hàm rồi cập nhật. Một epoch cũng là khi thuật toán chạy hết dữ liệu một lượt. Như vậy,\\nmột epochbao gồm xấp xỉN/k lần iteration. Mini-batch GD được sử dụng trong hầu hết\\ncác thuật toán machine learning, đặc biệt là trong deep learning. Giá trịk được gọi làbatch\\nsize (không phảimini-batch size) thường được chọn là khoảng từ vài chục đến vài trăm.\\nHình 12.13 là ví dụ về giá trị của hàm mất mát của một bài toán khác phức tạp hơn mỗi\\nkhi cập nhật tham sốθ khi sử dụng mini-batch gradient descent. Mặc dù giá trị của hàm\\nmất mát sau các vòng lặp không phải lúc nào cũng giảm, chúng ta vẫn thấy rằng giá trị này\\ncó xu hướng giảm và hội tụ.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 166, 'page_label': '155'}, page_content='155 CHƯƠNG 12. GRADIENT DESCENT\\n12.7 Thảo luận\\n12.7.1 Điều kiện dừng thuật toán\\nCó một điểm chúng ta chưa đề cập kỹ–khi nào thì nên dừng thuật toán gradient descent?\\nTrong thực nghiệm, chúng ta có thể kết hợp các phương pháp sau.\\n1. Giới hạn số vòng lặp. Một nhược điểm của cách làm này là có thể thuật toán dừng lại\\ntrước khi nghiệm đủ tốt. Tuy nhiên, đây là phương pháp phổ biến nhất và cũng để đảm\\nbảo rằng chương trình chạy không quá lâu.\\n2. So sánh gradient của nghiệm tại hai lần cập nhật liên tiếp, khi nào giá trị này đủ nhỏ\\nthì dừng lại. Phương pháp này cũng có một nhược điểm lớn là việc tính đạo hàm đôi khi\\ntrở nên quá phức tạp.\\n3. So sánh giá trị của hàm mất mát của nghiệm tại hai lần cập nhật liên tiếp, khi nào giá\\ntrị này đủ nhỏ thì dừng lại. Nhược điểm của phương pháp này là nếu tại một thời điểm,\\nđồ thị hàm số có dạngbẳng phẳngtại một khu vực nhưng khu vực đó không chứa điểm\\nlocal minimum, thuật toán cũng dừng lại trước khi đạt giá trị mong muốn.\\n4. Vừa chạy gradient descent, vừa kiểm tra kết quả. Một kỹ thuật thường được sử dụng\\nnữa là cho thuật toán chạy với số lượng vòng lặp cực lớn. Trong quá trình chạy, chương\\ntrình thường xuyên kiểm tra chất lượng mô hình bằng cách áp dụng nó lên dữ liệu tập\\nhuấn luyện và/hoặc validation. Đồng thời, mô hình sau một vài vòng lặp được lưu lại\\ntrong bộ nhớ. Mô hình tốt nhất có thể không phải là mô hình với số vòng lặp lớn hơn.\\n12.7.2 Đọc thêm\\nSource code trong chương này có thể được tìm thấy tạihttps://goo.gl/RJrRv7 .\\nNgoài các thuật toán đã đề cập trong chương này, rất nhiều thuật toán khác giúp cải thiện\\ngradient descent được đề xuất gần đây [Rud16]. Bạn đọc có thể đọc thêm AdaGrad [DHS11],\\nRMSProp [TH12], Adam [KB14], v.v..\\nCác trang web và video dưới đây cũng là các tài liệu tốt cho gradient descent.\\n1. An overview of gradient descent optimization algorithms(https://goo.gl/AGwbbg ).\\n2. Stochastic Gradient descent–Wikipedia(https://goo.gl/pmuLzk ).\\n3. Stochastic gradient descent–Andrew Ng(https://goo.gl/jgBf2N ).\\n4. An Interactive Tutorial on Numerical Optimization(https://goo.gl/t85mvA ).\\n5. Machine Learning cơ bản, Bài 7, 8(https://goo.gl/US17PP ).\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 167, 'page_label': '156'}, page_content='Chương 13\\nPerceptron learning algorithm\\n13.1 Giới thiệu\\nTrong chương này, chúng ta cùng tìm hiểu một trong các thuật toán đầu tiên trong lịch sử\\nmachine learning. Đây là một thuật toán phân lớp đơn giản có tên làperceptron learning\\nalgorithm (PLA [Ros57]). Thuật toán này được thiết kế cho bài toánphân lớp nhị phân\\n(binary classification) với chỉ hai lớp dữ liệu. Đây là nền tảng cho các thuật toán liên quan\\ntới neural networks rồi deep learning sau này.\\nGiả sử có hai class đã được gán nhãn được minh hoạ trong Hình 13.1a tương ứng với tập\\ncác điểm màu xanh và tập các điểm màu đỏ. Bài toán đặt ra là từ dữ liệu của hai tập được\\ngán nhãn cho trước, hãy xây dựng một bộ phân lớp có khả năng dự đoán được nhãn (màu)\\ncủa một điểm dữ liệu mới, chẳng hạn điểm màu xám.\\nNếu coi mỗi vector đặc trưng là một điểm trong không gian nhiều chiều, bài toán phân lớp\\ncó thể được coi như bài toán xác định mỗi điểm trong không gian thuộc vào lớp nào. Nói\\ncách khác, nếu ta coi mỗi lớpchiếm một hoặc vài vùnglãnh thổ trong không gian, ta cần\\nđi tìm ranh giới (boundary) giữa các vùng đó. Ranh giới đơn giản nhất trong không gian\\nhai chiều là một đường thẳng, trong không gian ba chiều là một mặt phẳng, trong không\\ngian nhiều chiều hơn là mộtsiêu mặt phẳnghoặc siêu phẳng(hyperplane). Những ranh giới\\nphẳng này được coi là đơn giản vì chúng có thể được biểu diễn dưới dạng toán học bằng\\nmột hàm số tuyến tính. Tất nhiên, ta đang giả sử rằng tồn tại một siêu phẳng như vậy.\\nHình 13.1b minh họa một đường thẳng phân chia hai lớp trong không gian hai chiều. Lãnh\\nthổ của hai lớp xanh và đỏ được mô tả bởi hai nửa mặt phẳng với màu tương ứng. Trong\\ntrường hợp này, điểm dữ liệu mới hình tam giác được phân vào lớp đỏ.\\nPerceptron learning algorithm (PLA) là một thuật toán đơn giản giúp tìm một ranh giới\\nsiêu phẳng cho bài toán phân lớp nhị phân, với giả sử rằng tồn tại ranh giới phẳng đó. Nếu\\nhai lớp dữ liệu có thể được phân chia hoàn toàn bằng một siêu phẳng, ta nói rằng hai lớp\\nđó linearly separable.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 168, 'page_label': '157'}, page_content='157 CHƯƠNG 13. PERCEPTRON LEARNING ALGORITHM\\nx1\\nx2\\n?\\n(a)\\nx1\\nx2\\n (b)\\nHình 13.1:Bài toán phân lớp nhị phân trong không gian hai chiều. (a) Cho hai lớp dữ liệu vuông\\nxanh và tròn đỏ, hãy xác định điểm dữ liệu tam giác xám thuộc lớp nào. (b) Ví dụ về một ranh\\ngiới phẳng của hai lớp, điểm tam giác được phân vào lớp đỏ với đường ranh giới này.\\n13.2 Thuật toán perceptron\\n13.2.1 Cách phân lớp của perceptron learning algorithm\\nGiả sử X = [x1,x2,..., xN] ∈Rd×N là ma trận chứa các điểm dữ liệu huấn luyện mà mỗi\\ncột xi là một điểm dữ liệu trong không giand chiều. Giả sử thêm các nhãn tương ứng với\\ntừng điểm dữ liệu được lưu trong một vector hàngy = [y1,y2,...,y N] ∈R1×N, vớiyi = 1\\nnếu xi thuộc lớp thứ nhất (vuông xanh) vàyi = −1 nếu xi thuộc lớp còn lại (tròn đỏ).\\nTại một thời điểm, giả sử ta tìm được ranh giới là một siêu phẳng có phương trình\\nfw(x) = w1x1 + ··· + wdxd + w0 = wTx + w0 = 0 (13.1)\\nvới w ∈Rd là vector hệ số vàw0 là số hạng tự do được gọi là bias. Bằng cách sử dụng bias\\ntrick (xem Mục 7.2.4), ta có thể coi phương trình siêu phẳng làfw(x) = wTx = 0 với x ở\\nđây được ngầm hiểu là vector đặc trưng mở rộng thêm một đặc trưng bằng 1. Vector hệ số\\nw cũng chính làvector pháp tuyếncủa siêu phẳngwTx = 0.\\nTrong không gian hai chiều, giả sử đường thẳngw1x1 + w2x2 + w0 = 0 chính là nghiệm cần\\ntìm như Hình 13.2a. Nhận xét rằng các điểm nằm về cùng một phía so với đường thẳng này\\nsẽ làm cho hàm sốfw(x) mang cùng dấu. Chỉ cần đổi dấu củaw nếu cần thiết, ta có thể\\ngiả sử các điểm nằm trong nửa mặt phẳng nền xanh mang dấu dương (+), các điểm nằm\\ntrong nửa mặt phẳng nền đỏ mang dấu âm (-). Các dấu này cũng tương đương với nhãny\\ncủa mỗi nhãn. Vậy nếuw là một nghiệm của bài toán perceptron, với một điểm dữ liệu mới\\nx chưa được gán nhãn, ta có thể xác định nhãn của nó bằng một phép toán đơn giản:\\nlabel(x) =\\n{\\n1 nếu wTx ≥0\\n−1 o.w. (13.2)\\nNói cách khác, label(x) = sgn(wTx) với sgn là hàm xác định dấu, giả sử rằng sgn(0) = 1.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 169, 'page_label': '158'}, page_content='CHƯƠNG 13. PERCEPTRON LEARNING ALGORITHM 158\\nx1\\nx2\\n+ -\\nw1x1\\n+\\nw2x2\\n+\\nw0\\n= 0\\n+ -\\nw1x1\\n+\\nw2x2\\n+\\nw0\\n= 0\\n(a) Đường thẳng phân chia không có lỗi.\\nx1\\nx2\\n+ -\\nw1x1 + w2x2 + w0 = 0 (b) Đường thẳng phân chia có lỗi tại các điểm khoanh tròn.\\nHình 13.2:Ví dụ về các đường thẳng trong không gian hai chiều: (a) một nghiệm của bài toán\\nPLA, (b) không phải nghiệm.\\n13.2.2 Xây dựng hàm mất mát\\nTiếp theo, chúng ta xây dựng một hàm mất mát với tham sốw bất kỳ. Vẫn trong không\\ngian hai chiều, giả sử đường thẳngw1x1 +w2x2 +w0 = 0 được cho như Hình 13.2b. Các điểm\\nđược khoanh tròn là các điểm bịphân lớp lỗi(misclassified). Ta luôn muốn rằng không có\\nđiểm nào bị phân lớp lỗi. Một cách tự nhiên, ta có thể sử dụng hàmđếm số lượng các điểm\\nbị phân lớp lỗi và tìm cách tối thiểu hàm số này.\\nXét một điểmxi bất kỳ với nhãnyi. Nếu nó bị phân lớp lỗi, ta phải có sgn(wTx) ̸= yi. Vì\\nhai giá trị này chỉ bằng1 hoặc −1, ta sẽ cóyisgn(wTx) = −1. Như vậy, hàm số đếm số\\nlượng điểm bị phân lớp lỗi có thể được viết dưới dạng\\nJ1(w) =\\n∑\\nxi∈M\\n(−yisgn(wTxi)) (13.3)\\ntrong đóMký hiệu tập các điểm bị phân lớp lỗi ứng với mỗiw. Mục đích cuối cùng là đi\\ntìm w sao cho không có điểm nào bị phân lớp lỗi, tứcJ1(w) = 0. Một điểm quan trọng, đây\\nlà một hàm số rời rạc nên rất khó được tối ưu. Chúng ta cần tìm một hàm mất mát khác\\nđể việc tối ưu khả thi hơn. Xét hàm mất mát\\nJ(w) =\\n∑\\nxi∈M\\n(−yiwTxi) (13.4)\\nHàm J(w) khác một chút với hàmJ1(w) ở chỗ hàm rời rạc sgn đã được lược bỏ. Ngoài ra,\\nkhi một điểm bị phân lớp lỗixi nằm càng xa ranh giới, giá trị−yiwTxi sẽ càng lớn, nghĩa\\nlà hàm mất mát sẽ lớn lên. Vì tổng vẫn được tính trên các tập điểm bị phân lớp lỗiM, giá\\ntrị nhỏ nhất của hàm mất mát này cũng bằng không nếu không có điểm nào bị phân lớp\\nlỗi. Vì vậy,J(w) được cho là tốt hơnJ1(w) vì nótrừng phạt rất nặng những điểmlấn sâu\\nsang lãnh thổ của lớp kia. Trong khi đó,J1() trừng phạt các điểm phân lớp lỗi một lượng\\nnhư nhau bằng một, bất kể chúng gần hay xa ranh giới.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 170, 'page_label': '159'}, page_content='159 CHƯƠNG 13. PERCEPTRON LEARNING ALGORITHM\\n13.2.3 Tối ưu hàm mất mát\\nTại một thời điểm, nếu ta chỉ quan tâm tới các điểm bị phân lớp lỗi thì hàm sốJ(w) khả vi\\ntại mọiw, vậy ta có thể sử dụng gradient descent hoặc stochastic gradient descent (SGD)\\nđể tối ưu hàm mất mát này. Chúng ta sẽ giải quyết bài toán tối ưu hàm mất mátJ(w) bằng\\nSGD bằng cách cập nhậtw tại mỗi vòng lặp dựa trên chỉ một điểm dữ liệu. Với chỉmột\\nđiểm dữ liệuxi bị phân lớp lỗi, hàm mất mát và đạo hàm của nó lần lượt là\\nJ(w; xi; yi) = −yiwTxi; ∇wJ(w; xi; yi) = −yixi (13.5)\\nVậy quy tắc cập nhậtw sử dụng SGD là\\nw ←w −η(−yixi) = w + ηyixi (13.6)\\nvới η là learning rate. Trong PLA,η được chọn bằng 1. Ta có một quy tắc cập nhật rất gọn:\\nwt+1 = wt + yixi (13.7)\\nNói cách khác, với mỗi điểmxi bị phân lớp lỗi, bằng cách nhân điểm đó với nhãnyi của nó,\\nlấy kết quả cộng vàow hiện tại, ta sẽ đượcw mới. Tiếp theo, ta thấy rằng\\nwT\\nt+1xi = (wt + yixi)Txi = wT\\nt xi + yi∥xi∥2\\n2 (13.8)\\nNếu yi = 1, vìxi bị phân lớp lỗi nênwT\\nt xi <0. Cũng vìyi = 1 nên yi∥xi∥2\\n2 = ∥xi∥2\\n2 ≥1 (chú\\ný xi là một vector đặc trưngmở rộngvới một phần tử bằng 1). Từ đó suy rawT\\nt+1xi >wT\\nt xi.\\nNói cách khác,−yiwT\\nt+1xi <−yiwT\\nt xi. Điều tương tự cũng xảy ra vớiyi = −1. Việc này chỉ\\nra rằng đường thẳng được mô tả bởiwt+1 có xu hướng khiến hàm mất mát tại điểm bị phân\\nlớp lỗixi giảm đi.Chú ý rằng việc này không đảm bảo hàm mất mát trên toàn bộ dữ liệu sẽ\\ngiảm, vì rất có thể đường thẳng mới sẽ làm cho một điểm lúc trước được phân lớp đúng trở\\nthành một điểm bị phân lớp sai. Tuy nhiên, thuật toán này được đảm bảo sẽ hội tụ sau một\\nsố hữu hạn bước.Thuật toán perceptron được tóm tắt dưới đây.\\nThuật toán 13.1: Perceptron\\n1. Tại thời điểmt= 0, chọn ngẫu nhiên một vector hệ sốw0.\\n2. Tại thời điểmt, nếu không có điểm dữ liệu nào bị phân lớp lỗi, dừng thuật toán.\\n3. Giả sửxi là một điểm bị phân lớp lỗi. Cập nhật\\nwt+1 = wt + yixi\\n4. Thay đổit= t+ 1 rồi quay lại Bước 2.\\n13.2.4 Chứng minh hội tụ\\nGọi w∗là một nghiệm của bài toán phân lớp nhị phân với hai lớp linearly separable. Nghiệm\\nnày luôn tồn tại khi hai lớp là linearly separable. Ta sẽ chứng minh Thuật toán 13.1 kết thúc\\nsau một số hữu hạn bước bằng phản chứng.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 171, 'page_label': '160'}, page_content='CHƯƠNG 13. PERCEPTRON LEARNING ALGORITHM 160\\nGiả sử ngược lại, tồn tại mộtw mà Thuật toán 13.1 chạy mãi mãi. Trước hết ta thấy rằng,\\nvới α >0 bất kỳ, nếuw∗ là nghiệm,αw∗ cũng là nghiệm của bài toán. Xét dãy số không\\nâm uα(t) = ∥wt −αw∗∥2\\n2. Theo giả thiết phản chứng, tồn tại một điểm bị phân lớp lỗi khi\\ndùng nghiệmwt. Giả sử đó là điểmxi với nhãnyi. Ta có\\nuα(t+ 1) = ∥wt+1 −αw∗∥2\\n2 (13.9)\\n= ∥wt + yixi −αw∗∥2\\n2 (13.10)\\n= ∥wt −αw∗∥2\\n2 + y2\\ni∥xi∥2\\n2 + 2yixT\\ni (wt −αw∗) (13.11)\\n<uα(t) + ∥xi∥2\\n2 −2αyixT\\ni w∗ (13.12)\\nDấu nhỏ hơn ở dòng cuối là vìy2\\ni = 1 và 2yixT\\ni wt <0. Nếu tiếp tục đặt\\nβ2 = max\\ni=1,2,...,N\\n∥xi∥2\\n2, γ = min\\ni=1,2,...,N\\nyixT\\ni w∗ (13.13)\\nvà chọnα= β2\\nγ , ta sẽ có0 ≤uα(t+ 1) <uα(t) + β2 −2αγ = uα(t) −β2. Ta có thể chọn giá\\ntrị này vì (13.12) đúng vớiα bất kỳ. Điều này chỉ ra rằng nếu luôn có điểm bị phân lớp lỗi\\nthì dãyuα(t) là một dãy giảm, bị chặn dưới bởi 0, và phần tử sau kém phần tử trước ít nhất\\nmột lượng làβ2 >0. Điều vô lý này chứng tỏ đến một lúc nào đó sẽ không còn điểm nào bị\\nphân lớp lỗi. Nói cách khác, thuật toán perceptron hội tụ sau một số hữu hạn bước.\\n13.3 Ví dụ và minh hoạ trên Python\\nThuật toán 13.1 có thể được triển khai như sau:\\nimport numpy as np\\ndef predict(w, X):\\n’’’ predict label of each row of X, given w\\nX: a 2-d numpy array of shape (N, d), each row is a datapoint\\nw_init: a 1-d numpy array of shape (d) ’’’\\nreturn np.sign(X.dot(w))\\ndef perceptron(X, y, w_init):\\n’’’ perform perceptron learning algorithm\\nX: a 2-d numpy array of shape (N, d), each row is a datapoint\\ny: a 1-d numpy array of shape (N), label of each row of X. y[i] = 1/-1\\nw_init: a 1-d numpy array of shape (d) ’’’\\nw = w_init\\nwhile True:\\npred = predict(w, X)\\n# find indexes of misclassified points\\nmis_idxs = np.where(np.equal(pred, y) == False)[0]\\n# number of misclassified points\\nnum_mis = mis_idxs.shape[0]\\nif num_mis == 0: # no more misclassified points\\nreturn w\\n# random pick one misclassified point\\nrandom_id = np.random.choice(mis_idxs, 1)[0]\\n# update w\\nw = w + y[random_id]*X[random_id]\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 172, 'page_label': '161'}, page_content='161 CHƯƠNG 13. PERCEPTRON LEARNING ALGORITHM\\n3\\n 2\\n 1\\n 0 1 2 3\\n1\\n0\\n1\\n2\\niter 1/6\\n3\\n 2\\n 1\\n 0 1 2 3\\n1\\n0\\n1\\n2\\niter 2/6\\n3\\n 2\\n 1\\n 0 1 2 3\\n1\\n0\\n1\\n2\\niter 3/6\\n3\\n 2\\n 1\\n 0 1 2 3\\n1\\n0\\n1\\n2\\niter 4/6\\n3\\n 2\\n 1\\n 0 1 2 3\\n1\\n0\\n1\\n2\\niter 5/6\\n3\\n 2\\n 1\\n 0 1 2 3\\n1\\n0\\n1\\n2\\niter 6/6\\nHình 13.3:Minh hoạ thuật toán perceptron. Các điểm màu lam thuộc lớp1, các điểm màu đỏ\\nthuộc lớp −1. Tại mỗi vòng lặp, đường thẳng màu đen là đường ranh giới. Vector màu lục là\\nwt. Điểm được khoanh tròn là một điểm bị phân lớp lỗixi. Vector màu cam thể hiện vectorxi.\\nVector màu đỏ chính làwt+1. Nếuyi = 1 (màu lam), vector màu đỏ bằng tổng hai vector kia.\\nNếu yi = −1, vector màu đỏ bằng hiệu hai vector kia.\\nTrong đó, hàmpredict(w, X) dự đoán nhãn của mỗi hàng củaX dựa trên công thức (13.2).\\nHàm perceptron(X, y, w_init) thực hiện thuật toán PLA với tập dữ liệuX, nhãny và nghiệm\\nban đầuw_init.\\nĐể kiểm tra đoạn code trên, ta áp dụng nó vào một ví dụ với dữ liệu trong không gian hai\\nchiều như dưới đây.\\nmeans = [[-1, 0], [1, 0]]\\ncov = [[.3, .2], [.2, .3]]\\nN = 10\\nX0 = np.random.multivariate_normal(means[0], cov, N)\\nX1 = np.random.multivariate_normal(means[1], cov, N)\\nX = np.concatenate((X0, X1), axis = 0)\\ny = np.concatenate((np.ones(N), -1*np.ones(N)))\\nXbar = np.concatenate((np.ones((2*N, 1)), X), axis = 1)\\nw_init = np.random.randn(Xbar.shape[1])\\nw = perceptron(Xbar, y, w_init)\\nMỗi lớp có 10 phần tử, là các vector ngẫu nhiên lấy theo phân phối chuẩn có ma trận hiệp\\nphương saicov và vector kỳ vọng được lưu trongmeans. Hình 13.3 minh hoạ nghiệm sau mỗi\\nvòng lặp. Ta thấy rằng perceptron cho bài toán này hội tụ sau chỉ sau sáu vòng lặp.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 173, 'page_label': '162'}, page_content='CHƯƠNG 13. PERCEPTRON LEARNING ALGORITHM 162\\n1x0\\nx1\\nx2\\nx3\\nxd\\nΣ\\nz y\\nw0\\nw1\\nw2\\nw3\\nwd\\nz =\\nd∑\\ni=0\\nwixi = wT x\\ny = sgn(z)\\n(a)\\nInput layer Output layer (b)\\nInput layer Output layer (c)\\nHình 13.4: Biểu diễn perceptron và linear regression dưới dạng neural network. (a) perceptron\\nđầy đủ, (b) perceptron thu gọn, (c) linear regression thu gọn.\\n13.4 Mô hình neural network đầu tiên\\nHàm số dự đoán đầu ra của perceptron label(x) = sgn(wTx) có thể được mô tả trên\\nHình 13.4a. Đây chính là dạng đơn giản của neural network.\\nĐầu vào của networkx được minh họa bằng cácnode màu lục với nodex0 luôn luôn bằng\\n1. Tập hợp các node màu lục được gọi làtầng đầu vào(input layer). Số node trong input\\nlayer làd+1 . Đôi khi nodex0 = 1này được ẩn đi. Cáctrọng số w0,w1,...,w d được gán vào\\ncác mũi tên đi tới nodez = ∑d\\ni=0 wixi = wTx. Nodey = sgn(z) là output của network. Ký\\nhiệu hình chữ Z ngược màu lam trong nodey thể hiện đồ thị của hàm sgn. Hàmy= sgn(z)\\nđóng vai trò là mộthàm kích hoạt(activation function). Dữ liệu đầu vào được đặt vào input\\nlayer, lấy tổng có trọng số lưu vào biếnz rồi đi qua hàm kích hoạt để có kết quả ởy. Đây\\nchính là dạng đơn giản nhất của một neural network. Perceptron cũng có thể được vẽ giản\\nlược như Hình 13.4b, với ẩn ý rằng dữ liệu ở input layer được lấy tổng có trọng số trước khi\\nđi qua hàm lấy dấuy= sgn(z).\\nCác neural network có thể có một hoặc nhiều node ở output tạo thành mộttầng đầu ra\\n(output layer), hoặc có thể có thêm các layer trung gian giữainput layer và output layer,\\nđược gọi làtầng ẩn(hidden layer). Các neural network thường có nhiều hidden layer và các\\nlayer có thể có các hàm kích hoạt khác nhau. Chúng ta sẽ đi sâu vào các neural network\\nvới nhiều hidden layer ở Chương 16. Trước đó, chúng ta sẽ tìm hiểu các neural network đơn\\ngiản hơn không có hidden layer.\\nĐể ý rằng nếu ta thayactivation function bởi hàm identity y = z, ta sẽ có một neural\\nnetwork mô tả linear regression như Hình 13.4c. Với đường thẳng chéo màu xanh thể hiện\\nđồ thị hàm sốy= z. Các trục tọa độ đã được lược bỏ.\\nMô hình perceptron ở trên khá giống với một node nhỏ của dây thần kinh sinh học như\\nHình 13.5.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 174, 'page_label': '163'}, page_content='163 CHƯƠNG 13. PERCEPTRON LEARNING ALGORITHM\\nHình 13.5:Cấu trúc của một neuron thần kinh sinh học. Nguồn:Single-Layer Neural Networks\\nand Gradient Descent(https://goo.gl/RjBREb ).\\nDữ liệu từ nhiều dây thần kinh (tương tự nhưxi) đi về mộtcell nucleus. Cell nucleus đóng\\nvai trò như bộ lấy tổng có trọng số∑d\\ni=0 wixi. Thông tin này sau đó được tổng hợp (tương\\ntự như hàm kích hoạt) và đưa ra ở output. Tên gọineural network hoặc artificial neural\\nnetwork được khởi nguồn từ đây.\\n13.5 Thảo Luận\\nPLA có thể cho vô số nghiệm khác nhau.Nếu hai lớp dữ liệu là linearly separable thì\\ncó vô số đường thằng ranh giới của hai lớp dữ liệu đó như trên Hình 13.6a. Tất cả các đường\\nthẳng màu đen đều có thể đóng vài trò là đường ranh giới. Tuy nhiên, các đường khác nhau\\nsẽ quyết định điểm hình tam giác thuộc các lớp khác nhau. Trong các đường đó, đường nào\\nlà tốt nhất? Và định nghĩa “tốt nhất” được hiểu theo nghĩa nào? Các câu hỏi này sẽ được\\nthảo luận kỹ hơn trong Chương 26.\\nPLA đòi hỏi hai lớp dữ liệu phải linearly separable.Hình 13.6b mô tả hai lớp dữ liệu\\ntương đối linearly separable. Mỗi lớp có một điểm coi nhưnhiễu nằm lẫn trong các điểm\\ncủa lớp kia. PLA sẽ không làm việc, tức không bao giờ dừng lại, trong trường hợp này vì\\nvới mọi đường thẳng ranh giới, luôn có ít nhất hai điểm bị phân lớp lỗi.\\nTrong một chừng mực nào đó, đường thẳng màu đen vẫn có thể coi là một nghiệm tốt vì\\nnó đã giúp phân loại chính xác hầu hết các điểm. Việc không hội tụ với dữ liệugần linearly\\nseparable chính là một nhược điểm lớn của PLA.\\nNhược điểm này có thể được khắc phục bằngpocket algorithmdưới đây.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 175, 'page_label': '164'}, page_content='CHƯƠNG 13. PERCEPTRON LEARNING ALGORITHM 164\\nx1\\nx2\\n(a)\\nx1\\nx2\\n (b)\\nHình 13.6: Với bài toán phân lớp nhị phân, PLA có thể (a) cho vô số nghiệm, hoặc (b) vô\\nnghiệm thậm chí với chỉ một nhiễu nhỏ.\\nPocket algorithm [AMMIL12]:một cách tự nhiên, nếu có một vàinhiễu, ta sẽ đi tìm\\nmột đường thẳng phân chia hai class sao cho có ít điểm bị phân lớp lỗi nhất. Việc này có\\nthể được thực hiện thông qua PLA với một chút thay đổi nhỏ:\\n1. Giới hạn số lượng vòng lặp của PLA. Đặt nghiệmw sau vòng lặp đầu tiên và số điểm bị\\nphân lớp lỗi vào trongtúi quần (pocket).\\n2. Mỗi lần cập nhật nghiệmwt mới, ta đếm xem có bao nhiêu điểm bị phân lớp lỗi. So sánh\\nsố điểm bị phân lớp lỗi này với số điểm bị phân lớp lỗi trongpocket, nếu nhỏ hơn thì lấy\\nnghiệm cũ ra, đặt nghiệm mới này vào. Lặp lại bước này đến khi hết số vòng lặp.\\nThuật toán này giống với thuật toán tìm phần tử nhỏ nhất trong một mảng một chiều.\\nSource code cho chương này có thể được tìm thấy tạihttps://goo.gl/tisSTq .\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 176, 'page_label': '165'}, page_content='Chương 14\\nLogistic regression\\n14.1 Giới thiệu\\n14.1.1 Nhắc lại hai mô hình tuyến tính\\nHai mô hình tuyến tính đã thảo luận trong cuốn sách này, linear regression và perceptron\\n(PLA), đều có thể viết chung dưới dạngy = f(wTx) với f(s) là một hàm kích hoạt. Với\\nf(s) = s trong linear regression, vàf(s) = sgn(s) trong PLA. Trong linear regression, tích\\nvô hướngwTx được trực tiếp sử dụng để dự đoán outputy, loại này phù hợp nếu ta cần dự\\nđoán một đầu ra không bị chặn trên và dưới. Trong PLA, đầu ra chỉ nhận một trong hai\\ngiá trị 1 hoặc −1, phù hợp với các bài toán phân lớp nhị phân. Trong chương này, chúng\\nta sẽ thảo luận một mô hình tuyến tính với một hàm kích hoạt khác, thường được áp dụng\\ncho các bài toán phân lớp nhị phân. Trong mô hình này, đầu ra có thể được thể hiện dưới\\ndạng xác suất. Ví dụ, xác suất thi đỗ nếu biết thời gian ôn thi, xác suất ngày mai có mưa\\ndựa trên những thông tin đo được trong ngày hôm nay, v.v.. Mô hình này có tên làlogistic\\nregression. Mặc dù trong tên có chứa từregression, logistic regression thường được sử dụng\\nnhiều hơn cho các bài toán phân lớp.\\n14.1.2 Một ví dụ nhỏ\\nBảng 14.1: Thời gian ôn thi (Hours) và kết quả thi của 20 sinh viên.\\nHours Pass Hours Pass Hours Pass Hours Pass\\n0.5 0 0.75 0 1 0 1.25 0\\n1.5 0 1.75 0 1.75 1 2 0\\n2.25 1 2.5 0 2.75 1 4 0\\n3.25 1 3.5 0 4 1 4.25 1\\n4.5 1 4.75 1 5 1 5.5 1\\nXét một ví dụ về sự liên quan giữa thời gian ôn thi và kết quả thi của 20 sinh viên được\\ncho trong Bảng 14.1. Bài toán đặt ra là từ dữ liệu này hãy xây dựng một mô hình đánh'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 177, 'page_label': '166'}, page_content='CHƯƠNG 14. LOGISTIC REGRESSION 166\\n0 1 2 3 4 5 6\\nhours studying\\n0\\n1fail(0) / pass(1)\\nHình 14.1: Ví dụ về kết quả thi\\ndựa trên số giờ ôn tập. Trục hoành\\nthể hiển thời gian ôn tập của mỗi\\nsinh viên, trục tung gồm hai giá trị\\n0/fail (các điểm màu đỏ) và 1/pass\\n(các điểm màu xanh).\\n0\\n1\\nhard threshold\\nf(s) = 1\\n1+e−s\\nf(s) = es\\nes+e−s\\nlinear\\nHình 14.2: Một vài ví dụ về\\ncác hàm kích hoạt khác nhau.\\ngiá khả năng đỗ của một sinh viên dựa trên thời gian ôn thi. Dữ liệu trong Bảng 14.1 được\\nmô tả trên Hình 14.1. Nhìn chung, thời gian học càng nhiều thì khả năng đỗ càng cao. Tuy\\nnhiên, không có một ngưỡng nào để có thể khẳng định rằng mọi sinh viên học nhiều thời\\ngian hơn ngưỡng đó sẽ chắc chắn đỗ. Nói cách khác, dữ liệu của hai lớp này là không linearly\\nseparable, và vì vậy PLA sẽ không hữu ích ở đây. Tuy nhiên, thay vì dự đoán chính xác hai\\ngiá trị đỗ/trượt, ta có thể dự đoán xác suất để một sinh viên thi đỗ dựa trên thời gian ôn\\nthi.\\n14.1.3 Mô hình logistic regression\\nQuan sát Hình 14.2 với các hàm kích hoạtf(s) khác nhau.\\n• Đường màu vàng biểu diễn một hàm kích hoạt tuyến tính. Đường này không bị chặn nên\\nkhông phù hợp cho bài toán đang xét với đầu ra là một giá trị trong khoảng[0,1].\\n• Đường màu đỏ tương tự với hàm kích hoạt của PLA với ngưỡng có thể khác không1.\\n• Các đường màu lam và lục phù hợp với bài toán đang xét hơn. Chúng có một vài tính\\nchất quan trọng:\\n– Là các hàm số liên tục nhận giá trị thực, bị chặn trong khoảng(0,1).\\n– Nếu coi điểm có tung độ là 1/2 là ngưỡng, các điểm càng xa ngưỡng về phía bên trái\\ncó giá trị càng gần 0, các điểm càng xa ngưỡng về phía bên phải có giá trị càng gần\\n1. Điều nàykhớp với nhận xét rằng học càng nhiều thì xác suất đỗ càng cao và ngược\\nlại.\\n– Hai hàm này có đạo hàm mọi nơi, vì vậy có thể được lợi trong việc tối ưu.\\n1 Đường này chỉ khác với activation function của PLA ở chỗ hai class là 0 và 1 thay vì -1 và 1.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 178, 'page_label': '167'}, page_content='167 CHƯƠNG 14. LOGISTIC REGRESSION\\nHàm sigmoid và tanh\\nTrong số các hàm số có ba tính chất nói trên, hàmsigmoid:\\nf(s) = 1\\n1 + e−s ≜σ(s) (14.1)\\nđược sử dụng nhiều nhất, vì nó bị chặn trong khoảng(0,1). Thêm nữa,\\nlim\\ns→−∞\\nσ(s) = 0; lim\\ns→+∞\\nσ(s) = 1 (14.2)\\nThú vị hơn,\\nσ′(s) = e−s\\n(1 + e−s)2 = 1\\n1 + e−s\\ne−s\\n1 + e−s = σ(s)(1 −σ(s)) (14.3)\\nVới đạo hàm đơn giản, hàm sigmoid được sử dụng rộng rãi trong neural network.Các bạn\\nsẽ sớm thấy hàm sigmoid được khám phá ra như thế nào.\\nNgoài ra, hàmtanh cũng hay được sử dụng: tanh(s) = es −e−s\\nes + e−s. Hàm số này nhận giá trị\\ntrong khoảng(−1,1). Bạn đọc có thể chứng minh được rằng tanh(s) = 2σ(2s) −1.\\nHàm sigmoid có thể được thực hiện trên Python như sau.\\ndef sigmoid(S):\\n\"\"\"\\nS: an numpy array\\nreturn sigmoid function of each element of S\\n\"\"\"\\nreturn 1/(1 + np.exp(-S))\\n14.2 Hàm mất mát và phương pháp tối ưu\\n14.2.1 Xây dựng hàm mất mát\\nVới các mô hình với hàm mất mát màu lam và lục như trên, ta có thể giả sử rằng xác suất\\nđể một điểm dữ liệux rơi vào lớp thứ nhất làf(wTx) và rơi vào lớp còn lại là1 −f(wTx):\\np(yi = 1|xi; w) = f(wTxi) (14.4)\\np(yi = 0|xi; w) = 1 −f(wTxi) (14.5)\\ntrong đóp(yi = 1|xi; w) được hiểu là xác suất xảy ra sự kiện đầu rayi = 1 khi biết tham\\nsố mô hìnhw và dữ liệu đầu vàoxi. Mục đích cuối cùng là là tìm các hệ sốw sao cho với\\ncác điểm dữ liệu ứng vớiyi = 1, f(wTxi) gần với 1, và ngược lại. Ký hiệuzi = f(wTxi), hai\\nbiểu thức (14.4) và (14.5) có thể được viết chung dưới dạng\\np(yi|xi; w) = zyi\\ni (1 −zi)1−yi (14.6)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 179, 'page_label': '168'}, page_content='CHƯƠNG 14. LOGISTIC REGRESSION 168\\nBiểu thức này tương đương với hai biểu thức (14.4) và (14.5) ở trên vì khiyi = 1, phần thứ\\nhai của vế phải sẽ bằng 1, khiyi = 0, phần thứ nhất sẽ bằng 1. Chúng ta muốn mô hình gần\\nvới dữ liệu đã cho nhất, tức xác suất này đạt giá trị cao nhất.\\nXét toàn bộ test set với ma trận dữ liệuX = [x1,x2,..., xN] ∈Rd×N và vector đầu ra tương\\nứng với mỗi cộty = [y1,y2,...,y N]. Ta cần giải bài toán tối ưu\\nw = arg max\\nw\\np(y|X; w) (14.7)\\nĐây chính là một bài toán maximum likelihood estimation với tham số mô hìnhw cần được\\nước lượng. Giả sử rằng các điểm dữ liệu được sinh ra một cách ngẫu nhiên độc lập với nhau,\\nta có thể viết\\np(y|X; w) =\\nN∏\\ni=1\\np(yi|xi; w) =\\nN∏\\ni=1\\nzyi\\ni (1 −zi)1−yi (14.8)\\nLấy logarit tự nhiên, đổi dấu, và lấy trung bình, ta thu được hàm số\\nJ(w) = −1\\nN log p(y|X; w) = −1\\nN\\nN∑\\ni=1\\n(yilog zi + (1 −yi) log(1−zi)) (14.9)\\nvới chú ý rằngzi là một hàm số củaw vàxi. Hàm số này chính là hàm mất mát của logistic\\nregression. Ta cần đi tìmw để J(w) đạt giá trị nhỏ nhất (vì ta đã đổi dấu của biểu thức\\ntrong dấuargmax của (14.7)).\\n14.2.2 Tối ưu hàm mất mát\\nBài toán tối ưu hàm mất mát của logistic regression có thể được giải quyết bằng stochastic\\ngradient descent (SGD). Tại mỗi vòng lặp,w sẽ được cập nhật dựa trên một điểm dữ liệu\\nngẫu nhiên. Hàm mất mát của logistic regression với chỉ một điểm dữ liệu(xi,yi) và đạo\\nhàm của nó lần lượt là\\nJ(w; xi,yi) = −(yilog zi + (1 −yi) log(1−zi)) (14.10)\\n∇wJ(w; xi,yi) = −(yi\\nzi\\n−1 −yi\\n1 −zi\\n)(∇wzi) = zi −yi\\nzi(1 −zi)(∇wzi) (14.11)\\nở đây ta đã sử dụng quy tắc chuỗi để tính đạo hàm vớizi = f(wTx). Để cho biểu thức này\\ntrở nêngọn và đẹp hơn, ta sẽ tìm hàmz = f(wTx) sao cho mẫu số bị triệt tiêu.\\nNếu đặts= wTx, ta sẽ có\\n∇wzi = ∂zi\\n∂s(∇ws) = ∂zi\\n∂sxi (14.12)\\nMột cách tự nhiên, ta sẽ tìm hàm sốz = f(s) sao cho:\\n∂z\\n∂s = z(1 −z) (14.13)\\nđể triệt tiêu mẫu số trong biểu thức (14.11). Phương trình vi phân này không quá phức tạp.\\nThật vậy, (14.13) tương đương với\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 180, 'page_label': '169'}, page_content='169 CHƯƠNG 14. LOGISTIC REGRESSION\\n∂z\\nz(1 −z) = ∂s\\n⇔ (1\\nz + 1\\n1 −z)∂z = ∂s\\n⇔ log z−log(1 −z) = s+ C\\n⇔ log z\\n1 −z = s+ C\\n⇔ z\\n1 −z = es+C\\n⇔ z = es+C(1 −z)\\n⇔ z = es+C\\n1 + es+C = 1\\n1 + e−s−C = σ(s+ C)\\nvới C là một hằng số. Đơn giản chọnC = 0, ta đượcz = f(wTx) = σ(s). Đây chính là lý\\ndo hàm sigmoid được ra đời. Logistic regression với hàm kích hoạt là hàm sigmoid được sử\\ndụng phổ biến nhất. Mô hình này còn có tên làlogistic sigmoid regression. Khi nói logistic\\nregression, ta ngầm hiểu rằng đó chính là logistic sigmoid regression.\\nThay (14.12) và (14.13) vào (14.11) ta thu được\\n∇wJ(w; xi,yi) = (zi −yi)xi = (σ(wTxi) −yi)xi (14.14)\\nVà công thức cập nhật nghiệm cho logistic sigmoid regression sử dụng SGD là\\nw ←w −η(zi −yi)xi = w −η(σ(wTxi) −yi)xi (14.15)\\nvới η là một learning rate dương.\\n14.2.3 Logistic regression với weight decay\\nMột trong các kỹ thuật phổ biến giúp tránh overfitting với các neural network là sử dụng\\nweight decay. Weight decay là một kỹ thuật regularization, trong đó một đại lượng tỉ lệ với\\nbình phương norm 2 của vector hệ số được cộng vào hàm mất mát để hạn chế độ lớn của\\ncác hệ số. Hàm mất mát trở thành\\n¯J(w) = 1\\nN\\nN∑\\ni=1\\n(\\n−yilog zi −(1 −yi) log(1−zi) + λ\\n2 ∥w∥2\\n2\\n)\\n(14.16)\\nCông thức cập nhật SGD chow với hàm này cũng đơn giản vì phần regularization có đạo\\nhàm đơn giản:\\nw ←w −η\\n(\\n(σ(wTxi) −yi)xi + λw\\n)\\n(14.17)\\n14.3 Triển khai thuật toán trên Python\\nHàm ước lượng xác suất cho mỗi điểm dữ liệu và hàm tính giá trị hàm mất mát với weight\\ndecay có thể được thực hiện như sau trong Python.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 181, 'page_label': '170'}, page_content='CHƯƠNG 14. LOGISTIC REGRESSION 170\\ndef prob(w, X):\\n\"\"\"\\nX: a 2d numpy array of shape (N, d). N datatpoint, each with size d\\nw: a 1d numpy array of shape (d)\\n\"\"\"\\nreturn sigmoid(X.dot(w))\\ndef loss(w, X, y, lam):\\n\"\"\"\\nX, w as in prob\\ny: a 1d numpy array of shape (N). Each elem = 0 or 1\\n\"\"\"\\nz = prob(w, X)\\nreturn -np.mean(y*np.log(z) + (1-y)*np.log(1-z)) + 0.5*lam/X.shape[0]*np.sum(w*w)\\nTừ công thức (14.17), ta có thể thực hiện thuật toán tìmw cho logistic regression như sau.\\ndef logistic_regression(w_init, X, y, lam = 0.001, lr = 0.1, nepoches = 2000):\\n# lam - reg paramether, lr - learning rate, nepoches - number of epoches\\nN, d = X.shape[0], X.shape[1]\\nw = w_old = w_init\\nloss_hist = [loss(w_init, X, y, lam)] # store history of loss in loss_hist\\nep = 0\\nwhile ep < nepoches:\\nep += 1\\nmix_ids = np.random.permutation(N)\\nfor i in mix_ids:\\nxi = X[i]\\nyi = y[i]\\nzi = sigmoid(xi.dot(w))\\nw = w - lr*((zi - yi)*xi + lam*w)\\nloss_hist.append(loss(w, X, y, lam))\\nif np.linalg.norm(w - w_old)/d < 1e-6:\\nbreak\\nw_old = w\\nreturn w, loss_hist\\n14.3.1 Logistic regression cho ví dụ ban đầu\\nÁp dụng vào bài toán ví dụ ban đầu.\\nX = np.array([[0.50, 0.75, 1.00, 1.25, 1.50, 1.75, 1.75, 2.00, 2.25, 2.50,\\n2.75, 3.00, 3.25, 3.50, 4.00, 4.25, 4.50, 4.75, 5.00, 5.50]]).T\\ny = np.array([0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1])\\n# bias trick\\nXbar = np.concatenate((X, np.ones((N, 1))), axis = 1)\\nw_init = np.random.randn(Xbar.shape[1])\\nlam = 0.0001\\nw, loss_hist = logistic_regression(w_init, Xbar, y, lam, lr = 0.05, nepoches = 500)\\nprint(w)\\nprint(loss(w, Xbar, y, lam))\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 182, 'page_label': '171'}, page_content='171 CHƯƠNG 14. LOGISTIC REGRESSION\\n0 1 2 3 4 5 6\\nstudying hours\\n−0.50\\n−0.25\\n0.00\\n0.25\\n0.50\\n0.75\\n1.00\\n1.25\\n1.50\\npredicted probability of pass\\n(a)\\n0 100 200 300 400 500\\nnumber of iterations\\n0.4\\n0.5\\n0.6\\n0.7\\n0.8\\n0.9\\n1.0\\n1.1\\nloss function (b)\\nHình 14.3: Nghiệm của logistic regression cho bài toán dự đoán kết quả thi dựa trên thời gian\\nhọc. (a) Đường màu lục thể hiện xác suất thi đỗ dựa trên thời gian học. Điểm tam giác vàng thể\\nhiện ngưỡng ra quyết định đỗ/trượt. Điểm này có thể thay đổi tuỳ vào bài toán. (b) Giá trị của\\nhàm mất mát qua các vòng lặp. Hàm mất mát giảm rất nhanh và hội tụ rất sớm.\\nKết quả:\\nSolution of Logistic Regression: [ 1.54337021 -4.06486702]\\nFinal loss: 0.402446724975\\nTừ đây ta có thể rút ra xác suất thi đỗ dựa trên công thức:\\nprobability_of_pass ≈sigmoid(1.54 * hours_of_studying - 4.06)\\nBiểu thức này cũng chỉ ra rằng xác suất thi đỗ tăng khi thời gian ôn tập tăng, do sigmoid\\nlà một hàm đồng biến. Nghiệm của mô hình logistic regression và giá trị hàm mất mát qua\\nmỗi epoch được mô tả trên Hình 14.3.\\n14.3.2 Ví dụ với dữ liệu hai chiều\\nChúng ta xét thêm một ví dụ nhỏ trong không gian hai chiều. Giả sử có hai lớp xanh và đỏ\\nvới dữ liệu được phân bố như Hình 14.4a. Với dữ liệu đầu vào nằm trong không gian hai\\nchiều, hàm sigmoid có dạng như thác nước như Hình 14.4b.\\nKết quả tìm được khi áp dụng mô hình logistic regression được minh họa như Hình 14.5 với\\nmàu nền thể hiện xác suất điểm đó thuộc class đỏ. Màu xanh đậm thể hiện giá trị 0, màu\\nđỏ đậm thể hiện giá trị rất gần với 1.\\nKhi phải lựa chọn một ranh giới thay vì xác suất, ta quan sát thấy các đường thẳng nằm\\ntrong khu vực lục và vàng là một lựa chọn hợp lý. Ta sẽ chứng minh ở phần sau rằng tập\\nhợp các điểm cho cùng xác suất đầu ra tạo thành một siêu phẳng.\\nSource code cho chương này có thể được tìm thấy tạihttps://goo.gl/9e7sPF.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 183, 'page_label': '172'}, page_content='CHƯƠNG 14. LOGISTIC REGRESSION 172\\nx1\\nx2\\n(a) Dữ liệu cho bài toán phân lớp trong không gian hai chiều.\\n(b) Đồ thị hàm sigmoid trong không gian hai chiều.\\nHình 14.4: Ví dụ về dữ liệu trong không gian hai chiều và hàm sigmoid trong không gian đó.\\nx1\\nx2\\nHình 14.5: Ví dụ về Logistic Re-\\ngression với dữ liệu hai chiều. Vùng\\nmàu đỏ càng đậm thể hiện xác suất\\nthuộc lớp dữ liệu đỏ càng cao, vùng\\nmàu xanh càng đậm thể hiện xác\\nsuất thuộc lớp dữ liệu đỏ càng thấp\\n- tức xác suất thuộc lớp dữ liệu\\nxanh càng cao. Vùng biên giữa hai\\nlớpthểhiệncácđiểmthuộcvàomỗi\\nlớp với xác suất thấp hơn (độ tin\\ncậy thấp hơn).\\nCách sử dụng logistic regression trong thư viện scikit-learn có thể được tìm thấy tại\\nhttps://goo.gl/BJLJNx.\\n14.4 Tính chất của logistic regression\\n1. Logistic Regression được sử dụng nhiều trong các bài toán Classification.\\nMặc dù trong tên có từ regression, logistic regression được sử dụng nhiều trong các bài\\ntoán classification. Sau khi tìm được mô hình, việc xác định classy cho một điểm dữ liệu\\nx được xác định bằng việc so sánh hai biểu thức xác suất\\nP(y= 1|x; w); P(y= 0|x; w) (14.18)\\nNếu biểu thức thứ nhất lớn hơn, ta kết luận điểm dữ liệu thuộc class 1, và ngược lại. Vì\\ntổng hai biểu thức này luôn bằng một nên một cách gọn hơn, ta chỉ cần xác định xem\\nP(y= 1|x; w) lớn hơn 0.5 hay không.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 184, 'page_label': '173'}, page_content='173 CHƯƠNG 14. LOGISTIC REGRESSION\\n2. Đường ranh giới tạo bởi logistic regression là một siêu phẳng\\nThật vậy, giả sử những điểm có xác suất đầu ra lớn hơn 0.5 được coi là thuộc vào lớp có\\nnhãn là 1. Tập hợp các điểm này là nghiệm của bất phương trình\\nP(y= 1|x; w) >0.5 ⇔ 1\\n1 + e−wT x >0.5 ⇔e−wT x <1 ⇔wTx >0 (14.19)\\nNói cách khác, tập hợp các điểm thuộc lớp 1 tạo thành nửa không gian (halfspace)\\nwTx >0, tập hợp các điểm thuộc lớp 0 tạo thành nửa không gian còn lại. Ranh giới giữa\\nhai lớp chính là siêu phẳngwTx = 0.\\nChính vì điều này, logistic regression được coi như một bộ phân lớp tuyến tính.\\n3. Logistic regression không yêu cầu giả thiết linearly separable.\\nMột điểm cộng của logistic regression so với PLA là nó không cần có giả thiết dữ liệu hai\\nlớp là linearly separable. Tuy nhiên, ranh giới tìm được vẫn có dạng tuyến tính. Vì vậy,\\nmô hình này chỉ phù hợp với loại dữ liệu mà hai lớp gần với linearly separable, tức chỉ\\ncó một vài điểm dữ liệu phá vỡ tính linearly separable của hai lớp.\\n4. Ngưỡng ra quyết định có thể thay đổi.\\nHàm dự đoán đầu ra của các điểm dữ liệu mới có thể được viết như sau.\\ndef predict(w, X, threshold = 0.5):\\n\"\"\"\\npredict output of each row of X\\nX: a numpy array of shape (N, d)\\nthreshold: a threshold between 0 and 1\\nreturn a 1d numpy array, each element is 0 or 1\\n\"\"\"\\nres = np.zeros(X.shape[0])\\nres[np.where(prob(w, X) > threshold)[0]] = 1\\nreturn res\\nTrong các ví dụ đã nêu, ngưỡng ra quyết định đều được lấy tại 0.5. Trong nhiều trường\\nhợp, ngưỡng này có thể được thay đổi. Ví dụ, việc xác định các giao dịch là lừa đảo của\\nmột công ty tín dụng là rất quan trọng. Việc phân lớp nhầm một giao dịch lừa đảo thành\\nmột giao dịch thông thường gây ra hậu quả nghiêm trọng hơn chiều ngược lại. Trong bài\\ntoán đó, ngưỡng phân loại có thể giảm xuống còn 0.3. Nghĩa là các giao dịch được dự\\nđoán là lừa đảo với xác suất lớn hơn 0.3 sẽ được xếp vào lớp lừa đảo và nên được tiếp\\ntục đánh giá bằng các bước khác.\\n5. Khi biểu diễn theo neural networks, linear regression, PLA, và logistic regression có thể\\nđược biểu diễn như trên Hình 14.6. Sự khác nhau chỉ nằm ở lựa chọn hàm kích hoạt.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 185, 'page_label': '174'}, page_content='CHƯƠNG 14. LOGISTIC REGRESSION 174\\nHình 14.6: Biểu diễn linear regression, PLA, và logistic regression dưới dạng neural network.\\n14.5 Bài toán phân biệt hai chữ số viết tay\\nChúng ta cùng làm một ví dụ thực tế hơn với bài toán phân biệt hai chữ số 0 và 1 trong\\nbộ cơ sở dữ liệu MNIST. Trong mục này, chúng ta sẽ sử dụng classLogisticRegression trong\\nthư viện scikit-learn. Trước tiên, ta khai báo các thư viện và tải về bộ cơ sở dữ liệu MNIST.\\nimport numpy as np\\nfrom sklearn.datasets import fetch_mldata\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.metrics import accuracy_score\\nmnist = fetch_mldata(’MNIST original’, data_home=’../../data/’)\\nN, d = mnist.data.shape\\nCó tổng cộng 70000 điểm dữ liệu trong tập dữ liệu MNIST, mỗi điểm là một mảng 784 phần\\ntử tương ứng với 784 pixel. Mỗi chữ số từ 0 đến 9 chiếm khoảng 10%. Chúng ta sẽ lấy ra tất\\ncả các điểm ứng với chữ số 0 và 1, sau đó lấy ra ngẫu nhiên 2000 điểm làm test set, phần\\ncòn lại đóng vai trò training set.\\nX_all = mnist.data\\ny_all = mnist.target\\nX0 = X_all[np.where(y_all == 0)[0]] # all digit 0\\nX1 = X_all[np.where(y_all == 1)[0]] # all digit 1\\ny0 = np.zeros(X0.shape[0]) # class 0 label\\ny1 = np.ones(X1.shape[0]) # class 1 label\\nX = np.concatenate((X0, X1), axis = 0) # all digits\\ny = np.concatenate((y0, y1)) # all labels\\n# split train and test\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=2000)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 186, 'page_label': '175'}, page_content='175 CHƯƠNG 14. LOGISTIC REGRESSION\\nHình 14.7: Các chữ số bị phân lớp lỗi\\ntrong bài toán phân lớp nhị phân với hai\\nchữ số 0 và 1.\\nTiếp theo, ta xây dựng mô hình logistic regression trên test set và dự đoán nhãn của các\\nđiểm trong test set. Kết quả này được so sánh với nhãn thật của mỗi điểm dữ liệu để tính\\nđộ chính xác của bộ phân lớp trên tập kiểm thử.\\nmodel = LogisticRegression(C = 1e5) # C is inverse of lam\\nmodel.fit(X_train, y_train)\\ny_pred = model.predict(X_test)\\nprint(\"Accuracy %.2f %%\" % (100*accuracy_score(y_test, y_pred.tolist())))\\nTuyệt vời, gần như 100% được phân loại chính xác. Điều này là dễ hiểu vì hai chữ số 0 và 1\\nkhác nhau rất nhiều.\\nTiếp theo, ta cùng đi tìm những ảnh bị phân loại sai và hiển thị chúng.\\nmis = np.where((y_pred - y_test) !=0)[0]\\nXmis = X_test[mis, :]\\nfrom display_network import *\\nfilename = ’mnist_mis.pdf’\\nwith PdfPages(filename) as pdf:\\nplt.axis(’off’)\\nA = display_network(Xmis.T, 1, Xmis.shape[0])\\nf2 = plt.imshow(A, interpolation=’nearest’ )\\nplt.gray()\\npdf.savefig(bbox_inches=’tight’)\\nplt.show()\\nChỉ có hai chữ số bị phân lớp lỗi được cho trên Hình 14.7. Trong đó, chữ số 0 bị phân lớp\\nlỗi là dễ hiểu vì nó trông rất giống chữ số 1.\\nBạn đoc có thể xem thêm ví dụ về bài toán xác định giới tính dựa trên ảnh khuôn mặt tại\\nhttps://goo.gl/9V8wdD.\\n14.6 Bộ phân lớp nhị phân cho bài toán phân lớp đa lớp\\nLogistic regression được áp dụng cho các bài toán phân lớp nhị phân. Các bài toán phân lớp\\nthực tế có thể có nhiều hơn hai lớp dữ liệu rất nhiều, được gọi là bài toánphân lớp đa lớp\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 187, 'page_label': '176'}, page_content='CHƯƠNG 14. LOGISTIC REGRESSION 176\\n(multi-class classification). Với một vài kỹ thuật nhỏ, ta có thể áp dụng logistic regression\\ncho các bài toán phân lớp đa lớp.\\nCó ít nhấtbốn cách để áp dụng logistic regression hay các bộ phân lớp nhị phân vào các bài\\ntoán phân lớp đa lớp.\\n14.6.1 One-vs-one\\nXây dựng rất nhiều các bộ phân lớp nhị phân cho từng cặp hai lớp dữ liệu. Bộ thứ nhất\\nphân biệt lớp thứ nhất và thứ hai, bộ thứ hai phân biệt lớp thứ nhất và lớp thứ ba, v.v.. Dữ\\nliệu mới được đưa vào tất cả các bộ phân lớp nhị phân nêu trên. Kết quả cuối cùng có thể\\nđược xác định bằng cách xem lớp nào mà điểm dữ liệu đó được phân vào nhiều nhất. Hoặc\\nvới logistic regression thì ta có thể tínhtổng các xác suấtmà điểm dữ liệu đó rơi vào mỗi\\nlớp. Như vậy, nếu cóC lớp thì số bộ phân lớp cần dùng làC(C−1)\\n2 . Đây là một con số lớn,\\ncách làm này không lợi về tính toán. Hơn nữa, nếu một chữ số thực ra là chữ số1, nhưng\\nlại được đưa vào bộ phân lớp giữa các chữ số5 và 6, thì cả hai khả năng đều không hợp lý.\\n14.6.2 Phân tầng\\nCách làm nhưone-vs-onesẽ mất rất nhiều thời gian huấn luyện vì có quá nhiều bộ phân lớp\\ncầnđượcxâydựng.Mộtcáchgiúpgiảmsốbộphânlớpnhịphânlà phân tầng(hierarchical).\\nÝ tưởng của phương pháp này có thể được thấy qua ví dụ sau.\\nGiả sử ta có bài toán phân lớp 4 chữ số 4, 5, 6, 7 trong MNIST. Vì chữ số 4 và 7 khá giống\\nnhau, chữ số 5 và 6 khá giống nhau nên trước tiên ta xây dựng bộ phân lớp [4, 7]vs [5, 6].\\nSau đó xây dựng thêm hai bộ 4vs 7 và 5vs 6. Tổng cộng, ta cần ba bộ phân lớp. Chú ý\\nrằng có nhiều cách chia khác nhau, ví dụ [4, 5, 6]vs 7, [4, 5]vs 6, rồi 4vs 5. Ưu điểm của\\nkỹ thuật này là nó sử dụng ít bộ phân lớp tuyến tính hơnone-vs-one. Hạn chế lớn nhất của\\nnó là việc nếu chỉ một bộ phân lớp cho kết quả sai thì kết quả cuối cùng chắc chắn sẽ sai.\\nVí dụ, nếu một ảnh chứa chữ số 5 bị phân lớp lỗi bởi bộ phân lớp đầu tiên, nó sẽ bị phân\\nsang nhánh [4, 7]. Cuối cùng, nó sẽ bị phân vào lớp 4 hoặc 7, cả hai đều không chính xác.\\n14.6.3 Binary coding\\nCó một cách giảm số binary classifiers hơn nữa làbinary coding, tứcmã hóaoutput của mỗi\\nlớp bằng một số nhị phân. Ví dụ, nếu có bốn lớp dữ liệu thì các lớp được mã hoá là 00, 01,\\n10, và 11. Với cách làm này, số bộ phân lớp nhị phân cần xây dựng chỉ làm = ⌈log2(C)⌉\\ntrong đó C là số lớp,⌈a⌉là số nguyên nhỏ nhất không nhỏ hơna. Bộ thứ nhất đi tìm bit\\nđầu tiên của output (đã được mã hóa nhị phân), bộ thứ hai sẽ đi tìm bit thứ hai, v.v.. Cách\\nlàm này sử dụng một số lượng nhỏ nhất các bộ phân lớp tuyến tính. Tuy nhiên, nó có một\\nhạn chế rất lớn là chỉ cần một bit bị phân loại sai sẽ dẫn đến dữ liệu bị phân loại sai. Hơn\\nnữa, nếu số lớp không phải là lũy thừa của hai, mã nhị phân nhận được có thể là một giá\\ntrị không tương ứng với lớp nào.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 188, 'page_label': '177'}, page_content='177 CHƯƠNG 14. LOGISTIC REGRESSION\\na)\\n b)\\n c)\\nHình 14.8: Một số ví dụ về phân phối của các lớp dữ liệu trong bài toán phân lớp đa lớp.\\n14.6.4 one-vs-rest hay one-hot coding\\nKỹ thuật được sử dụng nhiều nhất làone-vs-rest (một số tài liệu gọi làove-vs-all, one-\\nagainst-rest, hoặcone-against-all). Cụ thể, nếu cóC lớp thì ta sẽ xây dựngC bộ phân\\nlớp nhị phân, mỗi bộ tương ứng với một lớp. Bộ thứ nhất giúp phân biệt lớp thứ nhất với\\ncác lớp còn lại, tức xem một điểm có thuộc lớp thứ nhất hay không, hoặc xác suất để một\\nđiểm rơi vào lớp đó là bao nhiêu. Tương tự như thế, bộ thứ hai sẽ phân biệt lớp thứ hai với\\ncác lớp còn lại, v.v.. Kết quả cuối cùng có thể được xác định bằng cách xác định lớp mà một\\nđiểm rơi vào với xác suất cao nhất.\\nLogistic regression trong thư viện sklearn có thể được dùng trực tiếp để áp dụng vào các\\nbài toán phân lớp đa lớp với kỹ thuậtone-vs-rest. Với bài toán MNIST, để dùng logistic\\nregression kết hợp với one-vs-rest (mặc định trong scikit-learn), ta có thể làm như sau.\\n# all class\\nX_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=10000)\\nmodel = LogisticRegression(C = 1e5) # C is inverse of lam\\nmodel.fit(X_train, y_train)\\ny_pred = model.predict(X_test)\\nprint(\"Accuracy %.2f %%\" % (100*accuracy_score(y_test, y_pred.tolist())))\\nKết quả thu được khoảng 91.7%. Đây vẫn là một kết quả quá thấp so với con số 99.7% mà\\ndeep learning đã đạt được. Ngay cả K-nearest neighbors cũng đã đạt khoảng 96 %.\\n14.7 Thảo luận\\n14.7.1 Kết hợp các phương pháp trên\\nTrong nhiều trường hợp, ta cần phải kết hợp hai hoặc ba trong số bốn kỹ thuật đã đề cập.\\nXét ba ví dụ trong Hình 14.8.\\n• Hình 14.8a: cả 4 phương pháp trên đây đều có thể áp dụng được.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 189, 'page_label': '178'}, page_content='CHƯƠNG 14. LOGISTIC REGRESSION 178\\n• Hình 14.8b: one-vs-rest không phù hợp vì lớp màu lục và hợp của lớp lam và lớp đỏ là\\nkhông (gần)linearly separable. Lúc này, one-vs-one hoặc hierarchical phù hợp hơn.\\n• Hình 14.8c: Tương tự như trên, ba lớp lam, lục, đỏ thẳng hàng nên sẽ không dùng được\\none-vs-rest. Trong khi đó, one-vs-one vẫn hiệu quả vì từng cặp lớp dữ liệu làlinearly\\nseparable. Tương tự hierarchical cũng làm việc nếu ta phân chia các nhóm một cách hợp\\nlý. Hoặc chúng ta có thể kết hợp nhiều phương pháp. Ví dụ: dùng one-vs-rest để tìmđỏ\\nvới không đỏ. Nếu một điểm dữ liệu làkhông đỏ, với ba lớp còn lại, ta lại quay lại trường\\nhợp Hình 14.8a và có thể dùng các phương pháp khác. Nhưng khó khăn vẫn nằm ở việc\\nphân nhóm như thế nào, liệu rằng những lớp nào có thể cho vào cùng một nhóm?\\nVới bài toán phân lớp đa lớp, nhìn chung các kỹ thuật sử dụng các bộ phân lớp nhị phân\\nđã trở nên ít hiệu quả hơn so với các phương pháp mới. Mời bạn đọc thêm Chương 15 và\\nChương 29 để tìm hiểu về các bộ phân lớp đa lớp phổ biến nhất hiện nay.\\n14.7.2 Biểu diễn các kỹ thuật đã nêu dưới dạng neural network\\nLấy ví dụ với bài toán có bốn lớp dữ liệu 1, 2, 3, 4; ta có thể biểu diễn các mô hình được\\nđề cập trong Mục 14.6 dưới dạng neural network như trên Hình 14.9. Các node màu đỏ thể\\nhiện đầu ra là một trong hai giá trị.\\nCác network này đều có nhiều node ở output layer, và một vector trọng sốw bây giờ đã trở\\nthành ma trận trọng sốW mà mỗi cột của nó tương ứng với vector trọng số của một node\\noutput. Việc tối ưu đồng thời các bộ phân lớp nhị phân trong mỗi network cũng được tổng\\nquát lên nhờ các phép tính với ma trận. Lúc này, công thức cập nhật của logistic regression\\nw ←w −η(zi −yi)xi (14.20)\\ncó thể được tổng quát thành\\nW ←W −ηxi(zi −yi)T (14.21)\\nVớiW,yi,zi lần lượt là ma trận trọng số, vector (cột) outputthật với toàn bộ các bộ phân\\nlớp nhị phân tương ứng với điểm dữ liệuxi, và vector output tìm được của networks tại thời\\nđiểm đang xét nếu đầu vào mỗi network làxi. Chú ý rằng vectoryi là một vector nhị phân,\\nvector zi gồm các phần tử nằm trong khoảng(0,1).\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 190, 'page_label': '179'}, page_content='179 CHƯƠNG 14. LOGISTIC REGRESSION\\n1 vs 2\\n1 vs 3\\n1 vs 4\\n2 vs 3\\n2 vs 4\\n3 vs 4\\none-vs-one\\n1,2 vs 3,4\\n1 vs 2\\n3 vs 4\\nHierarchical\\nbit 0 vs bit 1\\nbit 0 vs bit 1\\nclass 1 = ’00’\\nclass 2 = ’01’\\nclass 3 = ’10’\\nclass 4 = ’11’\\nBinary coding\\n1 vs rest\\n2 vs rest\\n3 vs rest\\n4 vs rest\\none-vs-rest\\nHình 14.9: Mô\\nhình neural net-\\nworks cho các kỹ\\nthuật sử dụng các\\nbộ phân lớp nhị\\nphânchobàitoán\\nphân lớp đa lớp.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 191, 'page_label': '180'}, page_content='Chương 15\\nSoftmax regression\\nCác bài toán phân lớp thực tế thường có rất nhiều lớp dữ liệu. Như đã thảo luận trong\\nChương 14, các bộ phân lớp nhị phân tuy có thể kết hợp được với nhau để giải quyết các bài\\ntoán này, chúng vẫn có những hạn chế nhất định. Trong chương này, một phương pháp mở\\nrộng của logistic regression có tên làsoftmax regressionsẽ được giới thiệu nhằm khắc phục\\nnhững hạn chế đã đề cập. Một lần nữa, mặc dù trong tên có chứa từ “regression”, softmax\\nregression được sử dụng cho các bài toán phân lớp. Nó cũng chính là một trong những thành\\nphần phổ biến nhất trong các bộ phân lớp hiện nay.\\n15.1 Giới thiệu\\nVới bài toán phân lớp nhị phân sử dụng logistic regression, đầu ra của neural network là\\nmột số thực trong khoảng(0,1), đóng vai trò như là xác suất để đầu vào thuộc một trong\\nhai lớp. Ý tưởng này cũng có thể mở rộng cho bài toán phân lớp đa lớp, ở đó cóC node ở\\noutput layer và giá trị mỗi node đóng vai trò như xác suất để đầu vào rơi vào lớp tương ứng.\\nNhư vậy, các đầu ra này liên kết với nhau qua việc chúng đều là các số dương và có tổng\\nbằng một. Mô hình softmax regression thảo luận trong chương này đảm bảo tính chất đó.\\nNhắc lại kỹ thuậtone-vs-rest được trình bày trong chương trước được biểu diễn dưới dạng\\nneuron network như trong Hình 15.1. Output layer màu đỏ có thể phân tách thành hai\\nsublayer và mỗi thành phần của sublayer thứ haiai chỉ phụ thuộc vào thành phần tương\\nứng ở sublayer thứ nhấtzi thông qua hàm sigmoidai = σ(zi). Các giá trị đầu raai đều\\nlà các số dương nhưng vì không có ràng buộc giữa chúng, tổng của chúng có thể là một số\\ndương bất kỳ.\\nChú ý rằng các mô hình linear regression, PLA, và logistic regression chỉ có một node ở\\noutput layer. Trong các trường hợp đó, tham số mô hình chỉ là một vectorw. Trong trường\\nhợp output layer có nhiều hơn một node, tham số mô hình sẽ là tập hợp tham sốwi ứng\\nvới từng node. Lúc này, ta có mộtma trận trọng số(weight matrix) W = [w1,w2,..., wC],\\nmỗi cột ứng với một node ở output layer.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 192, 'page_label': '181'}, page_content='181 CHƯƠNG 15. SOFTMAX REGRESSION\\n1x0\\nx1\\nx2\\nxd\\nx\\nW\\nΣ\\nΣ\\nΣ\\nΣ\\nz1\\nz2\\nzC\\nz\\na1\\na2\\naC\\na\\n1 vs rest\\n2 vs rest\\nC vs rest\\nxi Σ\\nzj\\nwij\\nw0j: biases, don’t forget!\\nd: data dimension\\nC: number of classes\\nx ∈ Rd+1\\nW ∈ R(d+1)×C\\nzi = wT\\ni x\\nz = WT x ∈ RC\\nai = sigmoid(zi) ∈ R\\n0 < ai < 1\\nHình 15.1: Phân lớp đa lớp với logistic regression và one-vs-rest.\\n15.2 Softmax function\\n15.2.1 Công thức của Softmax function\\nChúng ta cần một mô hình xác suất sao cho với mỗi inputx, ai thể hiện xác suất để input\\nđó rơi vào lớp thứi. Vậy điều kiện cần là cácai phải dương và tổng của chúng bằng một.\\nNgoài ra, ta sẽ thêm một điều kiện cũng rất tự nhiên nữa, đó là giá trịzi = wT\\ni x càng lớn\\nthì xác suất dữ liệu rơi vào lớp thứi càng cao. Điều kiện cuối này chỉ ra rằng ta cần một\\nquan hệ đồng biến ở đây.\\nChú ý rằngzi có thể nhận giá trị cả âm và dương vì nó là một tổ hợp tuyến tính của các\\nthành phần của vector đặc trưngx. Một hàm số khả vi đơn giản có thể chắc chắn biếnzi\\nthành một giá trị dương, và hơn nữa, đồng biến, là hàmexp(zi) =ezi. Điều kiện khả vi để\\nthuận lợi cho việc sử dụng đạo hàm cho việc tối ưu. Điều kiện cuối cùng, tổng cácai bằng\\nmột có thể được đảm bảo nếu\\nai = exp(zi)∑C\\nj=1 exp(zj)\\n, ∀i= 1,2,...,C (15.1)\\nMối quan hệ này, với mỗiai phụ thuộc vào tất cả cáczi, thoả mãn tất cả các điều kiện đã\\nxét: dương, tổng bằng một, giữ đượcthứ tựcủa zi. Hàm số này được gọi làsoftmax function.\\nLúc này, ta có thể coi rằng\\np(yk = i|xk; W) =ai (15.2)\\nTrong đó,p(y = i|x; W) được hiểu là xác suất để một điểm dữ liệux rơi vào lớp thứi nếu\\nbiết tham số mô hình là ma trận trọng sốW. Hình 15.2 thể hiện mô hình softmax regression\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 193, 'page_label': '182'}, page_content='CHƯƠNG 15. SOFTMAX REGRESSION 182\\n1x0\\nx1\\nx2\\nxd\\nx\\nW\\nΣ\\nΣ\\nΣ\\nΣ\\nz1\\nz2\\nzC\\nz\\na1\\na2\\naC\\na\\nxi Σ\\nzj\\nwij\\nw0j: biases, don’t forget!\\nd: data dimension\\nC: number of classes\\nx ∈ Rd+1\\nW ∈ R(d+1)×C\\nzi = wT\\ni x\\nz = WT x ∈ RC\\na = softmax(z) ∈ RC\\nai > 0,\\nC∑\\ni=1\\nai = 1\\nx\\na\\nz = softmax(WT x)\\nshort form\\nHình 15.2: Mô hình softmax regression dưới dạng neural network.\\ndưới dạng neural network. Sự khác nhau giữa mô hình này và mô hình one-vs-rest nằm ở\\nchỗ nó có các liên kết giữa mọi node của hai sublayer màu đỏ.\\n15.2.2 Softmax function trong Python\\nDưới đây là một đoạn code thực hiện hàm softmax. Đầu vào là một ma trận với mỗihàng\\nlà một vectorz, đầu ra cũng là một ma trận mà mỗi hàng có giá trị làa = softmax(z). Các\\ngiá trị củaz còn được gọi làscores.\\nimport numpy as np\\ndef softmax(Z):\\n\"\"\"\\nCompute softmax values for each sets of scores in V.\\neach column of V is a set of scores.\\nZ: a numpy array of shape (N, C)\\nreturn a numpy array of shape (N, C)\\n\"\"\"\\ne_Z = np.exp(Z)\\nA = e_Z / e_Z.sum(axis = 1, keepdims = True)\\nreturn A\\n15.2.3 Một vài ví dụ\\nHình 15.3 mô tả một vài ví dụ về mối quan hệ giữa đầu vào và đầu ra của hàm softmax.\\nHàng trên màu xanh nhạt thể hiện các scoreszi với giả sử rằng số lớp dữ liệu là ba. Hàng\\ndưới màu đỏ nhạt thể hiện các giá trị đầu raai của hàm softmax.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 194, 'page_label': '183'}, page_content='183 CHƯƠNG 15. SOFTMAX REGRESSION\\n2\\n2\\n2\\nz1 z2 z3\\n0.333\\n0.333\\n0.333\\na1 a2 a3\\nsoftmax\\n2\\n1.8\\n0\\nz1 z2 z3\\n0.512\\n0.419\\n0.069\\na1 a2 a3\\n-1\\n-1.5\\n-2\\nz1 z2 z3\\n0.507\\n0.307\\n0.186\\na1 a2 a3\\n3\\n3\\n.1\\nz1 z2 z3\\n0.486\\n0.486\\n0.027\\na1 a2 a3\\nHình 15.3: Một số ví dụ về đầu vào và đầu ra của hàm softmax.\\nCó một vài quan sát như sau:\\n• Cột 1: Nếu cáczi bằng nhau (bằng 2 hoặc một số bất kỳ), thì cácai cũng bằng nhau và\\nbằng 1/3.\\n• Cột 2: Nếu giá trị lớn nhất trong cáczi là z1 vẫn bằng 2, thì mặc dù xác suất tương ứng\\na1 vẫn là lớn nhất, nó đã thay đổi lên hơn 0.5. Sự chênh lệch ở đầu ra là đáng kể, nhưng\\nthứ tự tương ứng không thay đổi.\\n• Cột 3: Khi các giá trịzi là âm thì các giá trịai vẫn là dương và thứ tự vẫn được đảm bảo.\\n• Cột 4: Nếuz1 = z2, thìa1 = a2.\\nBạn đọc có thể thử với các giá trị khác trực tiếp trên trình duyệt tạihttps://goo.gl/pKxQYc ,\\nphần Softmax.\\n15.2.4 Phiên bản ổn định hơn của softmax function\\nKhi một trong các zi quá lớn, việc tính toán exp(zi) có thể gây ra hiện tượng tràn số\\n(overflow), ảnh hưởng lớn tới kết quả của hàm softmax. Có một cách khắc phục hiện tượng\\nnày bằng cách dựa trên quan sát\\nexp(zi)∑C\\nj=1 exp(zj)\\n= exp(−c) exp(zi)\\nexp(−c)∑C\\nj=1 exp(zj)\\n= exp(zi −c)∑C\\nj=1 exp(zj −c)\\n(15.3)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 195, 'page_label': '184'}, page_content='CHƯƠNG 15. SOFTMAX REGRESSION 184\\nvới c là một hằng số bất kỳ. Vậy một phương pháp đơn giản giúp khắc phục hiện tượng\\noverflow là trừ tất cả cáczi đi một giá trị đủ lớn. Trong thực nghiệm, giá trị đủ lớn này\\nthường được chọn làc= maxizi. Vậy chúng ta có thể sửa đoạn code cho hàmsoftmax phía\\ntrên bằng cách trừ mỗi hàng của ma trận đầu vàoZ đi giá trị lớn nhất trong hàng đó. Ta có\\nphiên bản ổn định hơn làsoftmax_stable1.\\ndef softmax_stable(Z):\\n\"\"\"\\nCompute softmax values for each sets of scores in Z.\\neach row of Z is a set of scores.\\n\"\"\"\\n# Z = Z.reshape(Z.shape[0], -1)\\ne_Z = np.exp(Z - np.max(Z, axis = 1, keepdims = True))\\nA = e_Z / e_Z.sum(axis = 1, keepdims = True)\\nreturn A\\n15.3 Hàm mất mát và phương pháp tối ưu\\n15.3.1 Cross entropy\\nĐầu ra của softmax network không còn là một giá trị biểu thị lớp cho dữ liệu mà đã trở\\nthành một vector ở dạng one-hot với chỉ một phần tử bằng 1 tại vị trí tương ứng với lớp đó\\n(tính từ 1), các phần tử còn lại bằng 0.\\nVới mỗi đầu vàox, đầu ra tương ứng qua softmax network sẽ là vectora = softmax(WTx);\\nđầu ra này được gọi làđầu ra dự đoán. Trong khi đó,đầu ra thực sựcủa nó là một vector ở\\ndạng one-hot.\\nHàm mất mát của softmax regression được xây dựng dựa trên bài toán tối thiểu sự khác\\nnhau giữađầu ra dự đoána và đầu ra thực sựy (ở dạng one-hot). Khi cả hai là các vector\\nthể hiện xác suất, khoảng cách giữa chúng thường được đo bằng một đại lượng được gọi là\\ncross entropy. Một đặc điểm nổi bật của đại lượng này là nếu cố định một vector xác suất,\\ngiá trị của nóđạt giá trị nhỏ nhất khi hai vector xác suất bằng nhau, và rất lớn khi hai vector\\nđó lệch nhau nhiều.\\nCross entropy giữa hai vector phân phốip và q rời rạc được định nghĩa bởi\\nH(p,q) = −\\nC∑\\ni=1\\npilog qi (15.4)\\nHình 15.4 thể hiển rõ ưu điểm của hàm cross entropy so với hàm bình phương khoảng cách\\nEuclid. Đây là ví dụ trong trường hợpC = 2 và p1 lần lượt nhận các giá trị0.5,0.1 và 0.8.\\nChú ý rằngp2 = 1 −p1. Có hai nhận xét quan trọng sau đây:\\n1. Giá trị nhỏ nhất của cả hai hàm số đạt được khiq= p tại hoành độ các điểm màu lục.\\n1 Xem thêm về cách xử lý mảng numpy trong Python tạihttps://fundaml.com\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 196, 'page_label': '185'}, page_content='185 CHƯƠNG 15. SOFTMAX REGRESSION\\n(a)\\n (b)\\n (c)\\nHình 15.4: So sánh giữa hàm cross entropy và hàm bình phương khoảng cách. Các điểm màu\\nlục thể hiện các giá trị nhỏ nhất của mỗi hàm.\\n2. Quan trọng hơn, hàm cross entropy nhận giá trị rất cao (tức mất mát rất cao) khiq ở\\nxa p. Trong khi đó, sự chênh lệch giữa các mất mát ở gần hay xa nghiệm của hàm bình\\nphương khoảng cách(q−p)2 là ít đáng kể hơn. Về mặt tối ưu, hàm cross entropy sẽ cho\\nnghiệm gần với p hơn vì những nghiệm ở xa bịtrừng phạt rất nặng.\\nHai tính chất trên đây khiến cho cross entropy được sử dụng rộng rãi khi tính khoảng cách\\ngiữa hai phân phối xác suất. Tiếp theo, chúng ta sẽ chứng minh nhận định sau.\\nCho p ∈RC\\n+ là một vector với các thành phần dương và tổng bằng 1. Bài toán tối ưu\\nq = arg min\\nq\\nH(p,q)\\nthoả mãn:\\nC∑\\ni=1\\nqi = 1; qi >0\\ncó nghiệmq = p.\\nBài toán này có thể giải quyết bằng phương pháp nhân tử Lagrange (xem Phụ lục A).\\nLagrangian của bài toán này là\\nL(q1,q2,...,q C,λ) = −\\nC∑\\ni=1\\npilog(qi) + λ(\\nC∑\\ni=1\\nqi −1)\\nTa cần giải hệ phương trình\\n∇q1,...,qC,λL(q1,...,q C,λ) = 0 ⇔\\n{−pi\\nqi\\n+ λ= 0, i = 1,...,C\\nq1 + q2 + ··· + qC = 1\\nTừ phương trình thứ nhất ta cópi = λqi. Vì vậy,1 = ∑C\\ni=1 pi = λ∑C\\ni=1 qi = λ ⇒λ = 1.\\nĐiều này tương đương vớiqi = pi,∀i. □\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 197, 'page_label': '186'}, page_content='CHƯƠNG 15. SOFTMAX REGRESSION 186\\nChú ý\\n1. Hàm cross entropy không có tính đối xứngH(p,q) ̸= H(q,p). Điều này có thể dễ\\ndàng nhận ra ở việc các thành phần củap trong công thức(1) có thể nhận giá trị\\nbằng 0, trong khi đó các thành phần củaq phải là dương vìlog(0) không xác định.\\nChính vì vậy, khi sử dụng cross entropy trong các bài toán phân lớp,p là đầu ra\\nthực sự vì nó là một vector ở dang one-hot,q là đầu ra dự đoán. Trong các thành\\nphần thể hiện xác suất củaq, không có thành phần nào tuyệt đối bằng 1 hoặc tuyệt\\nđối bằng 0 (do hàmexp luôn trả về một giá trị dương).\\n2. Khi p là một vector ở dạng one-hot, giả sử chỉ cópc = 1, khi đó biểu thức cross\\nentropy trở thành−log(qc). Biểu thức này đạt giá trị nhỏ nhất nếuqc = 1, điều\\nnày là không khả thi vì nghiệm này không thuộc miền xác định của bài toán. Tuy\\nnhiên, giá trị cross entropy tiệm cận tới 0 khiqc tiến đến 1. Điều này xảy ra khi\\nzc rất rất lớn so với cáczi còn lại.\\n15.3.2 Xây dựng hàm mất mát\\nTrong trường hợp cóC lớp dữ liệu,mất mátgiữa đầu ra dự đoán và đầu ra thực sự của một\\nđiểm dữ liệuxi với label (one-hot)yi được tính bởi\\nJi(W) ≜J(W; xi,yi) = −\\nC∑\\nj=1\\nyji log(aji) (15.5)\\nvới yji và aji lần lượt là phần tử thứj của vector xác suấtyi và ai. Nhắc lại rằng đầu raai\\nphụ thuộc vào đầu vàoxi và ma trận trọng sốW. Tới đây, nếu để ý rằng chỉ có đúng một\\nj sao choyji = 1,∀i, biểu thức (15.5) chỉ còn lại một số hạng tương ứng với giá trịj đó. Để\\ntránh việc sử dụng quá nhiều ký hiệu, chúng ta giả sử rằngyi là nhãn của điểm dữ liệuxi\\n(các nhãn là các số tự nhiên từ 1 tớiC), khi đój chính bằngyi. Sau khi có ký hiệu này, ta\\ncó thể viết lại\\nJi(W) = −log(ayi,i) (15.6)\\nvới ayi,i là phần tử thứyi của vectorai.\\nKết hợp tất cả các cặp dữ liệuxi,yi,i = 1,2,...,N , hàm mất mát cho softmax regression\\nđược xác định bởi\\nJ(W; X,Y) = −1\\nN\\nN∑\\ni=1\\nlog(ayi,i) (15.7)\\nỞ đây, ma trận trọng sốW là biến cần tối ưu. Mặc dù hàm mất mát này trông phức tạp,\\nđạo hàm của nó rất gọn. Ta cũng có thể thêm weight decay để tránh overfitting bằng cách\\ncộng thêm một đại lượng tỉ lệ với∥W∥2\\nF.\\n¯J(W; X,Y) = −1\\nN\\n( N∑\\ni=1\\nlog(ayi,i) + λ\\n2 ∥W∥2\\nF\\n)\\n(15.8)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 198, 'page_label': '187'}, page_content='187 CHƯƠNG 15. SOFTMAX REGRESSION\\nTrong các mục tiếp theo, chúng ta sẽ làm việc với hàm mất mát (15.7). Việc mở rộng cho\\nhàm mất mát với regularization (15.8) không phức tạp vì đạo hàm của số hạng regularized\\nλ\\n2 ∥W∥2\\nF đơn giản làλW. Hàm mất mát (15.7) có thể được thực hiện trên Python như sau2.\\ndef softmax_loss(X, y, W):\\n\"\"\"\\nW: 2d numpy array of shape (d, C),\\neach column correspoding to one output node\\nX: 2d numpy array of shape (N, d), each row is one data point\\ny: 1d numpy array -- label of each row of X\\n\"\"\"\\nA = softmax_stable(X.dot(W))\\nid0 = range(X.shape[0]) # indexes in axis 0, indexes in axis 1 are in y\\nreturn -np.mean(np.log(A[id0, y]))\\nChú ý\\n1. Khi biểu diễn dưới dạng toán học, mỗi điểm dữ liệu là một cột của ma trậnX;\\nnhưng khi làm việc với numpy, mỗi điểm dữ liệu được đọc theoaxis = 0 của mảng\\nhai chiềuX. Việc này thống nhất với các thư viện scikit-learn hay tensorflow ở chỗ\\nX[i] được dùng để chỉ điểm dữ liệu thứi, tính từ0. Tức là, nếu cóN điểm dữ liệu\\ntrong không giand chiều thìX ∈Rd×N, nhưngX.shape == (N, d).\\n2. W ∈Rd×C, W.shape == (d, c).\\n3. WTX sẽ được biểu diễn bởiX.dot(W), và cóshape == (N, C).\\n4. Khi làm việc với phép nhân ma trận hay mảng nhiều chiều trong numpy, ta luôn\\nnhớ chú ý tới kích thước của các ma trận sao cho các phép nhân thực hiện được.\\n15.3.3 Tối ưu hàm mất mát\\nHàm mất mát sẽ được tối ưu bằng gradient descent, cụ thể là mini-batch gradient descent.\\nMỗi lần cập nhật của mini-batch gradient descent được thực hiện trên mộtbatch có số phần\\ntử 1 <k ≪N. Để tính được đạo hàm của hàm mất mát theo tập con này, trước hết ta xem\\nxét đạo hàm của hàm mất mát tại một điểm dữ liệu.\\nVới chỉ một cặp dữ liệu(xi,yi), ta lại dùng (15.5)\\nJi(W) = −\\nC∑\\nj=1\\nyji log(aji) = −\\nC∑\\nj=1\\nyji log\\n(\\nexp(wT\\nj xi)\\n∑C\\nk=1 exp(wT\\nkxi)\\n)\\n= −\\nC∑\\nj=1\\n(\\nyjiwT\\nj xi −yji log\\n( C∑\\nk=1\\nexp(wT\\nkxi)\\n))\\n= −\\nC∑\\nj=1\\nyjiwT\\nj xi + log\\n( C∑\\nk=1\\nexp(wT\\nkxi)\\n)\\n(15.9)\\n2 Xem thêm: Truy cập vào nhiều phần tử của mảng hai chiều trong numpy - FundaMLhttps://goo.gl/SzLDxa .\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 199, 'page_label': '188'}, page_content='CHƯƠNG 15. SOFTMAX REGRESSION 188\\nTiếp theo ta sử dụng công thức\\n∇WJi(W) =\\n[\\n∇w1 Ji(W),∇w2 Ji(W),..., ∇wC Ji(W)\\n]\\n(15.10)\\nTrong đó, gradient theo từng cột củawj có thể tính được dựa theo (15.9) và quy tắc chuỗi\\ntính gradient\\n∇wj Ji(W) = −yjixi + exp(wT\\nj xi)\\n∑C\\nk=1 exp(wT\\nkxi)\\nxi\\n= −yjixi + ajixi = xi(aji −yji)\\n= ejixi (với eji = aji −yji) (15.11)\\nGiá trịeji = aji −yji chính là sự sai khác giữa đầu ra dự đoán và đầu ra thực sự tại thành\\nphần thứj. Kết hợp (15.10) và (15.11) vớiei = ai −yi, ta có\\n∇WJi(W) = xi[e1i,e2i,...,e Ci] = xieT\\ni (15.12)\\n⇒∇WJ(W) = 1\\nN\\nN∑\\ni=1\\nxieT\\ni = 1\\nNXET (15.13)\\nvớiE = A −Y.Côngthứctínhđạohàmđơngiảnthếnàygiúpchocảbatchgradientdescent,\\nvà mini-batch gradient descent đều có thể dễ dàng được áp dụng. Trong trường hợp mini-\\nbatch gradient, giả sử kích thước batch làk, ký hiệuXb ∈Rd×k,Yb ∈{0,1}C×k,Ab ∈RC×k\\nlà dữ liệu ứng với một batch, công thức cập nhật cho một batch sẽ là\\nW ←W − η\\nNb\\nXbET\\nb (15.14)\\nvới Nb là kích thước của mỗi batch. Hàm số tính đạo hàm theoW trong Python có thể được\\nthực hiện như sau:\\ndef softmax_grad(X, y, W):\\n\"\"\"\\nW: 2d numpy array of shape (d, C),\\neach column correspoding to one output node\\nX: 2d numpy array of shape (N, d), each row is one data point\\ny: 1d numpy array -- label of each row of X\\n\"\"\"\\nA = softmax_stable(X.dot(W)) # shape of (N, C)\\nid0 = range(X.shape[0])\\nA[id0, y] -= 1 # A - Y, shape of (N, C)\\nreturn X.T.dot(A)/X.shape[0]\\nHàm này đã được kiểm chứng lại bằng hàmcheck_grad.\\nTừ đó, ta có thể viết hàm số huấn luyện softmax regression như sau:\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 200, 'page_label': '189'}, page_content='189 CHƯƠNG 15. SOFTMAX REGRESSION\\ndef softmax_fit(X, y, W, lr = 0.01, nepoches = 100, tol = 1e-5, batch_size = 10):\\nW_old = W.copy()\\nep = 0\\nloss_hist = [loss(X, y, W)] # store history of loss\\nN = X.shape[0]\\nnbatches = int(np.ceil(float(N)/batch_size))\\nwhile ep < nepoches:\\nep += 1\\nmix_ids = np.random.permutation(N) # mix data\\nfor i in range(nbatches):\\n# get the i-th batch\\nbatch_ids = mix_ids[batch_size*i:min(batch_size*(i+1), N)]\\nX_batch, y_batch = X[batch_ids], y[batch_ids]\\nW -= lr*softmax_grad(X_batch, y_batch, W) # update gradient descent\\nloss_hist.append(softmax_loss(X, y, W))\\nif np.linalg.norm(W - W_old)/W.size < tol:\\nbreak\\nW_old = W.copy()\\nreturn W, loss_hist\\nCuối cùng là hàm dự đoán nhãn của các điểm dữ liệu mới. Nhãn của một điểm dữ liệu mới\\nđược xác định bằng chỉ số của lớp dữ liệu có xác suất rơi vào cao nhất, và cũng chính là chỉ\\nsố của score cao nhất.\\ndef pred(W, X):\\n\"\"\"\\npredict output of each columns of X . Class of each x_i is determined by\\nlocation of max probability. Note that classes are indexed from 0.\\n\"\"\"\\nreturn np.argmax(X.dot(W), axis =1)\\n15.4 Ví dụ trên Python\\nĐể minh hoạ ranh giới của các lớp dữ liệu khi sử dụng softmax regression, chúng ta cùng\\nlàm một ví dụ nhỏ trong không gian hai chiều với 5 lớp dữ liệu:\\nC, N = 5, 500 # number of classes and number of points per class\\nmeans = [[2, 2], [8, 3], [3, 6], [14, 2], [12, 8]]\\ncov = [[1, 0], [0, 1]]\\nX0 = np.random.multivariate_normal(means[0], cov, N)\\nX1 = np.random.multivariate_normal(means[1], cov, N)\\nX2 = np.random.multivariate_normal(means[2], cov, N)\\nX3 = np.random.multivariate_normal(means[3], cov, N)\\nX4 = np.random.multivariate_normal(means[4], cov, N)\\nX = np.concatenate((X0, X1, X2, X3, X4), axis = 0) # each row is a datapoint\\nXbar = np.concatenate((X, np.ones((X.shape[0], 1))), axis = 1) # bias trick\\ny = np.asarray([0]*N + [1]*N + [2]*N+ [3]*N + [4]*N)\\nW_init = np.random.randn(Xbar.shape[1], C)\\nW, loss_hist = softmax_fit(Xbar, y, W_init, batch_size = 10, nepoches = 100, lr =\\n0.05)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 201, 'page_label': '190'}, page_content='CHƯƠNG 15. SOFTMAX REGRESSION 190\\n0 20 40 60 80 100\\nnumber of epoches\\n0\\n2\\n4\\n6\\n8\\n10loss\\n(a)\\n (b)\\nHình 15.5: Ví dụ về sử dụng softmax regression cho năm lớp dữ liệu. (a) Nghiệm qua các\\nepoches. (b) Kết quả phân lớp cuối cùng.\\nGiá trị của hàm mất mát qua các vòng lặp được cho trên Hình 15.5a. Ta thấy rằng hàm mất\\nmát giảm rất nhanh sau đó hội tụ. Các điểm dữ liệu huấn luyện của mỗi lớp là các điểm có\\nmàu khác nhau trong Hình 15.5b. Các phần có màu nền khác nhau là cáclãnh thổ của mỗi\\nlớp dữ liệu tìm được bằng softmax regression. Ta có thể thấy rằng các đường ranh giới có\\ndạng đường thẳng. Kết quả phân chia lãnh thổ cũng khá tốt, chỉ có một số ít điểm trong\\ntập huấn luyện bị phân lớp sai. Để ý thấy rằng dùng softmax regression tốt hơn rất nhiều\\nso với phương pháp kết hợp các bộ phân lớp nhị phân.\\nMNIST với softmax regression trong scikit-learn\\nTrong scikit-learn, softmax regression được tích hợp trong class sklearn.linear_model.\\nLogisticRegression. Như sẽ thấy trong phần thảo luận, logistic regression chính là softmax\\nregression cho bài toán binary classification. Với bài toán multi-class classification, thư viện\\nnày mặc định sử dụng kỹ thuật one-vs-rest. Để sử dụng softmax regression, ta thay đổi thuộc\\ntính multi_class = ’multinomial’ vàsolver = ’lbfgs’. Ở đây,’lbfgs’ là một phương pháp tối\\nưu rất mạnh cũng dựa trên đạo hàm. Trong khuôn khổ của cuốn sách, chúng ta sẽ không\\nthảo luận về phương pháp này.\\nQuay lại với bài toán phân lớp chữ số viết tay trong cơ sở dữ liệu MNIST. Đoạn code dưới\\nđây thực hiện việc lấy ra 10000 điểm dữ liệu trong số 70000 điểm làm tập kiểm thử, còn lại\\nlà tập huấn luyện. Bộ phân lớp được sử dụng là softmax regression.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 202, 'page_label': '191'}, page_content='191 CHƯƠNG 15. SOFTMAX REGRESSION\\nimport numpy as np\\nfrom sklearn.datasets import fetch_mldata\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import accuracy_score\\nmnist = fetch_mldata(’MNIST original’, data_home=’../../data/’)\\nX = mnist.data\\ny = mnist.target\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=10000)\\nmodel = LogisticRegression(C = 1e5,\\nsolver = ’lbfgs’, multi_class = ’multinomial’) # C is inverse of lam\\nmodel.fit(X_train, y_train)\\ny_pred = model.predict(X_test)\\nprint(\"Accuracy %.2f %%\" % (100*accuracy_score(y_test, y_pred.tolist())))\\nKết quả:\\nAccuracy: 92.19 %\\nSo với kết quả hơn 91.7% của one-vs-rest logistic regression, kết quả của softmax regression\\nđã được cải thiện được một chút. Kết quả thấp như thế này là có thể dự đoán được vì thực\\nra softmax regression vẫn chỉ tạo ra các đường ranh giới là các đường tuyến tính. Kết quả\\ntốt nhất của bài toán phân loại chữ số trong MNIST hiện nay vào khoảng hơn 99.7%, đạt\\nđược bằng một convolutional neural network với rất nhiều hidden layer và layer cuối cùng\\nchính là một softmax regression.\\n15.5 Thảo luận\\n15.5.1 Logistic regression là một trường hợp đặt biệt của softmax regression\\nKhi C = 2, softmax regression và logistic regression là giống nhau. Thật vậy, vớiC = 2, đầu\\nra của hàm softmax cho một đầu vàox là\\na1 = exp(wT\\n1 x)\\nexp(wT\\n1 x) + exp(wT\\n2 x) = 1\\n1 + exp((w2 −w1)Tx); a2 = 1 −a1 (15.15)\\nTừ đây ta thấy rằng,a1 có dạng là một hàm sigmoid với vector hệ sốw = −(w2 −w1).\\nKhi C = 2, bạn đọc cũng có thể thấy rằng hàm mất mát của logistic regression và softmax\\nregression là như nhau. Hơn nữa, mặc dù có hai outputs, softmax regression có thể biểu diễn\\nbởi một output vì tổng của hai outputs luôn luôn bằng 1.\\nSoftmax regression còn có các tên gọi khác là multinomial logistic regression, hay maximum\\nentropy classifier. Giống như logisticregression, softmaxregression được sử dụng trong các\\nbài toánclassification. Các tên gọi này được giữ lại vì vấn đề lịch sử.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 203, 'page_label': '192'}, page_content='CHƯƠNG 15. SOFTMAX REGRESSION 192\\n15.5.2 Ranh giới tạo bởi softmax regression là một mặt tuyến tính\\nThật vậy, dựa vào hàm softmax thì một điểm dữ liệux được dự đoán là rơi vào classj nếu\\naj ≥ak, ∀k̸= j. Bạn đọc có thể chứng minh được rằng\\naj ≥ak ⇔zj ≥zk ⇔wT\\nj x ≥wT\\nkx ⇔(wj −wk)Tx ≥0 (15.16)\\nNhư vậy, một điểm thuộc lớp thứj nếu và chỉ nếu(wj −wk)Tx ≥0, ∀k̸= j. Như vậy,lãnh\\nthổ của mỗi lớp dữ liệu là giao của các nửa không gian. Nói cách khác, đường ranh giới giữa\\ncác lớp là các mặt tuyến tính.\\n15.5.3 Softmax Regression là một trong hai classifiers phổ biến nhất\\nSoftmax regression cùng với multi-class support vector machine (Chương 29) là hai bộ phân\\nlớp phổ biến nhất được dùng hiện nay. Softmax regression đặc biệt được sử dụng nhiều trong\\ncác deep neural network với rất nhiều hidden layer. Những layer phía trước có thể được coi\\nnhư một bộ tạo vector đặc trưng, layer cuối cùng thường là một softmax regression.\\n15.5.4 Source code\\nSource code cho chương này có thể được tìm thấy tạihttps://goo.gl/XU8ZXm .\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 204, 'page_label': '193'}, page_content='Chương 16\\nMultilayer neural network và\\nbackpropagation\\n16.1 Giới thiệu\\n16.1.1 Perceptron cho các hàm logic cơ bản\\nChúng ta cùng xét khả năng biểu diễn của perceptron (PLA) cho các bài toán biểu diễn các\\nhàm logic nhị phân: NOT, AND, OR, và XOR1. Để có thể sử dụng perceptron (với đầu ra\\nlà 1 hoặc -1), chúng ta sẽ thay các giá trị bằng 0 (false) của tại đầu ra của các hàm này bởi\\n-1. Quan sát hàng trên của Hình 16.1, các điểm hình vuông màu xanh là các điểm có nhãn\\nbằng 1, các điểm hình tròn màu đỏ là các điểm có nhãn bằng -1. Hàng dưới của Hình 16.1\\nlà các mô hình perceptron với các hệ số tương ứng.\\nNhận thấy rằng với các bài toán NOT, AND, và OR, dữ liệu hai lớp là linearly separable,\\nvì vậy ta có thể tìm được các hệ số cho perceptron giúp biểu diễn chính xác mỗi hàm\\nsố. Chẳng hạn với hàm NOT, khix1 = 0 , ta có a = sgn(−2 ×0 + 1) = 1 ; khi x1 = 1 ,\\na= sgn(−2 ×1 + 1) = −1. Trong cả hai trường hợp, đầu ra dự đoán đều giống với đầu ra\\nthực sự. Bạn đọc có thể tự kiểm chứng các hệ số với hàm AND và OR.\\n16.1.2 Biểu diễn hàm XOR với nhiều perceptron\\nHàm XOR, vì dữ liệu không linearly separable, không thể biểu diễn bằng một perceptron.\\nNếu thay perceptron bằng logistic regression tức thay hàm kích hoạt từ hàm sign sang hàm\\nsigmoid, ta cũng không tìm được các hệ số thỏa mãn, vì về bản chất, logistic regression (hay\\ncả softmax regression) cũng chỉ tạo ra các ranh giới có dạng tuyến tính. Như vậy là các mô\\nhình neural network chúng ta đã biết không thể biểu diễn được hàm số logic đơn giản này.\\n1 đầu ra bằng 1 (true) nếu và chỉ nếu hai đầu vào logic khác nhau.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 205, 'page_label': '194'}, page_content='CHƯƠNG 16. MULTILAYER NEURAL NETWORK VÀ BACKPROPAGATION 194\\n0 1\\nx1\\n0\\n1\\nx2\\n2x1 + 2\\nx2 −3 = 0\\n+\\n−\\nAND problem\\n1x0\\nx1\\nx2 a\\n−3\\n2\\n2\\na = sgn(2x1 + 2x2 − 3)\\n0 1\\nx1\\n0\\n1\\nx2\\n 2x1 + 2\\nx2 −1 = 0\\n+−\\nOR problem\\n1x0\\nx1\\nx2 a\\n−1\\n2\\n2\\na = sgn(2x1 + 2x2 − 1)\\n0 1\\nx1 −2x1+ 1 = 0\\n+ -\\nNOT problem\\n1x0\\nx1\\na\\n1\\n−2\\na = sgn(−2x1 + 1)\\n0 1\\nx1\\n0\\n1\\nx2\\n?\\nXOR problem\\n1x0\\nx1\\nx2 a\\n?\\n?\\n?\\nNo solution!\\nHình 16.1: Biểu diễn các hàm logic cơ bản sử dụng perceptron learning algorithm.\\n0 1\\nx1\\n0\\n1\\nx2\\n−2x1 −2x2 + 3 = 0\\n2x1 + 2\\nx2 −1 = 0\\n−\\n+\\n+−\\nXOR problem (2 layers)\\nInput layer\\n1\\nx0\\nx1\\nx2\\nW (1)\\nb (1)\\nHidden layer\\na(1)\\n1\\na(1)\\n2\\n1\\na(1)\\n0\\n−1\\n2\\n2\\n3\\n−2\\n−2\\nW (2)\\nb (2)\\nOutput layer\\na(2)\\n1\\n1\\n−1\\n(a) (b)\\nW(1) =\\n[−2 2\\n−2 2\\n]\\n; b(1) =\\n[ 3\\n−1\\n]\\nW(2) =\\n[1\\n1\\n]\\n; b(2) =\\n[−1]\\nx =\\n[x1\\nx2\\n]\\n; a(1) =\\n[\\na(1)\\n1\\na(1)\\n2\\n]\\na(1) = f\\n(\\nW(1)T x + b(1)\\n)\\na(2) = f\\n(\\nW(2)T a(1) + b(2)\\n)\\nf(.) =sgn(.) (element-wise)\\nHình 16.2: Ba perceptron biểu diễn hàm XOR.\\nNhận thấy rằng nếu cho phép sử dụng hai đường thẳng, bài toán biểu diễn hàm XOR có thể\\nđược giải quyết như Hình 16.2. Các hệ số tương ứng với hai đường thẳng trong Hình 16.2a\\nđược minh họa trên Hình 16.2b bằng các mũi tên xuất phát từ các điểm màu lục và cam.\\nĐầu raa(1)\\n1 bằng 1 với các điểm nằm về phía (+) của đường thẳng3 −2x1 −2x2 = 0, bằng\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 206, 'page_label': '195'}, page_content='195 CHƯƠNG 16. MULTILAYER NEURAL NETWORK VÀ BACKPROPAGATION\\n-1 với các điểm nằm về phía (-). Tương tự, đầu raa2 bằng 1 với các điểm nằm về phía (+)\\ncủa đường thẳng −1 + 2x1 + 2x2 = 0 . Như vậy, hai đường thằng ứng với hai perceptron\\nnày tạo ra hai đầu ra tại các nodea(1)\\n1 ,a(1)\\n2 . Vì hàm XOR chỉ có một đầu ra nên ta cần làm\\nthêm một bước nữa: coia1,a2 như là đầu vào của một perceptron khác. Trong perceptron\\nmới này, input là các node màu cam (đừng quên bias node luôn có giá trị bằng 1), đầu ra là\\nnode màu đỏ. Các hệ số được cho trên Hình 16.2b. Kiểm tra lại một chút, với các điểm hình\\nvuông xanh (Hình 16.2a),a(1)\\n1 = a(1)\\n2 = 1, khi đóa(2) = sgn(−1 + 1 + 1) = 1. Với các điểm\\nhình tròn đỏ, vìa(1)\\n1 = −a(1)\\n2 nên a(2) = sgn(−1 + a(1)\\n1 + a(1)\\n2 ) = sgn(−1) = −1. Trong cả hai\\ntrường hợp, đầu ra dự đoán đều giống với đầu ra thực sự. Vậy, nếu sử dụng ba perceptron\\ntương ứng với các đầu raa(1)\\n1 ,a(1)\\n2 ,a(2), ta sẽ biểu diễn được hàm XOR. Ba perceptron kể\\ntrên được xếp vào hailayers. Layer thứ nhất: đầu vào - lục, đầu ra - cam. Layer thứ hai:\\nđầu vào - cam, đầu ra - đỏ. Ở đây, đầu ra của layer thứ nhất chính là đầu vào của layer thứ\\nhai. Tổng hợp lại ta được một mô hình mà ngoài layer đầu vào (lục) và đầu ra (đỏ), ta còn\\ncó một layer nữa (cam).\\nMột neural network với nhiều hơn hai layer còn được gọi là multilayer neural network,\\nmultilayer perceptrons(MLPs), deep feedforward networkhoặc feedforward neural network.\\nTừ feedforward được hiểu là dữ liệu đithẳng từ đầu vào tới đầu ra theo các mũi tên mà\\nkhông quay lại ở điểm nào, tức là network có dạng mộtacyclic graph (đồ thị không chứa\\nchu trình kín). Tên gọiperceptronở đây có thể gây nhầm lẫn một chút2, vì cụm từ này để\\nchỉ neural network với nhiều layer và mỗi layer không nhất thiết, nếu không muốn nói là rất\\nhiếm khi, là một hoặc nhiều perceptron. Hàm kích hoạt có thể là các hàm phi tuyến khác\\nthay vì hàm sgn.\\nCụ thể hơn, một multilayer neural network là một neural network có nhiều layer, làm nhiệm\\nvụ xấp xỉ mối quan hệ giữa các cặp quan hệ(x,y) trong tập huấn luyện bằng một hàm số\\ncó dạng\\ny ≈g(L) (\\ng(L−1) (\\n... (g(2)(g(1)(x)))\\n))\\n, (16.1)\\nTrong đó, layer thứ nhất đóng vai trò như hàma(1) ≜g(1)(x); layer thứ hai đóng vai trò như\\nhàm a(2) ≜g(2)(g(1)(x)) = f(2)(a(1)), v.v..\\nTrong phạm vi cuốn sách, chúng ta quan tâm tới các layer đóng vai trò như các hàm có dạng\\ng(l)(a(l−1)) = f(l)(W(l)Ta(l−1) + b(l)) (16.2)\\nvới W(l),b(l) là ma trận và vector với số chiều phù hợp,f(l) là một hàm số được gọi làhàm\\nkích hoạt(activation function).\\nMột vài lưu ý:\\n• Để cho đơn giản, chúng ta sử dụng ký hiệuW(l)T để thay cho(W(l))T (ma trận chuyển\\nvị). Trong Hình 16.2b, ký hiệu ma trậnW(2) được sử dụng, mặc dù đúng ra nó phải là\\n2 Geofrey Hinton,phù thuỷ Deep Learning, từng thừa nhận trong khoá học “Neural Networks for Machine Learning”\\n(https://goo.gl/UfdT1t ) rằng “Multilayer Neural Networks should never have been called Multilayer Perceptron.\\nIt is partly my fault, and I’m sorry.”.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 207, 'page_label': '196'}, page_content='CHƯƠNG 16. MULTILAYER NEURAL NETWORK VÀ BACKPROPAGATION 196\\nInput\\nW(1)\\nHidden 1\\nW(2)\\nHidden 2\\nW(3)\\nOutput\\nHình 16.3: MLP với hai hidden\\nlayers (các biases đã bị ẩn).\\nvector, để biểu diễn tổng quát cho trường hợp output layer có thể có nhiều hơn một node.\\nTương tự với biasb(2).\\n• Khác với các chương trước về neural network, khi làm việc với multilayer neural network,\\nta nên tách riêng phần bias và ma trận hệ số. Điều này đồng nghĩa với việc vector input\\nx là vector KHÔNG mở rộng.\\nĐầu ra của multilayer neural network loại này ứng với một đầu vàox có thể được tính theo\\na(0) = x (16.3)\\nz(l) = W(l)Ta(l−1) + b(l), l = 1,2,...,L (16.4)\\na(l) = f(l)(z(l)), l = 1,2,...,L (16.5)\\nˆ y= a(L) (16.6)\\nĐây chính là đầu ra dự đoán. Bước này được gọi làfeedforward vì cách tính toán được thực\\nhiện từ đầu đến cuối của network. Hàm mất mát thoả mãn đạt giá trị nhỏ khi đầu ra này\\ngần với đầu ra thực sự. Tuỳ vào bài toán, là classification hoặc regression, chúng ta cần thiết\\nkế các hàm mất mát phù hợp.\\n16.2 Các ký hiệu và khái niệm\\n16.2.1 Layer\\nNgoài input layer và output layer, một multilayer neural network có thể có nhiềuhidden\\nlayer ở giữa. Cáchidden layertheo thứ tự từ input layer đến output layer được đánh số thứ\\nthự làhidden layer 1, hidden layer 2, v.v.. Hình 16.3 là một ví dụ về một multilayer neural\\nnetwork với hai hidden layer.\\nSố lượng layer trong một multilayer neural network, được ký hiệu làL, được tính bằng số\\nhidden layer cộng với một. Khi đếm số layer của một multilayer neural network, ta không\\ntính input layer. Trong Hình 16.3,L= 3.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 208, 'page_label': '197'}, page_content='197 CHƯƠNG 16. MULTILAYER NEURAL NETWORK VÀ BACKPROPAGATION\\nz(l−1) a(l−1)\\n(l −1)th layer\\n1\\nz(l−1)\\n1 a(l−1)\\n1...\\nz(l−1)\\ni a(l−1)\\ni...\\nz(l−1)\\nd(l−1) a(l−1)\\nd(l−1)\\nW ( l ) ∈ R d\\n( l − 1)\\n× d\\n( l )\\nb ( l ) ∈ R d\\n( l )\\n× 1\\nz\\n( l )\\nj = w\\n( l ) T\\nj a ( l − 1) + b\\n( l )\\nj\\nz ( l ) = W ( l ) T a ( l − 1) + b ( l )\\na ( l ) = f ( z ( l ) )\\nlth layer\\nz(l) a(l)\\nz(l)\\n1 a(l)\\n1\\nz(l)\\n2 a(l)\\n2...\\nz(l)\\nj a(l)\\nj...\\nz(l)\\nd(l) a(l)\\nd(l)\\nw(l)\\nij\\nb(l)\\nj\\nHình 16.4: Các ký hiệu sử\\ndụng trong multilayer neural\\nnetwork.\\n16.2.2 Units\\nQuan sát Hình 16.4, mỗinode hình tròn trong một layer được gọi là mộtunit. Unit ở input\\nlayer, các hidden layer, và output layer được lần lượt gọi là input unit, hidden unit, và output\\nunit. Đầu vào của hidden layer thứl được ký hiệu bởiz(l), đầu ra của mỗi unit thường được\\nký hiệu làa(l) (thể hiện activation, tức giá trị của mỗi unit sau khi ta áp dụng activation\\nfunction lên đầu vàoz(l)). Đầu ra của unit thứi trong layer thứl được ký hiệu làa(l)\\ni . Giả\\nsử thêm rằng số unit trong layer thứl (không tính bias) làd(l). Vector biểu diễn output của\\nlayer thứl được ký hiệu làa(l) ∈Rd(l)\\n.\\n16.2.3 Weights và Biases\\nCó Lma trận trọng số cho một multilayer neural network cóLlayer. Các ma trận này được\\nký hiệu làW(l) ∈Rd(l−1)×d(l)\\n,l = 1,2,...,L trong đóW(l) thể hiện cáckết nối từ layer thứ\\nl−1 tới layer thứl (nếu ta coi input layer là layer thứ0). Cụ thể hơn, phần tửw(l)\\nij thể hiện\\nkết nối từ node thứicủa layer thứ(l−1) tới node từj của layer thứ(l). Các bias của layer\\nthứ (l) được ký hiệu làb(l) ∈Rd(l)\\n. Các trọng số này được ký hiệu như trên Hình 16.4. Khi\\ntối ưu một multilayer neural network cho một công việc nào đó, chúng ta cần đi tìm các\\nweight và bias này. Tập hợp các weight và bias lần lượt được ký hiệu làW và b.\\n16.3 Activation function–Hàm kích hoạt\\nMỗi output của một layer (trừ input layer) được tính dựa vào công thức\\na(l) = f(l)(W(l)Ta(l−1) + b(l)) (16.7)\\nTrong đóf(l)(.) là một hàm kích hoạt phi tuyến. Nếu hàm kích hoạt tại một layer là một\\nhàm tuyến tính, layer này và layer tiếp theo có thể rút gọn thành một layer vìhợp của các\\nhàm tuyến tính là một hàm tuyến tính.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 209, 'page_label': '198'}, page_content='CHƯƠNG 16. MULTILAYER NEURAL NETWORK VÀ BACKPROPAGATION 198\\n−2 0 2\\nz\\n0.0\\n0.2\\n0.4\\n0.6\\n0.8\\n1.0\\na = 1/(1 + e−z)\\nsigmoid function\\n(a)\\n−2 0 2\\nz\\n−1.0\\n−0.5\\n0.0\\n0.5\\n1.0\\na = (ez − e−z/(ez + e−z)\\ntanh function (b)\\nHình 16.5: Ví dụ về đồ thị của hàm (a)sigmoid và (b)tanh.\\nHàm kích hoạt thường là một hàm số áp dụng lêntừng phần tử của ma trận hoặc vector\\nđầu vào, nói cách khác, hàm kích hoạt thường làelement-wise3.\\n16.3.1 Hàmsgn không được sử dụng trong MLP\\nHàm sgn chỉ được sử dụng trong perceptron. Trong thực tế, hàmsgn không được sử dụng\\nvì và đạo hàm tại hầu hết các điểm bằng 0 (trừ tại điểm 0 không có đạo hàm). Việc đạo\\nhàm bằng 0 này khiến cho các thuật toán dựa trên gradient không hoạt động.\\n16.3.2 Sigmoid và tanh\\nHàm sigmoid có dạng sigmoid(z) = 1/(1 + exp(−z)) với đồ thị như trong Hình 16.5a. Nếu\\nđầu vào lớn, hàm số sẽ cho đầu ra gần với 1. Với đầu vào nhỏ (rất âm), hàm số sẽ cho đầu ra\\ngần với 0. Trước đây, hàm kích hoạt này được sử dụng nhiều vì có đạo hàm rấtđẹp. Những\\nnăm gần đây, hàm số này ít khi được sử dụng. Một hàm tương tự thường được sử dụng và\\nmang lại hiệu quả tốt hơn là hàm tanh với tanh(z) = exp(z) −exp (−z)\\nexp(z) + exp(−z) . Hàm số này có\\ntính chất đầu ra chạy từ -1 đến 1, khiến cho nó có tính chất zero-centered, thay vì chỉ dương\\nnhư hàm sigmoid. Gần đây, hàm sigmoid chỉ được sử dụng ở output layer khi yêu cầu của\\nđầu ra là các giá trị nhị phân. Một nhược điểm dễ nhận thấy là khi đầu vào có trị tuyệt\\nđối lớn (rất âm hoặc rất dương), đạo hàm của cả sigmoid và tanh sẽ rất gần với 0. Điều\\nnày đồng nghĩa với việc các hệ số tương ứng với unit đang xét sẽ gần như không được cập\\nnhật khi sử dụng công thức cập nhật gradient desent. Thêm nữa, khi khởi tạo các hệ số cho\\nmultilayer neural network với hàm kích hoạt sigmoid, chúng ta phải tránh trường hợp đầu\\nvào một hidden layer nào đó quá lớn, vì khi đó đầu ra của hidden layer đó sẽ rất gần với 0\\nhoặc 1, dẫn đến đạo hàm bằng 0 và gradient desent hoạt động không hiệu quả.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 210, 'page_label': '199'}, page_content='199 CHƯƠNG 16. MULTILAYER NEURAL NETWORK VÀ BACKPROPAGATION\\n−3 −2 −1 0 1 2 3\\nz\\n0.0\\n0.5\\n1.0\\n1.5\\n2.0\\n2.5\\n3.0\\na = max(z, 0)\\nReLU function\\n(a)\\n(b)\\nHình 16.6: Hàm ReLU và tốc độ hội tụ khi so sánh với hàm tanh.\\n16.3.3 ReLU\\nReLU (Rectified Linear Unit) được sử dụng rộng rãi gần đây vì tính đơn giản của nó. Đồ\\nthị của hàm ReLU được minh họa trên Hình 16.6a. Hàm ReLU có công thức toán học\\nf(z) = max(0 ,z) - rất đơn giản, rất lợi về mặt tính toán. Đạo hàm của nó bằng 0 tại các\\nđiểm âm, bằng 1 tại các điểm dương. ReLU được chứng minh giúp cho việc huấn luyện các\\nmultilayer neural network và deep network (rất nhiều hidden layer) nhanh hơn rất nhiều so\\nvới hàm tanh [KSH12]. Hình 16.6b so sánh sự hội tụ của hàm mất mát khi sử dụng hai hàm\\nkích hoặc ReLU và tanh. Sự tăng tốc này được cho là vì ReLU được tính toán gần như tức\\nthời và gradient của nó cũng được tính cực nhanh.\\nMặc dù cũng có nhược điểm đạo hàm bằng 0 với các giá trị đầu vào âm, ReLU được chứng\\nminh bằng thực nghiệm rằng có thể khắc phục việc này bằng việc tăng số hidden unit4.\\nReLU trở thành hàm kích hoạt đầu tiên chúng ta nên thử khi thiết kế một multilayer neural\\nnetwork. Hầu hết các network đều có hàm kích hoạt là ReLU trong các hidden unit, trừ hàm\\nkích hoạt ở output layer phụ thuộc vào đầu ra thực sự của mỗi bài toán (có thể nhận giá trị\\nâm, hoặc nhị phân, v.v.).\\nNgoài ra, các biến thể của ReLU như leaky rectified linear unit (Leaky ReLU), parametric\\nrectified linear unit (PReLU) và randomized leaky rectified linear units (RReLU) [XWCL15]\\ncũng được sử dụng và được báo cáo có kết quả tốt. Trong thực tế, trước khi thiết kế, ta\\nthường không biết chính xác hàm kích hoạt nào sẽ cho kết quả tốt nhất. Tuy nhiên, ta nên\\nbắt đầu bằng ReLU, nếu kết quả chưa khả quan thì có thể thay thế bằng các biến thể của\\nnó và so sánh kết quả.\\n3 Hàm softmax không phải là một hàmelement-wise vì nó sử dụng mọi thành phần của vector đầu vào.\\n4 Neural Networks and Deep Learning – Activation function(https://goo.gl/QGjKmU ).\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 211, 'page_label': '200'}, page_content='CHƯƠNG 16. MULTILAYER NEURAL NETWORK VÀ BACKPROPAGATION 200\\n16.4 Backpropagation\\nPhương pháp phổ biến nhất để tối ưu multilayer neural network chính là gradient descent\\n(GD). Để áp dụng GD, chúng ta cần tính được đạo hàm của hàm mất mát theo từng ma\\ntrận trọng sốW(l) và vector biasb(l).\\nGiả sửJ(W,b,X,Y) là một hàm mất mát của bài toán, trong đóW,b là tập hợp tất cả\\ncác ma trận trọng số giữa các layer và vector bias của mỗi layer.X,Y là cặp dữ liệu huấn\\nluyện với mỗi cột tương ứng với một điểm dữ liệu. Để có thể áp dụng các phương pháp\\ngradient descent, chúng ta cần tính được các∇W(l) J; ∇b(l) J, ∀l= 1,2,...,L .\\nNhắc lại quá trình feedforward\\na(0) = x (16.8)\\nz(l) = W(l)Ta(l−1) + b(l), l = 1,2,...,L (16.9)\\na(l) = f(l)(z(l)), l = 1,2,...,L (16.10)\\nˆ y= a(L) (16.11)\\nMột ví dụ của hàm mất mát là hàm mean square error (MSE):\\nJ(W,b,X,Y) = 1\\nN\\nN∑\\nn=1\\n∥yn −ˆ yn∥2\\n2 = 1\\nN\\nN∑\\nn=1\\n∥yn −a(L)\\nn ∥2\\n2 (16.12)\\nvới N là số cặp dữ liệu(x,y) trong tập huấn luyện. Theo các công thức này, việc tính toán\\ntrực tiếp các giá trị đạo hàm là cực kỳ phức tạp vì hàm mất mát không phụ thuộc trực\\ntiếp vào các ma trận hệ số và vector bias. Phương pháp phổ biến nhất được dùng có tên là\\nbackpropagation giúp tính đạo hàm ngược từ layer cuối cùng đến layer đầu tiên. Layer cuối\\ncùng được tính toán trước vì nógần gũihơn vớiđầu ra dự đoánvà hàm mất mát. Việc tính\\ntoán đạo hàm của các ma trận hệ số trong các layer trước được thực hiện dựa trên một quy\\ntắc chuỗi quen thuộc chođạo hàm của hàm hợp.\\nStochastic gradient descent có thể được sử dụng để tính gradient cho các ma trận trọng số\\nvà biases dựa trên một cặp điểm trainingx,y. Để cho đơn giản, ta coiJ là hàm mất mát\\nnếu chỉ xét cặp điểm này, ở đâyJ là hàm mất mát bất kỳ, không chỉ hàm MSE như ở trên.\\nĐạo hàm của hàm mất mát theochỉ một thành phầncủa ma trận trọng số của output layer\\n∂J\\n∂w(L)\\nij\\n= ∂J\\n∂z(L)\\nj\\n.∂z(L)\\nj\\n∂w(L)\\nij\\n= e(L)\\nj a(L−1)\\ni (16.13)\\ntrong đóe(L)\\nj = ∂J\\n∂z(L)\\nj\\nthường là một đại lượngkhông quá khó để tính toánvà ∂z(L)\\nj\\n∂w(L)\\nij\\n= a(L−1)\\ni\\nvì z(L)\\nj = w(L)T\\nj a(L−1) + b(L)\\nj . Tương tự, đạo hàm của hàm mất mát theo bias của layer cuối\\ncùng là\\n∂J\\n∂b(L)\\nj\\n= ∂J\\n∂z(L)\\nj\\n.∂z(L)\\nj\\n∂b(L)\\nj\\n= e(L)\\nj (16.14)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 212, 'page_label': '201'}, page_content='201 CHƯƠNG 16. MULTILAYER NEURAL NETWORK VÀ BACKPROPAGATION\\nz(l−1) a(l−1)\\n(l −1)th layer\\n1\\nz(l−1)\\n1 a(l−1)\\n1...\\nz(l−1)\\ni a(l−1)\\ni...\\nz(l−1)\\nd(l−1) a(l−1)\\nd(l−1)\\nW(l) ∈Rd(l−1)×d(l)\\nb(l) ∈Rd(l)×1\\nz(l)\\nj = w(l)T\\nj a(l−1) + b(l)\\nj\\nz(l) = W(l)T a(l−1) + b(l)\\na(l) = f(z(l))\\nlth layer\\nz(l) a(l)\\nz(l)\\n1 a(l)\\n1\\nz(l)\\n2 a(l)\\n2...\\nz(l)\\nj a(l)\\nj...\\nz(l)\\nd(l) a(l)\\nd(l)\\nw(l)\\nij\\nb(l)\\nj\\n(l + 1)th layer\\nz(l+1) a(l+1)\\nz(l+1)\\n1 a(l+1)\\n1\\nz(l+1)\\nk a(l+1)\\nk\\n...\\nz(l+1)\\nd(l+1) a(l+1)\\nd(l+1)\\n...\\nw(l+1)\\njk\\nHình 16.7: Mô phỏng cách tính backpropagation. Layer cuối có thể là output layer.\\nVới đạo hàm theo hệ số ở các lớpl thấp hơn, chúng ta hãy xem Hình 16.7. Ở đây, tại mỗi\\nunit, đầu vàoz và đầu raa được viết riêng để chúng ta tiện theo dõi.\\nDựa vào Hình 16.7, bằng quy nạp ngược từ cuối, ta có thể tính được\\n∂J\\n∂w(l)\\nij\\n= ∂J\\n∂z(l)\\nj\\n.∂z(l)\\nj\\n∂w(l)\\nij\\n= e(l)\\nj a(l−1)\\ni (16.15)\\nvới\\ne(l)\\nj = ∂J\\n∂z(l)\\nj\\n= ∂J\\n∂a(l)\\nj\\n.∂a(l)\\nj\\n∂z(l)\\nj\\n(16.16)\\n=\\n\\uf8eb\\n\\uf8ed\\nd(l+1)\\n∑\\nk=1\\n∂J\\n∂z(l+1)\\nk\\n.∂z(l+1)\\nk\\n∂a(l)\\nj\\n\\uf8f6\\n\\uf8f8f(l)′\\n(z(l)\\nj ) =\\n\\uf8eb\\n\\uf8ed\\nd(l+1)\\n∑\\nk=1\\ne(l+1)\\nk w(l+1)\\njk\\n\\uf8f6\\n\\uf8f8f(l)′\\n(z(l)\\nj ) (16.17)\\ntrong đóe(l+1) = [e(l+1)\\n1 ,e(l+1)\\n2 ,...,e (l+1)\\nd(l+1) ]T ∈Rd(l+1)×1 và w(l+1)\\nj: được hiểu làhàng thứ j của\\nma trậnW(l+1) (chú ý dấu hai chấm, khi không có dấu này, chúng ta mặc định dùng nó để\\nký hiệu cho vectorcột). Dấu ∑tính tổng ở dòng thứ hai trong phép tính trên xuất hiện\\nvì a(l)\\nj đóng gópvào việc tính tất cả cácz(l+1)\\nk ,k = 1,2,...,d (l+1). Biểu thức đạo hàm ngoài\\ndấu ngoặc lớn là vìa(l)\\nj = f(l)(z(l)\\nj ). Tới đây, ta có thể thấy rằng việc activation function có\\nđạo hàm đơn giản sẽ có ích rất nhiều trong việc tính toán. Với cách làm tương tự, bạn đọc\\ncó thể suy ra\\n∂J\\n∂b(l)\\nj\\n= e(l)\\nj . (16.18)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 213, 'page_label': '202'}, page_content='CHƯƠNG 16. MULTILAYER NEURAL NETWORK VÀ BACKPROPAGATION 202\\nNhận thấy rằng trong các công thức trên đây, việc tính cáce(l)\\nj đóng một vài trò quan trọng.\\nHơn nữa, để tính được giá trị này, ta cần tính được cáce(l+1)\\nj . Nói cách khác, ta cần tính\\nngược các giá trị này từ cuối. Cái tênbackpropagation cũng xuất phát từ việc này.\\nViệc tính toán các đạo hàm khi sử dụng SGD có thể tóm tắt như sau\\nThuật toán 16.1: Backpropagation tớiw(l)\\nij ,b(l)\\ni\\n1. Bước feedforward: Với 1 giá trị đầu vàox, tính giá trị đầu ra của network, trong\\nquá trình tính toán, lưu lại các giá trị activationa(l) tại mỗi layer.\\n2. Với mỗi unitj ở output layer, tính\\ne(L)\\nj = ∂J\\n∂z(L)\\nj\\n; ∂J\\n∂w(L)\\nij\\n= a(L−1)\\ni e(L)\\nj ; ∂J\\n∂b(L)\\nj\\n= e(L)\\nj (16.19)\\n3. Vớil= L−1,L −2,..., 1, tính:\\ne(l)\\nj =\\n(\\nw(l+1)\\nj: e(l+1)\\n)\\nf′(z(l)\\nj ) (16.20)\\n4. Cập nhật đạo hàm cho từng hệ số\\n∂J\\n∂w(l)\\nij\\n= a(l−1)\\ni e(l)\\nj ; ∂J\\n∂b(l)\\nj\\n= e(l)\\nj (16.21)\\nPhiên bảnvectorization của thuật toán trên có thể được thực hiện như sau.\\nThuật toán 16.2: Backpropagation tớiW(l) và vector biasb(l)\\n1. Bước feedforward: Với một giá trị đầu vàox, tính giá trị đầu ra của network, trong\\nquá trình tính toán, lưu lại các activationa(l) tại mỗi layer.\\n2. Với output layer, tính\\ne(L) = ∇z(L) J ∈Rd(L)\\n; ∇W(L) J = a(L−1)e(L)T ∈Rd(L−1)×d(L)\\n; ∇b(L) J = e(L)\\n3. Vớil= L−1,L −2,..., 1, tính:\\ne(l) =\\n(\\nW(l+1)e(l+1))\\n⊙f′(z(l)) ∈Rd(l)\\n(16.22)\\ntrong đó⊙là element-wise product hay Hadamard product tức lấy từng thành phần\\ncủa hai vector nhân với nhau để được vector kết quả.\\n4. Cập nhật đạo hàm cho các ma trận trọng số và vector bias:\\n∇W(l) J = a(l−1)e(l)T ∈Rd(l−1)×d(l)\\n; ∇b(l) J = e(l) (16.23)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 214, 'page_label': '203'}, page_content='203 CHƯƠNG 16. MULTILAYER NEURAL NETWORK VÀ BACKPROPAGATION\\nKhi làm việc với các phép tính đạo hàm phức tạp, ta luôn cần nhớ hai điều sau.\\n1. Đạo hàm của một hàm có đầu ra là một số vô hướng theo một vector hoặc ma trận là\\nmột đại lượng có cùng chiều với vector hoặc ma trận đó.\\n2. Để các phép nhân các ma trận, vector thực hiện được, ta cần đảm bảo chiều của chúng\\nphù hợp.\\nTrong công thức∇W(L) J = a(L−1)e(L)T, vế trái là một ma trận thuộcRd(L−1)×d(L)\\n, vậy vế\\nphải cũng phải là một đại lượng có chiều tương tự. Từ đó bạn đọc có thể thấy tại sao vế\\nphải phải làa(L−1)e(L)T mà không thể làa(L−1)e(L) hay e(L)a(L−1).\\n16.4.1 Backpropagation cho batch (mini-batch) gradient descent\\nNếu ta muốn thực hiện batch hoặc mini-batch GD thì thế nào? Trong thực tế, mini-batch GD\\nđược sử dụng nhiều nhất với các bài toán mà tập huấn luyện lớn. Nếu lượng dữ liệu là nhỏ,\\nbatch GD trực tiếp được sử dụng. Khi đó, cặp (input, output) sẽ ở dạng ma trận(X,Y). Giả\\nsử rằng mỗi lần tính toán, ta lấyN dữ liệu để tính toán. Khi đó,X ∈Rd(0)×N,Y ∈Rd(L)×N.\\nVới d(0) = d là chiều của dữ liệu đầu vào (không tính bias).\\nKhi đó các activation sau mỗi layer sẽ có dạngA(l) ∈Rd(l)×N. Tương tự,E(l) ∈Rd(l)×N. Và\\nta cũng có thể suy ra công thức cập nhật như sau.\\nThuật toán 16.3: Backpropagation tớiW(l) và biasb(l) (mini-batch)\\n1. Bước feedforward: Với toàn bộ dữ liệu (batch) hoặc một nhóm dữ liệu (mini-batch)\\nđầu vàoX, tính giá trị đầu ra của network, trong quá trình tính toán, lưu lại các\\nactivation A(l) tại mỗi layer. Mỗi cột củaA(l) tương ứng với một cột củaX, tức\\nmột điểm dữ liệu đầu vào.\\n2. Với output layer, tính\\nE(L) = ∇Z(L) J; ∇W(L) J = A(L−1)E(L)T; ∇b(L) J =\\nN∑\\nn=1\\ne(L)\\nn (16.24)\\n3. Vớil= L−1,L −2,..., 1, tính:\\nE(l) =\\n(\\nW(l+1)E(l+1))\\n⊙f′(Z(l)) (16.25)\\ntrong đó⊙là element-wise product hay Hadamard product tức lấy từng thành phần\\ncủa hai ma trận nhân với nhau để được ma trận kết quả.\\n4. Cập nhật đạo hàm cho ma trận trọng số và vector biases:\\n∇W(l) J = A(l−1)E(l)T; ∇b(l) J =\\nN∑\\nn=1\\ne(l)\\nn (16.26)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 215, 'page_label': '204'}, page_content='CHƯƠNG 16. MULTILAYER NEURAL NETWORK VÀ BACKPROPAGATION 204\\n(a)\\n (b)\\nHình 16.8: Dữ liệu giả trong không gian hai chiều và ví dụ về các ranh giới tốt.\\nInput layer\\nW(1)\\nHidden layer\\nW(2)\\nOutput\\nSoftmax Regression\\nHình 16.9: Multilayer neural net-\\nworkvớiinputlayercóhaiunit(bias\\nđã được ẩn), một hidden layer với\\nhàm kích hoạt ReLU (có thể có số\\nlượng hidden unit tuỳ ý), và output\\nlayer là một softmax regression với\\nba phần tử đại diện cho ba lớp dữ\\nliệu.\\n16.5 Ví dụ trên Python\\nTrong mục này, chúng ta sẽ tạo dữ liệu giả trong không gian hai chiều sao cho đường ranh\\ngiới giữa các classkhông có dạng tuyến tính. Điều này khiến cho softmax regression không\\nlàm việc được. Tuy nhiên, bằng cách thêm một hidden layer, chúng ta sẽ thấy rằng neural\\nnetwork này làm việc rất hiệu quả.\\n16.5.1 Tạo dữ liệu giả\\nCác điểm dữ liệu giả của ba lớp được tạo và minh hoạ bởi các màu khác nhau trên Hình 16.8a.\\nTa thấy rõ ràng rằng đường ranh giới giữa các lớp dữ liệu không thể là các đường thẳng.\\nHình 16.8b là một ví dụ về các đường ranh giới được coi là tốt với hầu hết các điểm dữ\\nliệu nằm đúng vào khu vực có màu nền tương ứng. Các đường biên này được tạo sử dụng\\nmultilayer neural network với một hidden layer sử dụng ReLU làm hàm kích hoạt và output\\nlayer là một softmax regression như trên Hình 16.9. Chúng ta cùng đi sâu vào xây dựng bộ\\nphân lớp dựa trên dữ liệu huấn luyện này.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 216, 'page_label': '205'}, page_content='205 CHƯƠNG 16. MULTILAYER NEURAL NETWORK VÀ BACKPROPAGATION\\nNhắc lại hàm ReLUf(z) = max(z,0), với đạo hàm\\nf′(z) =\\n{\\n0 nếu z ≤0\\n1 o.w (16.27)\\nVì lượng dữ liệu huấn luyện là nhỏ với 100 điểm cho mỗi lớp, ta có thể dùng batch GD để\\ncập nhật các ma trận hệ số và vector bias. Trước hết, ta cần tính đạo hàm của hàm mất\\nmát theo các ma trận và vector này bằng cách áp dụng backpropagation.\\n16.5.2 Tính toán Feedforward\\nGiả sử các cặp dữ liệu huấn luyện là(xi,yi) với yi là một vector ở dạng one-hot. Các điểm\\ndữ liệu này xếp cạnh nhau tạo thành các ma trận đầu vàoX và ma trận đầu raY. Bước\\nfeedforward của neural network này được thực hiện như sau.\\nZ(1) = W(1)TX + B(1) (16.28)\\nA(1) = max(Z(1),0) (16.29)\\nZ(2) = W(2)TA(1) + B(2) (16.30)\\nˆY = A(2) = softmax(Z(2)) (16.31)\\nTrong đóB(1),B(2) là các ma trận bias với tất cả các cột bằng nhau và lần lượt bằngb(1)\\nvà b(2)5. Hàm mất mát được tính dựa trên hàm cross-entropy\\nJ ≜J(W,b; X,Y) = −1\\nN\\nN∑\\ni=1\\nC∑\\nj=1\\nyji log(ˆyji) (16.32)\\n16.5.3 Tính toán Backpropagation\\nÁp dụng Thuật toán 16.3, ta có\\nE(2) = ∇Z(2) = 1\\nN(A(2) −Y) (16.33)\\n∇W(2) = A(1)E(2)T; ∇b(2) =\\nN∑\\nn=1\\ne(2)\\nn (16.34)\\nE(1) =\\n(\\nW(2)E(2))\\n⊙f′(Z(1)) (16.35)\\n∇W(1) = A(0)E(1)T = XE(1)T; ∇b(1) =\\nN∑\\nn=1\\ne(1)\\nn (16.36)\\nCác công thức toán học phức tạp này sẽ được lập trình một cách đơn giản hơn trên numpy.\\n5 Ta cần xếp các vector bias giống nhau để tạo thành các ma trận bias vì trong toán học, không có định nghĩa tổng\\ncủa một ma trận và một vector. Khi lập trình, việc này là khả thi.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 217, 'page_label': '206'}, page_content='CHƯƠNG 16. MULTILAYER NEURAL NETWORK VÀ BACKPROPAGATION 206\\n16.5.4 Triển khai thuật toán trên numpy\\nTrước hết, ta viết lại hàm softmax và cross-entropy. Sau đó viết các hàm khởi tạo và dự\\nđoán nhãn của các điểm dữ liệu.\\ndef softmax_stable(Z):\\n\"\"\"\\nCompute softmax values for each sets of scores in Z.\\neach ROW of Z is a set of scores.\\n\"\"\"\\ne_Z = np.exp(Z - np.max(Z, axis = 1, keepdims = True))\\nA = e_Z / e_Z.sum(axis = 1, keepdims = True)\\nreturn A\\ndef crossentropy_loss(Yhat, y):\\n\"\"\"\\nYhat: a numpy array of shape (Npoints, nClasses) -- predicted output\\ny: a numpy array of shape (Npoints) -- ground truth.\\nNOTE: We don’t need to use the one-hot vector here since most of elements\\nare zeros. When programming in numpy, in each row of Yhat, we need to access\\nto the corresponding index only.\\n\"\"\"\\nid0 = range(Yhat.shape[0])\\nreturn -np.mean(np.log(Yhat[id0, y]))\\ndef mlp_init(d0, d1, d2):\\n\"\"\"\\nInitialize W1, b1, W2, b2\\nd0: dimension of input data\\nd1: number of hidden unit\\nd2: number of output unit = number of classes\\n\"\"\"\\nW1 = 0.01*np.random.randn(d0, d1)\\nb1 = np.zeros(d1)\\nW2 = 0.01*np.random.randn(d1, d2)\\nb2 = np.zeros(d2)\\nreturn (W1, b1, W2, b2)\\ndef mlp_predict(X, W1, b1, W2, b2):\\n\"\"\"\\nSuppose that the network has been trained, predict class of new points.\\nX: data matrix, each ROW is one data point.\\nW1, b1, W2, b2: learned weight matrices and biases\\n\"\"\"\\nZ1 = X.dot(W1) + b1 # shape (N, d1)\\nA1 = np.maximum(Z1, 0) # shape (N, d1)\\nZ2 = A1.dot(W2) + b2 # shape (N, d2)\\nreturn np.argmax(Z2, axis=1)\\nTiếp theo là hàm chính huấn luyện softmax regression.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 218, 'page_label': '207'}, page_content='207 CHƯƠNG 16. MULTILAYER NEURAL NETWORK VÀ BACKPROPAGATION\\ndef mlp_fit(X, y, W1, b1, W2, b2, eta):\\nloss_hist = []\\nfor i in xrange(20000): # number of epoches\\n# feedforward\\nZ1 = X.dot(W1) + b1 # shape (N, d1)\\nA1 = np.maximum(Z1, 0) # shape (N, d1)\\nZ2 = A1.dot(W2) + b2 # shape (N, d2)\\nYhat = softmax_stable(Z2) # shape (N, d2)\\nif i %1000 == 0: # print loss after each 1000 iterations\\nloss = crossentropy_loss(Yhat, y)\\nprint(\"iter %d, loss: %f\" %(i, loss))\\nloss_hist.append(loss)\\n# back propagation\\nid0 = range(Yhat.shape[0])\\nYhat[id0, y] -=1\\nE2 = Yhat/N # shape (N, d2)\\ndW2 = np.dot(A1.T, E2) # shape (d1, d2)\\ndb2 = np.sum(E2, axis = 0) # shape (d2,)\\nE1 = np.dot(E2, W2.T) # shape (N, d1)\\nE1[Z1 <= 0] = 0 # gradient of ReLU, shape (N, d1)\\ndW1 = np.dot(X.T, E1) # shape (d0, d1)\\ndb1 = np.sum(E1, axis = 0) # shape (d1,)\\n# Gradient Descent update\\nW1 += -eta*dW1\\nb1 += -eta*db1\\nW2 += -eta*dW2\\nb2 += -eta*db2\\nreturn (W1, b1, W2, b2, loss_hist)\\nSau khi đã hoàn thành các hàm chính của multilayer neural network này, chúng ta đưa dữ\\nliệu vào, xác định số hidden unit, và huấn luyện network.\\n# suppose X, y are training input and output, respectively\\nd0 = 2 # data dimension\\nd1 = h = 100 # number of hidden units\\nd2 = C = 3 # number of classes\\neta = 1 # learning rate\\n(W1, b1, W2, b2) = mlp_init(d0, d1, d2)\\n(W1, b1, W2, b2, loss_hist) =mlp_fit(X, y, W1, b1, W2, b2, eta)\\ny_pred = mlp_predict(X, W1, b1, W2, b2)\\nacc = 100*np.mean(y_pred == y)\\nprint(’training accuracy: %.2f %%’ % acc)\\nKết quả:\\niter 0, loss: 1.098628\\niter 2000, loss: 0.030014\\niter 4000, loss: 0.021071\\niter 6000, loss: 0.018158\\niter 8000, loss: 0.016914\\ntraining accuracy: 99.33 %\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 219, 'page_label': '208'}, page_content='CHƯƠNG 16. MULTILAYER NEURAL NETWORK VÀ BACKPROPAGATION 208\\n#hidden units = 2, accuracy =65.0%\\n(a)\\n#hidden units = 5, accuracy =85.6666666667% (b)\\n#hidden units = 15, accuracy = 99.00\\n(c)\\n#hidden units = 30, accuracy = 99.33 (d)\\nHình 16.10: Kết quả với số lượng units trong hidden layer là khác nhau.\\nTa có thể thấy rằng hàm mất mát giảm dần và hội tụ. Kết quả phân lớp trên tập huấn luyện\\nrất tốt, chỉ một vài điểm bị phân lớp lỗi, nhiều khả năng chúng nằm ở khu vực trung tâm.\\nVới chỉ một hidden layer, network đã thực hiện công việc gần như hoàn hảo.\\nBằng cách thay đổi số lượng hidden unit (biếnd1) và huấn luyện lại các network, minh hoạ\\nranh giới giữa các lớp dữ liệu, chúng ta thu được các kết quả như trên Hình 16.10. Khi chỉ\\ncó hai hidden unit, các đường ranh giới vẫn gần như đường thẳng, kết quả là có tới 35% số\\nđiểm dữ liệu trong tập huấn luyện bị phân lớp lỗi. Khi số lượng hidden unit là 5, độ chính\\nxác được cải thiện thêm khoảng 20%, tuy nhiên, các đường ranh giới vẫn chưa thực sự tốt.\\nThậm chí lớp đỏ và lam còn bị chia cắt một cách không tự nhiên. Nếu tiếp tục tăng số lượng\\nhidden unit, ta thấy rằng các đường ranh giới tương đối hoàn hảo.\\nCó thể chứng minh được rằng với một hàm số liên tục bất kỳf(x) và một sốε >0, luôn\\nluôn tồn tại một neural network với đầu ra có dạngg(x) với một hidden layer (với số hidden\\nunit đủ lớn và hàm kích hoạt phi tuyến phù hợp) sao cho với mọix,|f(x) −g(x)|< ε. Nói\\ncách khác, neural network có khả năng xấp xỉ bất kỳ hàm liên tục nào [Cyb89].\\nTrên thực tế, việc tìm ra số lượng hidden unit và hàm kích hoạt nói trên hầu như bất khả\\nthi. Thay vào đó, thực nghiệm chứng minh rằng neural network với nhiều hidden layer kết\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 220, 'page_label': '209'}, page_content='209 CHƯƠNG 16. MULTILAYER NEURAL NETWORK VÀ BACKPROPAGATION\\nhợp với các hàm kích hoạt đơn giản, ví dụ ReLU, có khả năng xấp xỉ dữ liệu tốt hơn tốt\\nhơn. Tuy nhiên, khi số lượng hidden layer lớn lên, số lượng hệ số cần tối ưu cũng lớn lên và\\nmô hình sẽ trở nên phức tạp. Sự phức tạp này ảnh hưởng tới hai khía cạnh. Thứ nhất, tốc\\nđộ tính toán sẽ bị chậm đi rất nhiều. Thứ hai, nếu mô hình quá phức tạp, nó có thể biểu\\ndiễn rất tốt dữ liệu huấn luyện, nhưng có thể không biểu diễn tốt dữ liệu kiểm thử. Đây\\nchính là hiện tượng overfitting.\\nVậy có các kỹ thuật nào giúp tránh overfitting cho multilayer neural network? Ngoài kỹ\\nthuật toán cross-validation, chúng ta quan tâm hơn tới các phương pháp regularization. Các\\nneural network với regularization được gọi làregularized neural network. Kỹ thuật phổ biến\\nnhất được dùng để tránh overfitting làweight decay.\\n16.6 Tránh overfitting cho neural network bằng weight decay\\nVới weight decay, hàm mất mát sẽ được cộng thêm một đại lượng regularization có dạng\\nλR(W) = λ\\nL∑\\nl=1\\n∥W(l)∥2\\nF\\ntức tổng bình phương Frobenius norm của tất cả các ma trận hệ số. Chú ý rằng khi làm việc\\nvới multilayer neural network, bias hiếm khi đượcregularized. Đây cũng là lý do vì sao ta\\nnên tách rời ma trận hệ số và vector bias khi làm việc với multilayer neural network. Việc\\ntối thiểu hàm mất mát mới (với số hạng regularization) sẽ khiến cho các thành phần của\\ncác vector hệ sốW(l) không quá lớn, thậm chí nhiều thành phần sẽ gần với không. Điều này\\nkhiến cho việc có nhiều hidden unit vẫn an toàn vì nhiều trong số chúng gần với không.\\nTiếp theo, chúng ta sẽ làm một ví dụ nữa trong không gian hai chiều. Lần này, chúng ta sẽ\\nsử dụng thư viện scikit-learn.\\nfrom __future__ import print_function\\nimport numpy as np\\nfrom sklearn.neural_network import MLPClassifier\\nmeans = [[-1, -1], [1, -1], [0, 1]]\\ncov = [[1, 0], [0, 1]]\\nN = 20\\nX0 = np.random.multivariate_normal(means[0], cov, N)\\nX1 = np.random.multivariate_normal(means[1], cov, N)\\nX2 = np.random.multivariate_normal(means[2], cov, N)\\nX = np.concatenate((X0, X1, X2), axis = 0)\\ny = np.asarray([0]*N + [1]*N + [2]*N)\\nalpha = 1e-1 # regularization parameter\\nclf = MLPClassifier(solver=’lbfgs’, alpha=alpha, hidden_layer_sizes=(100))\\nclf.fit(X, y)\\ny_pred = clf.predict(X)\\nacc = 100*np.mean(y_pred == y)\\nprint(’training accuracy: %.2f %%’ % acc)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 221, 'page_label': '210'}, page_content='CHƯƠNG 16. MULTILAYER NEURAL NETWORK VÀ BACKPROPAGATION 210\\n#alpha = 0.01, accuracy =100.0%\\n(a)\\n#alpha = 0.1, accuracy =100.0% (b)\\n#alpha = 1.0, accuracy =80.0%\\n(c)\\n#alpha = 10.0, accuracy =80.0% (d)\\nHình 16.11: Kết quả với số lượng units trong hidden layer là khác nhau.\\nKết quả:\\ntraining accuracy: 100.00 %\\nTrong đoạn code trên, thuộc tínhalpha chính là tham số regularizationλ. alpha càng lớn sẽ\\nkhiến các thành phần trong các ma trận hệ số càng nhỏ. Thuộc tínhhidden_layer_sizes chính\\nlà số lượng hidden unit trong mỗi hidden layer. Nếu có nhiều hidden layer, chẳng hạn hai\\nvới số lượng hidden unit lần lượt là 10 và 100, ta cần khai báohidden_layer_sizes=(10, 100).\\nHình 16.11 minh hoạ ranh giới giữa các lớp tìm được với các giá trịalpha khác nhau, tức mức\\nđộ regularization khác nhau. Khialpha nhỏ cỡ 0.01, các ranh giới tìm được trông không được\\ntự nhiên và vùng xác định lớp màu lục không được liên tục. Mặc dù độ chính xác trên tập\\nhuấn luyện này là 100%, ta có thể quan sát thấy rằng overfitting đã xảy ra. Vớialpha = 0.1,\\nkết quả cho thấylãnh thổ của các lớp đã liên tục, nhưng overfitting vẫn xảy ra. Khialpha\\ncao hơn, độ chính xác đã giảm xuống nhưng các đường ranh giới tự nhiên hơn. Bạn đọc có\\nthể thay đổi các giá trịalpha trong source code (https://goo.gl/czxrSf ) và quan sát các hiện\\ntượng xảy ra. Đặc biệt, khialpha = 100, độ chính xác còn 33.33%. Tại sao lại như vậy? Hy\\nvọng bạn đọc có thể tự trả lời được.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 222, 'page_label': '211'}, page_content='211 CHƯƠNG 16. MULTILAYER NEURAL NETWORK VÀ BACKPROPAGATION\\n16.7 Đọc thêm\\n1. Neural Networks: Setting up the Architecture,AndrejKarpathy( https://goo.gl/rfzCVK ).\\n2. Neural Networks, Case study, Andrej Karpathy (https://goo.gl/3ihCxL ).\\n3. Lecture Notes on Sparse Autoencoders, Andrew Ng (https://goo.gl/yTgtLe ).\\n4. Yes you should understand backprop(https://goo.gl/8B3h1b ).\\n5. Backpropagation, Intuitions, Andrej Karpathy (https://goo.gl/fjHzNV ).\\n6. How the backpropagation algorithm works, Michael Nielsen (https://goo.gl/mwz2kU ).\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 223, 'page_label': '212'}, page_content=''),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 224, 'page_label': '213'}, page_content='Phần V\\nRecommendation systems–Hệ thống khuyến nghị\\nCác bạn có lẽ đã gặp những hiện tượng sau đây nhiều lần. Youtube tự động chạy các clip\\nliên quan đến clip bạn đang xem, hoặc tự động gợi ý những clip mà có thể bạn sẽ thích. Khi\\nbạn mua một món hàng trên Amazon, hệ thống sẽ tự động gợi ý những sản phẩmfrequently\\nbought together, hoặc nó biết bạn có thể thích món hàng nào dựa trên lịch sử mua hàng của\\nbạn. Facebook hiển thị quảng cáo những sản phẩm có liên quan đến từ khoá bạn vừa tìm\\nkiếm trên Google. Facebook gợi ý kết bạn. Netflix tự động gợi ý phim cho người dùng. Và\\ncòn rất nhiều ví dụ khác mà hệ thống có khả năng tự động gợi ý cho ngừời dùng những\\nsản phẩm họcó thể thích. Bằng cáchquảng cáo hướng đúng đối tượngđó, hiệu quả của việc\\nmarketing cũng sẽ tăng lên.\\nNhững thuật toán đằng sau những ứng dụng này là những thuật toán machine learning có\\ntên gọi chung làhệ thống khuyến nghị(recommender systemhoặc recommendation system).\\nTrong phần này của cuốn sách, chúng ta sẽ cùng tìm hiểu ba thuật toán cơ bản nhất trong\\nrất nhiều các thuật toánrecommendation system.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 225, 'page_label': '214'}, page_content='Chương 17\\nContent-based recommendation\\nsystem\\n17.1 Giới thiệu\\nRecommendation system là một mảng khá rộng của machine learning, và cótuổi đời ít hơn\\nso với classification hay regression vì internet mới chỉ thực sự bùng nổ khoảng 10-15 năm gần\\nđây. Có hai thực thể chính trong một recommendation system làuser vàitem. User là người\\ndùng; item là sản phẩm, ví dụ như các bộ phim, bài hát, cuốn sách, clip, hoặc cũng có thể\\nlà các người dùng khác trong bài toán gợi ý kết bạn. Mục đích chính của các recommender\\nsystem là dự đoánmức độ quan tâmcủa một người dùng tới một sản phẩm nào đó, qua đó\\ncó chiến lượcrecommendation phù hợp.\\n17.1.1 Hiện tượnglong tail trong thương mại\\nChúng ta cùng đi vào việc so sánh điểm khác nhau căn bản giữa cáccửa hàng thựcvà các\\ncửa hàng điện tử, xét trên khía cạnh lựa chọn sản phẩm để quảng bá. Ở đây, chúng ta tạm\\nquên đi khía cạnhcó cảm giác thật chạm vào sản phẩmcủa các cửa hàng thực. Hãy cùng\\ntập trung vào phần làm thế nào để quảng bá đúng sản phẩm tới đúng khách hàng.\\nCó thể các bạn đã biết tớiNguyên lý Pareto (hay quy tắc 20/80)(https://goo.gl/NujWjH ):\\nphần lớn kết quả được gây ra bởi phẩn nhỏ nguyên nhân. Phần lớn số từ sử dụng hàng ngày\\nchỉ là một phần nhỏ số từ trong bộ từ điển. Phần lớn của cải được sở hữu bởi phần nhỏ số\\nngười. Khi làm thương mại cũng vậy, những sản phẩm bán chạy nhất chỉ chiếm phần nhỏ\\ntổng số sản phẩm.\\nCác cửa hàng thựcthường có hai khu vực, một là khu trưng bày, hai là kho. Nguyên tắc dễ\\nthấy để đạt doanh thu cao là trưng ra các sản phẩm phổ biến nhất ở những nơi dễ nhìn thấy\\nvà cất những sản phẩm ít phổ biến trong kho. Cách làm này có một hạn chế rõ rệt: những\\nsản phẩm được trưng ra mang tính phổ biến chứ chưa chắc đã phù hợp với một khách hàng'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 226, 'page_label': '215'}, page_content='215 CHƯƠNG 17. CONTENT-BASED RECOMMENDATION SYSTEM\\ncụ thể. Một cửa hàng có thể có món hàng một khách hàng tìm kiếm nhưng có thể không\\nbán được vì khách hàng không nhìn thấy sản phẩm đó trên giá; việc này dẫn đến việc khách\\nhàng không tiếp cận được sản phẩm ngay cả khi chúng đã được trưng ra. Ngoài ra, vì không\\ngian có hạn, cửa hàng không thể trưng ra tất cả các sản phẩm mà mỗi loại chỉ đưa ra một\\nsố lượng nhỏ. Ở đây, phần lớn doanh thu (80%) đến từ phần nhỏ số sản phẩm phổ biến nhất\\n(20%). Nếu sắp xếp các sản phẩm của cửa hàng theo doanh số từ cao đến thấp, ta sẽ nhận\\nthấy có thể phần nhỏ các sản phẩm tạo ra phần lớn doanh số; và một danh sách dài phía sau\\nchỉ tạo ra một lượng đóng góp nhỏ. Hiện tượng này còn được gọi làlong tail phenomenon,\\ntức phầnđuôi dài của những sản phẩm ít phổ biến.\\nVới cáccửa hàng điện tử, nhược điểm trên hoàn toàn có thể tránh được. Vìgian trưng bày\\ncủa cáccửa hàng điện tửgần như là vô tận, mọi sản phẩm đều có thể được trưng ra. Hơn\\nnữa, việc sắp xếp online là linh hoạt, tiện lợi với chi phí chuyển đổi gần như bằng 0 khiến\\nviệc mang đúng sản phẩm tới khách hàng trở nên thuận tiện hơn. Doanh thu, vì thế có thể\\nđược tăng lên.\\n17.1.2 Hai nhóm chính của recommendation system\\nCác recommendation system thường được chia thành hai nhóm lớn:\\n1. Content-based system: khuyến nghị dựa trên đặc tính của sản phẩm. Ví dụ, một người\\ndùng xem rất nhiều các bộ phim về cảnh sát hình sự, vậy thì gơi ý một bộ phim trong\\ncơ sở dữ liệu có chung đặc tínhhình sự tới người dùng này, ví dụ phimNgười phán xử.\\nCách tiếp cận này yêu cầu việc sắp xếp các sản phẩm vào từng nhóm hoặc đi tìm các\\nđặc trưng của từng sản phẩm. Tuy nhiên, có những sản phẩm không có nhóm cụ thể và\\nviệc xác định nhóm hoặc đặc trưng của từng sản phẩm đôi khi là bất khả thi.\\n2. Collaborative filtering: hệ thống khuyến nghị các sản phẩm dựa trên sự tương quan\\n(similarity) giữa các người dùng và/hoặc sản phẩm. Có thể hiểu rằng ở nhóm này một\\nsản phẩm đượckhuyến nghị tới một người dùng dựa trên những người dùng cóhành vi\\ntương tự. Ví dụ, ba người dùngA, B, C đều thích các bài hát của Noo Phước Thịnh.\\nNgoài ra, hệ thống biết rằng người dùngB, C cũng thích các bài hát của Bích Phương\\nnhưng chưa có thông tin về việc liệu người dùngA có thích Bích Phương hay không. Dựa\\ntrên thông tin của những người dùng tương tự làB và C, hệ thống có thể dự đoán rằng\\nA cũng thích Bích Phương và gợi ý các bài hát của ca sĩ này tớiA.\\nTrong chương này, chúng ta sẽ làm quen với nhóm thứ nhất,content-based system. Nhóm\\nthứ hai,collaborative filtering, sẽ được thảo luận trong các chương còn lại của chương.\\n17.2 Utility matrix\\nNhư đã đề cập, có hai thực thể chính trong các recommendation system làuser vàitem. Mỗi\\nuser sẽ cómức độ quan tâm(degree of preference) tới từngitem khác nhau. Mức độ quan\\ntâm này,nếu đã biết trước, được gán cho một giá trị ứng với mỗi cặpuser-item. Thông tin\\nvề mức độ quan tâm của mộtuser tới một item có thể được thu thập thông qua một hệ\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 227, 'page_label': '216'}, page_content='CHƯƠNG 17. CONTENT-BASED RECOMMENDATION SYSTEM 216\\nA\\n5\\n5\\n?\\n1\\n1\\nB\\n5\\n?\\n4\\n1\\n0\\nC\\n0\\n?\\n1\\n4\\n5\\nD\\n0\\n0\\n?\\n4\\n?\\nE\\n1\\n?\\n?\\n4\\n?\\nF\\n?\\n?\\n1\\n?\\n?\\nMưa nửa đêm\\nCỏ úa\\nVùng lá me bay\\nCon cò bé bé\\nEm yêu trường em\\nHình 17.1: Ví dụ về utility matrix\\nvới hệ thống khuyến nghị bài hát.\\nCác bài hát (item) được người dùng\\n(user) đánh giá theo mức độ từ 0\\nđến 5 sao. Các dấu ’?’ nền màu\\nxám ứng với việc dữ liệu chưa tồn\\ntại trong cơ sở dữ liệu. Recommen-\\ndation system cần phảitự điềncác\\ngiá trị này.\\nthống đánh giá (review và rating); hoặc có thể dựa trên việcuser đã click vào thông tin của\\nitem trên website; hoặc có thể dựa trên việc thời gian và số lần mộtuser xem thông tin của\\nmột item. Các ví dụ trong phần này đều dựa trên hệ thốngrating.\\n17.2.1 Ví dụ về utility matrix\\nVới một hệ thốngrating, mức độ quan tâmcủa mộtuser tới mộtitem được đo bằng giá trị\\nuser đó đã đánh giá choitem đó, chẳng hạn số sao trên tổng cộng năm sao. Tập hợp tất cả\\ncác rating, bao gồm cả những giá trị chưa biết cần được dự đoán, tạo nên một ma trận gọi\\nlà ma trậnutility. Xét ví dụ như trong Hình 17.1. Trong ví dụ này, có sáuuser A, B, C, D,\\nE, F và năm bài hát. Các ô màu xanh thể hiện việc mộtuser đã đánh giá một bài hát với\\nrating từ 0 (không thích) đến 5 (rất thích). Các ô có dấu ’?’ màu xám tương ứng với các ô\\nchưa có dữ liệu. Công việc của một recommendation system là dự đoán giá trị tại các ô màu\\nxám này, từ đó đưa ra gợi ý chouser. Vì vậy, bài toán recommendation system đôi khi được\\ncoi là bài toánhoàn thiện ma trận(matrix completion).\\nTrong ví dụ đơn giản này, dễ nhận thấy có hai thể loại nhạc khác nhau: ba bài đầu là nhạc\\nbolero và hai bài sau là nhạcthiếu nhi. Từ dữ liệu này, ta cũng có thể đoán được rằngA, B\\nthích thể loại nhạcBolero; trong khiC, D, E, Fthích thể loại nhạcThiếu nhi. Từ đó, một\\nhệ thống tốt nên gợi ýCỏ úa cho B; Vùng lá me baycho A; Em yêu trường emcho D, E,\\nF. Giả sử chỉ có hai thể loại nhạc này, khi có một bài hát mới, ta chỉ cần phân lớp nó vào\\nthể loại nào, từ đó đưa ra gợi ý với từnguser.\\nThông thường, có rất nhiềuuser và item trong hệ thống, và mỗiuser thường chỉrate một\\nsố lượng rất nhỏ cácitem, thậm chí có nhữnguser không rateitem nào. Vì vậy, lượng ô màu\\nxám của ma trận utility thường là rất lớn, và lượng các ô đã được điền là một số rất nhỏ.\\nRõ ràng rằng càng nhiều ô được điền thì độ chính xác của hệ thống sẽ càng được cải thiện.\\nVì vậy, các hệ thống luôn khuyến khíchuser bày tỏ sự quan tâm của họ tới cácitem thông\\nqua việc đánh giá cácitem đó. Việc đánh giá cácitem, vì thế, không những giúp cácuser\\nkhác biết được chất lượng củaitem đó mà còn giúp hệ thốngbiết được sở thích củauser,\\nqua đó có chính sách quảng cáo hợp lý.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 228, 'page_label': '217'}, page_content='217 CHƯƠNG 17. CONTENT-BASED RECOMMENDATION SYSTEM\\n17.2.2 Xây dựng ma trận utility\\nKhông có ma trận utility, hệ thống gần như không thể gợi ý đượcitem tới user, ngoài cách\\nluôn luôn gợi ý cácitem phổ biến nhất. Vì vậy, trong các recommender system, việc xây\\ndựng ma trận utility là tối quan trọng. Tuy nhiên, việc xây dựng ma trận này thường có\\ngặp nhiều khó khăn. Có hai hướng tiếp cận phổ biến để xác định giá trịrating cho mỗi cặp\\nuser-item trong utility matrix:\\n1. Nhờ user đánh giáitem. Amazon luônnhờ user đánh giá cácitem của họ bằng cách gửi\\ncác email nhắc nhở nhiều lần. Tuy nhiên, cách tiếp cận này cũng có một vài hạn chế, vì\\nthường thìuser ít khi đánh giá sản phẩm. Và nếu có, đó có thể là những đánh giá thiên\\nlệch bởi những người sẵn sàng đáng giá.\\n2. Hướng tiếp cận thứ hai là dựa trên hành vi củauser. Nếu mộtuser mua mộtitem trên\\nAmazon, xem một clip trên Youtube (có thể là nhiều lần), hay đọc một bài báo, có thể\\nkhẳng định user đó có xu hướng thích item đó. Facebook cũng dựa trên việc bạnlike\\nnhững nội dung nào để hiển thị trênnewsfeed của bạn những nội dung liên quan. Bạn\\ncàng đam mê Facebook, Facebook càng được hưởng lợi, thế nên nó luôn mang tới bạn\\nnhững thông tin mà khả năng cao là bạnmuốn đọc. Thường thì với cách này, ta chỉ xây\\ndựng được một ma trận với các thành phần là1 và 0, với1 thể hiệnuser thích item, 0\\nthể hiện chưa có thông tin. Trong trường hợp này,0 không có nghĩa là thấp hơn1, nó\\nchỉ có nghĩa làuser chưa cung cấp thông tin. Chúng ta cũng có thể xây dựng ma trận\\nvới các giá trị cao hơn 1 thông qua thời gian hoặc số lượt màuser xem mộtitem nào đó.\\nNgoài ra, đôi khi nútdislike cũng mang lại những lợi ích nhất định cho hệ thống, lúc này\\ncó thể gán giá trị tương ứng bằng−1.\\n17.3 Content-based recommendation\\n17.3.1 Xây dựngitem profile\\nTrong các hệ thốngcontent-based, tức dựa trênnội dung của mỗi item, chúng ta cần xây\\ndựng một bộ hộ sơ(profile) cho mỗiitem. Profile này được biểu diễn dưới dạng toán học\\nlà một vector đặc trưng. Trong những trường hợp đơn giản, vector này được trực tiếp trích\\nxuất từitem. Ví dụ, xem xét các thông tin của một bài hát mà có thể được sử dụng trong\\ncác recommendation system:\\n1. Ca sĩ. Cùng là bàiThành phố buồnnhưng có người thích bản của Đan Nguyên, có người\\nlại thích bản của Đàm Vĩnh Hưng.\\n2. Nhạc sĩ sáng tác. Cùng là nhạc trẻ nhưng có người thích Phan Mạnh Quỳnh, người khác\\nlại thích MTP.\\n3. Năm sáng tác. Một số người thích nhạc xưa cũ hơn nhạc hiện đại.\\n4. Thể loại. Quan họ và Bolero sẽ có thể thu hút những nhóm người khác nhau.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 229, 'page_label': '218'}, page_content='CHƯƠNG 17. CONTENT-BASED RECOMMENDATION SYSTEM 218\\nA\\n5\\n5\\n?\\n1\\n1\\nB\\n5\\n?\\n4\\n1\\n0\\nC\\n0\\n?\\n1\\n4\\n5\\nD\\n0\\n0\\n?\\n4\\n?\\nE\\n1\\n?\\n?\\n4\\n?\\nF\\n?\\n?\\n1\\n?\\n?\\nitem’s feature vectors\\nx1 = [0.99,0.02]T\\nx2 = [0.91,0.11]T\\nx3 = [0.95,0.05]T\\nx4 = [0.01,0.99]T\\nx5 = [0.03,0.98]T\\n←need to optimizeθ1 θ2 θ3 θ4 θ5 θ6\\nMưa nửa đêm\\nCỏ úa\\nVùng lá me bay\\nCon cò bé bé\\nEm yêu trường em\\nUser’s models\\nHình 17.2:Giả sử feature vector cho mỗi sản phẩm được cho trong cột cuối cùng. Với mỗi người\\ndùng, chúng ta cần tìm một mô hìnhθi tương ứng sao cho mô hình thu được là tốt nhất.\\nCó rất nhiều đặc trưng khác của một bài hát có thể được sử dụng. Ngoại trừThể loại khó\\nđịnh nghĩa, các yếu tố khác đều có thể được xác định rõ ràng.\\nTrong ví dụ ở Hình 17.1, chúng ta đơn giản hoá bài toán bằng việc xây dựng một vector đặc\\ntrưng hai chiều cho mỗi bài hát: chiều thứ nhất là mức độBolero, chiều thứ hai là mức độ\\nThiếu nhi của bài đó. Gọi các vector đặc trưng cho mỗi bài hát làx1,x2,x3,x4,x5. Giả sử\\ncác vector đặc trưng (ở dạng cột) cho mỗi bài hát được cho trong Hình 17.2. Ở đây, chúng\\nta tạm coi các vector này đã được xác định bằng một cách nào đó.\\nTương tự như thế, hành vi của mỗiuser cũng có thể được mô hình hoá dưới dạng tập các\\ntham sốθ. Dữ liệu huấn luyện để xây dựng mỗi mô hìnhθu là các cặp (item profile, rating)\\ntương ứng với cácitem mà user đó đã đánh giá. Việc điền các giá trị còn thiếu trong ma\\ntrận utility chính là việc dự đoán mức độ quan tâm khi áp dụng mô hìnhθu lên chúng.\\nĐầu ra này có thể được viết dưới dạng một hàmf(θu,xi). Việc lựa chọn dạng củaf(θu,xi)\\ntuỳ thuộc vào mỗi bài toán. Trong chương này, chúng ta sẽ quan tâm tới dạng đơn giản\\nnhất–dạng tuyến tính.\\n17.3.2 Xây dựng hàm mất mát\\nGiả sử rằng số lượnguser là N, số lượngitem là M. Ma trậnprofile X = [x1,x2,..., xM] ∈\\nRd×M, và ma trận utility làY ∈RM×N. Thành phần ở hàng thứm, cột thứncủa Y là mức\\nđộ quan tâm(ở đây là số sao đãrate) củauser thứ n lên item thứ m mà hệ thống đã thu\\nthập được. Ma trậnY bị khuyết rất nhiều thành phần tương ứng với các giá trị mà hệ thống\\ncần dự đoán. Thêm nữa, gọiR là ma trậnrated or notthể hiện việc mộtuser đã đánh giá\\nmột item hay chưa. Cụ thể,rmn bằng 1 nếuitem thứ m đã được đánh giá bởiuser thứ n,\\nbằng 0 trong trường hợp ngược lại.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 230, 'page_label': '219'}, page_content='219 CHƯƠNG 17. CONTENT-BASED RECOMMENDATION SYSTEM\\nMô hình tuyến tính\\nGiả sử rằng ta có thể tìm được một mô hình cho mỗiuser, được minh hoạ bởi một vector\\ncột hệ sốwn ∈Rd và biasbn sao chomức độ quan tâmcủa mộtuser tới mộtitem có thể\\ntính được bằng một hàm tuyến tính:\\nymn = wT\\nnxm + bn (17.1)\\nXét mộtuser thứ n bất kỳ, nếu ta coi tập huấn luyện là tập hợp các thành phần đã được\\nđiền của yn (cột thứ n của ma trậnY), ta có thể xây dựng hàm mất mát tương tự như\\nridge regression(linear regression vớil2 regularization) như sau:\\nLn(wn,bn) = 1\\n2sn\\n∑\\nm:rmn=1\\n(wT\\nnxm + bn −ymn)2 + λ\\n2sn\\n∥wn∥2\\n2 (17.2)\\ntrong đó, thành phần thứ hai là regularization vàλ là một tham số dương;sn là số lượng\\ncác item mà user thứ nđã đánh giá, là tổng các phần tử trên cột thứncủa ma trậnR, tức\\nsn = ∑M\\nm=1 rmn. Chú ý rằng regularization thường không được áp dụng lên biasbn.\\nVì biểu thức hàm mất mát (17.2) chỉ phụ thuộc vào cácitem đã được đánh giá, ta có thể\\nrút gọn nó bằng cách đặtˆyn ∈Rsn là vector con của yn, được xây dựng bằng cách trích\\ncác thành phần khác dấu ‘?’ ở cột thứn của Y. Đồng thời, đặtˆXn ∈Rd×sn là ma trận con\\ncủa ma trận đặc trưngX, được tạo bằng cách trích các cột tương ứng với cácitem đã được\\nđánh giá bởiuser thứ n. (Xem ví dụ phía dưới để hiểu rõ hơn). Khi đó, biểu thức hàm mất\\nmát của mô hình chouser thứ n được viết gọn thành:\\nLn(wn,bn) = 1\\n2sn\\n∥ˆXT\\nnwn + bnen −ˆyn∥2\\n2 + λ\\n2sn\\n∥wn∥2\\n2 (17.3)\\ntrong đó, en là vector cột với tất cả các thành phần là 1. Đây chính xác là hàm mất\\nmát của ridge regression. Cặp nghiệmwn,bn có thể được tìm thông qua các thuật toán\\ngradient descent. Trong chương này, chúng ta sẽ trực tiếp sử dụng classRidge trong sklearn\\n.linear_model. Có một điểm đáng lưu ý ở đây làwn chỉ được xác định nếuuser thứ n đã\\nđánh giá ít nhất một sản phẩm.\\nChúng ta cùng theo dõi ví dụ nhỏ sau đây.\\n17.3.3 Ví dụ về hàm mất mát cho user E\\nQuay trở lại với ví dụ trong Hình 17.2, ma trận đặc trưng cho cácitem (mỗi cột tương ứng\\nvới mộtitem) là\\nX =\\n[0.99 0 .91 0 .95 0 .01 0 .03\\n0.02 0 .11 0 .05 0 .99 0 .98\\n]\\n(17.4)\\nXét trường hợp củauser E với n= 5, y5 = [1,?,?,4,?]T ⇒r5 = [1,0,0,1,0]T. VìE mới chỉ\\nđánh giáitem thứ nhất và thứ tư nêns5 = 2. Hơn nữa,\\nˆX5 =\\n[0.99 0 .01\\n0.02 0.99\\n]\\n,ˆy5 =\\n[1\\n4\\n]\\n, e5 =\\n[1\\n1\\n]\\n(17.5)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 231, 'page_label': '220'}, page_content='CHƯƠNG 17. CONTENT-BASED RECOMMENDATION SYSTEM 220\\nKhi đó, hàm mất mát cho hệ số tương ứng vớiuser E là:\\nL5(w5,b5) = 1\\n4\\n\\ued79\\ued79\\ued79\\ued79\\n[0.99 0 .02\\n0.01 0.99\\n]\\nw5 + b5\\n[1\\n1\\n]\\n−\\n[1\\n4\\n]\\ued79\\ued79\\ued79\\ued79\\n2\\n2\\n+ λ\\n4 ∥w5∥2\\n2 (17.6)\\nChúng ta sẽ áp dụng những phân tích trên đây để đi tìm nghiệm cho một bài toán gần với\\nthực tế dưới đây.\\n17.4 Bài toán với cơ sở dữ liệu MovieLens 100k\\n17.4.1 Cơ sở dữ liệu MovieLens 100k\\nBộ cơ sở dữ liệu MovieLens 100k (https://goo.gl/BzHgtq ) được công bố năm 1998 bởi\\nGroupLens (https://grouplens.org). Bộ cơ sở dữ liệu này bao gồm 100,000 (100k) đánh giá\\ntừ 943user cho 1682 bộ phim. Các bạn cũng có thể tìm thấy các bộ cơ sở dữ liệu tương tự\\nvới khoảng 1M, 10M, 20M đánh giá.\\nSau khi download và giải nén, chúng ta sẽ thu được rất nhiều các file nhỏ, chúng ta chỉ cần\\nquan tâm các file sau:\\n• u.data: Chứa toàn bộ các đánh giá của 943 người dùng cho 1682 bộ phim. Mỗi người dùng\\nđánh giá ít nhất 20 movie. Thông tin về thời điểm đánh giá cũng được cho nhưng chúng\\nta không sử dụng trong ví dụ này.\\n• ua.base, ua.test, ub.base, ub.test: là hai cách chia toàn bộ dữ liệu ra thành hai tập con,\\nmột cho huấn luyện, một cho kiểm thử. Chúng ta sẽ thực hành trênua.base và ua.test.\\nBạn đọc có thể thử với cách chia dữ liệu còn lại.\\n• u.user: Chứa thông tin về người dùng, bao gồm: id, tuổi, giới tính, nghề nghiệp, zipcode\\n(vùng miền), vì những thông tin này cũng có thể ảnh hưởng tới sở thích của các người\\ndùng. Tuy nhiên, trong ví dụ này, chúng ta sẽ không sử dụng các thông tin này, trừ thông\\ntin vềid để xác định các user khác nhau.\\n• u.genre: Chứa tên của 19 thể loại phim. Các thể loại bao gồm:unknown, Action, Adventure,\\nAnimation, Children‘s, Comedy, Crime, Documentary, Drama, Fantasy, Film−Noir, Horror,\\nMusical, Mystery, Romance, Sci−Fi, Thriller, War, Western,\\n• u.item: thông tin về mỗi bộ phim. Một vài dòng đầu tiên của file:\\n1|Toy Story (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?Toy%20Story%20(1995)\\n|0|0|0|1|1|1|0|0|0|0|0|0|0|0|0|0|0|0|0\\n2|GoldenEye (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?GoldenEye%20(1995)\\n|0|1|1|0|0|0|0|0|0|0|0|0|0|0|0|0|1|0|0\\n3|Four Rooms (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?Four%20Rooms\\n%20(1995)|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0|1|0|0\\n4|Get Shorty (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?Get%20Shorty\\n%20(1995)|0|1|0|0|0|1|0|0|1|0|0|0|0|0|0|0|0|0|0\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 232, 'page_label': '221'}, page_content='221 CHƯƠNG 17. CONTENT-BASED RECOMMENDATION SYSTEM\\nTrong mỗi dòng, chúng ta sẽ thấyid của phim, tên phim, ngày phát hành, link trên imdb,\\nvà các số nhị phân0, 1 phía cuối để chỉ ra bộ phim thuộc các thể loại nào trong 19 thể loại\\nđã cho trongu.genre. Một bộ phim có thể thuộc nhiều thể loại khác nhau. Thông tin về thể\\nloại này sẽ được dùng để xây dựng item profiles.\\nVới cơ sở dữ liệu này, chúng ta sẽ sử dụng thêm thư viện pandas (http://pandas.pydata.org)\\nđể đọc dữ liệu.\\nfrom __future__ import print_function\\nimport numpy as np\\nimport pandas as pd\\n# Reading user file:\\nu_cols = [’user_id’, ’age’, ’sex’, ’occupation’, ’zip_code’]\\nusers = pd.read_csv(’ml-100k/u.user’, sep=’|’, names=u_cols)\\nn_users = users.shape[0]\\nprint(’Number of users:’, n_users)\\n#Reading ratings file:\\nr_cols = [’user_id’, ’movie_id’, ’rating’, ’unix_timestamp’]\\nratings_base = pd.read_csv(’ml-100k/ua.base’, sep=’\\\\t’, names=r_cols)\\nratings_test = pd.read_csv(’ml-100k/ua.test’, sep=’\\\\t’, names=r_cols)\\nrate_train = ratings_base.as_matrix()\\nrate_test = ratings_test.as_matrix()\\nprint(’Number of traing rates:’, rate_train.shape[0])\\nprint(’Number of test rates:’, rate_test.shape[0])\\nKết quả:\\nNumber of users: 943\\nNumber of traing rates: 90570\\nNumber of test rates: 9430\\nVì ta đang dựa trên thể loại của phim để xây dựng profile, ta sẽ chỉ quan tâm tới 19 giá trị\\nnhị phân ở cuối mỗi hàng:\\nX0 = items.as_matrix()\\nX_train_counts = X0[:, -19:]\\n17.4.2 Xây dựng item profiles\\nCông việc quan trọng trong content-based recommendation system là xây dựng profile cho\\nmỗi item, tức vector đặc trưng cho mỗiitem. Trước hết, chúng ta cần load toàn bộ thông\\ntin về cácitem vào biếnitems:\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 233, 'page_label': '222'}, page_content='CHƯƠNG 17. CONTENT-BASED RECOMMENDATION SYSTEM 222\\n#Reading items file:\\ni_cols = [’movie id’, ’movie title’ ,’release date’,’video release date’, ’IMDb URL’,\\n’unknown’, ’Action’, ’Adventure’, ’Animation’, ’Children\\\\’s’, ’Comedy’, ’Crime’, ’\\nDocumentary’, ’Drama’, ’Fantasy’, ’Film-Noir’, ’Horror’, ’Musical’, ’Mystery’, ’\\nRomance’, ’Sci-Fi’, ’Thriller’, ’War’, ’Western’]\\nitems = pd.read_csv(’ml-100k/u.item’, sep=’|’, names=i_cols)\\nn_items = items.shape[0]\\nprint(’Number of items:’, n_items)\\nKết quả:\\nNumber of items: 1682\\nTiếp theo, chúng ta hiển thị một số hàng đầu tiên của ma trậnrate_train\\nprint(rate_train[:4, :])\\nKết quả:\\n[[ 1 1 5 874965758]\\n[ 1 2 3 876893171]\\n[ 1 3 4 878542960]\\n[ 1 4 3 876893119]]\\nHàng thứ nhất được hiểu làuser thứ nhất đánh giámovie thứ nhất 5 sao. Cột cuối cùng là\\nmột số chỉ thời điểm đánh giá, chúng ta sẽ bỏ qua thông số này.\\nTiếp theo, chúng ta sẽ xây dựng feature vector cho mỗi item dựa trên ma trận thể loại phim\\nvà feature TF-IDF (https://goo.gl/bpDdQ8 ) trong thư việnsklearn.\\n#tfidf\\nfrom sklearn.feature_extraction.text import TfidfTransformer\\ntransformer = TfidfTransformer(smooth_idf=True, norm =’l2’)\\nX = transformer.fit_transform(X_train_counts.tolist()).toarray()\\nSau bước này, mỗi hàng củaX tương ứng với vector đặc trưng của một bộ phim.\\n17.4.3 Tìm mô hình cho mỗi user\\nVới mỗi người dùng, chúng ta cần đi tìm những bộ phim nào mà người dùng đó đã đánh\\ngiá, và giá trị của cácrating đó.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 234, 'page_label': '223'}, page_content='223 CHƯƠNG 17. CONTENT-BASED RECOMMENDATION SYSTEM\\ndef get_items_rated_by_user(rate_matrix, user_id):\\n\"\"\"\\nreturn (item_ids, scores)\\n\"\"\"\\ny = rate_matrix[:,0] # all users\\n# item indices rated by user_id\\n# we need to +1 to user_id since in the rate_matrix, id starts from 1\\n# but id in python starts from 0\\nids = np.where(y == user_id +1)[0]\\nitem_ids = rate_matrix[ids, 1] - 1 # index starts from 0\\nscores = rate_matrix[ids, 2]\\nreturn (item_ids, scores)\\nBây giờ, ta có thể đi tìm các hệ số của Ridge Regression cho mỗi người dùng:\\nfrom sklearn.linear_model import Ridge\\nfrom sklearn import linear_model\\nd = X.shape[1] # data dimension\\nW = np.zeros((d, n_users))\\nb = np.zeros(n_users)\\nfor n in range(n_users):\\nids, scores = get_items_rated_by_user(rate_train, n)\\nmodel = Ridge(alpha=0.01, fit_intercept = True)\\nXhat = X[ids, :]\\nmodel.fit(Xhat, scores)\\nW[:, n] = model.coef_\\nb[n] = model.intercept_\\nSau khi tính được các hệ sốW và b, rating mà mỗi người dùng đánh giá mỗi bộ phim được\\ndự đoán bằng cách:\\n# predicted scores\\nYhat = X.dot(W) + b\\nDưới đây là một ví dụ với người dùng cóid là 10.\\nn = 10\\nnp.set_printoptions(precision=2) # 2 digits after .\\nids, scores = get_items_rated_by_user(rate_test, n)\\nprint(’Rated movies ids :’, ids )\\nprint(’True ratings :’, scores)\\nprint(’Predicted ratings:’, Yhat[ids, n])\\nKết quả:\\nRated movies ids : [ 37 109 110 226 424 557 722 724 731 739]\\nTrue ratings : [3 3 4 3 4 3 5 3 3 4]\\nPredicted ratings: [3.18 3.13 3.42 3.09 3.35 5.2 4.01 3.35 3.42 3.72]\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 235, 'page_label': '224'}, page_content='CHƯƠNG 17. CONTENT-BASED RECOMMENDATION SYSTEM 224\\n17.4.4 Đánh giá mô hình\\nĐể đánh giá mô hình tìm được, chúng ta sẽ sử dụng Root Mean Squared Error (RMSE), tức\\ncăn bậc hai của trung bình cộng bình phương của lỗi.\\ndef evaluate(Yhat, rates, W, b):\\nse = cnt = 0\\nfor n in xrange(n_users):\\nids, scores_truth = get_items_rated_by_user(rates, n)\\nscores_pred = Yhat[ids, n]\\ne = scores_truth - scores_pred\\nse += (e*e).sum(axis = 0)\\ncnt += e.size\\nreturn np.sqrt(se/cnt)\\nprint(’RMSE for training: %.2f’ %evaluate(Yhat, rate_train, W, b))\\nprint(’RMSE for test : %.2f’ %evaluate(Yhat, rate_test, W, b))\\nKết quả:\\nRMSE for training: 0.91\\nRMSE for test : 1.27\\nNhư vậy, với training set, sai số vào khoảng 0.91 (sao); với test set, sai số lớn hơn một chút,\\nkhoảng 1.27. Các kết quả này chưa thực sự tốt vì mô hình đã được đơn giản hoá quá nhiều.\\nKết quả tốt hơn có thể được thấy trong các chương tiếp theo về collaborative filtering.\\n17.5 Thảo luận\\n• Content-based recommendation system là phương pháp đơn giản nhất trong các hệ thống\\nrecommendation system. Đặc điểm của phương pháp này là việc xây dựng mô hình cho\\nmỗi user không phụ thuộc vào cácuser khác.\\n• Việc xây dựng mô hình cho mỗi user có thể được coi như bài toán regression hoặc\\nclasssification với dữ liệu huấn luyện là các cặp (item profile, rating) màuser đó đã đánh\\ngiá. Item profile không phụ thuộc vàouser mà phụ thuộc vào các đặc điểm mô tả của\\nitem hoặc cũng có thể được xác định bằng cách yêu cầu người dùng gắntag.\\n• Source code trong chương này có thể được tìm thấy tạihttps://goo.gl/u9M3vb .\\nĐọc thêm\\n1. Recommendation Systems–Stanford InfoLab(https://goo.gl/P1pesC ).\\n2. Recommendation systems–Machine Learning, Andrew Ng(https://goo.gl/jdFvej ).\\n3. Content Based Recommendations–Stanford University(https://goo.gl/3wnbZ4 ).\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 236, 'page_label': '225'}, page_content='Chương 18\\nNeighborhood-based collaborative\\nfiltering\\n18.1 Giới thiệu\\nTrong content-based recommendation system, chúng ta đã làm quen với một hệ thống gợi\\ný item đơn giản dựa trên vector đặc trưng của mỗi item. Đặc điểm của content-based\\nrecommendation system là việc xây dựng mô hình cho mỗiuser không phụ thuộc vào các\\nuser khác mà phụ thuộc vàoprofile của cácitem. Việc làm này có lợi thế là tiết kiệm bộ nhớ\\nvà thời gian tính toán. Cách làm này có hai nhược điểm cơ bản.Thứ nhất, khi xây dựng mô\\nhình cho một user, các hệ thống content-based không tận dụng được thông tin từ cácuser\\nkhác. Những thông tin này thường rất hữu ích vì hành vi mua hàng của cácuser thường\\nđược nhóm thành một vài nhóm đơn giản. Nếu biết hành vi mua hàng của một vàiuser\\ntrong nhóm, hệ thống nên có khả năngsuy luậnra hành vi của nhữnguser còn lại.Thứ hai,\\nkhông phải lúc nào chúng ta cũng có thể xây dựngprofile cho mỗiitem.\\nNhững nhược điểm này có thể được giải quyết bằng một kỹ thuật có tên làcollaborative\\nfiltering1 (CF) [SFHS07,ERK+11]. Trong chương này, chúng ta cùng làm quen với một\\nphương pháp CF có tên làneighborhood-based collaborative filtering (NBCF). Chương tiếp\\ntheo sẽ trình bày về một phương pháp CF khác có tênmatrix factorization collaborative\\nfiltering. Khi chỉ nóicollaborative filtering, ta sẽ ngầm hiểu rằng đó làneighborhood-based\\ncollaborative filtering.\\nÝ tưởng của NBCF là xác địnhmức độ quan tâmcủa mộtuser tới mộtitem dựa trên hành\\nvi của cácuser khác gần giốngvới user này. Việcgần giống nhaugiữa cácuser có thể được\\nxác định thông quamức độ quan tâmcủa cácuser này tới cácitem khác mà hệ thống đã\\nbiết. Ví dụ,A, B đều thích phimCảnh sát hình sự, đều đã đánh giá bộ phim này 5 sao. Ta\\nđã biếtA cũng thíchNgười phán xử, vậy nhiều khả năngB cũng thích bộ phim này.\\n1 Tiếng Việt có tài liệu dịch làlọc cộng hưởng.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 237, 'page_label': '226'}, page_content='CHƯƠNG 18. NEIGHBORHOOD-BASED COLLABORATIVE FILTERING 226\\nCác bạn có thể đã hình dung ra, hai câu hỏi quan trọng nhất trong một hệ thống\\nneighborhood-based collaborative filtering là\\n1. Làm thế nào xác định đượcsự giống nhaugiữa haiuser?\\n2. Khi đã xác định được cácuser gần giống nhau(similar user) rồi, làm thế nào dự đoán\\nđược mức độ quan tâmcủa mộtuser lên mộtitem?\\nViệc xác định mức độ quan tâm của mỗiuser tới mộtitem dựa trên mức độ quan tâm của\\nuser tương tự tớiitem đó còn được gọi làuser-user collaborative filtering. Có một hướng\\ntiếp cận khác được cho là làm việc hiệu quả hơn làitem-item collaborative filtering. Trong\\nhướng tiếp cận này, thay vì xác định sự giống nhau giữa cácuser, hệ thống sẽ xác định sự\\ngiống nhau giữa cácitem. Từ đó, hệ thống gợi ý nhữngitem gần giống vớinhững item mà\\nuser đó có mức độ quan tâm cao.\\nCấu trúc của chương như sau: Mục 18.2 trình bàyuser-user collaborative filtering. Mục 18.3\\nnêu một số hạn chế củauser-user collaborative filteringvà cách khắc phục bằngitem-item\\ncollaborative filtering. Kết quả của hai phương pháp này được trình bày qua ví dụ trên cơ sở\\ndữ liệu MovieLens 100k trong Mục 18.4. Mục 18.5 thảo luận các ưu nhược điểm của NBCF.\\n18.2 User-user collaborative filtering\\n18.2.1 Hàm xác định độ giống nhau\\nCông việc quan trọng nhất phải làm trước tiên trong user-user collaborative filtering là phải\\nxác định đượcsự giống nhau(similarity) giữa haiuser. Giả sử dữ liệu duy nhất chúng ta\\ncó làutility matrix Y, vậysự giống nhaucần được xác định dựa trên các cột tương ứng với\\nhai user trong ma trận này. Xét ví dụ trong Hình 18.1.\\nGiả sử có cácuser từ u0 đến u6 và cácitem từ i0 đến i4 trong đó các số trong mỗi ô vuông\\nthể hiệnsố saomà mỗiuser đã đánh giáitem đó với giá trị cao hơn thể hiệnmức độ quan\\ntâm cao hơn. Các dấu hỏi chấm là các giá trị mà hệ thống cần phải đi tìm. Đặtmức độ\\ngiống nhau của haiuser ui,uj là sim(ui,uj). Quan sát đầu tiên có thể nhận thấy làu0,u1\\nthích i0,i1,i2 và không thíchi3,i4 cho lắm. Điều ngược lại xảy ra ở cácuser còn lại. Vì vậy,\\nmột hàm đo sự giống nhau similiarity functiontốt cần đảm bảo\\nsim(u0,u1) >sim(u0,ui), ∀i> 1. (18.1)\\nĐể xác địnhmức độ quan tâmcủa u0 lên i2, chúng ta nên dựa trênhành vi của u1 lên item\\nnày. Rất may rằngu1 đã thích i2 nên hệ thống cần khuyến nghịi2 tới u0.\\nCâu hỏi đặt ra là, hàm sốsimilarity cần được xây dựng như thế nào? Để đosimilarity giữa\\nhai user, cách thường làm là xây dựng một vector đặc trưng cho mỗiuser rồi áp dụng một\\nhàm có khả năng đosimilarity giữa hai vector đó. Chú ý rằng việc xây dựng vector đặc trưng\\nnày khác với việc xây dựngitem profilenhư trong content-based recommendation systems.\\nCác vector này được xây dựng trực tiếp dựa trên ma trận utility chứ không dùng thêm thông\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 238, 'page_label': '227'}, page_content='227 CHƯƠNG 18. NEIGHBORHOOD-BASED COLLABORATIVE FILTERING\\nu0\\n5\\n3\\n?\\n2\\n2\\nu1\\n5\\n?\\n4\\n2\\n0\\nu2\\n2\\n?\\n1\\n3\\n4\\nu3\\n0\\n0\\n?\\n4\\n?\\nu4\\n1\\n?\\n?\\n4\\n?\\nu5\\n?\\n?\\n1\\n?\\n?\\nu6\\n?\\n?\\n2\\n4\\n5\\ni0\\ni1\\ni2\\ni3\\ni4\\nHình 18.1: Ví dụ về utility ma-\\ntrix dựa trên số sao mộtuser đánh\\ngiá mộtitem. Một cách trực quan,\\nhành vi của u0 giống vớiu1 hơn là\\nu2,u3,u4,u5,u6. Từ đó có thể dự\\nđoán rằngu0 sẽ quan tâm tớii2 vì\\nu1 cũng quan tâm tớiitem này.\\ntin bên ngoài như item profile. Với mỗiuser, thông tin duy nhất chúng ta biết là cácrating\\nmà user đó đã thực hiện, tức cột tương ứng vớiuser đó trong ma trận utility. Tuy nhiên,\\nkhó khăn là các cột này thường có rất nhiều giá trị bị khuyết (các dấu ‘?’ trong Hình 18.1)\\nvì mỗiuser thường chỉ đánh giá một số lượng rất nhỏ cácitem. Một cách khắc phục là giúp\\nhệ thống ban đầuước lượng thôcác giá trị này sao cho việc điền không làm ảnh hưởng nhiều\\ntới sự giống nhaugiữa hai vector. Việcước lượng này chỉ phục vụ cho việc tínhsimilarity,\\nkhông phải là kết quả cuối cùng hệ thống cần ước lượng.\\nVậy mỗi dấu ‘?’ nên được thay bởi giá trị nào để hạn chế việc ước lượng bị sai lệch? Lựa\\nchọn đầu tiên có thể nghĩ đén là thay các dấu ‘?’ bằng giá trị 0. Điều này không thực sự tốt\\nvì giá trị 0 tương ứng với mức độ quan tâm thấp nhất; và mộtuser chưa đánh giá mộtitem\\nkhông có nghĩa là họ hoàn toàn không quan tâm tớiitem đó. Một giá trịan toànhơn là 2.5\\nvì nó là trung bình cộng của 0, mức thấp nhất, và 5, mức cao nhất. Tuy nhiên, giá trị này\\ncó hạn chế đối với nhữnguser dễ tính hoặc khó tính. Nhữnguser dễ tính có thể đánh giá\\nba sao cho cácitem họ không thích, ngược lại, nhữnguser khó tính có thể đánh giá ba sao\\ncho nhữngitem họ thích. Việc thay đồng loạt các phần tử khuyết bởi 2.5 trong trường hợp\\nnày chưa mang lại hiệu quả. Một giá trị khả dĩ hơn cho việc này là ước lượng các phần tử\\nkhuyết như là giá trị trung bình mà mộtuser đánh giá. Điều này giúp tránh việc mộtuser\\nquá khó tính hoặc dễ tính. Và các giá trị ước lượng này phụ thuộc vào từnguser. Quan sát\\nví dụ trong Hình 18.2.\\nHàng cuối cùng trong Hình 18.2a là trung bình của các đánh giá của mỗiuser. Các giá trị\\ncao tương ứng với cácuser dễ tínhvà ngược lại. Khi đó, nếu tiếp tục trừ từ mỗirating đi giá\\ntrị trung bình này và thay các giá trị chưa biết bằng 0, ta sẽ được mộtma trận utility chuẩn\\nhoá(normalized utility matrix) như trong Hình 18.2b. Việc làm này có một vài ưu điểm:\\n• Việc trừ đi trung bình cộng của mỗicột khiến mỗi cột có cả những giá trị dương và âm.\\nNhững item ứng với các giá trị dương có thể được coi như cácitem mà user đó quan tâm\\nhơn so nhữngitem ứng với các giá trị âm. Nhữngitem mang giá trị bằng 0 chủ yếu ứng\\nvới việcchưa xác địnhđược độ quan tâm củauser đó.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 239, 'page_label': '228'}, page_content='CHƯƠNG 18. NEIGHBORHOOD-BASED COLLABORATIVE FILTERING 228\\na) Original utility matrixY\\nand mean user ratings.\\n↓ ↓ ↓ ↓ ↓ ↓ ↓\\nu0\\n5\\n4\\n?\\n2\\n2\\nu1\\n5\\n?\\n4\\n2\\n0\\nu2\\n2\\n?\\n1\\n3\\n4\\nu3\\n0\\n0\\n?\\n4\\n?\\nu4\\n1\\n?\\n?\\n4\\n?\\nu5\\n?\\n2\\n1\\n?\\n?\\nu6\\n?\\n?\\n1\\n4\\n5\\ni0\\ni1\\ni2\\ni3\\ni4\\n¯uj 3.25 2.75 2.5 1.33 2.5 1.5 3.33\\nb) Normalized utility matrix¯Y.\\nu0\\n1.75\\n0.75\\n0\\n-1.25\\n-1.25\\nu1\\n2.25\\n0\\n1.25\\n-0.75\\n-2.75\\nu2\\n-0.5\\n0\\n-1.5\\n0.5\\n1.5\\nu3\\n-1.33\\n-1.33\\n0\\n2.67\\n0\\nu4\\n-1.5\\n0\\n0\\n1.5\\n0\\nu5\\n0\\n0.5\\n-0.5\\n0\\n0\\nu6\\n0\\n0\\n-2.33\\n0.67\\n1.67\\ni0\\ni1\\ni2\\ni3\\ni4\\nc) User similarity matrixS.\\nu0\\n1\\n0.83\\n-0.58\\n-0.79\\n-0.82\\n0.2\\n-0.38\\nu1\\n0.83\\n1\\n-0.87\\n-0.40\\n-0.55\\n-0.23\\n-0.71\\nu2\\n-0.58\\n-0.87\\n1\\n0.27\\n0.32\\n0.47\\n0.96\\nu3\\n-0.79\\n-0.40\\n0.27\\n1\\n0.87\\n-0.29\\n0.18\\nu4\\n-0.82\\n-0.55\\n0.32\\n0.87\\n1\\n0\\n0.16\\nu5\\n0.2\\n-0.23\\n0.47\\n-0.29\\n0\\n1\\n0.56\\nu6\\n-0.38\\n-0.71\\n0.96\\n0.18\\n0.16\\n0.56\\n1\\nu0\\nu1\\nu2\\nu3\\nu4\\nu5\\nu6\\nd) ˆY\\nu0\\n1.75\\n0.75\\n0.91\\n-1.25\\n-1.25\\nu1\\n2.25\\n1.25\\n-0.75\\n-2.75\\nu2\\n-0.5\\n-0.17\\n-1.5\\n0.5\\n1.5\\nu3\\n-1.33\\n-1.33\\n-1.84\\n2.67\\n1.57\\nu4\\n-1.5\\n-1.33\\n-1.78\\n1.5\\n1.56\\nu5\\n0.18\\n0.5\\n-0.5\\n0.59\\n1.59\\nu6\\n-0.63\\n0.05\\n-2.33\\n0.67\\n1.67\\ni0\\ni1\\ni2\\ni3\\ni4\\n0.48\\ne) Example\\nPredict normalized rating of u1 on i1 with k = 2\\nUsers who rated i1 : {u0 , u3 , u5 }\\nCorresponding similarities: {0.83, -0.40, -0.23 }\\n⇒ most similar users: N(u1 , i1 ) = {u0 , u5 }\\nwith normalized ratings {0.75, 0.5 }\\n⇒ ˆy i 1 ,u 1 =\\n0 .83 ∗0 .75+( −0 .23) ∗0 .5\\n0 .83+ |− 0 .23 | ≈ 0 .48\\nf) Full Y\\nu0\\n5\\n4\\n4.15\\n2\\n2\\nu1\\n5\\n3.23\\n4\\n2\\n0\\nu2\\n2\\n2.33\\n1\\n3\\n4\\nu3\\n0\\n0\\n-0.5\\n4\\n2.9\\nu4\\n1\\n1.67\\n0.71\\n4\\n4.06\\nu5\\n1.68\\n2\\n1\\n2.10\\n3.10\\nu6\\n2.70\\n3.38\\n1\\n4\\n5\\ni0\\ni1\\ni2\\ni3\\ni4\\nHình 18.2: Ví dụ mô tả User-user Collaborative Filtering. a) Utility Matrix ban đầu. b) Utility\\nMatrix đã được chuẩn hoá. c) User similarity matrix. d) Dự đoán các (normalized)ratings còn\\nthiếu. e) Ví dụ về cách dự đoán normalized rating củau1 cho i1. f) Dự đoán các (denormalized)\\nratings còn thiếu.\\n• Về mặt kỹ thuật, số chiều của ma trận utility là rất lớn với hàng triệuuser và item, nếu\\nlưu toàn bộ các giá trị này trong một ma trận thì khả năng cao là sẽ không đủ bộ nhớ.\\nQuan sát thấy rằng vì số lượng đánh giá biết trước thường là một số rất nhỏ so với kích\\nthước của ma trận utility, sẽ tốt hơn nếu chúng ta lưu ma trận này dưới dạng một ma\\ntrận sparse, tức chỉ lưu các giá trị khác không và vị trí của chúng. Vì vậy, tốt hơn hết,\\ncác dấu ’?’ nên được thay bằng giá trị ’0’, tức chưa xác định liệuuser có thíchitem hay\\nkhông. Việc này không những tối ưu bộ nhớ mà việc tính toán ma trậnsimilarity sau\\nnày cũng hiệu quả hơn. Ở đây, phần tử ở hàng thứi, cột thứj của ma trậnsimilarity là\\nđộ similarity của user thứ i và thứj.\\nSau khi dữ liệu đã được chuẩn hoá, hàmsimilarity thường được sử dụng làcosine similarity:\\ncosine_similarity(u1,u2) =cos(u1,u2) = uT\\n1 u2\\n∥u1∥2.∥u2∥2\\n(18.2)\\nTrong đóu1,2 là các vector tương ứng vớiuser 1 vàuser 2 như ở trên. Có một hàm trong\\nPython phục vụ cách tính giá trị này một cách hiệu quả, chúng ta sẽ thấy trong phần lập\\ntrình.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 240, 'page_label': '229'}, page_content='229 CHƯƠNG 18. NEIGHBORHOOD-BASED COLLABORATIVE FILTERING\\nMức độsimilarity của hai vector là một số thực trong đoạn [-1, 1]. Giá trị bằng 1 thể hiện\\nhai vector hoàn toànsimilar nhau. Hàm số cos của một góc bằng 1 nghĩa là góc giữa hai\\nvector bằng 0, tức hai vector có cùng phương và cùng hướng. Giá trị cos bằng -1 thể hiện\\nhai vector này hoàn toàn trái ngược nhau, tức cùng phương nhưng khác hương. Điều này\\nđồng nghĩa với việc nếuhành vicủa haiuser là hoàn toàn ngược nhau thì mức độsimilarity\\ngiữa hai vector đó là thấp nhất.\\nVí dụ vềcosine similarity của các user (đã được chuẩn hoá) trong Hình 18.2b được cho\\ntrong Hình 18.2c. Ma trận similarityS là một ma trận đối xứng vìcos là một hàm chẵn2 ,\\nvà nếuuser A giống user Bthì điều ngược lại cũng đúng. Các ô màu xanh trên đường chéo\\nđều là cos của góc giữa một vector và chính nó, tức cos(0) = 1 . Khi tính toán ở các bước\\nsau, chúng ta không cần quan tâm tới các giá trị 1 này. Tiếp tục quan sát các vector hàng\\ntương ứng vớiu0,u1,u2, chúng ta sẽ thấy một vài điều thú vị:\\n• u0 gần với u1 và u5 (độ giống nhau là dương) hơn cácuser còn lại. Việcsimilarity cao\\ngiữa u0 vàu1 là dễ hiểu vì cả hai đều có xu hướng quan tâm tớii0,i1,i2 hơn cácitem còn\\nlại. Việcu0 gần với u5 thoạt đầu có vẻ vô lý vìu5 đánh giá thấp cácitem mà u0 đánh giá\\ncao (Hình 18.2a); tuy nhiên khi nhìn vào ma trận utility đã chuẩn hoá ở Hình 18.2b, ta\\nthấy rằng điều này là hợp lý vìitem duy nhất mà cả haiuser này đã cung cấp thông tin\\nlà i1 với các giá trị tương ứng đều làtích cực.\\n• u1 gần vớiu0 và xa cácuser còn lại.\\n• u2 gần vớiu3,u4,u5,u6 và xa cácuser còn lại.\\nTừ ma trậnsimilarity này, chúng ta có thể phân nhóm cácuser ra làm hai nhóm(u0,u1)\\nvà (u2,u3,u4,u5,u6). Vì ma trậnS này nhỏ nên chúng ta có thể dễ dàng quan sát thấy điều\\nnày; khi sốuser lớn hơn, việc xác định bằngmắt thường là không khả thi. Việc xây dựng\\nthuật toán phân nhóm cácuser (users clustering) sẽ được trình bày trong chương tiếp theo.\\nCó một chú ý quan trọng ở đây là khi số lượnguser lớn, ma trậnS cũng rất lớn và nhiều\\nkhả năng là không có đủ bộ nhớ để lưu trữ, ngay cả khi chỉ lưu hơn một nửa số các phần\\ntử của ma trận đối xứng này. Với các trường hợp đó, mới mỗiuser, chúng ta chỉ cần tính và\\nlưu kết quả của một hàng củasimilarity matrix, tương ứng với việc độgiống nhaugiữa user\\nđó và cácuser còn lại.\\n18.2.2 Điền các giá trị khuyết trong ma trận utility\\nViệc dự đoán mức độ quan tâm(predicted rating) của mộtuser lên mộtitem dựa trên các\\nuser gần nhấtnày rất giống với những gì chúng ta thấy trongK-nearest neighbors(KNN)\\nvới hàm khoảng cách làcosine similarity.\\nTương tự như KNN, NBCF cũng dùng thông tin củak user lân cận để dự đoán. Tất nhiên,\\nđể đánh giá độ quan tâm của mộtuser lên một item, chúng ta chỉ quan tâm tới cácuser\\n2 Một hàm sốf : R →R được gọi làchẵn nếu f(x) =f(−x), ∀x∈R.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 241, 'page_label': '230'}, page_content='CHƯƠNG 18. NEIGHBORHOOD-BASED COLLABORATIVE FILTERING 230\\ntrong lân cậnđã đánh giáitem đó. Giá trị cần điềnthường được xác định làtrung bình có\\ntrọng số của cácrating đã chuẩn hoá. Có một điểm cần lưu ý, trong KNN, các trọng số\\nđược xác định dựa trên khoảng cách giữa hai điểm, và các khoảng cách này là các số không\\nâm. Trong NBCF, các trọng số được xác định dựa trênsimilarity giữa haiuser, những trọng\\nsố này có thể nhỏ hơn 0. Công thức phổ biến được sử dụng để dự đoán số sao màuser u\\nđánh giáitem i là3\\nˆyi,u =\\n∑\\nuj∈N(u,i) ¯yi,uj sim(u,uj)\\n∑\\nuj∈N(u,i) |sim(u,uj)| (18.3)\\ntrong đóN(u,i) là tập hợpk user gần giống nhất, tức cósimilarity cao nhất củauđã đánh\\ngiá i. Hình 18.2d thể hiện việcđiền các giá trị còn thiếu trong ma trậnutility đã chuẩn hoá.\\nCác ô màu nền đỏ thể hiện các giá trị dương, tức cácitem mà có thểuser đó quan tâm. Ở\\nđây, ngưỡng được lấy là 0, ngưỡng này hoàn toàn có thể được thay đổi tuỳ thuộc vào việc\\nta muốn gợi ý nhiều hay ítitem.\\nMột ví dụ về việc tínhnormalized rating của u1 cho i1 được cho trong Hình 18.2e với số\\nnearest neighborslà k= 2. Các bước thực hiện như sau\\n1. Xác định cácuser đã đánh giái1, chúng làu0,u3,u5.\\n2. Mức độsimilarity của u1 với cácuser này lần lượt là{0.83,−0.40,−0.23}. Hai (k = 2)\\ngiá trị lớn nhất là0.83 và −0.23 tương ứng vớiu0 và u5.\\n3. Xác định các đánh giá (đã chuẩn hoá) củau0 và u5 cho i1, ta thu được hai giá trị lần\\nlượt là0.75 và 0.5.\\n4. Dự đoán kết quả\\nˆyi1,u1 = 0.83 ×0.75 + (−0.23) ×0.5\\n0.83 + |−0.23| ≈0.48 (18.4)\\nViệc quy đổi các giá trị đánh giá đã chuẩn hoá về thang 5 có thể được thực hiện bằng cách\\ncộng các cột của ma trậnˆY với giá trị đánh giá trung bình của mỗiuser như đã tính trong\\nHình 18.2a. Việc hệ thống quyết định gợi ýitem nào cho mỗiuser có thể được xác định\\nbằng nhiều cách khác nhau. Hệ thống có thể sắp xếp cácitem chưa được đánh giá theo độ\\ngiảm dần củapredicted rating, hoặc có thể chỉ chọn cácitem có normalized predicted rating\\ndương–tương ứng với việcuser này có nhiều khả năng thích hơn.\\n18.3 Item-item collaborative filtering\\nUser-user CF có một số hạn chế như sau:\\n• Khi số lượnguser lớn hơn số lượngitem rất nhiều (điều này thường xảy ra), kích thước\\nma trận similarity là rất lớn (mỗi chiều của ma trận này có số phần tử chính bằng số\\nuser). Việc lưu trữ một ma trận với kích thước lớn nhiều khi không khả thi.\\n3 Sự khác biệt so với trung bình có trọng số là mẫu số có sử dụng trị tuyệt đối để xử lý các số âm.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 242, 'page_label': '231'}, page_content='231 CHƯƠNG 18. NEIGHBORHOOD-BASED COLLABORATIVE FILTERING\\n• Ma trận utilityY thường rấtsparse, tức chỉ có một tỉ lệ nhỏ các phần tử đã biết. Với số\\nlượng user rất lớn so với số lượngitem, rất nhiều cột của ma trận này có rất ít, thậm chí\\nkhông có phần tử khác 0 vì cácuser thường lười đánh giáitem. Cũng chính vì thế, một\\nkhi user đó thay đổi cácrating trước đó hoặc đánh giá thêmitem, trung bình cộng các\\nrating cũng như vector chuẩn hoá tương ứng vớiuser này thay đổi nhiều. Kéo theo đó,\\nviệc tính toán ma trận similarity, vốn tốn nhiều bộ nhớ và thời gian, cũng cần được thực\\nhiện lại.\\nCó một cách tiếp cận khác, thay vì tìm sự giống nhau giữa cácuser, ta có thể tìm sự giống\\nnhau giữa cácitem. Từ đó nếu mộtuser thích một item thì hệ thống nên gợi ý cácitem\\ntương tự tớiuser đó. Việc này có một số ưu điểm:\\n• Khi số lượngitem nhỏ hơn số lượnguser, ma trận similarity có kích thước nhỏ hơn, việc\\nnày khiến việc lưu trữ và tính toán ở các bước sau được thực hiện một cách hiệu quả hơn.\\n• Cũng giả sử rằng số lượngitem ít hơn số lượnguser. Vì tổng lượng đánh giá là không đổi,\\nsố lượng trung bình cácitem được đánh giá bởi mộtuser sẽ ít hơn số lượng trung bình\\ncác user đã đánh giá mộtitem. Nói cách khác, nếu ma trận utility có số hàng ít hơn số\\ncột, số lượng phần tử trung bình đã biết trong mỗi hàng sẽ nhiều hơn số lượng phần tử\\ntrung bình đã biết trong mỗi cột. Kéo theo đó, thông tin về mỗiitem là nhiều hơn thông\\ntin về mỗiuser, việc tính độsimilarity giữa các hàng cũng đáng tin cậy hơn. Hơn nữa,\\ngiá trị trung bình của mỗi hàng cũng thay đổi ít hơn khi có thêm một vài đánh giá. Như\\nvậy, việc cập nhật ma trận similarity có thể được thực hiện ít thường xuyên hơn.\\nCách tiếp cận thứ hai này được gọi làitem-item collaborative filtering(item-item CF). Khi\\nsố lượngitem ít hơn số lượnguser, phương pháp này được ưu tiên sử dụng hơn.\\nQuy trình dự đoán các đánh giá bị khuyết cũng tương tự như trong user-user CF, chỉ khác\\nlà bây giờ ta cần tính độgiống nhau giữa các hàng.\\nLiên hệ giữa item-item CF và user-user CF\\nVề mặt tính toán, item-item CF có thể nhận được từ user-user CF bằng cách chuyển\\nvị (transpose) ma trận utility, và coi như item đang đánh giá ngược user. Sau khi tính\\nra kết quả cuối cùng, ta lại chuyển vị một lần nữa để thu được kết quả.\\nHình 18.3 mô tả quy trình này với ví dụ nêu ở phần trên. Có một điểm thú vị trong ma\\ntrận similarity ở Hình 18.3c là có các phần tử trong hai khu vực hình vuông xanh và đỏ\\nđều là các số không âm, các phần tử bên ngoài là các số âm. Việc này thể hiện rằng các\\nitem có thể được chia thành hai nhóm rõ rệt với nhữngitem có similarity không âm trong\\nmột nhóm cột vào một nhóm. Như vậy, một cáchvô tình, chúng ta đã thực hiện việcitem\\nclustering. Việc này sẽ giúp ích rất nhiều trong việc dự đoán ở phần sau vì cácitem gần\\ngiống nhau rất có thể đã được phân vào một nhóm. Kết quả cuối cùng về việc chọnitem\\nnào đểrecommend cho mỗiuser được thể hiện bởi các ô màu đỏ trong Hình 18.3d. Kết quả\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 243, 'page_label': '232'}, page_content='CHƯƠNG 18. NEIGHBORHOOD-BASED COLLABORATIVE FILTERING 232\\na) Original utility matrixY\\nand mean item ratings.\\n→\\n→\\n→\\n→\\n→\\nu0\\n5\\n4\\n?\\n2\\n2\\nu1\\n5\\n?\\n4\\n2\\n0\\nu2\\n2\\n?\\n1\\n3\\n4\\nu3\\n0\\n0\\n?\\n4\\n?\\nu4\\n1\\n?\\n?\\n4\\n?\\nu5\\n?\\n2\\n1\\n?\\n?\\nu6\\n?\\n?\\n1\\n4\\n5\\ni0\\ni1\\ni2\\ni3\\ni4\\n2.6\\n2\\n1.75\\n3.17\\n2.75\\nb) Normalized utility matrix¯Y.\\nu0\\n2.4\\n2\\n0\\n-1.17\\n-0.75\\nu1\\n2.4\\n0\\n2.25\\n-1.17\\n-2.75\\nu2\\n-.6\\n0\\n-0.75\\n-0.17\\n1.25\\nu3\\n-2.6\\n-2\\n0\\n0.83\\n0\\nu4\\n-1.6\\n0\\n0\\n0.83\\n0\\nu5\\n0\\n0\\n-0.75\\n0\\n0\\nu6\\n0\\n0\\n-0.75\\n0.83\\n2.25\\ni0\\ni1\\ni2\\ni3\\ni4\\nc) Item similarity matrixS.\\ni0\\n1\\n0.77\\n0.49\\n-0.89\\n-0.52\\ni1\\n0.77\\n1\\n0\\n-0.64\\n-0.14\\ni2\\n0.49\\n0\\n1\\n-0.55\\n-0.88\\ni3\\n-0.89\\n-0.64\\n-0.55\\n1\\n0.68\\ni4\\n-0.52\\n-0.14\\n-0.88\\n0.68\\n1\\ni0\\ni1\\ni2\\ni3\\ni4\\nd) Normalized utility matrix¯Y.\\nu0\\n2.4\\n2\\n2.4\\n-1.17\\n-0.75\\nu1\\n2.4\\n2.4\\n2.25\\n-1.17\\n-2.75\\nu2\\n-.6\\n-0.6\\n-0.75\\n-0.17\\n1.25\\nu3\\n-2.6\\n-2\\n-2.6\\n0.83\\n1.03\\nu4\\n-1.6\\n-1.25\\n-1.20\\n0.83\\n1.16\\nu5\\n-0.29\\n0\\n-0.75\\n0.34\\n0.65\\nu6\\n-1.52\\n-2.25\\n-0.75\\n0.83\\n2.25\\ni0\\ni1\\ni2\\ni3\\ni4\\nHình 18.3: Ví dụ mô tả item-item CF. a) Ma trận utility ban đầu. b) Ma trận utility đã được\\nchuẩn hoá. c) User similarity matrix. d) Dự đoán các (normalized)rating còn thiếu.\\nnày có khác một chút so với kết quả tìm được bởi user-user CF ở hai cột cuối cùng tương\\nứng vớiu5,u6. Dường như kết quả nàyhợp lý hơn vì từ utility matrix, ta nhận thấy có hai\\nnhóm user thích hai nhómitem khác nhau. Nhóm thứ nhất làu0 vàu1; nhóm thứ hai là các\\nuser còn lại.\\nMục 18.4 sau đây mô tả cách lập trình cho NNCF trên Python. Chú ý rằng thư việnsklearn\\nchưa hỗ trợ các module cho recommendation system. Một thư viện khác khá tốt trên python\\nbạn đọc có thể tham khảo làsurprise (http://surpriselib.com/ ).\\n18.4 Lập trình trên Python\\nThuật toán collaborative filtering trong chương này tương đối đơn giản và không chứa bài\\ntoán tối ưu nào. Chúng ta tiếp tục sử dụng bộ cơ sở dữ liệu MovieLens 100k như trong chương\\ntrước. Dưới đây là đoạn code thể hiệnclass uuCF cho user-user collaborative filtering. Có\\nhai phương thức chính củaclass này làfit–tính ma trận similarity, vàpredict–dự đoán số\\nsao mà mộtuser sẽ đánh giá mộtitem.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 244, 'page_label': '233'}, page_content='233 CHƯƠNG 18. NEIGHBORHOOD-BASED COLLABORATIVE FILTERING\\nfrom __future__ import print_function\\nimport pandas as pd\\nimport numpy as np\\nfrom sklearn.metrics.pairwise import cosine_similarity\\nfrom scipy import sparse\\nclass uuCF(object):\\ndef __init__(self, Y_data, k, sim_func = cosine_similarity):\\nself.Y_data = Y_data # a 2d array of shape (n_users, 3)\\n# each row of Y_data has form [user_id, item_id, rating]\\nself.k = k # number of neighborhood\\nself.sim_func = sim_func # similarity function, default: cosine_similarity\\nself.Ybar = None # normalize data\\nself.n_users = int(np.max(self.Y_data[:, 0])) + 1 # number of users\\nself.n_items = int(np.max(self.Y_data[:, 1])) + 1 # number of items\\ndef fit(self):\\n# normalized Y_data -> Ybar\\nusers = self.Y_data[:, 0] # all users - first column of Y_data\\nself.Ybar = self.Y_data.copy()\\nself.mu = np.zeros((self.n_users,))\\nfor n in xrange(self.n_users):\\n# row indices of ratings made by user n\\nids = np.where(users == n)[0].astype(np.int32)\\n# indices of all items rated by user n\\nitem_ids = self.Y_data[ids, 1]\\n# ratings made by user n\\nratings = self.Y_data[ids, 2]\\n# avoid zero division\\nself.mu[n] = np.mean(ratings) if ids.size > 0 else 0\\nself.Ybar[ids, 2] = ratings - self.mu[n]\\n## form the rating matrix as a sparse matrix.\\n# see more: https://goo.gl/i2mmT2\\nself.Ybar = sparse.coo_matrix((self.Ybar[:, 2],\\n(self.Ybar[:, 1], self.Ybar[:, 0])), (self.n_items, self.n_users)).tocsr()\\nself.S = self.sim_func(self.Ybar.T, self.Ybar.T)\\ndef pred(self, u, i):\\n\"\"\" predict the rating of user u for item i\"\"\"\\n# find item i\\nids = np.where(self.Y_data[:, 1] == i)[0].astype(np.int32)\\n# all users who rated i\\nusers_rated_i = (self.Y_data[ids, 0]).astype(np.int32)\\n# similarity of u and users who rated i\\nsim = self.S[u, users_rated_i]\\n# most k similar users\\nnns = np.argsort(sim)[-self.k:]\\nnearest_s = sim[nns] # and the corresponding similarities\\n# the corresponding ratings\\nr = self.Ybar[i, users_rated_i[nns]]\\neps = 1e-8 # a small number to avoid zero division\\nreturn (r*nearest_s).sum()/(np.abs(nearest_s).sum() + eps) + self.mu[u]\\nTiếp theo, ta áp dụng vào MoviesLen 100k:\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 245, 'page_label': '234'}, page_content='CHƯƠNG 18. NEIGHBORHOOD-BASED COLLABORATIVE FILTERING 234\\nr_cols = [’user_id’, ’movie_id’, ’rating’, ’unix_timestamp’]\\nratings_base = pd.read_csv(’ml-100k/ua.base’, sep=’\\\\t’, names=r_cols)\\nratings_test = pd.read_csv(’ml-100k/ua.test’, sep=’\\\\t’, names=r_cols)\\nrate_train = ratings_base.as_matrix()\\nrate_test = ratings_test.as_matrix()\\n# indices start from 0\\nrate_train[:, :2] -= 1\\nrate_test[:, :2] -= 1\\nrs = uuCF(rate_train, k = 40)\\nrs.fit()\\nn_tests = rate_test.shape[0]\\nSE = 0 # squared error\\nfor n in xrange(n_tests):\\npred = rs.pred(rate_test[n, 0], rate_test[n, 1])\\nSE += (pred - rate_test[n, 2])**2\\nRMSE = np.sqrt(SE/n_tests)\\nprint(’User-user CF, RMSE =’, RMSE)\\nKết quả:\\nUser-user CF, RMSE = 0.976614028929\\nNhư vậy, trung bình mỗirating bị dự đoán sai lệch khoảng 0.976. Kết quả này có tốt hơn\\nkết quả có được bởi content-based recommendation system.\\nTiếp theo, chúng ta áp dụng item-item CF vào tập cơ sở dữ liệu này. Để áp dụng item-item\\nCF, chúng ta chỉ cần chuyển vị ma trận utility. Trong trường hợp này, vì ma trận utility\\nđược lưu dưới dạng[user_id, item_id, rating] nên ta chỉ cần đổi chỗ cột thứ nhất cho cột\\nthứ hai củaY_data:\\nrate_train = rate_train[:, [1, 0, 2]]\\nrate_test = rate_test[:, [1, 0, 2]]\\nrs = uuCF(rate_train, k = 40)\\nrs.fit()\\nn_tests = rate_test.shape[0]\\nSE = 0 # squared error\\nfor n in xrange(n_tests):\\npred = rs.pred(rate_test[n, 0], rate_test[n, 1])\\nSE += (pred - rate_test[n, 2])**2\\nRMSE = np.sqrt(SE/n_tests)\\nprint(’Item-item CF, RMSE =’, RMSE)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 246, 'page_label': '235'}, page_content='235 CHƯƠNG 18. NEIGHBORHOOD-BASED COLLABORATIVE FILTERING\\nKết quả:\\nItem-item CF, RMSE = 0.968846083868\\nNhư vậy, trong trường hợp này item-item collaborative filtering cho kết quả tốt hơn, ngay\\ncả khi sốitem (1682) lớn hơn số lượnguser (943). Với các bài toán khác, chúng ta nên thử\\ncả hai trên một tập validation và chọn ra phương pháp cho kết quả tốt hơn. Chúng ta cũng\\ncó thể thaykích thước lân cậnk bằng các giá trị khác và so sánh các kết quả.\\n18.5 Thảo luận\\n• CF là một phương pháp gợi ýitem với ý tưởng chính dựa trên hành vi của cácuser tương\\ntự khác lên cùng mộtitem. Việc suy ra này được thực hiện dựa trên ma trậnsimilarity\\nđo độ giống nhau giữa cácuser.\\n• Để tính ma trận similarity, trước tiên ta cần chuẩn hoá dữ liệu. Phương pháp phổ biến\\nlà mean offset, tức trừ cácratings đi giá trị trung bình mà mộtuser đưa ra cho cácitem.\\n• Similarity function thường được dụng làcosine similarity.\\n• Một hướng tiếp cận tương tự là thay vì đi tìm cácuser gần giống với mộtuser (user-\\nuser CF), ta đi tìm cácitem gần với mộtitem cho trước (item-item CF). Trên thực tế,\\nitem-item CF thường cho kết quả tốt hơn.\\n• Source code của chương này có thể được tìm thấy tạihttps://goo.gl/vGKjbo .\\nĐọc thêm\\n1. M.Ekstrand et al.,Collaborative filtering recommender systems.(https://goo.gl/GVn8av )\\nFoundations and Trends® in Human–Computer Interaction 4.2 (2011): 81-173.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 247, 'page_label': '236'}, page_content='Chương 19\\nMatrix factorization collaborative\\nfiltering\\n19.1 Giới thiệu\\nTrong Chương 18, chúng ta đã làm quen với một phương pháp collaborative filtering (CF)\\ndựa trên hành vi của cácuser hoặc item lân cận. Trong chương này, chúng ta sẽ làm quen\\nvới một hướng tiếp cận khác cho collaborative filtering dựa trên bài toánphân tích ma trận\\nthành nhân tử(matrix factorizationhoặc matrix decomposition). Phương pháp này được gọi\\nlà matrix factorization collaborative filtering(MFCF) [KBV09].\\nNhắc lại rằng trong content-based recommendation systems, mỗiitem được mô tả bằng một\\nvector x được gọi làitem profile. Trong phương pháp đó, ta cần tìm một vector hệ sốw\\ntương ứng với mỗiuser sao chorating đã biết màuser đó choitem xấp xỉ với\\ny≈wTx = xTw (19.1)\\nVới cách làm này, ma trận utilityY, giả sử đã được điền hết, sẽ xấp xỉ với:\\nY ≈\\n\\uf8ee\\n\\uf8ef\\uf8ef\\uf8ef\\uf8f0\\nxT\\n1 w1 xT\\n1 w2 ... xT\\n1 wN\\nxT\\n2 w1 xT\\n2 w2 ... xT\\n2 wN\\n... ... ... ...\\nxT\\nMw1 xT\\nMw2 ... xT\\nMwN\\n\\uf8f9\\n\\uf8fa\\uf8fa\\uf8fa\\uf8fb=\\n\\uf8ee\\n\\uf8ef\\uf8ef\\uf8f0\\nxT\\n1\\nxT\\n2\\n...\\nxT\\nM\\n\\uf8f9\\n\\uf8fa\\uf8fa\\uf8fb\\n[\\nw1 w2 ... wN\\n]\\n= XTW (19.2)\\nvới M,N lần lượt là số lượngitem và user. Chú ý rằng trong content-based collaborative\\nfiltering, x được xây dựng dựa trên thông tin mô tả củaitem và quá trình xây dựng này độc\\nlập với quá trình đi tìm hệ số phù hợp cho mỗiuser. Như vậy, việc xây dựngitem profile\\nđóng vai trò rất quan trọng và có ảnh hưởng trực tiếp lên hiệu năng của mô hình. Thêm\\nnữa, việc xây dựng từng mô hình riêng lẻ cho mỗiuser dẫn đến kết quả chưa thực sự tốt vì\\nkhông khai thác được mối quan hệ giữa cácuser.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 248, 'page_label': '237'}, page_content='237 CHƯƠNG 19. MATRIX FACTORIZATION COLLABORATIVE FILTERING\\nY\\n(Full) Utility matrix\\nN\\nM ≈ X TM\\nK\\n×\\nItem features\\nY ≈ ˆY = X T W\\nWK\\nN\\nUser features\\nHình 19.1: Matrix factorization. Ma trận utilityY ∈RM×N được phân tích thành tích của hai\\nma trậnX ∈RM×K và W ∈RK×N.\\nBây giờ, giả sử rằng ta không cần xây dựng từ trước cácitem profilex mà vector đặc trưng\\ncho mỗiitem này có thể đượchuấn luyệnđồng thời với mô hình của mỗiuser (ở đây là một\\nvector hệ số). Điều này nghĩa là, biến số trong bài toán tối ưu là cảX và W; trong đó,X là\\nma trận của toàn bộitem profile, mỗicột tương ứng với mộtitem, W là ma trận của toàn\\nbộ user model, mỗicột tương ứng với mộtuser.\\nVới cách làm này, chúng ta đang cố gắng xấp xỉ ma trận utilityY ∈RM×N bằng tích của\\nhai ma trậnX ∈RK×M và W ∈RK×N. Thông thường,K được chọn là một số nhỏ hơn rất\\nnhiều so vớiM,N . Khi đó, cả hai ma trậnX và W đều có rank không vượt quáK. Chính\\nvì vậy, phương pháp này còn được gọi làlow-rank matrix factorization(xem Hình 19.1).\\nCó một vài điểm cần lưu ý:\\n• Ý tưởng chính đằng sau matrix factorization cho recommendation system là tồn tại các\\nđặc trưng ẩn(latent feature) mô tả sự liên quan giữa cácitem và cácuser. Ví dụ, trong\\nhệ thống khuyến nghị các bộ phim, tính chất ẩn có thể làhình sự, chính trị, hành động,\\nhài, v.v.; cũng có thể là một sự kết hợp nào đó của các thể loại này; hoặc cũng có thể là\\nbất cứ điều gì mà chúng ta không thực sự cần đặt tên. Mỗiitem sẽ mang tính chất ẩn ở\\nmột mức độ nào đó tương ứng với các hệ số trong vectorx của nó, hệ số càng cao tương\\nứng với việc mang tính chất đó càng cao. Tương tự, mỗiuser cũng sẽ có xu hướng thích\\nnhững tính chất ẩn nào đó và được mô tả bởi các hệ số trong vectorw của nó. Hệ số cao\\ntương ứng với việcuser thích các bộ phim có tính chất ẩn đó. Giá trị của biểu thứcxTw\\nsẽ cao nếu các thành phần tương ứng củax và w đều cao (và dương). Điều này nghĩa là\\nitem mang các tính chất ẩn màuser thích, vậy ta nên gợi ýitem này chouser đó.\\n• Tại sao matrix factorization lại được xếp vào collaborative filtering? Câu trả lời đến từ\\nviệc đi tối ưu hàm mất mát mà chúng ta sẽ thảo luận ở Mục 19.2. Về cơ bản, để tìm\\nnghiệm của bài toán tối ưu, ta phải lần lượt đi tìmX và W khi thành phần còn lại được\\ncố định. Như vậy, mỗi cột củaX sẽ phụ thuộc vào toàn bộ các cột củaW. Ngược lại,\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 249, 'page_label': '238'}, page_content='CHƯƠNG 19. MATRIX FACTORIZATION COLLABORATIVE FILTERING 238\\nmỗi cột củaW lại phụ thuộc vào toàn bộ các cột củaX. Như vậy, có những mỗi quan\\nhệ ràng buộcchằng chịt giữa các thành phần của hai ma trận trên. Tức chúng ta cần sử\\ndụng thông tin của tất cả để suy ra tất cả. Vậy nên phương pháp này cũng được xếp vào\\ncollaborative filtering.\\n• Trong các bài toán thực tế, số lượngitem M và số lượnguser N thường rất lớn. Việc\\ntìm ra các mô hình đơn giản giúp dự đoán cácrating cần được thực hiện một cách nhanh\\nnhất có thể. Neighborhood-based collaborative filtering không yêu cầu việc huấn luyện\\nquá nhiều, nhưng trong quá trình dự đoán, ta cần đi tìm độsimilarity của user đang xét\\nvới toàn bộ các user còn lại rồi suy ra kết quả. Ngược lại, với matrix factorization, việc\\nhuấn luyện có thể hơi phức tạp một chút vì phải lặp đi lặp lại việc tối ưu một ma trận\\nkhi cố định ma trận còn lại, nhưng việc dự đoán đơn giản hơn vì ta chỉ cần lấy tích vô\\nhướng của hai vectorxTw, mỗi vector có độ dàiK là một số nhỏ hơn nhiều so vớiM,N .\\nVì vậy, quá trình dự đoán không yêu cầu khả năng tính toán cao. Việc này khiến nó phù\\nhợp với các mô hình có tập dữ liệu lớn.\\n• Thêm nữa, việc lưu trữ hai ma trậnX vàW yêu cầu lượng bộ nhớ nhỏ so với việc lưu toàn\\nbộ ma trận utility và similarity trong neighborhood-based collaborative filtering. Cụ thể,\\nta cần bộ nhớ để chứaK(M + N) phần tử thay vìM2 hoặc N2 của ma trậnsimilarity.\\n19.2 Xây dựng và tối ưu hàm mất mát\\n19.2.1 Xấp xỉ các đánh giá đã biết\\nNhư đã đề cập, đánh giá củauser n lên item m có thể được xấp xỉ bởiymn = xT\\nmwn. Ta\\ncũng có thể thêm các bias vào công thức xấp xỉ này và tối ưu các bias đó. Cụ thể:\\nymn ≈xT\\nmwn + bm + dn (19.3)\\nTrong đó,bm và dn lượt lượt là các hệ số tự do tương tứng vớiitem m và user n. Vector\\nb = [b1,b2,...,b M]T là vector bias cho cácitem, vectord = [d1,d2,...,d N]T là vector bias\\ncho cácuser. Giống như trong neighborhood-based collaborative filtering (NBCF), các giá trị\\nnày cũng có thể được coi là các giá trị giúp chuẩn hoá dữ liệu vớib tương ứng với item-item\\nCF vàd tương ứng với user-user CF. Không giống như trong NBCF, các giá trị này sẽ được\\ntối ưu để tìm ra các giá trị giúp xấp xỉ tập huấn luyện tốt nhất. Thêm vào đó, huấn luyện\\ncùng lúc cảd và b giúp kết hợp cả user-user CF và item-item CF vào trong một bài toán\\ntối ưu. Vì vậy, chúng ta mong đợi rằng phương pháp này sẽ mang lại hiệu quả tốt hơn.\\n19.2.2 Hàm mất mát\\nHàm mất mát cho MFCF có thể được viết như sau\\nL(X,W,b,d) = 1\\n2s\\nN∑\\nn=1\\n∑\\nm:rmn=1\\n(xT\\nmwn + bm + dn −ymn)\\n\\ued19 \\ued18\\ued17 \\ued1a\\ndata loss\\n+ λ\\n2 (∥X∥2\\nF + ∥W∥2\\nF)\\n\\ued19 \\ued18\\ued17 \\ued1a\\nregularization loss\\n(19.4)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 250, 'page_label': '239'}, page_content='239 CHƯƠNG 19. MATRIX FACTORIZATION COLLABORATIVE FILTERING\\ntrong đórmn = 1 nếu item thứ mđã được đánh giá bởiuser thứ n, slà số lượngrating trong\\ntập huấn luyện,ymn là rating chưa chuẩn hoá1 của user thứ ncho item thứ m. Thành phần\\nthứ nhất của hàm mất mát,data loss, chính là trung bình sai số của mô hình. Thành phần\\nthứ hai,regularization loss, làl2 regularization, thành phần này giúp tránh overfitting2.\\nViệc tối ưu đồng thờiX,W,b,d là tương đối phức tạp. Thay vào đó, phương pháp được sử\\ndụng là lần lượt tối ưu một trong hai cặp(X,b), (W,d) khi cố định cặp còn lại. Quá trình\\nnày được lặp đi lặp lại tới khi hàm mất mát hội tụ.\\n19.2.3 Tối ưu hàm mất mát\\nKhi cố định cặp(X,b), bài toán tối ưu cặp(W,d) có thể được tách thànhN bài toán nhỏ:\\nL1(wn,dn) = 1\\n2s\\n∑\\nm:rmn=1\\n(xT\\nmwn + bm + dn −ymn)2 + λ\\n2 ∥wn∥2\\nF (19.5)\\nMỗi bài toán có thể được tối ưu bằng gradient descent. Công việc quan trọng của chúng\\nta là tính các đạo hàm của từng hàm mất mát nhỏ này theown và dn. Vì biểu thức trong\\ndấu ∑chỉ phụ thuộc vào cácitem đã được đánh giá bởiuser đang xét (tương ứng với các\\nrmn = 1), ta có thể đơn giản (19.5) bằng cách đặtˆXn là ma trận con được tạo bởi các cột\\ncủa X tương ứng với cácitem đã được đánh giá bởiuser n, ˆbn là vector bias con tương ứng,\\nvà ˆyn là cácrating tương ứng. Khi đó,\\nL1(wn,dn) = 1\\n2s∥ˆXT\\nnwn + ˆbn + dn1 −ˆyn∥2 + λ\\n2 ∥wn∥2\\n2 (19.6)\\nvới 1 là vector với mọi phần tử bằng 1 và kích thước phù hợp. Đạo hàm của nó là\\n∇wnL1 = 1\\ns\\nˆXn( ˆXT\\nnwn + ˆbn + dn1 −ˆyn) + λwn (19.7)\\n∇bnL1 = 1\\ns1T( ˆXT\\nnwn + ˆbn + dn1 −ˆyn) (19.8)\\nCông thức cập nhật chown và dn\\nwn ←wn −η\\n(1\\ns\\nˆXn( ˆXT\\nnwn + ˆbn + dn1 −ˆyn) + λwn\\n)\\n(19.9)\\ndn ←dn −η\\n(1\\ns1T( ˆXT\\nnwn + ˆbn + dn1 −ˆyn)\\n)\\n(19.10)\\nTương tự như thế, mỗi cộtxm của X, tức vector đặc trưng cho mỗiitem, vàbm sẽ được tìm\\nbằng cách tối ưu bài toán\\nL2(xm,bm) = 1\\n2s\\n∑\\nn:rmn=1\\n(wT\\nnxm + dn + bm −ymn)2 + λ\\n2 ∥xm∥2\\n2 (19.11)\\n1 việc chuẩn hoá sẽ được tự động thực hiện thông qua việc huấn luyệnb và d\\n2 Bạn đọc có thể thử cộng thêm∥b∥2\\n2 + ∥d∥2\\n2 vào trong dấu ngoặc của regularization loss. Kết quả có thể thay đổi,\\nnhưng không đáng kể.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 251, 'page_label': '240'}, page_content='CHƯƠNG 19. MATRIX FACTORIZATION COLLABORATIVE FILTERING 240\\nĐặt ˆWm là ma trận được tạo bằng các cột củaW ứng với cácuser đã đánh giáitem m, ˆdm\\nlà vector con bias tương ứng, vàˆym là vectorrating tương ứng. Bài toán (19.11) trở thành\\nL(xm,bm) = 1\\n2s∥ˆWT\\nmxm + ˆdm + bn1 −ˆym∥+ λ\\n2 ∥xm∥2\\n2 (19.12)\\nTương tự như trên, ta có\\nCông thức cập nhật choxm và bm\\nxm ←xm −η\\n(1\\ns\\nˆWm( ˆWT\\nmxm + ˆdm + bn1 −ˆym) + λxm\\n)\\n(19.13)\\nbm ←bm −η\\n(1\\ns1T( ˆWT\\nmxm + ˆdm + bn1 −ˆym)\\n)\\n(19.14)\\nTrong mục tiếp theo, chúng ta sẽ giải quyết bài toán này trên Python.\\n19.3 Lập trình Python\\nTrước hết, chúng ta sẽ viết mộtclass MF thực hiện việc tối ưu các biến với một ma trận\\nutility được cho dưới dạngY_data giống như với NBCF.\\nTrước tiên, ta khai báo một vài thư viện cần thiết và khởi tạoclass MF\\nfrom __future__ import print_function\\nimport pandas as pd\\nimport numpy as np\\nfrom sklearn.metrics.pairwise import cosine_similarity\\nfrom scipy import sparse\\nclass MF(object):\\ndef __init__(self, Y, K, lam = 0.1, Xinit = None, Winit = None,\\nlearning_rate = 0.5, max_iter = 1000, print_every = 100):\\nself.Y = Y # represents the utility matrix\\nself.K = K #\\nself.lam = lam # regularization parameter\\nself.learning_rate = learning_rate # for gradient descent\\nself.max_iter = max_iter # maximum number of iterations\\nself.print_every = print_every # print loss after each a few iters\\nself.n_users = int(np.max(Y[:, 0])) + 1\\nself.n_items = int(np.max(Y[:, 1])) + 1\\nself.n_ratings = Y.shape[0] # number of known ratings\\nself.X = np.random.randn(self.n_items, K) if Xinit is None else Xinit\\nself.W = np.random.randn(K, self.n_users) if Winit is None else Winit\\nself.b = np.random.randn(self.n_items) # item biases\\nself.d = np.random.randn(self.n_users) # user biases\\nTiếp theo, chúng ta viết các phương thứcloss, updateXb, updateWd cho class MF.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 252, 'page_label': '241'}, page_content='241 CHƯƠNG 19. MATRIX FACTORIZATION COLLABORATIVE FILTERING\\ndef loss(self):\\nL = 0\\nfor i in range(self.n_ratings):\\n# user_id, item_id, rating\\nn, m, rating = int(self.Y[i, 0]), int(self.Y[i, 1]), self.Y[i, 2]\\nL += 0.5*(self.X[m].dot(self.W[:, n]) + self.b[m] + self.d[n] - rating)**2\\nL /= self.n_ratings\\n# regularization, don’t ever forget this\\nreturn L + 0.5*self.lam*(np.sum(self.X**2) + np.sum(self.W**2))\\ndef updateXb(self):\\nfor m in range(self.n_items):\\n# get all users who rated item m and get the corresponding ratings\\nids = np.where(self.Y[:, 1] == m)[0] # row indices of items m\\nuser_ids, ratings = self.Y[ids, 0].astype(np.int32), self.Y[ids, 2]\\nWm, dm = self.W[:, user_ids], self.d[user_ids]\\nfor i in range(30): # 30 iteration for each sub problem\\nxm = self.X[m]\\nerror = xm.dot(Wm) + self.b[m] + dm - ratings\\ngrad_xm = error.dot(Wm.T)/self.n_ratings + self.lam*xm\\ngrad_bm = np.sum(error)/self.n_ratings\\n# gradient descent\\nself.X[m] -= self.learning_rate*grad_xm.reshape(-1)\\nself.b[m] -= self.learning_rate*grad_bm\\ndef updateWd(self): # and d\\nfor n in range(self.n_users):\\n# get all items rated by user n, and the corresponding ratings\\nids = np.where(self.Y[:,0] == n)[0] # row indices of items rated by user n\\nitem_ids, ratings = self.Y[ids, 1].astype(np.int32), self.Y[ids, 2]\\nXn, bn = self.X[item_ids], self.b[item_ids]\\nfor i in range(30): # 30 iteration for each sub problem\\nwn = self.W[:, n]\\nerror = Xn.dot(wn) + bn + self.d[n] - ratings\\ngrad_wn = Xn.T.dot(error)/self.n_ratings + self.lam*wn\\ngrad_dn = np.sum(error)/self.n_ratings\\n# gradient descent\\nself.W[:, n] -= self.learning_rate*grad_wn.reshape(-1)\\nself.d[n] -= self.learning_rate*grad_dn\\nPhần tiếp theo là quá trình tối ưu chính của MF (fit), dự đoánrating mới (pred) và đánh\\ngiá chất lượng mô hình bằng root-mean-square error (evaluate_RMSE).\\ndef fit(self):\\nfor it in range(self.max_iter):\\nself.updateWd()\\nself.updateXb()\\nif (it + 1) % self.print_every == 0:\\nrmse_train = self.evaluate_RMSE(self.Y)\\nprint(’iter = %d, loss = %.4f, RMSE train = %.4f’%(it + 1,\\nself.loss(), rmse_train))\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 253, 'page_label': '242'}, page_content='CHƯƠNG 19. MATRIX FACTORIZATION COLLABORATIVE FILTERING 242\\ndef pred(self, u, i):\\n\"\"\"\\npredict the rating of user u for item i\\n\"\"\"\\nu, i = int(u), int(i)\\npred = self.X[i, :].dot(self.W[:, u]) + self.b[i] + self.d[u]# + bias\\nreturn max(0, min(5, pred)) # pred should be between 0 and 5 in MoviesLen\\ndef evaluate_RMSE(self, rate_test):\\nn_tests = rate_test.shape[0] # number of test\\nSE = 0 # squared error\\nfor n in range(n_tests):\\npred = self.pred(rate_test[n, 0], rate_test[n, 1])\\nSE += (pred - rate_test[n, 2])**2\\nRMSE = np.sqrt(SE/n_tests)\\nreturn RMSE\\nTới đây, chúng ta đã xây dựng trong classMF với các phương thức cần thiết. Tiếp theo, chúng\\nta kiểm tra chất lượng mô hình khi nó được áp dụng lên tập dữ liệu MoviesLen 100k.\\nr_cols = [’user_id’, ’movie_id’, ’rating’, ’unix_timestamp’]\\nratings_base = pd.read_csv(’ml-100k/ua.base’, sep=’\\\\t’, names=r_cols)\\nratings_test = pd.read_csv(’ml-100k/ua.test’, sep=’\\\\t’, names=r_cols)\\nrate_train = ratings_base.as_matrix()\\nrate_test = ratings_test.as_matrix()\\n# indices start from 0\\nrate_train[:, :2] -= 1\\nrate_test[:, :2] -= 1\\nrs = MF(rate_train, K = 50, lam = .01, print_every = 5, learning_rate = 50,\\nmax_iter = 30)\\nrs.fit()\\n# evaluate on test data\\nRMSE = rs.evaluate_RMSE(rate_test)\\nprint(’\\\\nMatrix Factorization CF, RMSE = %.4f’ %RMSE)\\nKết quả:\\niter = 5, loss = 0.4447, RMSE train = 0.9429\\niter = 10, loss = 0.4215, RMSE train = 0.9180\\niter = 15, loss = 0.4174, RMSE train = 0.9135\\niter = 20, loss = 0.4161, RMSE train = 0.9120\\niter = 25, loss = 0.4155, RMSE train = 0.9114\\niter = 30, loss = 0.4152, RMSE train = 0.9110\\nMatrix Factorization CF, RMSE = 0.9621\\nRMSE thu được là 0.9621, tốt hơn so với NBCF trong chương trước (0.9688).\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 254, 'page_label': '243'}, page_content='243 CHƯƠNG 19. MATRIX FACTORIZATION COLLABORATIVE FILTERING\\n19.4 Thảo luận\\n• Nonnegative matrix factorization. Khi dữ liệu chưa được chuẩn hoá, chúng đều mang\\ncác giá trị không âm. Kể cả trong trường hợp dải giá trị củarating có chứa giá trị âm,\\nta chỉ cần cộng thêm vào ma trận utility một giá trị hợp lý để có được cácrating là các\\nsố không âm. Khi đó, một phương pháp matrix factorization khác với thêm ràng buộc\\ncũng được sử dụng rất nhiều và mang lại hiệu quả cao trong recommendation system là\\nnonnegative matrix factorization(NMF) [ZWFM06], tức phân tích ma trận thành tích\\ncác ma trận có các phần tử không âm.\\nThông qua matrix factorization, cácuser vàitem được liên kết với nhau bởi cácđặc trưng\\nẩn. Độ liên kết của mỗiuser và item tới mỗi đặc trưng ẩn được đo bằng thành phần\\ntương ứng trong vector đặc trung của chúng, giá trị càng lớn thể hiện việcuser hoặc item\\ncó liên quan đến đặc trưng ẩn đó càng lớn. Bằng trực giác, sự liên quan của mộtuser\\nhoặc item đến một đặc trưng ẩn nên là một số không âm với giá trị 0 thể hiện việckhông\\nliên quan. Hơn nữa, mỗiuser và item chỉ liên quanđến một vài đặc trưng ẩn nhất định.\\nVì vậy, các vector đặc trưng chouser vàitem nên là các vector không âm và có rất nhiều\\ngiá trị bằng 0. Những nghiệm này có thể đạt được bằng cách cho thêm ràng buộc không\\nâm vào các thành phần củaX và W. Đây chính là nguồn gốc của ý tưởng và tên gọi\\nnonnegative matrix factorization.\\n• Incremental matrix factorization. Như đã đề cập, thời gian dự đoán của một recom-\\nmendation system sử dụng matrix factorization là rất nhanh nhưng thời gian huấn luyện\\nlà khá lâu với các tập dữ liệu lớn. Thực tế cho thấy, ma trận utility thay đổi liên tục vì có\\nthêm user, item cũng như cácrating mới hoặcuser muốn thay đổirating của họ, vì vậy\\ncác tham số mô hình cũng phải thường xuyên được cập nhật. Điều này đồng nghĩa với\\nviệc ta phải tiếp tục thực hiện quá trìnhtraining vốn tốn khá nhiều thời gian. Việc này\\nđược giải quyết phần nào bằngincremental matrix factorization[VJG14]. Từincremental\\ncó thể được hiểu làđiều chỉnh nhỏcho phù hợp với dữ liệu.\\n• Bài toán tối ưu của matrix factorization có nhiều hướng giải quyết khác ngoài cách\\náp dụng gradient descent. Bạn đọc có thể xem thêmAlternating Least Square (ALS)\\n(https://goo.gl/g2M4fb ), Generalized Low Rank Models(https://goo.gl/DrDWyW ), và\\nSingular Value Decomposition[SKKR02,Pat07]. Chương 20 sẽ bàn kỹ hơn về Singular\\nValue Decomposition.\\n• Source code trong chương này có thể được tìm thấy tạihttps://goo.gl/XbbFH4 .\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 255, 'page_label': '244'}, page_content=''),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 256, 'page_label': '245'}, page_content='Phần VI\\nDimensionality reduction–Giảm chiều dữ liệu\\nSố lượng điểm dữ liệu và kích thước của các vector đặc trưng thường rất lớn trong các bài\\ntoán thực tế. Nếu thực hiện lưu trữ và tính toán trực tiếp trên dữ liệu có số chiều cao\\nnày thì sẽ gặp khó khăn cả về việc lưu trữ và tốc độ tính toán. Vì vậy,giảm chiều dữ liệu\\n(dimensionality reduction hoặc dimension reduction) là một bước quan trọng trong nhiều\\nbài toán machine learning.\\nMột cách toán học, giảm chiều dữ liệu là việc đi tìm một hàm sốf : RD →RK với K <D\\nbiến một điểm dữ liệux trong không gian có số chiều lớnRD thành một điểmz trong không\\ngian có số chiều nhỏ hơnRD. Việc giảm chiều dữ liệu có thể được thực hiện nhằm vào các\\nmục đích khác nhau. Nó có thể phục vụ việcnén thông tin sao chox có thể được suy ngược\\nlại (xấp xỉ) từz. Nó cũng có thể phục vụ các bài toán phân lớp bằng cách chọn ra những đặc\\ntrưng quan trọng (feature selection) hoặc tạo ra các đặc trưng mới từ đặc trưng cũ (feature\\nextraction) sao cho kết quả của bài toán phân lớp được cải thiện.\\nTrong nhiều trường hợp, làm việc trên dữ liệu được giảm chiều cho kết quả tốt hơn dữ liệu\\ntrong không gian ban đầu.\\nTrong phần này, chúng ta sẽ xem xét các phương pháp giảm chiều dữ liệu phổ biến nhất:\\nprinciple component analysischo bài toán giảm chiều dữ liệu vẫn giữ được tối đa lượng thông\\ntin, vàlinear discriminant analysischo bài toán giữ lại những đặc trưng quan trọng nhất\\ncho việc phân lớp. Trước hết, chúng ta cùng tìm hiểu một phương pháp phân tích ma trận\\nthành nhân tử vô cùng quan trọng –singular value decomposition.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 257, 'page_label': '246'}, page_content='Chương 20\\nSingular value decomposition\\n20.1 Giới thiệu\\nNhắc lại bài toán chéo hoá ma trận: Một ma trận vuôngA ∈Rn×n được gọi làchéo hoá\\nđược (diagonalizable) nếu tồn tại ma trận đường chéoD và ma trận khả nghịchP sao cho:\\nA = PDP−1 (20.1)\\nSố lượng phần tử khác 0 của ma trận đường chéoD chính là rank của ma trậnA.\\nNhân cả hai vế của (20.1) vớiP ta có:\\nAP = PD (20.2)\\nGọi pi,di lần lượt là cột thứi của ma trậnP và D. Vì mỗi một cột của vế trái và vế phải\\ncủa (20.2) phải bằng nhau, ta cần có\\nApi = Pdi = diipi (20.3)\\nvới dii là phần tử thứicủa di. Dấu bằng thứ hai xảy ra vìD là ma trận đường chéo, tứcdi\\nchỉ có thành phầndii là khác 0. Biểu thức (20.3) chỉ ra rằng mỗi phần tửdii phải là một trị\\nriêng củaA và mỗi vector cộtpi phải là một vector riêng củaA ứng với trị riêngdii.\\nCách phân tích một ma trận vuông thành nhân tử như (20.1) còn được gọi làEigen Decom-\\nposition. Một điểm quan trọng là cách phân tích này chỉ được áp dụng với ma trận vuông\\nvà không phải lúc nào cũng tồn tại. Nó chỉ tồn tại nếu ma trậnA có nvector riêng độc lập\\ntuyến tính, vì nếu không thì không tồn tại ma trậnP khả nghịch. Thêm nữa, cách phân tích\\nnày cũng không phải là duy nhất vì nếuP,D thoả mãn (20.1) thìkP,D cũng thoả mãn với\\nk là một số thực khác 0 bất kỳ.\\nViệc phân tích một ma trận ra thành tích của nhiều ma trận đặc biệt khác (matrix factor-\\nization hoặc matrix decomposition) mang lại nhiều ích lợi quan trọng mà các bạn sẽ thấy:'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 258, 'page_label': '247'}, page_content='247 CHƯƠNG 20. SINGULAR VALUE DECOMPOSITION\\ngiảm số chiều dữ liệu, nén dữ liệu, tìm hiểu các đặc tính của dữ liệu, giải các hệ phương\\ntrình tuyến tính, clustering, và nhiều ứng dụng khác. Hệ thống khuyến nghị cũng là một\\ntrong rất nhiều ứng dụng của matrix factorization.\\nTrong chương này, chúng ta sẽ làm quen với một trong những phương pháp matrix factor-\\nization rất đẹp của đại số tuyến tính có tên làsingular value decomposition(SVD) [GR70].\\nCác bạn sẽ thấy, mọi ma trận, không nhất thiết là vuông, đều có thể được phân tích thành\\ntích của ba ma trận đặc biệt.\\n20.2 Singular value decomposition\\nĐể hạn chế nhầm lẫn trong các phép toán nhân ma trận, chúng ta cần để ý tới kích thước\\ncủa mỗi ma trận. Trong chương này, ta sẽ ký hiệu một ma trận cùng với số chiều của nó, ví\\ndụ Am×n dùng để ký hiệu một ma trậnA ∈Rm×n.\\n20.2.1 Phát biểu SVD\\nSingular value decomposition\\nMột ma trậnAm×n bất kỳ đều có thể phân tích thành dạng:\\nAm×n = Um×mΣm×n(Vn×n)T (20.4)\\nTrong đó,U,V là các ma trận trực giao,Σ là một ma trận đường chéo cùng kích\\nthước vớiA. Các phần tử trên đường chéo chính củaΣ là không âm và được theo thứ\\ntự giảm dầnσ1 ≥σ2 ≥···≥ σr ≥0 = 0 = ··· = 0. Số lượng các phần tử khác 0 trong\\nΣ chính là rank của ma trậnA: r= rank(A).\\nSVD của một ma trận bất ký luôn tồn tại. Bạn đọc có thể tìm thấy chứng minh cho việc\\nnày tạihttps://goo.gl/TdtWDQ . Cách biểu diễn (20.4) không là duy nhất vì ta chỉ cần đổi\\ndấu của cảU và V thì (20.4) vẫn thoả mãn.\\nHình 20.1 mô tả SVD của ma trậnAm×n trong hai trường hợp:m < nvà m > n. Trường\\nhợp m= n có thể xếp vào một trong hai trường hợp trên.\\n20.2.2 Nguồn gốc tên gọi singular value decomposition\\nTạm bỏ qua chiều của mỗi ma trận, từ (20.4) ta có:\\nAAT = UΣVT(UΣVT)T (20.5)\\n= UΣVTVΣTUT (20.6)\\n= UΣΣTUT = UΣΣTU−1 (20.7)\\nDấu bằng ở (20.6) xảy ra vìVTV = I do V là một ma trận trực giao. Dấu bằng ở (20.7)\\nxảy ra vìU là một ma trận trực giao.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 259, 'page_label': '248'}, page_content='CHƯƠNG 20. SINGULAR VALUE DECOMPOSITION 248\\nAm×n = ×Um×m ... Σm×n ×\\nVT\\nn×n\\n(a) (m < n)\\n(b) (m > n)\\nAm×n\\n= ×\\nUm×m\\n...\\nΣm×n\\n× VT\\nn×n\\nHình 20.1: SVD cho ma trậnA khi: m < n(hình trên), vàm > n(hình dưới).Σ là một ma\\ntrận đường chéo với các phần tử trên đó giảm dần và không âm. Màu đỏ càng đậm thể hiện giá\\ntrị càng cao. Các ô màu trắng trên ma trận này thể hiện giá trị 0.\\nQuan sát thấy rằngΣΣT là một ma trận đường chéo với các phần tử trên đường chéo là\\nσ2\\n1,σ2\\n2,... . Vậy (20.7) chính là một eigen decomposition củaAAT. Thêm nữa, σ2\\n1,σ2\\n2,...\\nchính là các trị riêng củaAAT. Ma trậnAAT luôn là ma trận nửa xác định dương nên các\\ntrị riêng của nó là không âm. Cácσi, là căn bậc hai của các trị riêng củaAAT, còn được\\ngọi làsingular value của A. Tên gọisingular value decompositionxuất phát từ đây.\\nCũng theo đó, mỗi cột củaU chính là một vector riêng củaAAT. Ta gọi mỗi cột này là một\\nleft-singular vectorcủa A. Tương tự như thế,ATA = VΣTΣVT và các cột củaV còn được\\ngọi là cácright-singular vectorscủa A.\\nTrong Python, để tính SVD của một ma trận, chúng ta sử dụng modulelinalg của numpy:\\nfrom __future__ import print_function\\nimport numpy as np\\nfrom numpy import linalg as LA\\nm, n = 3, 4\\nA = np.random.rand(m, n)\\nU, S, V = LA.svd(A) # A = U*S*V (no V transpose here)\\n# checking if U, V are orthogonal and S is a diagonal matrix with\\n# nonnegative decreasing elements\\nprint(’Frobenius norm of (UU^T - I) =’, LA.norm(U.dot(U.T) - np.eye(m)))\\nprint(’S = ’, S)\\nprint(’Frobenius norm of (VV^T - I) =’, LA.norm(V.dot(V.T) - np.eye(n)))\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 260, 'page_label': '249'}, page_content='249 CHƯƠNG 20. SINGULAR VALUE DECOMPOSITION\\nKết quả:\\nFrobenius norm of (UU^T - I) = 4.09460889695e-16\\nS = [ 1.76321041 0.59018069 0.3878011 ]\\nFrobenius norm of (VV^T - I) = 5.00370755311e-16\\nLưu ý rằng biếnS được trả về chỉ bao gồm các phần tử trên đường chéo củaΣ. BiếnV trả\\nvề làVT trong (20.4).\\n20.2.3 Singular value của một ma trận nửa xác định dương\\nGiả sửA là một ma trận đối xứng vuông nửa xác định dương, ta sẽ chứng minh rằng các\\nsingular value củaA chính là các trị riêng của nó. Thật vậy, gọiλlà một trị riêng củaA và\\nx là một vector riêng ứng với trị riêng đó, hơn nữa∥x∥2 = 1. VìA là nửa xác định dương,\\nta phải cóλ≥0. Ta có\\nAx = λx ⇒ATAx = λAx = λ2x (20.8)\\nNhư vậy,λ2 là một trị riêng củaATA ⇒singular value củaA chính là\\n√\\nλ2 = λ.\\n20.2.4 Compact SVD\\nViết lại biểu thức (20.4) dưới dạng tổng của các ma trận có rank bằng 1:\\nA = σ1u1vT\\n1 + σ2u2vT\\n2 + ··· + σrurvT\\nr (20.9)\\nvới chú ý rằng mỗiuivT\\ni ,1 ≤i≤r, là một ma trận có rank bằng 1.\\nRõ ràng trong cách biểu diễn này, ma trậnA chỉ phụ thuộc vàor cột đầu tiên củaU,V và\\nr giá trị khác 0 trên đường chéo của ma trậnΣ. Vì vậy ta có một cách phân tíchgọn hơn\\nvà gọi làcompact SVD:\\nA = UrΣr(Vr)T (20.10)\\nvới Ur,Vr lần lượt là ma trận được tạo bởir cột đầu tiên củaU và V. Σr là ma trận con\\nđược tạo bởir hàng đầu tiên vàr cột đầu tiên củaΣ. Nếu ma trậnA có rank nhỏ hơn rất\\nnhiều so với số hàng và số cộtr≪m,n, ta sẽ được lợi nhiều về việc lưu trữ.\\nDưới đây là ví dụ minh hoạ vớim= 4,n = 6,r = 2.\\n20.2.5 Truncated SVD\\nNhắc lại rằng trong ma trận Σ, các giá trị trên đường chéo là không âm và giảm dần\\nσ1 ≥σ2 ≥..., ≥σr ≥0 = 0 = ··· = 0. Thông thường, chỉ một lượng nhỏ cácσi mang giá\\ntrị lớn, các giá trị còn lại thường nhỏ và gần 0. Khi đó ta có thể xấp xỉ ma trậnA bằng tổng\\ncủa k <rma trận có rank 1:\\nA ≈Ak = UkΣk(Vk)T = σ1u1vT\\n1 + σ2u2vT\\n2 + ··· + σkukvT\\nk (20.11)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 261, 'page_label': '250'}, page_content='CHƯƠNG 20. SINGULAR VALUE DECOMPOSITION 250\\nA\\n=\\nU r Σ r ( V r )\\nT\\nσ 1 u 1 v\\nT\\n1\\n+=\\nσ 2 u 2 v\\nT\\n2\\nHình 20.2: Biểu diễn SVD dạng thu gọn và biểu diễn ma trận dưới dạng tổng các ma trận có\\nrank bằng 1. Các khối ma trận đặt cạnh nhau thể hiện phép nhân ma trận.\\nDưới đây là một định lý thú vị. Định lý này nói rằng sai số do cách xấp xỉ trên chính là căn\\nbậc hai của tổng bình phương của các singular value mà ta đã bỏ qua ở phần cuối củaΣ. Ở\\nđây sai số được định nghĩa là Frobineous norm của hiệu hai ma trận.\\nĐịnh lý 20.1: Sai số do xấp xỉ bởi truncated SVD\\nNếu xấp xỉ một ma trậnA có rankr bởi truncated SVD vớik <rphần tử, sai số do\\ncách xấp xỉ này là\\n∥A −Ak∥2\\nF =\\nr∑\\ni=k+1\\nσ2\\ni (8) (20.12)\\nChứng minh: Sử dụng tính chất∥X∥2\\nF = trace(XXT) và trace(XY) = trace(YX) với mọi\\nma trậnX,Y ta có\\n∥A −Ak∥2\\nF =\\n\\ued79\\ued79\\ued79\\ued79\\ued79\\nr∑\\ni=k+1\\nσiuivT\\ni\\n\\ued79\\ued79\\ued79\\ued79\\ued79\\n2\\nF\\n= trace\\n\\uf8f1\\n\\uf8f2\\n\\uf8f3\\n( r∑\\ni=k+1\\nσiuivT\\ni\\n)( r∑\\nj=k+1\\nσjujvT\\nj\\n)T\\n\\uf8fc\\n\\uf8fd\\n\\uf8fe(20.13)\\n= trace\\n{ r∑\\ni=k+1\\nr∑\\nj=k+1\\nσiσjuivT\\ni vjuT\\nj\\n}\\n= trace\\n{ r∑\\ni=k+1\\nσ2\\niuiuT\\ni\\n}\\n(20.14)\\n= trace\\n{ r∑\\ni=k+1\\nσ2\\niuT\\ni ui\\n}\\n(20.15)\\n= trace\\n{ r∑\\ni=k+1\\nσ2\\ni\\n}\\n=\\nr∑\\ni=k+1\\nσ2\\ni (20.16)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 262, 'page_label': '251'}, page_content='251 CHƯƠNG 20. SINGULAR VALUE DECOMPOSITION\\nDấu bằng thứ hai ở (20.14) xảy ra vìV có các cột vuông góc với nhau. Dấu bằng ở (20.15)\\nxảy ra vì hàm trace có tính chất giao hoán. Dấu bằng ở (20.16) xảy ra vì biểu thức trong\\ndấu ngoặc là một số vô hướng. □\\nThay k= 0 ta sẽ có\\n∥A∥2\\nF =\\nr∑\\ni=1\\nσ2\\ni (20.17)\\nTừ đó\\n∥A −Ak∥2\\nF\\n∥A∥2\\nF\\n=\\n∑r\\ni=k+1 σ2\\ni∑r\\nj=1 σ2\\nj\\n(20.18)\\nNhư vậy,sai số do xấp xỉ càng nhỏ nếu các singular value bịtruncated có giá trị\\ncàng nhỏ so với các singular value được giữ lại.Đây là một định lý quan trọng giúp\\nxác định việc xấp xỉ ma trận dựa trên lượng thông tin muốn giữ lại. Với giả sử rằnglượng\\nthông tin được định nghĩa là tổng bình phương của các singular value. Ví dụ, nếu ta muốn\\ngiữ lại ít nhất 90% lương thông tin trongA, trước hết ta tính∑r\\nj=1 σ2\\nj, sau đó chọnk là số\\nnhỏ nhất sao cho ∑k\\ni=1 σ2\\ni∑r\\nj=1 σ2\\nj\\n≥0.9 (20.19)\\nKhi k nhỏ, ma trậnAk có rank làk, là một ma trận có rank nhỏ. Vì vậy, Truncated SVD\\ncòn được coi là một phương pháplow-rank approximation.\\n20.2.6 Xấp xỉ rankk tốt nhất\\nNgười ta chứng minh được rằng1 Ak chính là nghiệm của bài toán tối ưu sau đây:\\nmin\\nB\\n∥A −B∥F\\nthoả mãn: rank(B) = k\\n(20.20)\\nvà như đã chứng minh ở trên∥A −Ak∥2\\nF = ∑r\\ni=k+1 σ2\\ni.\\nNếu sử dụngℓ2 norm của ma trận (xem Phụ lục A) thay vì Frobenius norm để đo sai số,Ak\\ncũng là nghiệm của bài toán tối ưu\\nmin\\nB\\n∥A −B∥2\\nthoả mãn: rank(B) = k\\n(20.21)\\nvà sai số∥A −Ak∥2\\n2 = σ2\\nk+1. Trong đó, norm 2 của một ma trận được định nghĩa bởi\\n∥A∥2 = max\\n∥x∥2=1\\n∥Ax∥2 (20.22)\\nFrobenius norm vàℓ2 norm là hai norm được sử dụng nhiều nhất trong ma trận. Như vậy,\\nxét trên cả hai norm này, truncated SVD đều cho xấp xỉ tốt nhất. Vì vậy, truncated SVD\\ncòn được coi làxấp xỉ rank thấp tốt nhất(best low-rank approximation).\\n1 Singular Value Decomposition – Princeton (https://goo.gl/hU38GF ).\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 263, 'page_label': '252'}, page_content='CHƯƠNG 20. SINGULAR VALUE DECOMPOSITION 252\\n(a)\\n0 200 400 600 800 1000\\nk\\n101\\n102\\n103\\n104\\n105\\nσk (b)\\n0 200 400 600 800 1000\\nk\\n0.875\\n0.900\\n0.925\\n0.950\\n0.975\\n1.000\\n∥A − Ak∥2\\nF /∥A∥2\\nF (c)\\nk = 5: error = 0.0448\\n(d)\\nk = 50: error = 0.0059 (e)\\nk = 100: error = 0.0026 (f)\\nHình 20.3: Ví dụ về SVD cho ảnh. (a) Bức ảnh gốc là một ảnh xám, là một ma trận cỡ\\n960 ×1440. (b) Giá trị của các singular values của ma trận ảnh theo logscale. Có thể thấy rằng\\ncác singular value giảm nhanh ở khoảngk= 200. (c) Biểu diễn lượng thông tin được giữ lại khi\\nchọn cáck khác nhau. Có thể nhận thấy từ khoảngk= 200, lượng thông tin giữ lại là gần bằng\\n1. Vậy ta có thể xấp xỉ ma trận ảnh này bằng một ma trận có rank nhỏ hơn. (d), (e), (f) Các\\nảnh xấp xỉ vớik lần lượt là 5, 50, 100.\\n20.3 SVD cho image compression\\nXét ví dụ trong Hình 20.3. Bức ảnh gốc trong Hình 20.3a là một ảnh xám có kích thước\\n960 ×1440 pixel. Bức ảnh này có thể được coi là một ma trậnA ∈R960×1440. Ta có thể quan\\nsát thấy rằng ma trận này làlow-rank vì rất nhiềutầng của toà nhà nhìn tương tự nhau.\\nHình 20.3b là giá trị của các singular value của bức ảnh được sắp xếp theo thứ tự giảm dần.\\nChú ý rằng giá trị của các singular value được biểu diễn trên thang log10 nên các giá trị\\nsingular đầu tiên rất lớn so với các giá trị singular ở cuối. Hình 20.3c mô tả chất lượng của\\nviệc xấp xỉA bởi Ak bằng truncated SVD. Ta cũng thấy rằng giá trị này xấp xỉ bằng 1 tại\\nk = 200. Hình 20.3d, 20.3e, 20.3f là các bức ảnh xấp xỉ khi chọn các giá trịk khác nhau.\\nKhi k gần 100, lượng thông tin mất đi rơi vào khoảng nhỏ hơn 3%, ảnh thu được có chất\\nlượng gần như ảnh gốc.\\nĐể lưu ảnh với truncated SVD, ta sẽ lưu các ma trậnUk ∈Rm×k,Σk ∈Rk×k,Vk ∈Rn×k.\\nTổng số phần tử phải lưu làk(m+ n+ 1) với chú ý rằng ta chỉ cần lưu các giá trị trên đường\\nchéo củaΣk. Giả sử mỗi phần tử được lưu bởi một số thực bốn byte, thế thì số byte cần lưu\\ntrữ là4k(m+ n+ 1). Nếu so giá trị này với ảnh gốc có kích thướcmn, mỗi giá trị là một số\\nnguyên một byte, tỉ lệ nén là\\n4k(m+ n+ 1)\\nmn (20.23)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 264, 'page_label': '253'}, page_content='253 CHƯƠNG 20. SINGULAR VALUE DECOMPOSITION\\nKhi k ≪m,n, ta được một tỉ lệ nhỏ hơn 1. Trong ví dụ trên,m= 960,n = 1440,k = 100,\\ntỉ lệ nén là xấp xỉ 0.69, tức đã tiết kiệm được khoảng 30% bộ nhớ.\\n20.4 Thảo luận\\n• Ngoài ứng dụng nêu trên, SVD còn được ứng dụng trong việc giải phương trình tuyến\\ntính thông qua giả nghịch đảo Moore Penrose (https://goo.gl/4wrXue ), recommendation\\nsystem [SKKR00], dimensionality reduction [Cyb89], image debluring [HNO06], cluster-\\ning [DFK+04], v.v..\\n• Khi ma trậnA lớn, việc tính toán SVD của nó tốn nhiều thời gian. Cách tính Truncated\\nSVD vớik nhỏ bằng cách tính SVD như được sử dụng trở nên không khả thi. Thay vào\\nđó, có một phương pháp lặp giúp tính các trị riêng và vector riêng của một ma trận lớn\\nmột cách hiệu quả, và ta chỉ cần tìmk trị riêng lớn nhất củaAAT và các vector riêng\\ntương ứng, việc này sẽ tiết kiệm được khá nhiều thời gian. Bạn đọc có thể tìm đọc thêm\\nPower method for approximating eigenvalues(https://goo.gl/PfDqsn ).\\n• Source code trong chương này có thể được tìm thấy tạihttps://goo.gl/Z3wbsU .\\nĐọc thêm\\n1. Singular Value Decomposition - Stanford University(https://goo.gl/Gp726X ).\\n2. Singular Value Decomposition - Princeton(https://goo.gl/HKpcsB ).\\n3. CS168: The Modern Algorithmic Toolbox Lecture #9: The Singular Value Decomposition\\n(SVD) and Low-Rank Matrix Approximations - Stanford(https://goo.gl/RV57KU ).\\n4. The Moore-Penrose Pseudoinverse (Math 33A - UCLA)(https://goo.gl/VxMYx1 ).\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 265, 'page_label': '254'}, page_content='Chương 21\\nPrincipal component analysis\\n21.1 Principal component analysis\\n21.1.1 Ý tưởng\\nGiả sử dữ liệu ban đầu làx ∈RD và dữ liệu đã được giảm chiều làz ∈RK với K < D.\\nCách đơn giản nhất để giảm chiều dữ liệu từD về K < Dlà chỉ giữ lạiK phần tử quan\\ntrọng nhất. Có hai câu hỏi lập tức được đặt ra ở đây. Thứ nhất, làm thế nào để xác định\\ntầm quan trọngcủa mỗi chiều dữ liệu? Thứ hai, nếu tầm quan trọng của các chiều dữ liệu\\nlà như nhau, ta cần bỏ đi những chiều nào?\\nĐể trả lời câu hỏi thứ nhất, ta hãy quan sát Hình 21.1a. Giả sử các điểm dữ liệu có thành\\nphần thứ hai (phương đứng) giống hệt nhau hoặc sai khác nhau rất ít (phương sai nhỏ). Như\\nvậy, thành phần này hoàn toàn có thể được lược bỏ đi, và ta ngầm hiểu rằng nó sẽ được xấp\\nxỉ bằng kỳ vọng của thành phần đó trên toàn bộ các điểm dữ liệu. Ngược lại, việc làm này\\nnếu được áp dụng lên thành phần thứ nhất (phương ngang) sẽ khiếnlượng thông tinbị mất\\nđi rất nhiều do sai số xấp xỉ là quá lớn. Lượng thông tin theo mỗi thành phần, vì vậy, có thể\\nđược đo bằng phương sai của dữ liệu trên thành phần đó. Tổng lượng thông tin có thể được\\ncoi là tổng phương sai trên toàn bộ các thành phần. Lấy một ví dụ về việc có hai camera\\nđược đặt dùng để chụp một con người, một camera đặt phía trước người và một camera đặt\\ntrên đầu. Rõ ràng, hình ảnh thu được từ camera đặt phía trước người mang nhiều thông tin\\nhơn so với hình ảnh nhìn từ phía trên đầu. Vì vậy, bức ảnh chụp từ phía trên đầu có thể\\nđược bỏ qua mà không có quá nhiều thông tin về hình dáng của người đó bị mất.\\nCâu hỏi thứ hai tương ứng với trường hợp Hình 21.1b. Trong cả hai chiều, phương sai của\\ndữ liệu đều lớn; việc bỏ đi một trong hai chiều đều dẫn đến việc lượng thông tin bị mất đi\\nlà lớn. Tuy nhiên, quan sát ban đầu của chúng ta là nếu xoay trục toạ độ đi một góc phù\\nhợp, một trong hai chiều dữ liệu có thể được giảm đi vì dữ liệu có xu hướng phân bố xung\\nquanh một đường thẳng.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 266, 'page_label': '255'}, page_content='255 CHƯƠNG 21. PRINCIPAL COMPONENT ANALYSIS\\nσ1\\nσ2 e1\\ne2\\n(a)\\ne1\\ne2\\nσ1\\nσ2\\n(b)\\nHình 21.1: Ví dụ về phương sai của dữ liệu trong không gian hai chiều. (a) Chiều thứ hai có\\nphương sai (tỉ lệ với độ rộng của đường hình chuông) nhỏ hơn chiều thứ nhất. (b) Cả hai chiều\\ncó phương sai đáng kể. Phương sai của mỗi chiều là phương sai của thành phần tương ứng được\\nlấy trên toàn bộ dữ liệu. Phương sai tỉ lệ thuận với độ phân tán của dữ liệu.\\nX\\nOriginal data\\nN\\nD = U K ˆU K\\nAn orthogonal matrix\\nK D − K\\nD ×\\nZ\\nY\\nCoordinates in new basis\\nN\\nK\\nD − K\\nU K\\nK\\nD\\n×= Z\\nN\\nK +\\nˆU KD\\n× Y\\nHình 21.2: Ý tưởng chính của PCA: Tìm một hệ trực chuẩn mới sao cho trong hệ này, các\\nthành phần quan trọng nhất nằm trongK thành phần đầu tiên.\\nPrinciple component analysis (PCA) là một phương pháp đi tìm một phép xoay trục toạ độ\\nđể được một hệ trục toạ độ mới sao cho trong hệ mới này, thông tin của dữ liệu chủ yếu tập\\ntrung ở một vài thành phần. Phần còn lại chưa ít thông tin hơn có thể được lược bỏ.\\nPhép xoay trục toạ độ có liên hệ chặt chẽ tới hệ trực chuẩn và ma trận trực giao (xem\\nMục 1.9 và 1.10). Giả sử hệ cơ sở trực chuẩn mới làU (mỗi cột củaU là một vector đơn\\nvị cho một chiều) và chúng ta muốn giữ lạiK toạ độ trong hệ cơ sở mới này. Không mất\\ntính tổng quát, giả sử đó làK thành phần đầu tiên. Quan sát Hình 21.2 với cơ sở mới\\nU = [UK, ˆUK]là một hệ trực chuẩn vớiUK là ma trận con tạo bởiK cột đầu tiên củaU.\\nVới cơ sở mới này, ma trận dữ liệu có thể được viết thành\\nX = UKZ + ˆUKY (21.1)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 267, 'page_label': '256'}, page_content='CHƯƠNG 21. PRINCIPAL COMPONENT ANALYSIS 256\\nTừ đây ta cũng suy ra\\n[Z\\nY\\n]\\n=\\n[UT\\nK\\nˆUT\\nK\\n]\\nX ⇒ Z = UT\\nKX\\nY = ˆUT\\nKX (21.2)\\nMục đích của PCA là đi tìm ma trận trực giaoU sao cho phần lớn thông tin được giữ lại\\nở phần màu xanhUKZ và phần màu đỏˆUKY sẽ được lược bỏ và thay bằng một ma trận\\nkhông phụ thuộc vào từng điểm dữ liệu. Cụ thể, ta sẽ xấp xỉY bởi một ma trận có toàn bộ\\ncác cột là như nhau.Chú ý rằng các cột này có thể phụ thuộc vào dữ liệu huấn luyện nhưng\\nkhông phụ thuộc vào dữ liệu kiểm thử.Gọi mỗi cột đó làb và có thể coi nó là bias, khi đó,\\nta sẽ xấp xỉY ≈b1T, trong đó1T ∈R1×N là một vector hàng có toàn bộ các phần tử bằng\\n1. Giả sử đã tìm đượcU, ta cần tìmb thoả mãn:\\nb = argminb∥Y −b1T∥2\\nF = argminb∥ˆUT\\nKX −b1T∥2\\nF (21.3)\\nGiải phương trình đạo hàm theob của hàm mục tiêu bằng0:\\n(b1T −ˆUT\\nKX)1 = 0 ⇒Nb = ˆUT\\nKX1 ⇒b = ˆUT\\nKx (21.4)\\nở đây ta đã sử dụng1T1 = N và x = 1\\nNX1 là vector trung bình của toàn bộ các cột củaX.\\nVới giá trịb tìm được này, dữ liệu ban đầu sẽ được xấp xỉ bởi\\nX = UKZ + ˆUkY ≈UKZ + ˆUkb1T = UKZ + ˆUK ˆUT\\nK¯x1T ≜˜X (21.5)\\n21.1.2 Hàm mất mát\\nHàm mất mát của PCA có thể được coi như sai số của phép xấp xỉ, và được định nghĩa là\\n1\\nN∥X −˜X∥2\\nF = 1\\nN∥ˆUKY −ˆUK ˆUT\\nKx1T∥2\\nF = 1\\nN∥ˆUK ˆUT\\nKX −ˆUK ˆUT\\nK¯x1T∥2\\nF\\n= 1\\nN∥ˆUkˆUT\\nk(X −x1T)∥2\\nF ≜J (21.6)\\nChú ý rằng, nếu các cột của một ma trậnV bất kỳ tạo thành một hệ trực chuẩn thì với một\\nma trậnW bất kỳ, ta luôn có\\n∥VW∥2\\nF = trace(WTVTVW) = trace(WTW) = ∥W∥2\\nF (21.7)\\nĐặt ˆX = X −x1T. Ma trận này có được bằng cách trừ mỗi cột (mỗi điểm dữ liệu) củaX\\nđi trung bình các cột của nó. Ta gọi ma trận nàyˆX là zero-corrected datahoặc dữ liệu đã\\nđược chuẩn hoá. Có thể nhận thấyˆxn = xn −¯xj, ∀n= 1,2,...,N .\\nVì vậy hàm mất mát trong (21.6) có thể được viết lại thành:\\nJ = 1\\nN∥ˆUT\\nK ˆX∥2\\nF = 1\\nN∥ˆXT ˆUK∥2\\nF = 1\\nN\\nD∑\\ni=K+1\\n∥ˆXTui∥2\\n2 (21.8)\\n= 1\\nN\\nD∑\\ni=K+1\\nuT\\ni ˆXˆXTui =\\nD∑\\ni=K+1\\nuT\\ni Sui (21.9)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 268, 'page_label': '257'}, page_content='257 CHƯƠNG 21. PRINCIPAL COMPONENT ANALYSIS\\nvới S = 1\\nN\\nˆXˆXT là ma trận hiệp phương sai của dữ liệu và luôn là một ma trận nửa xác định\\ndương (xem Mục 3.1.7).\\nCông việc còn lại là tìm cácui để mất mát là nhỏ nhất. Trước hết, chúng ta có một nhận\\nxét thú vị. Với ma trậnU trực giao bất kỳ, thayK = 0 vào (21.9) ta có\\nL=\\nD∑\\ni=1\\nuT\\ni Sui = 1\\nN∥ˆXTU∥2\\nF = 1\\nNtrace( ˆXTUUT ˆX) (21.10)\\n= 1\\nNtrace( ˆXT ˆX) = 1\\nNtrace( ˆXˆXT) = trace(S) =\\nD∑\\ni=1\\nλi (21.11)\\nVớiλ1 ≥λ2 ≥···≥ λD ≥0 là các trị riêng của ma trận nửa xác định dươngS. Chú ý rằng\\ncác trị riêng này là thực và không âm1.\\nNhư vậyL không phụ thuộc vào cách chọn ma trận trực giaoU và bằng tổng các\\nphần tử trên đường chéo củaS. Nói cách khác,Lchính là tổng của các phương sai theo từng\\nthành phần của dữ liệu ban đầu2.\\nVì vậy, việc tối thiểu hàm mất mátJ được cho bởi (21.9) tương đương với việc tối đa\\nF = L−J =\\nK∑\\ni=1\\nuiSuT\\ni (21.12)\\n21.1.3 Tối ưu hàm mất mát\\nNghiệm của bài toán tối ưu hàm mất mát cho PCA được tìm dựa trên khẳng định sau đây.\\nNếu S là một ma trận nửa xác định dương, bài toán tối ưu\\nmax\\nUK\\nK∑\\ni=1\\nuT\\ni Sui (21.13)\\nthoả mãn:UT\\nKUK = I (21.14)\\ncó nghiệmu1,..., uK là các vector riêng ứng vớiK trị riêng (kể cả lặp) lớn nhất của\\nS. Khi đó, giá trị của hàm mục tiêu là∑K\\ni=1 λi, với λ1 ≥λ2 ≥···≥ λD là các trị\\nriêng củaS.\\nKhẳng định này có thể được chứng minh bằng quy nạp3.\\n1 Tổng các trị riêng của một ma trận vuông bất kỳ luôn bằng trace của ma trận đó.\\n2 Mỗi thành phần trên đường chéo chính của ma trận hiệp phương sai chính là phương sai của thành phần dữ liệu\\ntương ứng.\\n3 Xin được bỏ qua phần chứng minh. Bạn đọc có thể xem Excercise 12.1 trong tài liệu tham khảo [Bis06] với lời giải\\ntại https://goo.gl/sM32pB .\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 269, 'page_label': '258'}, page_content='CHƯƠNG 21. PRINCIPAL COMPONENT ANALYSIS 258\\nˆσ1\\nˆσ2\\nu1\\nu2\\ne1\\ne2\\nσ1\\nσ2\\nHình 21.3:PCA có thể được coi là phương\\npháp đi tìm một hệ cơ sở trực chuẩn đóng\\nvai trò một phép xoay, sao cho trong hệ cơ\\nsở mới này, phương sai theo một số chiều\\nnào đó là rất nhỏ, và ta có thể bỏ qua.\\nTrị riêng lớn nhấtλ1 của ma trận hiệp phương saiS còn được gọi làthành phần chính thứ\\nnhất (the first principal component), trị riêng thứ haiλ2 còn được gọi làthành phần chính\\nthứ hai, v.v.. Tên gọiphân tích thành phần chính(principal component analysis) bắt nguồn\\ntừ đây. Ta chỉ giữ lạiK thành phần chính đầu tiên khi giảm chiều dữ liệu dùng PCA.\\nHình 21.3 minh hoạ các thành phần chính với dữ liệu hai chiều. Trong không gian ban đầu\\nvới các vector cơ sở màu đene1,e2, phương sai theo mỗi chiều dữ liệu (độ rộng của các hình\\nchuông màu lục) đều lớn. Trong không gian mới với các vector cơ sở màu đỏu1,u2, phương\\nsai theo chiều thứ haiˆσ2 rất nhỏ so vớiˆσ1. Điều này nghĩa là khi chiếu dữ liệu lênu2 ta\\nđược các điểm rất gần nhau và gần với giá trị trung bình theo chiều đó. Trong trường hợp\\nnày, giá trị trung bình theo mọi chiều bằng 0 nên ta có thể thay thế toạ độ theo chiềuu2\\nbằng 0. Rõ ràng là nếu dữ liệu có phương sai càng nhỏ theo một chiều nào đó thì khi xấp\\nxỉ chiều đó bằng một hằng số, sai số xấp xỉ càng nhỏ. PCA thực chất là đi tìm một phép\\nxoay tương ứng với một ma trận trực giao sao cho trong hệ toạ độ mới, tồn tại các chiều\\ncó phương sai nhỏ mà ta có thể bỏ qua; ta chỉ cần giữ lại các chiều/thành phần khác quan\\ntrọng hơn. Như đã khẳng định ở trên, tổng phương sai theo mọi chiều trong hệ cơ sở nào\\ncũng là như nhau và bằng tổng các trị riêng của ma trận hiệp phương sai. Vì vậy, PCA còn\\nđược coi là phương pháp giảm số chiều dữ liệu sao tổng phương sai còn lại là lớn nhất.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 270, 'page_label': '259'}, page_content='259 CHƯƠNG 21. PRINCIPAL COMPONENT ANALYSIS\\n21.2 Các bước thực hiện PCA\\nTừ các suy luận phía trên, ta có thể tóm tắt lại các bước trong PCA như sau:\\n1. Tính vector kỳ vọng của toàn bộ dữ liệu:¯x = 1\\nN\\n∑N\\nn=1 xn.\\n2. Trừ mỗi điểm dữ liệu đi vector kỳ vọng của toàn bộ dữ liệu để được dữ liệu chuẩn hoá:\\nˆxn = xn −¯x (21.15)\\n3. Đặt ˆX = [ˆx1,ˆx2,..., ˆxD] là ma trận dữ liệu chuẩn hoá, tính ma trận hiệp phương sai\\nS = 1\\nN\\nˆXˆXT (21.16)\\n4. Tính các trị riêng và vector riêng tương ứng cóℓ2 norm bằng 1 của ma trận này, sắp xếp\\nchúng theo thứ tự giảm dần của trị riêng.\\n5. Chọn K vector riêng ứng vớiK trị riêng lớn nhất để xây dựng ma trậnUK có các cột\\ntạo thành một hệ trực giao.K vectors này, còn được gọi là các thành phần chính, tạo\\nthành một không gian congần với phân bố của dữ liệu ban đầu đã chuẩn hoá.\\n6. Chiếu dữ liệu ban đầu đã chuẩn hoáˆX xuống không gian con tìm được.\\n7. Dữ liệu mới chính là toạ độ của các điểm dữ liệu trên không gian mới:Z = UT\\nK ˆX.\\nDữ liệu ban đầu có thể tính được xấp xỉ theo dữ liệu mới bởix ≈UKZ + ¯x.\\nMột điểm dữ liệu mớiv ∈RD (có thể không nằm trong tập huấn luyện) sẽ được giảm chiều\\nbằng PCA theo công thứcw = UT\\nK(v −x) ∈RK. Ngược lại, nếu biếtw, ta có thể xấp xỉv\\nbởi UKw + x. Các bước thực hiện PCA được minh hoạ trong Hình 21.4.\\n21.3 Mối quan hệ giữa PCA và SVD\\nGiữa PCA và SVD có mỗi quan hệ đặc biệt với nhau. Để nhận ra điều này, tôi xin được\\nnhắc lại hai điểm đã trình bày sau đây:\\n21.3.1 SVD cho bài toán xấp xỉ low-rank tốt nhất\\nNghiệm A của bài toán xấp xỉ một ma trận bởi một ma trận có rank không vượt quák:\\nmin\\nA\\n∥X −A∥F\\nthoả mãn: rank(A) = K\\n(21.17)\\nchính là truncated SVD củaA.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 271, 'page_label': '260'}, page_content='CHƯƠNG 21. PRINCIPAL COMPONENT ANALYSIS 260\\nPCA procedure\\nX\\n1. Find mean vector\\ne1\\ne2\\nˆX\\n2. Subtract mean 3. Compute covariance\\nmatrix:\\nS = 1\\nN\\nˆX ˆX T\\n4. Computer eigenvalues\\nand eigenvectors of S :\\n(λ1 ,u 1 ),..., (λD ,u D )\\nRemember the or-\\nthonormality of u i .\\nu1\\ne1\\ne2\\n5. Pick K eigenvectors w/\\nhighest eigenvalues\\n6. Project data to selected\\neigenvectors.\\ne1\\ne2\\nu1\\n7. Obtain projected points\\nin low dimension.\\nu1\\ne1\\ne2\\nZ\\nHình 21.4: Các bước thực hiện PCA.\\nCụ thể, nếu SVD củaX ∈RD×N là\\nX = UΣVT (21.18)\\nvới U ∈RD×D và V ∈RN×N là các ma trận trực giao, vàΣ ∈RD×N là ma trận đường chéo\\n(không nhất thiết vuông) với các phần tử trên đường chéo không âm giảm dần. Nghiệm của\\nbài toán (21.17) chính là:\\nA = UKΣKVT\\nK (21.19)\\nvới U ∈RD×K và V ∈RN×K là các ma trận tạo bởi K cột đầu tiên của U và V, và\\nΣK ∈RK×K là ma trận đường chéo con ứng vớiK hàng đầu tiên vàK cột đầu tiên củaΣ.\\n21.3.2 Ý tưởng của PCA\\nTrong PCA, như đã chứng minh ở (21.5), PCA là bài toán đi tìm ma trận trực giaoU và\\nma trận mô tả dữ liệu ở không gian thấp chiềuZ sao cho việc xấp xỉ sau đây là tốt nhất:\\nX ≈˜X = UKZ + ˆUK ˆUT\\nK¯x1T (21.20)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 272, 'page_label': '261'}, page_content='261 CHƯƠNG 21. PRINCIPAL COMPONENT ANALYSIS\\nvới UK, ˆUK lần lượt là các ma trận được tạo bởiK cột đầu tiên vàD−K cột cuối cùng\\ncủa ma trận trực giaoU, và¯x là vector kỳ vọng của dữ liệu.\\nGiả sử rằng vector kỳ vọng¯x = 0. Khi đó, (21.20) tương đương với\\nX ≈˜X = UKZ (21.21)\\nBài toán tối ưu của PCA sẽ trở thành:\\nUK,Z = arg min\\nUK,Z\\n∥X −UKZ∥F\\nthoả mãn: UT\\nKUK = IK\\n(21.22)\\nvới IK ∈RK×K là ma trận đơn vị trong không gianK chiều, và điều kiện ràng buộc là để\\nđảm bảo các cột củaUK tạo thành một hệ trực chuẩn.\\n21.3.3 Quan hệ giữa PCA và SVD\\nBạn có nhận ra điểm tương đồng giữa hai bài toán tối ưu (21.17) và (21.22) với nghiệm của\\nbài toán đầu tiên được cho trong (21.19)? Bạn có thể nhận ra ngay nghiệm của bài toán\\n(21.22) chính là\\nUK trong (21.22) = UKtrong (21.19)\\nZ trong (21.22) = ΣKVT\\nKtrong (21.19)\\nVậy, nếu các điểm dữ liệu được biễu diễn bởi các cột của một ma trận, và trung bình cộng\\ncủa mỗi hàng của ma trận đó bằng 0 (để cho vector trung bình bằng 0), thì nghiệm của bài\\ntoán PCA được rút ra trực tiếp từ truncated SVD của ma trận đó. Nói cách khác, việc đi\\ntìm nghiệm cho PCA chính là việc giải một bài toán matrix factorization thông qua SVD.\\n21.4 Làm thế nào để chọn số chiều của dữ liệu mới\\nMột câu hỏi được đặt ra là, làm thế nào để chọn ra giá trịK – chiều của dữ liệu mới – với\\ntừng dữ liệu cụ thể?\\nCó một cách xác địnhK là dựa trên việclượng thông tin muốn giữ lại. Như đã trình bày,\\nPCA còn được gọi là phương pháp tối đatổng phương sai được giữ lại. Vậy ta có thể coi\\ntổng các phương sai được giữ lại là lượng thông tin được giữ lại.\\nNhắc lại rằng trong mọi hệ trục toạ độ, tổng phương sai của dữ liệu là như nhau và bằng\\ntổng các trị riêng của ma trận hiệp phương sai∑D\\ni=1 λi. Thêm nữa, PCA giúp giữ lại lượng\\nthông tin (tổng các phương sai) là∑K\\ni=1 λi. Vậy ta có thể coi biểu thức:\\nrK =\\n∑K\\ni=1 λi\\n∑D\\nj=1 λj\\n(21.23)\\nlà tỉ lệ thông tin được giữ lại khi số chiều dữ liệu mới sau PCA làK. Như vậy, giả sử ta\\nmuốn giữ lại 99% dữ liệu, ta chỉ cần chọnK là số tự nhiên nhỏ nhất sao chorK ≥0.99.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 273, 'page_label': '262'}, page_content='CHƯƠNG 21. PRINCIPAL COMPONENT ANALYSIS 262\\nKhi dữ liệu phân bố quanh một không gian con, các giá trị phương sai lớn nhất ứng với các\\nλi đầu tiên lớn hơn nhiều so với các phương sai còn lại. Khi đó, ta có thể chọn đượcK khá\\nnhỏ để đạt đượcrK ≥0.99.\\n21.5 Lưu ý về tính PCA trong các bài toán thực tế\\nCó hai trường hợp trong thực tế mà chúng ta cần lưu ý về PCA. Trường hợp thứ nhất là\\nlượng dữ liệu có được nhỏ hơn rất nhiều so với số chiều dữ liệu. Trường hợp thứ hai là khi\\nlượng dữ liệu trong tập huấn luyện là rất lớn, có thể lên tới cả triệu. Việc tính toán ma trận\\nhiệp phương sai và trị riêng đôi khi trở nên bất khả thi. Có những hướng giải quyết hiệu\\nquả cho các trường hợp này.\\nTrong mục này, ta sẽ coi như dữ liệu đã được chuẩn hoá, tức đã được trừ đi vector kỳ vọng.\\nKhi đó, ma trận hiệp phương sai sẽ làS = 1\\nNXXT.\\n21.5.1 Số chiều dữ liệu nhiều hơn số điểm dữ liệu\\nĐó là trường hợpD > N, tức ma trận dữ liệuX là mộtma trận cao. Khi đó, số trị riêng\\nkhác không của ma trận hiệp phương saiS sẽ không vượt quá rank của nó, tức không vượt\\nquá N. Vậy ta cần chọnK ≤N vì không thể chọn ra được nhiều hơnN trị riêng khác 0 của\\nmột ma trận có rank bằngN.\\nViệc tính toán các trị riêng và vector riêng cũng có thể được thực hiện một cách hiệu quả\\ndựa trên các tính chất sau đây:\\nTính chất 1:Trị riêng củaA cũng là trị riêng củakA với k ̸= 0 bất kỳ. Điều này có thể\\nđược suy ra trực tiếp từ định nghĩa của trị riêng và vector riêng.\\nTính chất 2:Trị riêng củaAB cũng là trị riêng củaBA với A ∈Rd1×d2 ,B ∈Rd2×d1 là các\\nma trận bất kỳ vàd1,d2 là các số tự nhiên khác không bất kỳ.\\nNhư vậy, thay vì tìm trị riêng của ma trận hiệp phương saiS ∈RD×D, ta đi tìm trị riêng\\ncủa ma trậnT = XTX ∈RN×N có số chiều nhỏ hơn (vìN <D).\\nTính chất 3:Giả sử(λ,u) là một cặp trị riêng - vector riêng củaT, thế thì(λ,Xu) là một\\ncặp trị riêng - vector riêng củaS. Thật vậy,\\nXTXu = Tu = λu ⇒(XXT)(Xu) = λ(Xu) (21.24)\\nDấu bằng thứ nhất xảy ra theo định nghĩa của trị riêng và vector riêng. Từ (21.24) ta suy\\nra Tính chất 3.\\nNhư vậy, ta có thể hoàn toàn tính được trị riêng và vector riêng của ma trận hiệp phương sai\\nS dựa trên một ma trậnT có kích thước nhỏ hơn. Việc này trong nhiều trường hợp khiến\\nthời gian tính toán giảm đi đáng kể.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 274, 'page_label': '263'}, page_content='263 CHƯƠNG 21. PRINCIPAL COMPONENT ANALYSIS\\n21.5.2 Với các bài toán large-scale\\nTrong rất nhiều bài toán, cảD và N đều là các số rất lớn, đồng nghĩa với việc ta phải\\ntìm trị riêng cho một ma trận rất lớn. Ví dụ, có một triệu bức ảnh 1000×1000 pixel,\\nnhư vậyD = N = 106 là một số rất lớn, việc trực tiếp tính toán trị riêng và vector riêng\\ncho ma trận hiệp phương sai là không khả thi. Tuy nhiên, có một phương pháp cho phép\\ntính xấp xỉ các giá trị này một cách nhanh hơn. Phương pháp đó có tên làpower method\\n(https://goo.gl/eBRPxH ).\\n21.6 Một vài ứng dụng của PCA\\nỨng dụng đầu tiên có thể thấy của PCA chính là việc giảm chiều dữ liệu, giúp việc lưu trữ\\nvà tính toán được thuận tiện hơn. Thực tế cho thấy, nhiều khi làm việc trên dữ liệu đã được\\ngiảm chiều mang lại kết quả tốt hơn cho với dữ liệu gốc. Thứ nhất, có thể phần dữ liệu mang\\nthông tin nhỏ bị lược đi chính là phần gây nhiễu, những thông tin quan trọng hơn đã được\\ngiữ lại. Thứ hai, số điểm dữ liệu nhiều khi ít hơn số chiều dữ liệu. Khi có quá ít dữ liệu và\\nsố chiều dữ liệu quá lớn, overfitting rất dễ xảy ra. Việc giảm chiều dữ liệu phần nào giúp\\nkhắc phục hiện tượng này.\\nDưới đây là hai ví dụ về ứng dụng của PCA trong bài toánface classificationvà anomaly\\ndetection (dò điểm bất thường).\\n21.6.1 Eigenface\\nEigenface từng là một trong các kỹ thuật phổ biến nhất trong bài toán nhận dạng khuôn\\nmặt. Giả sử rằng vị trí các khuôn mặt đã được xác định trong ảnh và có kích thước như\\nnhau, bài toán đặt ra là xác định đó là khuôn mặt của ai. Ý tưởng của eigenface là đi tìm\\nmột không gian có số chiều nhỏ hơn để mô tả mỗi khuôn mặt, từ đó sử dụng vector trong\\nkhông gian thấp này như là vector đặc trưng đưa vào các bộ phân lớp. Điều đáng nói là\\nmột bức ảnh khuôn mặt có kích thước khoảng 200×200 sẽ có số chiều là 40k – là một số\\nrất lớn, trong khi đó, vector đặc trưng thường chỉ có số chiều bằng vài trăm hoặc vài nghìn.\\nEigenface thực ra chính là PCA. Các eigenface chính là các vector riêng (eigenvector) ứng\\nvới các trị riêng lớn nhất của ma trận hiệp phương sai.\\nTrong phần này, chúng ta cùng làm một thí nghiệm nhỏ trên cơ sở dữ liệu Yale face database\\n(https://goo.gl/LNg8LS ). Các bức ảnh trong thí nghiệm này đã được căn chỉnh cho cùng\\nvới kích thước và khuôn mặt nằm trọn vẹn trong một hình chữ nhật có kích thước116 ×98\\npixel. Có tất cả 15 người khác nhau, mỗi người có 11 bức ảnh được chụp ở các điều kiện\\nánh sáng và cảm xúc khác nhau, bao gồm’centerlight’, ’glasses’, ’happy’, ’leftlight’, ’\\nnoglasses’, ’normal’, ’rightlight’,’sad’, ’sleepy’, ’surprised’, và’wink’. Hình 21.5 minh\\nhoạ các bức ảnh của người có id là 10.\\nTa có thể thấy rằng số chiều dữ liệu là116 ×98 = 11368 là một số khá lớn. Tuy nhiên, vì\\nchỉ có tổng cộng15 ×11 = 165 bức ảnh nên ta có thể nén các bức ảnh này về dữ liệu mới\\ncó chiều nhỏ hơn 165. Trong ví dụ này, chúng ta chọnK = 100.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 275, 'page_label': '264'}, page_content='CHƯƠNG 21. PRINCIPAL COMPONENT ANALYSIS 264\\nHình 21.5: Ví dụ về ảnh của một người trong Yale Face Database.\\nDưới đây là đoạn code thực hiện PCA cho toàn bộ dữ liệu. Ở đây chúng ta trực tiếp sử dụng\\nPCA trongsklearn.\\nimport numpy as np\\nfrom scipy import misc # for loading image\\nnp.random.seed(1)\\n# filename structure\\npath = ’unpadded/’ # path to the database\\nids = range(1, 16) # 15 persons\\nstates = [’centerlight’, ’glasses’, ’happy’, ’leftlight’,\\n’noglasses’, ’normal’, ’rightlight’,’sad’,\\n’sleepy’, ’surprised’, ’wink’ ]\\nprefix = ’subject’\\nsurfix = ’.pgm’\\n# data dimension\\nh, w, K = 116, 98, 100 # hight, weight, new dim\\nD = h * w\\nN = len(states)*15\\n# collect all data\\nX = np.zeros((D, N))\\ncnt = 0\\nfor person_id in range(1, 16):\\nfor state in states:\\nfn = path + prefix + str(person_id).zfill(2) + ’.’ + state + surfix\\nX[:, cnt] = misc.imread(fn).reshape(D)\\ncnt += 1\\n# Doing PCA, note that each row is a datapoint\\nfrom sklearn.decomposition import PCA\\npca = PCA(n_components=K) # K = 100\\npca.fit(X.T)\\n# projection matrix\\nU = pca.components_.T\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 276, 'page_label': '265'}, page_content='265 CHƯƠNG 21. PRINCIPAL COMPONENT ANALYSIS\\nHình 21.6: Các eigenfaces tìm được bằng PCA.\\nTrong dòngpca = PCA(n_components=K), nếun_components là một số thực trong khoảng(0,1),\\nPCA sẽ thực hiện việc tìmK dựa trên biểu thức (21.23).\\nHình 21.6 biểu diễn 18 vector riêng đầu tiên (18 cột đầu tiên củaUk) tìm được bằng PCA.\\nCác vector đã đượcreshape về cùng kích thước như các bức ảnh gốc. Có một điều dễ nhận\\nra là các ảnh minh hoạ các vector thu được ít nhiều mang thông tin của mặt người. Thực\\ntế, một khuôn mặt gốc sẽ được xấp xỉ như tổng có trọng số của cáckhuôn mặt này. Vì các\\nvector riêng này đóng vai trò như cơ sở của không gian mới với ít chiều hơn, chúng còn được\\ngọi làkhuôn mặt chính, tứceigenface4 . Để xem mức độ hiệu quả của Eigenface, chúng ta\\nthử minh hoạ các bức ảnh gốc và các bức ảnh được xấp xỉ bằng PCA, kết quả được cho như\\ntrên Hình 21.7. Các khuôn mặt nhận được vẫn mang khá đầy đủ thông tin của các khuôn\\nmặt gốc. Điều đang nói hơn, các khuôn mặt trong hàng dưới được suy ra từ một vector 100\\nchiều, so với 11368 chiều như ở hàng trên.\\nSource code cho chương này có thể được tìm thấy tạihttps://goo.gl/zQ3DSZ .\\n21.6.2 Abnormal Detection\\nNgoài các ứng dụng về nén và phân lớp, PCA còn được sử dụng trong nhiều lĩnh vực khác\\nnhau.Abnormal detection, hayoutlier detection(xác định các hiện tượng không bình thường)\\n4 Từ riêng trong trường hợp này không thực sự truyền tải thông tin. Từchính được dùng vì nó đi kèm với văn cảnh\\ncủa phân tích thành phần chính.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 277, 'page_label': '266'}, page_content='CHƯƠNG 21. PRINCIPAL COMPONENT ANALYSIS 266\\nHình 21.7:Hàng trên: các ảnh gốc. Hàng dưới: các ảnh đượcsuy ratừ eigenfaces. Ảnh ở hàng\\ndưới có nhiều nhiễu nhưng vẫn mang những đặc điểm riêng mà mắt người có thể phân biệt được.\\nu2 u1\\nHình 21.8:PCAchoviệc xácđịnhcác\\nsự kiệnbất thường. Giả sử rằng các sự\\nkiện bình thường chiếm đa số và nằm\\ngần trong một không gian con nào đó.\\nKhi đó, nếu làm PCA trên toàn bộ dữ\\nliệu, không gian con thu được gần với\\nkhông gian con của tập các sự kiện\\nbình thường . Lúc này, các điểm quá\\nxa không gian con này, trong trường\\nhợp này là các điểm màu cam, có thể\\nđược coi là các sự kiệnbất thường.\\nlà một trong số đó [SCSC03,LCD04]. Thêm nữa, giả sử chúng ta không biết nhãn của các\\nsự kiện này, tức ta đang làm việc với một bài toán không giám sát.\\nÝ tưởng cơ bản là các sự kiện bình thường có thể nằm gần một không gian con nào đó, trong\\nkhi các sự kiện bất thường thường nằm xa không gian con đó. Hơn nữa, vì là bất thường\\nnên số lượng các sự kiện thuộc loại này là rất nhỏ so với các sự kiện bình thường. Như vậy,\\nchúng ta có thể làm PCA trên toàn bộ dữ liệu để tìm ra các thành phần chính của dữ liệu,\\ntừ đó suy ra không gian con mà các điểm bình thường nằm gần. Việc xác định một điểm là\\nbình thường hay bất thường được xác định bằng cách đo khoảng cách từ điểm đó tới không\\ngian con tìm được. Hình 21.8 minh hoạ cho việc xác định các sự kiện bất thường bằng PCA.\\n21.7 Thảo luận\\n• PCA là một phương pháp giảm chiều dữ liệu dựa trên việc tối đa lượng thông tin được\\ngiữ lại. Lượng thông tin được giữ lại được đo bằng tổng các phương sai trên mỗi thành\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 278, 'page_label': '267'}, page_content='267 CHƯƠNG 21. PRINCIPAL COMPONENT ANALYSIS\\nphần của dữ liệu. Lượng dữ liệu sẽ được giữ lại nhiều nhất khi các chiều dữ liệu còn lại\\ntương ứng với các vector riêng của trị riêng lớn nhất của ma trận hiệp phương sai.\\n• Với các bài toán large-scale, đôi khi việc tính toán trên toàn bộ dữ liệu là không khả thi\\nvì còn có vấn đề về bộ nhớ. Giải pháp là thực hiện PCA lần đầu trên một tập con dữ liệu\\nvừa với bộ nhớ, sau đó lấy một tập con khác đểtừ từ (incrementally) cập nhật nghiệm\\ncủa PCA tới khi nào hội tụ. Ý tưởng này khá giống với mini-batch Gradient Descent, và\\nđược gọi là Incremental PCA [ZYK06].\\n• Ngoài ra, còn rất nhiều hướng mở rộng của PCA, bạn đọc có thể tìm kiếm theo từ khoá:\\nSparse PCA [dGJL05], Kernel PCA [MSS+99], Robust PCA [CLMW11].\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 279, 'page_label': '268'}, page_content='Chương 22\\nLinear discriminant analysis\\n22.1 Giới thiệu\\nTrong chương trước, chúng ta đã làm quen với một thuật toán giảm chiều dữ liệu phổ\\nbiến nhất – principle component analysis (PCA). Như đã đề cập, PCA là một mô hình\\nunsupervised learning, tức là nó chỉ sử dụng các vector mô tả dữ liệu mà không cần tới\\nnhãn, nếu có, của dữ liệu. Tuy nhiên, trong bài toán phân lớp, việc khai thác mối liên quan\\ngiữa dữ liệu và nhãn sẽ mang lại kết quả phân loại tốt hơn.\\nNhắc lại rằng PCA là phương pháp giảm chiều dữ liệu sao cho lượng thông tin về dữ liệu,\\nthể hiện ở tổng phương sai của các thành phần được giữ lại, được giữ lại là nhiều nhất. Tuy\\nnhiên, trong nhiều bài toán, ta không cần giữ lại lượng thông tin lớn nhất mà chỉ cần giữ\\nlại thông tin cần thiết cho riêng bài toán đó. Xét ví dụ về bài toán phân lớp nhị phân được\\nmô tả trong Hình 22.1. Ở đây, ta giả sử rằng dữ liệu được chiếu lên một đường thẳng và\\nmỗi điểm được thay bởi hình chiếu của nó lên đường thẳng kia. Như vậy, số chiều dữ liệu\\nđã được giảm từ hai về một. Câu hỏi đặt ra là, đường thẳng cần có phương như thế nào để\\nhình chiếu của dữ liệu trên đường thẳng nàygiúp ích cho việc phân lớp nhất? Việc phân lớp\\nđơn giản nhất có thể được hiểu là việc tìm ra một ngưỡng giúp phân tách hai lớp một cách\\nđơn giản và đạt kết quả tốt nhất. Xét hai đường thằngd1 và d2. Trong đó phương củad1\\ngần với phương của thành phần chính nếu thực hiện PCA, phương củad2 gần với phương\\ncủa thành phần phụ tìm được bằng PCA. Nếu ta làm giảm chiều dữ liệu bằng PCA, ta sẽ\\nthu được dữ liệu gần với các điểm được chiếu lênd1. Lúc này việc phân tách hai lớp trở nên\\nphức tạp vì các điểm dữ liệu mới của hai lớp chồng lấn lên nhau. Ngược lại, nếu ta chiếu\\ndữ liệu lên đường thẳng gần với thành phần phụ tìm được bởi PCA, tứcd2, các điểm hình\\nchiếu nằm hoàn toàn về hai phía khác nhau của điểm màu lục trên đường thẳng này. Với\\nbài toán phân lớp, việc chiếu dữ liệu lênd2 vì vậy sẽ mang lại hiệu quả hơn. Việc phân loại\\nmột điểm dữ liệu mới sẽ được xác định nhanh chóng bằng cách so sánh hình chiếu của nó\\nlên d2 với điểm màu xanh lục này.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 280, 'page_label': '269'}, page_content='269 CHƯƠNG 22. LINEAR DISCRIMINANT ANALYSIS\\nd 2\\nd 1\\nHình 22.1: Chiếu dữ liệu lên các đường thẳng khác nhau. Có hai lớp dữ liệu minh hoạ bởi các\\nđiểm màu xanh và đỏ trong không gian hai chiều. Số chiều được giảm về một bằng cách chiếu\\ndữ liệu lên các đường thẳng khác nhaud1 và d2. Trong hai cách chiếu này, phương củad1 gần\\ngiống với phương của thành phần chính thứ nhất của dữ liệu, phương củad2 gần với thành phần\\nphụ của dữ liệu nếu dùng PCA. Khi chiếu dữ liệu lênd1, nhiều điểm màu đỏ và xanh bị chồng\\nlấn lên nhau, khiến cho việc phân loại dữ liệu là không khả thi trên đường thẳng này. Ngược lại,\\nkhi được chiếu lênd2, dữ liệu của hai lớp được chia thành các cụm tương ứng tách biệt nhau,\\nkhiến cho việc phân lớp trở nên đơn giản hơn và hiệu quả hơn. Các đường cong hình chuông thể\\nhiện xấp xỉ phân bố xác suất của dữ liệu hình chiếu trong mỗi lớp.\\nQua ví dụ trên ta thấy rằng,không phải trong mọi trường hợp việc giữ lại thông tin\\nnhiều nhất sẽ luôn mang lại kết quả tốt nhất.Chú ý rằng kết quả của phân tích trên\\nđây không có nghĩa là thành phần phụ mang lại hiệu quả tốt hơn thành phần chính. Việc\\nchiếu dữ liệu lên đường thẳng nào giúp ích cho các bài toán phân lớp cần nhiều phân tích cụ\\nthể hơn nữa. Ngoài ra, hai đường thằngd1 và d2 trên đây không vuông góc với nhau, chúng\\nđược chọn gần với các thành phần chính và phụ của dữ liệu phục vụ cho mục đích minh hoạ.\\nLinear discriminant analysis (LDA) được ra đời nhằm tìm ra phương chiếu dữ liệu hiệu quả\\ncho bài toán phân lớp. LDA có thể được coi là một phương pháp giảm chiều dữ liệu, cũng\\ncó thể được coi là một phương pháp phân lớp, và cũng có thể được áp dụng đồng thời cho\\ncả hai, tức giảm chiều dữ liệu sao cho việc phân lớp hiệu quả nhất. Số chiều của dữ liệu mới\\nlà nhỏ hơn hoặc bằngC−1 trong đóC là số lượng lớp dữ liệu. Từdiscriminant được hiểu\\nlà những thông tin đặc trưng cho mỗi lớp, khiến nó không bị lẫn với các classes khác. Từ\\nlinear được dùng vì cách giảm chiều dữ liệu được thực hiện dựa trên một ma trận chiếu –\\nlà một phép biến đổi tuyến tính.\\nTrong Mục 22.2 dưới đây, chúng ta sẽ thảo luận về LDA cho bài toán phân lớp nhị phân.\\nMục 22.3 sẽ tổng quát LDA lên cho trường hợp với nhiều lớp dữ liệu. Mục 22.4 sẽ có các ví\\ndụ và code Python cho LDA.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 281, 'page_label': '270'}, page_content='CHƯƠNG 22. LINEAR DISCRIMINANT ANALYSIS 270\\nm1 m2s1 s2s2\\na) Large(m1 − m2)2, larges2\\n1 + s2\\n2\\nm1 m2\\ns1 s2\\nb) Small (m1 − m2)2, small s2\\n1 + s2\\n2\\nm1 m2\\ns1 s2\\nc) Large(m1 − m2)2, small s2\\n1 + s2\\n2\\nHình 22.2:Khoảng cách giữa các kỳ vọng và tổng các phương sai ảnh hưởng tới độdiscriminant\\ncủa dữ liệu. (a) Khoảng cách giữa hai kỳ vọng là lớn nhưng phương sai trong mỗi class cũng lớn,\\nkhiến cho hai phân phối chồng lấn lên nhau (phần màu xám). (b) Phương sai cho mỗi class là\\nrất nhỏ nhưng hai kỳ vọng quá gần nhau, khiến khó phân biệt hai class. (c) Khi phương sai đủ\\nnhỏ và khoảng cách giữa hai kỳ vọng đủ lớn, ta thấy rằng dữ liệudiscriminative hơn.\\n22.2 LDA cho bài toán phân lớp nhị phân\\n22.2.1 Ý tưởng cơ bản\\nQuay lại với Hình 22.1, giả sử rằng dữ liệu của mỗi lớp khi được chiếu xuống một đường\\nthẳng tuân theo phân phối chuẩn, có hàm mật độ xác suất là một đường hình chuông. Độ\\nrộng của mỗi đường hình chuông này thể hiệnđộ lệch chuẩn(standard deviation1, ký hiệu\\nlà s) của dữ liệu. Dữ liệu càng tập trung thì độ lệch chuẩn càng nhỏ, càng phân tán thì độ\\nlệch chuẩn càng cao. Khi được chiếu lênd1, dữ liệu của hai lớp bị phân tán quá nhiều, khiến\\ncho chúng bị trộn lẫn vào nhau. Khi được chiếu lênd2, mỗi lớp đều có độ lệch chuẩn nhỏ,\\nkhiến cho dữ liệu trong từng lớp tập trung hơn, dẫn đến kết quả tốt hơn.\\nTuy nhiên, việc độ lệch chuẩn nhỏ trong mỗi lớp chưa đủ để đảm bảo độdiscriminant của\\ndữ liệu là tốt hơn. Xét các ví dụ trong Hình 22.2. Hình 22.2a chính là trường hợp trong\\nHình 22.1 khi dữ liệu được chiếu lênd1. Cả hai lớp đều quá phân tán khiến cho lượng chồng\\nlấn (phần diện tích màu xám) là lớn, tức dữ liệu chưa thực sựdiscriminative. Hình 22.2b là\\ntrường hợp khi độ lệch chuẩn của hai lớp đều nhỏ, tức dữ liệu trong mỗi lớp tập trung hơn.\\nTuy nhiên, vấn đề với trường hợp này là khoảng cách giữa hai lớp, được đo bằng khoảng\\ncách giữa hai kỳ vọngm1 và m2, là quá nhỏ, khiến cho phần chồng lấn cũng chiếm môt tỉ lệ\\nlớn, và tất nhiên, cũng không tốt cho việc phân lớp. Hình 22.2c là trường hợp khi cả hai độ\\nlệch chuẩn là nhỏ và khoảng cách giữa hai kỳ vọng là lớn, phần chống lấn nhỏ không đáng\\nkể.\\n1 độ lệch chuẩn là căn bậc hai của phương sai\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 282, 'page_label': '271'}, page_content='271 CHƯƠNG 22. LINEAR DISCRIMINANT ANALYSIS\\nVậy, độ lệch chuẩn và khoảng cách giữa hai kỳ vọng cụ thể đại diện cho các tiêu chí gì?\\n• Độ lệch chuẩn nhỏ thể hiện việc dữ liệu ít phân tán, tức dữ liệu trong mỗi lớp có xu hướng\\ngiống nhau. Hai phương sais2\\n1,s2\\n2 còn được gọi là cácwithin-class variance.\\n• Khoảng cách giữa các kỳ vọng là lớn chứng tỏ rằng hai lớp nằm xa nhau, tức dữ liệu giữa\\ncác lớp là khác nhau nhiều. Bình phương khoảng cách giữa hai kỳ vọng(m1 −m2)2 còn\\nđược gọi làbetween-class variance.\\nHai lớp dữ liệu được gọi làdiscriminative nếu hai lớp đó cách xa nhau (between-class variance\\nlớn) và dữ liệu trong mỗi lớp có xu hướng giống nhau (within-class variance nhỏ). LDA là\\nthuật toán đi tìm một phép chiếu sao cho tỉ lệ giữabetween-class variancevà within-class\\nvariance lớn nhất có thể.\\n22.2.2 Hàm mục tiêu của LDA\\nGiả sử rằng cóN điểm dữ liệux1,x2,..., xN ∈RD trong đóN1 < Nđiểm đầu tiên thuộc\\nlớp thứ nhất,N2 = N−N1 điểm còn lại thuộc lớp thứ hai. Ký hiệuC1 = {n|1 ≤n≤N1}là\\ntập hợp các chỉ số của các điểm thuộc lớp thứ nhất vàC2 = {m|N1 + 1 ≤m≤N}) là tập\\nhợp các chỉ số của các điểm thuộc lớp thứ hai. Phép chiếu dữ liệu xuống một đường thẳng\\ncó thể được mô tả bằng một vector hệ sốw, giá trị tương ứng của mỗi điểm dữ liệu mới\\nđược cho bởi\\nzn = wTxn,1 ≤n≤N (22.1)\\nVector kỳ vọng của mỗi lớp được tính bởi\\nmk = 1\\nNk\\n∑\\nn∈Ck\\nxn, k = 1,2 (22.2)\\n⇒m1 −m2 = 1\\nN1\\n∑\\ni∈C1\\nzi − 1\\nN2\\n∑\\nj∈C2\\nzj = wT(m1 −m2) (22.3)\\nCác within-class varianceđược định nghĩa là\\ns2\\nk =\\n∑\\nn∈Ck\\n(zn −mk)2, k = 1,2 (22.4)\\nChú ý rằng các within-class variance ở đây không được lấy trung bình như phương sai thông\\nthường. Điều này được lý giải là tầm quan trọng của mỗi within-class variance nên tỉ lệ thuận\\nvới số lượng điểm dữ liệu trong lớp đó, tức within-class variance bằng phương sai nhân với\\nsố điểm trong lớp đó.\\nLDA là thuật toán đi tìm giá trị lớn nhất của hàm mục tiêu\\nJ(w) = (m1 −m2)2\\ns2\\n1 + s2\\n2\\n(22.5)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 283, 'page_label': '272'}, page_content='CHƯƠNG 22. LINEAR DISCRIMINANT ANALYSIS 272\\nThông qua việc tối đa hàm mục tiêu này, ta sẽ thu đượcbetween-class variance(m1 −m2)2,\\nlớn vàwithin-class variance, s2\\n1 + s2\\n2 nhỏ.\\nTiếp theo, chúng ta sẽ tìm biểu thức phụ thuộc giữa tử số và mẫu số trong vế phải của (22.5)\\nvào w. Với tử số,\\n(m1 −m2)2 = (wT(m1 −m2))2 = wT (m1 −m2)(m1 −m2)T\\n\\ued19 \\ued18\\ued17 \\ued1a\\nSB\\nw = wTSBw (22.6)\\nSB còn được gọi là ma trậnbetween-class covariance. Có thể nhận thấy đây là một ma\\ntrận đối xứng nửa xác định dương. Với mẫu số,\\ns2\\n1 + s2\\n2 =\\n2∑\\nk=1\\n∑\\nn∈Ck\\n(\\nwT(xn −mk)\\n)2\\n= wT\\n2∑\\nk=1\\n∑\\nn∈Ck\\n(xn −mk)(xn −mk)T\\n\\ued19 \\ued18\\ued17 \\ued1a\\nSW\\nw = wTSWw (22.7)\\nSW còn được gọi là ma trậnwithin-class covariance. Đây cũng là một ma trận đối xứng\\nnửa xác định dương vì nó là tổng của hai ma trận đối xứng nửa xác định dương2.\\nNhư vậy, bài toán tối ưu cho LDA trở thành\\nw = arg max\\nw\\nwTSBw\\nwTSWw (22.8)\\n22.2.3 Nghiệm của bài toán tối ưu\\nNghiệm w của (22.8) sẽ là nghiệm của phương trình đạo hàm hàm mục tiêu bằng 0. Sử dụng\\nquy tắc chuỗi cho đạo hàm hàm nhiều biến và công thức∇wwAw = 2Aw nếu A là một\\nma trận đối xứng, ta thu được\\n∇wJ(w) = 1\\n(wTSWw)2\\n(\\n2SBw(wTSWw) −2wTSBwTSWw\\n)\\n= 0 (22.9)\\n⇔SBw = wTSBw\\nwTSWwSWw = J(w)SWw (22.10)\\n⇒S−1\\nW SBw = J(w)w (22.11)\\nLưu ý:Trong (22.11), ta đã giả sử rằng ma trậnSW là khả nghịch. Điều này không luôn\\nluôn đúng, nhưng có một kỹ thuật nhỏ là xấp xỉSW bởi ¯SW = SW + λI với λlà một số thực\\ndương nhỏ. Ma trận mới này là khả nghịch vì trị riêng nhỏ nhất của nó bằng với trị riêng\\nnhỏ nhất củaSW cộng vớiλ tức không nhỏ hơnλ >0. Điều này được suy ra từ việcSW\\n2 Trong (22.6) và (22.7), chúng ta đã sử dụng đẳng thức(aT b)2 = (aT b)(aT b) = aT bbT a với a,b là hai vectors\\ncùng chiều bất kỳ.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 284, 'page_label': '273'}, page_content='273 CHƯƠNG 22. LINEAR DISCRIMINANT ANALYSIS\\nlà một ma trận nửa xác định dương. Từ đó,¯SW là một ma trận xác định dương vì mọi trị\\nriêng của nó là không nhỏ hơnλ, và vì thế, nó khả nghịch. Khi tính toán, ta có thể sử dụng\\nnghịch đảo của¯SW. Kỹ thuật này được sử dụng rất nhiều khi cần sử dụng nghịch đảo của\\nmột ma trận nửa xác định dương và chưa biết nó có thực sự là xác định dương hay không.\\nQuay trở lại với đẳng thức (22.11), vìJ(w) là một số vô hướng, ta suy raw phải là một\\nvector riêng củaS−1\\nW SB ứng vớiJ(w). Vậy, để hàm mục tiêu là lớn nhất thìJ(w) chính là\\ntrị riêng lớn nhất củaS−1\\nW SB. Dấu bằng xảy ra khiw là vector riêng ứng với trị riêng lớn\\nnhất đó.\\nTừ có thể thấy ngay rằng nếuw là nghiệm của (22.8) thìkw cũng là nghiệm vớik là số\\nthực khác không bất kỳ. Vậy ta có thể chọnw sao cho(m1 −m2)Tw = L với L là trị riêng\\nlớn nhất củaS−1\\nW SB và cũng là giá trị tối ưu củaJ(w). Khi đó, thay định nghĩa củaSB ở\\n(22.6) vào (22.11) ta có:\\nLw = S−1\\nW (m1 −m2) (m1 −m2)Tw\\ued19 \\ued18\\ued17 \\ued1a\\nL\\n= LS−1\\nW (m1 −m2) (22.12)\\nĐiều này nghĩa là ta có thể chọn\\nw = αS−1\\nW (m1 −m2) (22.13)\\nvới α̸= 0 bất kỳ. Biểu thức (22.13) còn được biết như làFisher’s linear discriminant, được\\nđặt theo tên nhà khoa học Ronald Fisher (https://goo.gl/eUk1KS ).\\n22.3 LDA cho bài toán phân lớp nhiều lớp\\n22.3.1 Xây dựng hàm mục tiêu\\nTrong mục này, chúng ta sẽ xem xét trường hợp tổng quát của LDA, được gọi làmulti-class\\nLDA, khi có nhiều hơn hai lớp dữ liệu,C >2. Giả sử rằng chiều của dữ liệuD lớn hơnC.\\nGiả sử rằng chiều mà chúng ta muốn giảm về làD′ < Dvà dữ liệu mới ứng với mỗi điểm\\ndữ liệux là:\\nz = WTx (22.14)\\nvới W ∈RD×D′\\n. Một vài ký hiệu:\\n• Xk,Zk = WTXk lần lượt là ma trận dữ liệu của lớp thứk trong không gian ban đầu và\\nkhông gian mới với số chiều nhỏ hơn. Mỗi cột tương ứng với một điểm dữ liệu.\\n• mk = 1\\nNk\\n∑\\nn∈Ck\\nxk ∈RD là vector kỳ vọng của lớp thứk trong không gian ban đầu.\\n• ek = 1\\nNk\\n∑\\nn∈Ck\\nzn = WTmk ∈RD′\\nlà vector kỳ vọng của lớp thứk trong không gian mới.\\n• m ∈RD là vector trung bình của toàn bộ dữ liệu trong không gian ban đầu vàe ∈RD′\\nlà vector trung bình trong không gian mới.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 285, 'page_label': '274'}, page_content='CHƯƠNG 22. LINEAR DISCRIMINANT ANALYSIS 274\\ne1\\n∥Z1 −E1∥2F\\nej\\n∥Zj −Ej∥2F\\neC\\n∥ZC −EC∥2F\\ne\\nGoal:\\nC∑\\nk=1\\n∥Zk −Ek∥2F (within-class) small.\\nC∑\\nk=1\\n∥Ek −E∥2F (between-class) large.\\nHình 22.3: LDA cho multi-class\\nclassification problem. Mục đích\\ncũng là sự khác nhau giữa các\\nthành phần trong một lớp (within-\\nclass) là nhỏ và sự khác nhau giữa\\ncác lớp là lớn. Các điểm dữ liệu\\ncó màu khác nhau thể hiện các lớp\\nkhác nhau.\\nMột trong những cách xây dựng hàm mục tiêu cho multi-class LDA được minh họa trong\\nHình 22.3. Độ phân tán của một tập hợp dữ liệu có thể được coi như tổng bình phương\\nkhoảng cách từ mỗi điểm tới vector kỳ vọng của chúng. Nếu tất cả các điểm đều gần vector\\ntrung bình của chúng thì độ phân tán của tập dữ liệu đó được coi là nhỏ. Ngược lại, nếu\\ntổng này là lớn, tức trung bình các điểm đều xa trung tâm, tập hợp này có thể được coi\\nlà có độ phân tán cao. Dựa vào nhận xét này, ta có thể xây dựng các đại lượng within- và\\nbetween-class variance như dưới đây.\\nWithin-class variancecủa lớp thứk có thể được tính như sau:\\nσ2\\nk =\\n∑\\nn∈Ck\\n∥zn −ek∥2\\nF = ∥Zk −Ek∥2\\n2 = ∥WT(Xk −Mk)∥2\\nF (22.15)\\n= trace\\n(\\nWT(Xk −Mk)(Xk −Mk)TW\\n)\\n(22.16)\\nVới Ek một ma trận có các cột giống hệt nhau và bằng với vector trung bìnhek. Có thể\\nnhận thấyEk = WTMk với Mk là ma trận có các cột giống hệt nhau và bằng với vector\\ntrung bình mk trong không gian ban đầu. Vậy đại lượng đo within-class trong multi-class\\nLDA có thể được đo bằng:\\nsW =\\nC∑\\nk=1\\nσ2\\nk =\\nC∑\\nk=1\\ntrace\\n(\\nWT(Xk −Mk)(Xk −Mk)TW\\n)\\n= trace\\n(\\nWTSWW\\n)\\n(22.17)\\nvới\\nSW =\\nC∑\\nk=1\\n∥Xk −Mk∥2\\nF =\\nC∑\\nk=1\\n∑\\nn∈Ck\\n(xn −mk)(xn −mk)T (22.18)\\nMa trậnSW này là một ma trận nửa xác định dương.\\nBetween-class variancelớn có thể đạt được nếu tất cả các điểm trong không gian mới đều\\nxa vector trung bình chunge. Việc này cũng có thể đạt được nếu các vector trung bình của\\nmỗi lớp xa các vector trung bình chung (trong không gian mới). Vậy ta có thể định nghĩa\\nđại lượng between-class như sau:\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 286, 'page_label': '275'}, page_content='275 CHƯƠNG 22. LINEAR DISCRIMINANT ANALYSIS\\nsB =\\nC∑\\nk=1\\nNk∥ek −e∥2\\nF =\\nC∑\\nk=1\\n∥Ek −E∥2\\nF (22.19)\\nTa lấyNk làm trọng số vì có thể có những lớp có nhiều phần tử so với các lớp còn lại. Chú\\ný rằng ma trậnE có thể có số cộtlinh động, phụ thuộc vào số cột của ma trậnEk mà nó đi\\ncùng (và bằngNk).\\nLập luận tương tự như (22.17), bạn đọc có thể chứng minh được:\\nsB = trace\\n(\\nWTSBW\\n)\\n(22.20)\\nvới\\nSB =\\nC∑\\nk=1\\n(Mk −M)(Mk −M)T =\\nC∑\\nk=1\\nNk(mk −m)(mk −m)T (22.21)\\nvà số cột của ma trậnM cũng linh động theo số cột củaMk. Ma trận này là tổng của các\\nma trận đối xứng nửa xác định dương, nên nó là một ma trận đối xứng nửa xác định dương.\\n22.3.2 Hàm mục tiêu cho multi-class LDA\\nVới cách định nghĩa và ý tưởng về within-class variance nhỏ và between-class variance lớn\\nnhư trên, ta có thể xây dựng bài toán tối ưu\\nW = arg max\\nW\\nJ(W) = arg max\\nW\\ntrace(WTSBW)\\ntrace(WTSWW) (22.22)\\nNghiệm cũng được tìm bằng cách giải phương trình đạo hàm hàm mục tiêu bằng 0. Nhắc\\nlại về đạo hàm của hàm trace theo ma trận:\\n∇Wtrace(WTAW) = 2AW (22.23)\\nvới A ∈RD×D là một ma trận đối xứng.\\nVới cách tính tương tự như (22.9) - (22.11), ta có:\\n∇WJ(W) = 2\\n(\\nSBWtrace(WTSWW) −trace(WTSBW)SWW\\n)\\n(trace(WTSWW))2 = 0 (22.24)\\n⇔S−1\\nW BW = J(W)W (22.25)\\nTừ đó suy ra mỗi cột củaW là một vector riêng củaS−1\\nW SB ứng với trị riêng lớn nhất của\\nma trận này. Nhận thấy rằng các cột củaW cần phải độc lập tuyến tính. Vì nếu không, dữ\\nliệu trong không gian mớiz = WTx sẽ phụ thuộc tuyến tính và có thể tiếp tục được giảm\\nsố chiều. Vậy các cột củaW là các vector độc lập tuyến tính ứng với trị riêng cao nhất của\\nS−1\\nW SB. Câu hỏi đặt ra là: Có nhiều nhất bao nhiêu vector riêng độc lập tuyến tính ứng với\\ntrị riêng lớn nhất củaS−1\\nW SB? Số lượng này chính là số chiềuD′ của dữ liệu mới.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 287, 'page_label': '276'}, page_content='CHƯƠNG 22. LINEAR DISCRIMINANT ANALYSIS 276\\nSố lượng lớn nhất các vector riêng độc lập tuyến tính ứng với một trị riêng của một ma trận\\nkhông thể lớn hơn rank của ma trận đó. Dưới đây là một bổ đề quan trọng.\\nBổ đề:\\nrank(SB) ≤C−1 (22.26)\\nChứng minh3:\\nViết lại 22.21 dưới dạng\\nSB = PPT (22.27)\\nvới P ∈RD×C mà cột thứk cuả nó làpk = √Nk(mk −m).\\nHơn nữa, cột cuối cùng là một tổ hợp tuyến tính của các cột còn lại:\\nmC −m = mC −\\n∑C\\nk=1 Nkmk\\nN =\\nC−1∑\\nk=1\\nNk\\nN (mk −m) (22.28)\\nNhư vậy ma trậnP có nhiều nhấtC−1 cột độc lập tuyến tính, vậy nên rank4 của nó không\\nvượt quá C −1. Cuối cùng, SB là tích của hai ma trận với rank không quáC −1, nên\\nrank(SB) không vượt quáC−1. □\\nTừ đó ra có rank\\n(\\nS−1\\nW SB\\n)\\n≤rankSB ≤C−1. Vậy số chiều của không gian mới là một số\\nkhông lớn hơnC−1.\\nTóm lại, nghiệm của bài toán multi-class LDA là các vector riêng độc lập tuyến tính ứng với\\ntrị riêng cao nhất củaS−1\\nW SB.\\nLưu ý: Có nhiều cách khác nhau để xây dựng hàm mục tiêu cho multi-class LDA dựa\\ntrên việc định nghĩa within-class variance nhỏ và between-class variance lớn. Chúng ta đang\\nsử dụng hàm trace để đong đếm hai đại lượng này. Một ví dụ khác về hàm tối ưu là\\nJ(W) = trace(s−1\\nW sB) = trace{(WSWWT)−1(WSBWT)}[Fuk13]. Hàm số này cũng đạt giá\\ntrị lớn nhất khiW là tập hợp củaD′vector riêng ứng với các trị riêng lớn nhất củaS−1\\nW SB.\\nCó một điểm chung giữa các cách tiếp cận này là chiều của không gian mới sẽ không vượt\\nquá C−1.\\n22.4 Ví dụ trên Python\\nTrong mục này, chúng ta sẽ minh hoạ LDA cho bài toán phân lớp nhị phân qua một ví dụ\\nđơn giản với dữ liệu trong không gian hai chiều.\\nDữ liệu của hai lớp được tạo như sau:\\n3 Việc chứng minh này không thực sự quan trọng, chỉ phù hợp với những bạn muốn hiểu sâu.\\n4 Các tính chất của rank có thể được tìm thấy trong Mục 1.8.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 288, 'page_label': '277'}, page_content='277 CHƯƠNG 22. LINEAR DISCRIMINANT ANALYSIS\\nfrom __future__ import division, print_function, unicode_literals\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\nfrom matplotlib.backends.backend_pdf import PdfPages\\nnp.random.seed(22)\\nmeans = [[0, 5], [5, 0]]\\ncov0 = [[4, 3], [3, 4]]\\ncov1 = [[3, 1], [1, 1]]\\nN0, N1 = 50, 40\\nN = N0 + N1\\nX0 = np.random.multivariate_normal(means[0], cov0, N0) # each row is a data point\\nX1 = np.random.multivariate_normal(means[1], cov1, N1)\\nCác điểm dữ liệu của hai lớp được minh hoạ bởi các màu khác nhau trên Hình 22.4.\\nTiếp theo, chúng ta đi tính các ma trận within-class và between-class covariance:\\n# Build S_B\\nm0 = np.mean(X0.T, axis = 1, keepdims = True)\\nm1 = np.mean(X1.T, axis = 1, keepdims = True)\\na = (m0 - m1)\\nS_B = a.dot(a.T)\\n# Build S_W\\nA = X0.T - np.tile(m0, (1, N0))\\nB = X1.T - np.tile(m1, (1, N1))\\nS_W = A.dot(A.T) + B.dot(B.T)\\nNghiệm của bài toán là vector riêng ứng với trị riêng lớn nhất củaS−1\\nW WB:\\n_, W = np.linalg.eig(np.linalg.inv(S_W).dot(S_B))\\nw = W[:,0]\\nprint(’w = ’, w)\\nKết quả:\\nw = [ 0.75091074 -0.66040371]\\nĐường thẳng có phươngw được minh hoạ bởi đường màu lục trên Hình 22.4. Ta thấy rằng\\nnghiệm này hợp lý với dữ liệu của bài toán.\\nĐể kiểm chứng độ chính xác của nghiệm tìm được, ta cùng so sánh nó với nghiệm tìm được\\nbởi thư việnsklearn.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 289, 'page_label': '278'}, page_content='CHƯƠNG 22. LINEAR DISCRIMINANT ANALYSIS 278\\nSolution by LDA\\nclass 1\\nclass 2\\nHình 22.4:Ví dụ minh hoạ về LDA\\ntrong không gian hai chiều. Đường\\nthẳng màu lục là đường thẳng mà\\ndữ liệu sẽ được chiếu lên. Ta có\\nthể thấy rằng, nếu chiếu lên đường\\nthẳng này, dữ liệu của hai lớp sẽ\\nnằm về hai phía của một điểm trên\\nđường thẳng đó.\\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\\nX = np.concatenate((X0, X1))\\ny = np.array([0]*N0 + [1]*N1)\\nclf = LinearDiscriminantAnalysis()\\nclf.fit(X, y)\\nprint(’w_sklearn = ’, clf.coef_[0]/np.linalg.norm(clf.coef_)) # normalize\\nw_sklearn = [ 0.75091074 -0.66040371]\\nTa thấy rằng nghiệm tìm theo công thức và nghiệm tìm theo thư viện là như nhau.\\nMột ví dụ khác so sánh PCA và LDA có thể được tìm thấy tạiComparison of LDA and\\nPCA 2D projection of Iris dataset(https://goo.gl/tWjAEs ).\\n22.5 Thảo luận\\n• LDA là một phương pháp giảm chiều dữ liệu có sử dụng thông tin về label của dữ liệu.\\nVì vậy, LDA là một thuật toán supervised.\\n• Ý tưởng cơ bản của LDA là tìm một không gian mới với số chiều nhỏ hơn không gian\\nban đầu sao cho hình chiếu của các điểm trong cùng lớp lên không gian mới này là gần\\nnhau trong khi hình chiếu của các điểm của các lớp khác nhau là khác nhau.\\n• Trong PCA, số chiều của không gian mới có thể là bất kỳ số nào không lớn hơn số chiều\\nvà số điểm của dữ liệu. Trong LDA, với bài toán cóC classes, số chiều của không gian\\nmới chỉ có thể không vượt quáC−1.\\n• Với bài toán có hai lớp, từ Hình 22.1 ta có thể thấy rằng hai lớp là linearly separable nếu\\nvà chỉ nếu tồn tại một đường thẳng và một điểm trên đường thẳng đó (điểm mùa lục)\\nsao cho dữ liệu hình chiếu trên đường thẳng của hai lớp nằm về hai phía khác nhau của\\nđiểm đó.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 290, 'page_label': '279'}, page_content='279 CHƯƠNG 22. LINEAR DISCRIMINANT ANALYSIS\\n• LDA hoạt động rất tốt nếu các lớp là linearly separable. Chất lượng mô hình giảm đi rõ\\nrệt nếu các classes là không linearly separable. Điều này dễ hiểu vì khi đó, chiếu dữ liệu\\nlên phương nào thì cũng bị chồng lần, và việc tách biệt không thể thực hiện được như ở\\nkhông gian ban đầu.\\n• Mặc dù có hạn chế, ý tưởng vềsmall within-class variance và big within-class variance\\ncòn được gọi làFisher’s optimization criterion, được sử dụng rất nhiều trong các thuật\\ntoán phân lớp [VM17,VM16,YZFZ11].\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 291, 'page_label': '280'}, page_content=''),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 292, 'page_label': '281'}, page_content='Phần VII\\nConvex optimization–Tối ưu lồi'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 293, 'page_label': '282'}, page_content='Chương 23\\nTập lồi và hàm lồi\\n23.1 Giới thiệu\\nCác bài toán tối ưu đã thảo luận trong cuốn sách này đều là cácbài toán tối ưu không ràng\\nbuộc (unconstrained optimization problems), tức tối ưu hàm mất mát mà không cóđiều kiện\\nràng buộc(constraints) nào về nghiệm. Tuy nhiên, không chỉ trong Machine Learning, trên\\nthực tế các bài toán tối ưu thường có rất nhiều ràng buộc khác nhau.\\nTrong toán tối ưu, một bài toán có ràng buộc thường được viết dưới dạng\\nx∗= arg min\\nx\\nf0(x)\\nsubject to: fi(x) ≤0, i = 1,2,...,m\\nhj(x) = 0, j = 1,2,...,p\\nTrong đó, vectorx = [x1,x2,...,x n]T được gọi làbiến tối ưu(optimization variable). Hàm số\\nf0 : Rn →R được gọi làhàm mục tiêu(objective function, các hàm mục tiêu trong Machine\\nLearning thường được gọi làhàm mất mát). Các hàm sốfi,hj : Rn →R,i = 1,2,...,m ; j =\\n1,2,...,p được gọi là cáchàm ràng buộc(hoặc đơn giản làràng buộc- constraints). Tập hợp\\ncác điểmx thỏa mãn cácràng buộcđược gọi làfeasible set. Mỗi điểm trongfeasible setđược\\ngọi là mộtfeasible point, các điểm không trongfeasible setđược gọi là cácinfeasible point.\\nChú ý:\\n• Nếu bài toán là tìm giá trị lớn nhất thay vì nhỏ nhất của hàm mục tiêu, ta chỉ cần đổi\\ndấu củaf0(x).\\n• Nếu ràng buộc làlớn hơn hoặc bằng, tứcfi(x) ≥bi, ta chỉ cần đổi dấu của ràng buộc là\\nsẽ có điều kiệnnhỏ hơn hoặc bằng−fi(x) ≤−bi.\\n• Các ràng buộc cũng có thể làlớn hơn hoặc nhỏ hơn.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 294, 'page_label': '283'}, page_content='283 CHƯƠNG 23. TẬP LỒI VÀ HÀM LỒI\\nExample of convex sets\\nHình 23.1: Các ví dụ về tập lồi.\\n• Nếu ràng buộc làbằng nhau, tứchj(x) = 0, ta có thể viết nó dưới dạng hai bất đẳng thức\\nhj(x)≤0 và−hj(x)≤0. Trong một vài tài liệu, người ta bỏ các phương trình ràng buộc\\nhj(x) = 0đi.\\n• Trong chương này,x,y được dùng chủ yếu để ký hiệu các biến số, không phải là dữ liệu\\nnhư trong các chương trước. Biến tối ưu chính là biến được ghi dưới dấuarg min. Khi\\nviết một bài toán tối ưu, ta cần chỉ rõ biến nào cần được tối ưu, biến nào là cố định.\\nCác bài toán tối ưu, nhìn chung không có cách giải tổng quát, thậm chí có rất nhiều bài chưa\\ncó lời giải hiểu quả. Hầu hết các phương pháp tìm nghiệm không chứng minh được nghiệm\\ntìm được có phải là tức đúng là điểm làm cho hàm số đạt giá trị nhỏ nhất hay lớn nhất\\nhay không (global optimal). Thay vào đó, nghiệm thường là cácđiểm cực trị(local optimal).\\nTrong nhiều trường hợp, các nghiệmlocal optimalcũng mang lại những kết quả tốt.\\nĐể bắt đầu nghiên cứu về tối ưu, chúng ta cần biết tới một mảng rất quan trọng trong đó,\\ncó tên làtối ưu lồi (convex optimization), trong đóhàm mục tiêulà một hàm lồi (convex\\nfunction), feasible setlà mộttập lồi (convex set). Những tính chất đặc biệt vềlocal optimal\\nvà global optimalcủa mộthàm lồikhiến tối ưu lồi trở nên cực kỳ quan trọng. Trong chương\\nnày, chúng ta sẽ thảo luận định nghĩa và các tính chất cơ bản củatập lồi và hàm lồi. Bài\\ntoán tối ưu lồi(convex optimization problems) sẽ được đề cập trong chương tiếp theo.\\n23.2 Tập lồi – Convex sets\\n23.2.1 Định nghĩa\\nBạn đoc có thể đã biết đến khái niệmđa giác lồi. Lồi, hiểu đơn giản, làphình ra ngoài, hoặc\\nnhô ra ngoài. Trong toán học,bằng phẳngcũng được coi làlồi.\\nĐịnh nghĩa không chính thức của tập lồi:Một tập hợp được gọi làtập lồi nếu mọi\\nđiểm trên đoạn thẳng nối hai điểmbất kỳ trong tập hợp hợp đó đều thuộc tập hợp đó.\\nMột vài ví dụ về tập lồi được cho trong Hình 23.1. Các hình với đường biên màu đen thể\\nhiện việc biên cũng thuộc vào hình đó, biên màu trắng thể hiện việc biên đó không nằm\\ntrong hình. Đường thẳng hoặc đoạn thẳng cũng là một tập lồi theo định nghĩa phía trên.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 295, 'page_label': '284'}, page_content='CHƯƠNG 23. TẬP LỒI VÀ HÀM LỒI 284\\nExamples of nonconvex sets\\nHình 23.2: Các ví dụ về tập không lồi.\\nMột vài ví dụ thực tế:\\n• Giả sử có một căn phòng có dạng hình lồi, nếu ta đặt một bóng đèn đủ sáng ở bất kỳ vị\\ntrí nào trên trần nhà, mọi điểm trong căn phòng đều được chiếu sáng.\\n• Nếu một đất nước có bản đồ dạng một hình lồi thì đoạn thẳng nối hai thành phố bất kỳ\\ntrong đất nước đó nằm trọn vẹn trong nước đó. Một cách lý tưởng, mọi đường bay trong\\nđất nước đều được tối ưu vì chi phí bay thẳng ít hơn chi phí bay đường vòng hoặc qua\\nkhông phận của nước khác. Bản đồ Việt Nam không có dạng lồi vì đường thẳng nối sân\\nbay Nội Bài và Tân Sơn Nhất đi qua địa phận Campuchia.\\nHình 23.2 minh hoạ một vài ví dụ về các tập không phải là tập lồi, nói gọn làtập không lồi\\n(nonconvex set). Ba hình đầu tiên không phải là lồi vì các đường nét đứt chứa nhiều điểm\\nkhông nằm trong các tập đó. Hình thứ tư, hình vuông không có biên ở đáy, không phải là\\nmột tập lồivì đoạn thẳng nối hai điểm ở đáy có thể chứa phần ở giữa không thuộc tập đang\\nxét (nếu không có biên thì thình vuông vẫn là mộttập lồi, nhưng biênnửa vời như ví dụ\\nnày thì hãy chú ý). Một đường cong bất kỳ cũng không phải làtập lồi vì dễ thấy đường\\nthẳng nối hai điểm bất kỳ không thuộc đường cong đó.\\nĐể mô tả mộttập lồi dưới dạng toán học, ta sử dụng\\nĐịnh nghĩa 23.1: Convex set–Tập hợp lồi\\nMột tập hợp Cđược gọi là một tập lồi nếu với hai điểm bất kỳx1,x2 ∈C , điểm\\nxθ = θx1 + (1−θ)x2 cũng nằm trongCvới bất kỳ0 ≤θ≤1.\\nCó thể thấy rằng, tập hợp các điểm có dạng(θx1 + (1−θ)x2) chính làđoạn thẳng nối hai\\nđiểm x1 và x2.\\nVới các định nghĩa này thìtoàn bộ không gianlà mộttập lồi vì đoạn thằng nào cũng nằm\\ntrong không gian đó. Tập rỗng cũng có thể coi là một trường hợp đặc biệt củatập lồi.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 296, 'page_label': '285'}, page_content='285 CHƯƠNG 23. TẬP LỒI VÀ HÀM LỒI\\n23.2.2 Các ví dụ về tập lồi\\nSiêu mặt phẳng và nửa không gian\\nĐịnh nghĩa 23.2: Hyerplane–Siêu mặt phẳng\\nMột siêu mặt phẳng, haysiêu phẳng(hyperplane) trong không giannchiều là tập hợp\\ncác điểm thỏa mãn phương trình\\na1x1 + a2x2 + ··· + anxn = aTx = b (23.1)\\nvới b,ai,i = 1,2,...,n là các số thực.\\nHyperplanes là cáctập lồi. Điều này có thể được suy ra từ Định nghĩa 23.1. Thật vậy, nếu\\naTx1 = aTx2 = b\\nthì với0 ≤θ≤1 bất kỳ, ta cóaTxθ = aT(θx1 + (1 −θ)x2) = θb+ (1 −θ)b= b\\nĐịnh nghĩa 23.3: Halfspace–Nửa không gian\\nMột nửa không gian (halfspace) trong không giann chiều là tập hợp các điểm thỏa\\nmãn bất phương trình\\na1x1 + a2x2 + ··· + anxn = aTx ≤b\\nvới b,ai,i = 1,2,...,n là các số thực.\\nCác halfspace cũng là các tập lồi, bạn đọc có thể dễ dàng nhận thấy theo Định nghĩa 23.1\\nvà cách chứng minh tương tự như trên.\\nNorm balls\\nĐịnh nghĩa 23.4: Norm ball\\nCho một tâmxc và một bán kínhr và khoảng cách giữa các điểm được xác định bởi\\nmột norm.Norm ball tương ứng là tập hợp các điểm thoả mãn\\nB(xc,r) =\\n{\\nx\\n⏐⏐∥x −xc∥2 ≤r}= {xc + ru\\n⏐⏐∥u∥2 ≤1\\n}\\nKhi norm làℓ2 norm, ta có norm ball là một hình tròn trong không gian hai chiều, hình\\ncầu trong không gian ba chiều, hoặc siêu cầu trong các không gian nhiều chiều. Khi dùngℓ2\\nnorm, norm ball được gọi làEuclidean norm.\\nNorm balls là các tập lồi. Để chứng minh việc này, ta dùng Định nghĩa 23.1 và bất đẳng\\nthức tam giác của norms. Với x1,x2 bất kỳ thuộc B(xc,r) và 0 ≤ θ ≤ 1 bất kỳ, xét\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 297, 'page_label': '286'}, page_content='CHƯƠNG 23. TẬP LỒI VÀ HÀM LỒI 286\\n-1 1\\n1\\n-1\\n-1 1\\n1\\n-1\\n-1 1\\n1\\n-1\\n-1 1\\n1\\n-1\\n-1 1\\n1\\n-1\\np = 1\\n8 p = 1\\n4 p = 1\\n2 p = 2\\n3 p = 4\\n5\\n-1 1\\n1\\n-1\\n-1 1\\n1\\n-1\\n-1 1\\n1\\n-1\\n-1 1\\n1\\n-1\\n-1 1\\n1\\n-1\\np = 1 p = 4\\n3 p = 2 p = 4 p = ∞\\nCp = {(x, y)\\n⏐⏐ (|x|p + |y|p)1/p ≤1}\\n(a) p <1: nonconvex sets\\n(b) p ≥1: convex sets\\nHình 23.3: Hình dạng của các tập hợp bị chặn bởi (a) các pseudo-norm và (b) các norm.\\nxθ = θx1 + (1−θ)x2, ta có\\n∥xθ −xc∥= ∥θ(x1 −xc) + (1−θ)(x2 −xc)∥\\n≤θ∥x1 −xc∥+ (1−θ)∥x2 −xc∥≤ θr+ (1−θ)r= r\\nVậyxθ ∈B(xc,r).\\nHình 23.3 minh họa tập hợp các điểm có tọa độ(x,y) trong không gian hai chiều thỏa mãn:\\n(|x|p + |y|p)1/p ≤1 (23.2)\\nvới hàng trên là các tập với0 < p <1, là các pseudo-norm, và hàng dưới tương ứng với\\np ≥1, là các norm thực sự. Chúng ta có thể thấy rằng khip nhỏ gần bằng 0, tập hợp các\\nđiểm thỏa mãn bất đẳng thức (23.2) gần như nằm trên các trục tọa độ và bị chặn trong đoạn\\n[0,1]. Quan sát này sẽ giúp ích cho các bạn khi làm việc với pseudo-norm 0. Khip →∞,\\ncác tập hợp hội tụ về hình vuông. Đây cũng là một trong các lý do vì sao cần có điều kiện\\np≥1 khi định nghĩaℓp norm.\\n23.2.3 Giao của các tập lồi\\nGiao của các tập lồi là một tập lồi. Việc này có thể nhận nhận ra trong Hình 23.4a. Giao\\ncủa hai trong ba hoặc cả ba tập lồi đều là các tập lồi. Việc này có thể được chứng minh theo\\nĐịnh nghĩa 23.1. Nếux1,x2 thuộc vào giao của các tập lồi, tức thuộc tất cả các tập lồi đã\\ncho, thì(θx1 + (1−θ)x2) cũng thuộc vào tất cả các tập lồi, tức thuộc vào giao của chúng.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 298, 'page_label': '287'}, page_content='287 CHƯƠNG 23. TẬP LỒI VÀ HÀM LỒI\\n(b)(a)\\nHình 23.4:(a) Giao của các tập lồi là một tập lồi. (b) Giao của các hyperplanes và halfspace là\\nmột tập lồi và được gọi là polyhedron (số nhiều là polyhedra).\\nTừ đó suy ra giao của cáchalfspaces và cáchyperplanes cũng là một tập lồi. Chúng là các\\nđa giác lồi trong không gian hai chiều và đa diện lồi trong không gian ba chiều. Trong không\\ngian nhiều chiều, giao của cáchalfspaces và hyperplanes được gọi làpolyhedra. Giả sử có\\nmhalfspace và phyperplanes. Mỗi mộthalfspace có thể được viết dưới dạngaT\\ni x ≤bi, ∀i=\\n1,2,...,m . Mỗi mộthyperplane có thể được viết dưới dạngcT\\ni x = di, ∀i= 1,2,...,p .\\nVậy nếu đặt A = [a1,a2,..., am], b = [b1,b2,...,b m]T,C = [c1,c2,..., cp] và d =\\n[d1,d2,...,d p]T, ta có thể viết polyhedra dưới dạng tập hợp các điểmx thỏa mãn\\nATx ⪯b, CTx = d\\ntrong đó⪯là element-wise, tức mỗi phần tử trong vế trái nhỏ hơn hoặc bằng phần tử tương\\nứng trong vế phải.\\n23.2.4 Tổ hợp lồi và bao lồi\\nĐịnh nghĩa 23.5: Tổ hợp lồi–Convex combination\\nMột điểm được gọi làtổ hợp lồi(convex combination) của các điểmx1,x2,..., xk nếu\\nnó có thể được viết dưới dạng\\nx = θ1x1 + θ2x2 + ··· + θkxk, với θ1 + θ2 + ··· + θk = 1và θi ≥0,∀i= 1,2,...,k\\nBao lồi (convex hull) của một tập hợp bất kỳ là tập hợp tất cả các điểm là convex\\ncombination của tập hợp đó.Convex hull của một tập bất kỳ là mộtconvex set. Convex hull\\ncủa mộtconvex setlà chính nó.Convex hull của một tập hợp chính làconvex setnhỏ nhất\\nchứa tập hợp đó. Khái niệmnhỏ nhấtđược hiểu là mọi tập lồi chứa toàn bộ một tập hợp\\nbất kỳ đều chứa convex hull của tập hợp đó.\\nNhắc lại về khái niệmlinear separableđã sử dụng nhiều trong cuốn sách. Hai tập hợp được\\ngọi làlinearly separablenếu cácconvex hull của chúng không có điểm chung.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 299, 'page_label': '288'}, page_content='CHƯƠNG 23. TẬP LỒI VÀ HÀM LỒI 288\\nseparating hyperplane\\nHình 23.5:Trái: Giao của các tập lồi là một tập lồi. Phải: giao của các hyperplanes và halfspace\\nlà một tập lồi và được gọi là polyhedron (số nhiều là polyhedra).\\nTrong Hình 23.5, convex hull của các điểm màu xanh là vùng màu xám bao bởi các đa giác\\nlồi. Ở Hình 23.5 bên phải phải, convex hull của đa giác màu xanh là hợp của nó và phần\\ntam giác màu xám.\\nĐịnh lý 23.1: Siêu phẳng phân chia–Separating hyperplane theorem\\nHai tập lồi không rỗngC,Dlà không giao nhaunếu và chỉ nếu tồn tại một vectora và\\nmột sốb sao cho\\naTx ≤b,∀x ∈C, aTx ≥b,∀x ∈D\\nTập hợp tất cả các điểmx thỏa mãn aTx = b chính là một hyperplane. Hyperplane này\\nđược gọi làseparating hyperplane.\\nNgoài ra, còn nhiều tính chất thú vị của các tập lồi và các phép toán bảo toàn chính chất\\nlồi của một tập hợp, bạn đọc được khuyến khích đọc thêm Chương 2 của cuốn Convex\\nOptimization [BV04].\\n23.3 Convex functions\\n23.3.1 Định nghĩa\\nTrước hết ta xem xét các hàm một biến với đồ thị của nó là một đường trong một mặt\\nphẳng. Một hàm số được gọi làlồi nếu tập xác định của nó là một tập lồivà nếu ta\\nnối hai điểm bất kỳ trên đồ thị hàm số đó, ta được một đoạn thẳng nằm về phía trên hoặc\\nnằm trên đồ thị (xem Hình 23.6).Tập xác định(domain) của một hàm sốf(.) thường được\\nký hiệu làdomf.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 300, 'page_label': '289'}, page_content='289 CHƯƠNG 23. TẬP LỒI VÀ HÀM LỒI\\nf(x)\\nf(y)\\nf(θx+ (1−θ)y)\\nθf(x) + (1−θ)f(y)\\nθf(x) + (1−θ)f(y) ≥f(θx+ (1−θ)y)\\nHình 23.6: Định nghĩa hàm lồi.\\nDiễn đạt bằng lời, một hàm số là\\nlồi nếu đoạn thẳng nối 2 điểm bất\\nkỳ trên đồ thị của nókhông nằm\\ndưới đồ thị đó.\\nĐịnh nghĩa 23.6: Convex function–Hàm lồi\\nMột hàm sốf :Rn →R được gọi là mộthàm lồi nếu domf là mộttập lồi, và:\\nf(θx + (1−θ)y)≤θf(x) + (1−θ)f(y)\\nvới mọix,y ∈domf,0 ≤θ≤1.\\nĐiều kiệndomf là mộttập lồilà rất quan trọng. Nếu không có điều kiện này, tồn tại những\\nθ mà θx1 + (1−θ)x2 không thuộcdomf, và sẽ không định nghĩa đượcf(θx + (1−θ)y).\\nMột hàm sốf được gọi làconcave(tạm dịch làlõm) nếu−f là convex. Một hàm số có thể\\nkhông thuộc hai loại trên. Các hàm tuyến tính vừaconvex, vừaconcave.\\nĐịnh nghĩa 23.7: Strictly convex function–Hàm lồi chặt\\nMột hàm sốf :Rn →R được gọi làlồi chặt (strictly convex) nếudomf là mộttập\\nlồi, và\\nf(θx + (1−θ)y)<θf (x) + (1−θ)f(y)\\nvới mọix,y ∈domf,x ̸= y,0 <θ <1 (chỉ khác với hàm convex ở dấu nhỏ hơn).\\nTương tự với định nghĩastrictly concave.\\nNếu một hàm số làstrictly convexvà có điểm cực trị, thì điểm cực trị đó là duy\\nnhất và cũng làglobal minimum.\\n23.3.2 Các tính chất cơ bản\\n• Nếu f(x)là convex thì af(x)là convex nếu a> 0 và làconcave nếu a< 0. Điều này có\\nthể suy ra trực tiếp từ định nghĩa.\\n• Tổng của haihàm lồi là mộthàm lồi, với tập xác định là giao của hai tập xác định của\\nhai hàm đã cho (nhắc lại rằng giao của hai tập lồi là một tập lồi)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 301, 'page_label': '290'}, page_content='CHƯƠNG 23. TẬP LỒI VÀ HÀM LỒI 290\\nf1(x)\\nf2(x)f(x) = max{f1(x), f2(x)}\\nHình 23.7: Ví dụ về Pointwise maxi-\\nmum. Maximum của các hàm lồi là một\\nhàm lồi.\\n• Pointwise maximum và supremum:Nếu các hàm sốf1,f2,...,f m là convex thì:\\nf(x) = max{f1(x),f2(x),...,f m(x)}\\ncũng làconvex trên tập xác định là giao của tất cả các tập xác định của các hàm số trên.\\nHàmmax phía trên cũng có thể thay thế bằng hàmsupremum1. Tính chất này có thể được\\nchứng minh theo Định nghĩa 23.6. Hình 23.7 minh hoạ tính chất này. Các hàmf1(x),f2(x)\\nlà các hàm lồi. Đường màu xanh chính là đồ thị của hàm sốf(x) = max( f1(x),f2(x)).\\nMọi đoạn thẳng nối hai điểm bất kì trên đường màu xanh đềukhông nằm dướinó.\\n23.3.3 Ví dụ\\nCác hàm một biến\\nVí dụ về cácconvex functionsmột biến:\\n• Hàm y = ax+ b là mộthàm lồi vì đoạn thẳng nối hai điểm bất kỳ trên đường thẳng đó\\nđều không nằm phía dướiđường thẳng đó.\\n• Hàm y= eax với a∈R bất kỳ.\\n• Hàm y= xa trên tập các số thực dương vàa≥1 hoặc a≤0.\\n• Hàm negative entropyy= xlog x trên tập các số thực dương.\\nHình 23.8 minh hoạ đồ thị của một số hàm convex thường gặp với biến một chiều.\\nVí dụ về cácconcave functionsmột biến:\\n• Hàm y= ax+ b là mộtconcave functionvì −y là mộtconvex function.\\n• Hàm y= xa trên tập số dương và0 ≤a≤1.\\n• Hàm logarithmy= log(x) trên tập các số dương.\\nHình 23.9 minh hoạ đồ thị của một vài hàm số concave.\\n1 Xem Infimum and Supremum – Wikipedia(https://goo.gl/AsX4oM )\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 302, 'page_label': '291'}, page_content='291 CHƯƠNG 23. TẬP LỒI VÀ HÀM LỒI\\ny = ax + b y = | x | y = x\\n2 y = e\\nx\\ny = x\\n− 1\\n, x > 0\\nHình 23.8: Ví dụ về các hàm convex một biến.\\ny = ax + b y = 2\\n√\\nx y = 2 log( x ) y = 3 + x if x < 0\\ny = 3 − x\\n2\\nif x ≥ 0\\nHình 23.9: Ví dụ về các hàm concave một biến.\\nAffine functions\\nCác hàm số dạngf(x) = aTx + b vừa là convex, vừa là concave.\\nKhi biến là một ma trậnX, các hàm affine được định nghĩa có dạng:\\nf(X) = trace(ATX) + b\\ntrong đó,A là một ma trận có cùng kích thước nhưX để đảm bảo phép nhân ma trận thực\\nhiện được và kết quả là một ma trận vuông.\\nDạng toàn phương – Quadratic form\\nHàm bậc hai một biến có dạngf(x) = ax2 + bx+ c là convex nếua >0, là concave nếu\\na< 0.\\nVới biến là một vectorx = [ x1,x2,...,x n], mộtdạng toàn phương(quadratic form) là một\\nhàm số có dạng\\nf(x) = xTAx + bTx + c\\nvới A,b là các ma trận và vector với chiều phù hợp vàA thường là một ma trận đối xứng.\\nNếu A là một ma trận (nửa) xác định dương thìf(x) là một hàm convex. NếuA là một ma\\ntrận (nửa) xác định âm,f(x) là mộtconcave function.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 303, 'page_label': '292'}, page_content='CHƯƠNG 23. TẬP LỒI VÀ HÀM LỒI 292\\n(a) Norm 1\\n (b) Norm 2\\nHình 23.10: Ví dụ về mặt của các norm hai biến.\\nNhắc lại hàm mất mát trong linear regression có dạng\\nL(w) = 1\\n2N∥y −XTw∥2\\n2 = 1\\n2N(y −XTw)T(y −XTw)\\n= 1\\n2NwTXXTw − 1\\nNyTXTw + 1\\n2NyTy\\nvì XXT là một ma trận nửa xác định dương, hàm mất mát của linear regression chính là\\nmột convex function.\\nNorms\\nMọi hàm số bất kỳ thỏa mãn ba điều kiện của norm đều là convex. Việc này có thể được\\ntrực tiếp suy ra từ bất đẳng thức tam giác của một norm.\\nHình 23.10 minh hoạ hai ví dụ về bề mặt củaℓ1 norm vàℓ2 norm trong không gian hai chiều\\n(chiều thứ ba là giá trị của hàm số). Nhận thấy rằng các bề mặt này đều cómột đáy duy\\nnhất tương ứng với gốc tọa độ (đây chính là điều kiện đầu tiên của norm). Điều này cho\\nthấy nếu tathả một hòn biở vị trí bất kỳ trên các bề mặt này, cuối cùng nó sễlăn về đáy.\\nNếu liên tưởng tới thuật toán gradient descent thì việc áp dụng thuật toán này vào các bài\\ntoán không ràng buộc với hàm mục tiêu là strictly convex (và giả sửa là khả vi, tức có đạo\\nhàm) sẽ cho kết quả rất tốt với learning rate phù hợp. Tính chất này khiến cho các hàm\\nconvex và strictly convex được đặc biệt quan tâm trong tối ưu.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 304, 'page_label': '293'}, page_content='293 CHƯƠNG 23. TẬP LỒI VÀ HÀM LỒI\\nHình 23.11: Ví dụ về các hàm hai biến không convex.\\nHai hàm tiếp theo là ví dụ về các hàm không phải convex hay concave. Hàm thứ nhất\\nf(x,y) = x2 −y2 là một hyperbolic, hàm thứ haif(x,y) = 1\\n10 (x2 + 2y2 −2 sin(xy)). Các bề\\nmặt của hai hàm này được minh hoặc trên Hình 23.11\\n23.3.4 Contours–level sets\\nĐể khảo sát tính lồi của các bề mặt trong không gian ba chiều, việc minh hoạ trực tiếp như\\ncác ví dụ trên đây có thể khó tưởng tượng hơn. Một phương pháp thường được sử dụng là\\ndùng các đường đồng mức (contour hay level set). Contours là cách mô tả các mặt trong\\nkhông gian ba chiều trong không gian hai chiều. Ở đó, các điểm thuộc cùng mộtđường tương\\nứng với các điểm làm cho hàm số có giá trị như nhau. Mỗiđường đó còn được gọi là mộtlevel\\nset. Trong Hình 23.10 và Hình 23.11, các contour của các mặt trên mặt phẳng0xy chính là\\ncác level set. Nói cách khác, mỗi đườnglevel set là một vết cắt nếu ta cắt các bề mặt bởi\\nmột mặt phẳng song song với mặt phẳng0xy.\\nKhi khảo sát tính lồi của một hàm số hai biến, hoặc để tìm điểm cực trị của nó, người ta\\nthường vẽ các level set thay vì vẽ các mặt trong không gian ba chiều. Hình 23.12 minh hoạ\\nmột vài ví dụ về các level set. Ở hàng trên, các đườnglevel set là các đường khép kín. Khi\\ncác đường kín này tập trung nhỏ dần ở một điểm thì các điểm đó là các điểm cực trị. Với\\ncác hàm convex như trong ba ví dụ này, chỉ có một điểm cực trị và đó cũng là điểm làm cho\\nhàm số đạt giá trị nhỏ nhất (global optimal). Nếu để ý, bạn sẽ thấy các đường khép kín này\\ntạo thành biên của các tập lồi. Ở hàng dưới, các đường không phải khép kín. Hình 23.12d\\nminh hoạ các level set của một hàm tuyến tínhf(x,y) = x+ y, và đó là một hàmconvex.\\nHình 23.12e cũng minh hoạ các level set của một hàm lồi (chúng ta sẽ sớm thấy chứng minh)\\nnhưng các level set là cácđường không kín. Hàm này có chứalog nên tập xác định là góc\\nphần tư thứ nhất tương ứng với các tọa độ dương (chú ý rằng tập hợp các điểm có tọa độ\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 305, 'page_label': '294'}, page_content='CHƯƠNG 23. TẬP LỒI VÀ HÀM LỒI 294\\nf(x, y) = |x|+ |y|\\n(a)\\nf(x, y) = x2 + y2 (b)\\nf(x, y) = max(2x2 + y2 − xy, |x|+ 2|y|) (c)\\nf(x, y) = x + y\\n(d)\\nf(x, y) = xlog(x) + ylog(y) (e)\\nf(x, y) = x2 − y2 (nonconvex) (f)\\nHình 23.12: Ví dụ về các level set. Các đường màu càng xanh đậm thì tương ứng với các giá\\ntrị càng nhỏ, các đường màu càng đỏ đậm thì tương ứng các giá trị càng lớn.\\ndương cũng là mộttập lồi vì nó là một polyhedron). Cácđường không kínnày nếu kết hợp\\nvới trụcOx,Oy sẽ tạo thành biên của các tập lồi. Hình 23.12f minh hoạ các level set của\\nmột hàm hyperbolic, hàm này không phải là một hàm lồi.\\n23.3.5 α–sublevel sets\\nĐịnh nghĩa 23.8:α–sublevel set\\nα−sublevel set của một hàm sốf : Rn →R là một tập hợp được định nghĩa bởi\\nCα = {x ∈domf\\n⏐⏐f(x) ≤α}\\nDiễn đạt bằng lời, mộtα–sublevel set của một hàm sốf(.) là tập hợp các điểm trong tập\\nxác định củaf(.) mà tại đó hàm số đạt giá trị không lớn hơnα.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 306, 'page_label': '295'}, page_content='295 CHƯƠNG 23. TẬP LỒI VÀ HÀM LỒI\\nHình 23.13: Mọi alpha-sublevel sets là convex sets nhưng hàm số là nonconvex.\\nQuay lại với Hình 23.12, hàng trên, cácα–sublevel sets chính là các hình lồi được bao bởi\\ncác level set. Ở Hình 23.12d, cácα–sublevel sets chính là phần nửa mặt phẳng phía dưới\\nxác định bởi các đường thẳng level set. Ở Hình 23.12e, cácα–sublevel set chính là các vùng\\nbị giới hạn bởi các trục tọa độ và các đườnglevel set. Ở Hình 23.12f, cácα–sublevel set hơi\\nkhó tưởng tượng mộtchút. Vớiα >0, các level sets là các đường màu vàng hoặc đỏ, các\\nα–sublevel set tương ứng là phần nằm giữa các đường cùng màu. Các vùng này, có thể dễ\\nnhận thấy, làkhông lồi.\\nĐịnh lý 23.2\\nNếu một hàm số là lồi thìmọi α–sublevel set của nó là lồi. Điều gược lại chưa chắc\\nđã đúng, tức nếu cácα–sublevel set của một hàm số làlồi thì hàm số đó chưa chắc\\nđã lồi.\\nĐiều này chỉ ra rằng nếu tồn tại một giá trịα sao cho mộtα–sublevel set của một hàm số\\nlà không lồi (nonconvex), thì hàm số đó làkhông lồi (không lồi không có nghĩa làconcave,\\nchú ý). Vì vậy, hàm hyperbolic không phải là một hàm lồi. Các ví dụ ở Hình 23.12, trừ\\nHình 23.12f, đều tương ứng với các hàm lồi.\\nXét một ví dụ về việc một hàm số khôngconvex nhưng mọiα–sublevel sets làconvex. Hàm\\nf(x,y) = −ex+y có mọiα–sublevel set là một nửa mặt phẳng – làconvex, nhưng nó không\\nphải làconvex (trong trường hợp này nó làconcave).\\nHình 23.13 là một ví dụ khác về việc một hàm số có mọiα–sublevel set làlồi nhưng không\\nphải là một hàm lồi. Mọiα−sublevel set của hàm số này đều là các hình tròn – lồi, nhưng\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 307, 'page_label': '296'}, page_content='CHƯƠNG 23. TẬP LỒI VÀ HÀM LỒI 296\\nhàm số đó không phải làlồi. Vì có thể tìm được hai điểm trên mặt này sao cho đoạn thẳng\\nnối hai điểm nằm hoàn toàn phía dưới của mặt. Chẳng hạn, đoạn thẳng nối một điểm ở\\ncánh và một điểm ởđáy không nằm hoàn toàn phía trên của mặt.\\nNhững hàm số có tập xác định là một tập lồi và có mọiα–sublevel set là lồi được gọi chung\\nlà quasiconvex. Mọi hàm convex đềuquasiconvex nhưng ngược lại không đúng. Định nghĩa\\nchính thức củaquasiconvex functionđược phát biểu như sau\\nĐịnh nghĩa 23.9: Quasiconvex function\\nMột hàm sốf : C→ R với Clà một tập con lồi củaRn được gọi làquasiconvex nếu\\nvới mọix,y ∈C và mọiθ∈[0,1], ta có:\\nf(θx + (1 −θ)y) ≤max{f(x),f(y)}\\nĐịnh nghĩa này khác với định nghĩa vềconvex functionmột chút ở việc sử dụng hàm max.\\n23.3.6 Kiểm tra tính chất lồi dựa vào đạo hàm.\\nCó một cách để nhận biết một hàm số khả vi có là hàm lồi hay không dựa vào các đạo hàm\\nbậc nhất hoặc bậc hai của nó. Tất nhiên là trong trường hợp các đạo hàm đó tồn tại.\\nFirst-order condition\\nTrước hết chúng ta định nghĩa phương trình mặt tiếp tuyến của một hàm sốf khả vi tại\\nmột điểm nằm trên đồ thị (mặt) của hàm số đó(x0,f(x0). Với hàm một biến, phương trình\\ntiếp tuyến tại điểm co hoành độ(x0,f(x0)) là\\ny= f′(x0)(x−x0) + f(x0)\\nVới hàm nhiều biến, đặt∇f(x0) là gradient của hàm sốf tại điểm x0, phương trình mặt\\ntiếp tuyến được cho bởi:\\ny= ∇f(x0)T(x −x0) + f(x0)\\nFirst-order condition\\nGiả sử hàm sốf có tập xác định là lồi, có đạo hàm tại mọi điểm trên tập xác định\\nđó. Khi đó, hàm sốf là lồinếu và chỉ nếuvới mọix,x0 trên tập xác định của hàm\\nsố đó, ta có:\\nf(x) ≥f(x0) + ∇f(x0)T(x −x0) (23.3)\\nTương tự như thế, một hàm số làstricly convexnếu dấu bằng trong (23.3) xảy ra khi và chỉ\\nkhi x = x0.\\nNói một cách trực quan hơn, một hàm số là lồi nếu mặt tiếp tuyến tại một điểm bất kỳ trên\\nđồ thị của hàm số đókhông nằm trênđồ thị đó.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 308, 'page_label': '297'}, page_content='297 CHƯƠNG 23. TẬP LỒI VÀ HÀM LỒI\\n(x0, f(x0)) f(x0) +∇f(x0)T(x−x0)\\nf(x)\\nf is diﬀerentiable with convex domain\\nf is convex iﬀf(x) ≥f(x0) +∇f(x0)T(x−x0),∀x,x0 ∈domf\\n(a) convex function (b) nonconvex function\\nHình 23.14: Kiểm tra tính convexity dựa vào đạo hàm bậc nhất. Trái: hàm lồi vì tiếp tuyến tại\\nmọi điểm đều nằm dưới đồ thị hàm số đó, phải: hàm không lồi.\\nHình 23.14 minh hoạ đồ thị của một hàm lồi và một hàm không lồi. Hình 23.14a mô tả một\\nhàm lồi. Hình 23.14b mô tả một hàm không lồi vì đồ thị của nó vừa nằm trên, vừa nằm dưới\\nđường thẳng tiếp tuyến.\\nVí dụ: Nếu ma trận đối xứngA là xác định dươngthì hàm sốf(x) = xTAx là lồi.\\nChứng minh:Đạo hàm bậc nhất củaf(x) là ∇f(x) = 2Ax. Vậyfirst-order conditioncó thể\\nviết dưới dạng (chú ý rằngA là một ma trận đối xứng):\\nxTAx ≥2(Ax0)T(x −x0) + xT\\n0 Ax0\\n⇔xTAx ≥2xT\\n0 Ax −xT\\n0 Ax0\\n⇔(x −x0)TA(x −x0) ≥0\\nBất đẳng thức cuối cùng là đúng dựa trên định nghĩa của một ma trậnxác định dương. Vậy\\nhàm sốf(x) = xTAx là một hàm lồi. □\\nSecond-order condition\\nVới hàm nhiều biến, tức biến là một vector, giả sử có chiều làd, đạo hàm bậc nhất của nó\\nlà một vector cũng có chiều làd. Đạo hàm bậc hai của nó là một ma trận vuông có chiều là\\nd×d. Đạo hàm bậc hai của hàm sốf(x), còn được gọi làHessian, được ký hiệu là∇2f(x).\\nSecond-order condition\\nMột hàm số có đạo hàm bậc hai là convex nếudomf là convex và Hessian của nó là\\nmột ma trận nửa xác định dương với mọix trong tập xác định:\\n∇2f(x) ⪰0.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 309, 'page_label': '298'}, page_content='CHƯƠNG 23. TẬP LỒI VÀ HÀM LỒI 298\\nNếu Hessian của một hàm số là một ma trậnxác định dươngthì hàm số đó làstrictly convex.\\nTương tự, nếu Hessian là một ma trậnxác định âmthì hàm số đó làstrictly concave.\\nVới hàm số một biếnf(x), điều kiện này tương đương vớif”(x) ≥0 với mọix thuộc tập\\nxác định (và tập xác định là lồi).\\nVí dụ:\\n• Hàm negative entropyf(x) = xlog(x) là stricly convex vì tập xác định làx >0 là một\\ntập lồi vàf”(x) = 1/x là một số dương với mọix thuộc tập xác định.\\n• Hàm f(x) = x2 + 5 sin(x) không là hàm lồi vì đạo hàm bậc haif”(x) = 2 −5 sin(x) có\\nthể nhận giá trị âm.\\n• Hàm cross entropylà một hàmstrictly convex. Xét ví dụ đơn giản với chỉ hai xác suấtx\\nvà 1 −x với a là một hằng số thuộc đoạn[0,1] và 0 < x <1: f(x) = −(alog(x) + (1 −\\na) log(1−x)) có đạo hàm bậc hai làa\\nx2 + 1−a\\n(1−x)2 là một số dương.\\n• Nếu A là một ma trận xác định dương thìf(x) = 1\\n2 xTAx là lồi vìA chính là Hessian\\ncủa nó.\\n• Xét hàm sốnegative entropyvới hai biến:f(x,y) = xlog(x) +ylog(y) trên tập các giá trị\\ndương củaxvày. Hàm số này có đạo hàm bậc nhất là[log(x) + 1,log(y) + 1]T và Hessian\\nlà\\n[1/x 0\\n0 1 /y\\n]\\n, là một ma trận đường chéo với các thành phần trên đường chéo là dương\\nnên là một ma trận xác định dương. Vậynegative entropylà một hàm strictly convex.\\nNgoài ra còn nhiều tính chất thú vị của cáchàm lồi, các bạn được khuyến khích đọc thêm\\nChương 3 của cuốn Convex Optimization [BV04].\\n23.4 Tóm tắt\\n• Machine learning và tối ưu có quan hệ mật thiết với nhau. Trong tối ưu, tối ưu lồi là quan\\ntrọng nhất.\\n• Trong một tập lồi, mọi đoạn thẳng nối hai điểm bất kỳ trong tập đó sẽ nằm hoàn toàn\\ntrong tập đó. Tập hợp các giao điểm của các tập lồi là một tập lồi.\\n• Một hàm số là lồi nếu đoạn thẳng nối hai điểm bất kỳ trên đồ thì hàm số đókhông nằm\\ndưới đồ thị đó.\\n• Một hàm số khả vi là lồi nếu tập xác định của nó là lồi nếu mặt tiếp tuyến tại một điểm\\nbất kỳkhông nằm phía trênđồ thị của hàm số đó.\\n• Các norms là các hàm lồi, được sử dụng nhiều trong tối ưu.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 310, 'page_label': '299'}, page_content='Chương 24\\nBài toán tối ưu lồi\\n24.1 Giới thiệu\\nChúng ta cùng bắt đầu bài viết bằng ba bài toán tối ưu khá gần với thực tế.\\n24.1.1 Bài toán nhà xuất bản\\nBài toán: Một nhà xuất bản (NXB) nhận được đơn hàng 600 bản của cuốn “Machine\\nLearning cơ bản” tới Thái Bình và 400 bản tới Hải Phòng. NXB đó có 800 cuốn ở kho Nam\\nĐịnh và 700 cuốn ở kho Hải Dương. Giá chuyển phát một cuốn sách từ Nam Định tới Thái\\nBình là 50,000 VND (50k), tới Hải Phòng là 100k. Giá chuyển phát một cuốn từ Hải Dương\\ntới Thái Bình là 150k, trong khi tới Hải Phòng chỉ là 40k. Hỏi để tốn ít chi phí chuyển phát\\nnhất, công ty đó nên phân phối mỗi kho chuyển bao nhiêu cuốn tới mỗi địa điểm?\\nPhân tích\\nĐể cho đơn giản, ta xây dựng bảng số lượng chuyển sách từ nguồn tới đích như sau:\\nNguồn Đích Đơn giá (×10k) Số lượng\\nNam Định Thái Bình 5 x\\nNam Định Hải Phòng 10 y\\nHải Dương Thái Bình 15 z\\nHải Dương Hải Phòng 4 t\\nTổng chi phí (objective function) sẽ làf(x,y,z,t ) = 5x+ 10y+ 15z+ 4t. Các điều kiện ràng\\nbuộc (constraints) viết dưới dạng biểu thức toán học là:\\n• Chuyển 600 cuốn tới Thái Bình:x+ z = 600.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 311, 'page_label': '300'}, page_content='CHƯƠNG 24. BÀI TOÁN TỐI ƯU LỒI 300\\n• Chuyển 400 cuốn tới Hải Phòng:y+ t= 400.\\n• Lấy từ kho Nam Định không quá 800:x+ y≤800.\\n• Lấy từ kho Hải Dương không quá 700:z+ t≤700.\\n• x,y,z,t là các số tự nhiên. Ràng buộc là số tự nhiên sẽ khiến cho bài toán rất khó giải nếu\\nsố lượng biến là lớn. Với bài toán này, giả sử rằngx,y,z,t là các số thực dương. Nghiệm\\ntìm được sẽ được làm tròn tới số tự nhiên gần nhất.\\nVậy ta cần giải bài toán tối ưu sau đây:\\nBài toán NXB1\\n(x,y,z,t ) = arg min\\nx,y,z,t\\n5x+ 10y+ 15z+ 4t\\nthoả mãn:x+ z = 600\\ny+ t= 400\\nx+ y≤800\\nz+ t≤700\\nx,y,z,t ≥0\\n(24.1)\\nNhận thấy rằng hàm mục tiêu (objective function) là một hàm tuyến tính của các biến\\nx,y,z,t . Các điều kiện ràng buộc đều có dạng siêu phẳng hoặc nửa không gian, đều là\\ncác ràng buộc tuyến tính(linear constraints). Bài toán tối ưu với cảobjective function và\\nconstraintsđềulàtuyếntínhđượcgọilà quy hoạch tuyến tính(linearprogramming(LP) ).\\nDạng tổng quát và cách thức lập trình để giải một bài toán thuộc loại này sẽ được cho trong\\nphần sau của chương này.\\n24.1.2 Bài toán canh tác\\nBài toán:Một anh nông dân có tổng cộng 10ha (10 hecta) đất canh tác. Anh dự tính trồng\\ncà phê và hồ tiêu trên diện tích đất này với tổng chi phí cho việc trồng này là không quá\\n16T (triệu đồng). Chi phí để trồng cà phê là 2T cho 1ha, để trồng hồ tiêu là 1T/ha. Thời\\ngian trồng cà phê là 1 ngày/ha và hồ tiêu là 4 ngày/ha; trong khi anh chỉ có thời gian tổng\\ncộng là 32 ngày. Sau khi trừ tất cả các chi phí (bao gồm chi phí trồng cây), mỗi ha cà phê\\nmang lại lợi nhuận 5T, mỗi ha hồ tiêu mang lại lợi nhuận 3T. Hỏi anh phảiquy hoạchnhư\\nthế nào để tối đa lợi nhuận?\\nPhân tích\\nGọi x và y lần lượt là số ha cà phê và hồ tiêu mà anh nông dân nên trồng. Lợi nhuận anh\\nấy thu được làf(x,y) = 5x+ 3y (triệu đồng). Đây chính là hàm mục tiêu của bài toán. Các\\nràng buộc trong bài toán này được viết dưới dạng:\\n1 Nghiệm cho bài toán này có thể nhận thấy ngay làx= 600,y = 0,z = 0,t = 400. Nếu số lượng ràng buộc và số\\nbiến nhiều hơn, chúng ta cần một lời giải có thể tìm được bằng cách lập trình.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 312, 'page_label': '301'}, page_content='301 CHƯƠNG 24. BÀI TOÁN TỐI ƯU LỒI\\nx\\ny\\nx\\n+\\ny\\n= 10\\n2\\nx\\n+\\ny\\n= 16\\nx + 4 y = 32\\n5\\nx\\n+ 3\\ny\\n=\\nb\\n(a constant)\\nfeasible set\\nX\\n(0 , 0)\\nHình 24.1: Minh hoạ nghiệm cho\\nbài toán canh tác. Phần ngũ giác\\nmàu xám thể hiện tập hợp các\\nđiểm thoả mãn các ràng buộc. Các\\nđường nét đứt thể hiện các đường\\nđồng mức của hàm mục tiêu với\\nmàu càng đỏ tương ứng với giá trị\\ncàng cao. Nghiệm tìm được chính\\nlà điểm màu xanh, là giao điểm của\\nhình ngũ giác xám và đường đồng\\nmức ứng với giá trị cao nhất.\\n• Tổng diện tích trồng không vượt quá 10ha:x+ y≤10.\\n• Tổng chi phí trồng không vượt quá 16T:2x+ y≤16.\\n• Tổng thời gian trồng không vượt quá 32 ngày:x+ 4y≤32.\\n• Diện tích cà phê và hồ tiêu là các số không âm:x,y ≥0.\\nVậy ta có bài toán tối ưu sau đây:\\nBài toán canh tác\\n(x,y) = arg max\\nx,y\\n5x+ 3y\\nthoả mãn:x+ y≤10\\n2x+ y≤16\\nx+ 4y≤32\\nx,y ≥0\\n(24.2)\\nBài toán này yêu cầutối đa hàm mục tiêuthay vì tối thiểu nó. Việc chuyển bài toán này về\\nbài toántối thiểu có thể được thực hiện đơn giản bằng cách đổi dấu hàm mục tiêu. Khi đó\\nhàm mục tiêu vẫn là tuyến tình, các ràng buộc là tuyến tính, ta lại có một bài toánlinear\\nprogramming nữa. Hình 24.1 minh hoạ nghiệm cho bài toán canh tác.\\nVùng màu xám có dạngpolyhedron (trong trường hợp này là đa giác) chính là tập hợp các\\nđiểm thoả mãn các ràng buộc. Các đường nét đứt có màu chính là các đườngđồng mức\\n(level set) của hàm mục tiêu5x+ 3y, mỗi đường ứng với một giá trị khác nhau với màu\\ncàng đỏ ứng với giá trị càng cao. Một cách trực quan, nghiệm của bài toán có thể tìm được\\nbằng cách di chuyển đường nét đứt màu xanh về phía bên phải (phía làm cho giá trị của\\nhàm mục tiêu lớn hơn) đến khi nó không còn điểm chung với phần đa giác màu xám nữa.\\nCó thể nhận thấy nghiệm của bài toán chính là điểm màu xanh là giao điểm của hai đường\\nthẳng x+ y= 10và 2x+ y= 16. Giải hệ phương trình này ta cóx∗= 6và y∗= 4. Tức anh\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 313, 'page_label': '302'}, page_content='CHƯƠNG 24. BÀI TOÁN TỐI ƯU LỒI 302\\nnông dân nên trồng 6ha cà phê và 4ha hồ tiêu. Lúc đó lợi nhuận thu được là5x∗+ 3y∗= 42\\ntriệu đồng, trong khi anh chỉ mất thời gian là 22 ngày. Trong khi đó, nếu trồng toàn bộ hồ\\ntiêu trong 32 ngày, tức 8ha, anh chỉ thu được 24 triệu đồng.\\nVới các bài toán tối ưu có nhiều biến hơn và nhiều ràng buộc hơn, sẽ rất khó để minh hoạ\\nvà tìm nghiệm như cách này. Chúng ta cần có một công cụ hiệu quả hơn, tốt nhất là nghiệm\\ncó thể tìm được bằng cách lập trình.\\n24.1.3 Bài toán đóng thùng\\nBài toán:Một công ty phải chuyển 400m3 cát tới địa điểm xây dựng ở bên kia sông bằng\\ncách thuê một chiếc xà lan. Ngoài chi phí vận chuyển một lượt đi về là 100k của chiếc xà\\nlan, công ty đó phải thiết kế một thùng hình hộp chữ nhật đặt trên xà lan để đựng cát.\\nChiếc thùng này không cần nắp, chi phí cho các mặt xung quanh là 1T/m2, cho mặt đáy là\\n2T/m2. Hỏi kích thước của chiếc thùng đó như thế nào để tổng chi phí vận chuyển là nhỏ\\nnhất. Để cho đơn giản, giả sử cát chỉ được đổ ngang hoặc thấp hơn với phần trên của thành\\nthùng, không có ngọn. Giả sử thêm rằng xà lanrộng vô hạnvà chứa được sức nặng vô hạn,\\ngiả sử này khiến bài toán dễ giải hơn.\\nPhân tích\\nGiả sử chiếc thùng cần làm có chiều dài, chiều rộng, chiều cao lần lượt làx,y,z (m). Thể\\ntích của thùng làxyz (đơn vị làm3). Có hai loại chi phí:\\n• Chi phí thuê xà lan. Số chuyến xà lan phải thuê là400\\nxyz (ta hãy tạm giả sử rằng đây là\\nmột số tự nhiên, việc làm tròn này sẽ không thay đổi kết quả đáng kể vì chi phí vận\\nchuyển một chuyến là nhỏ so với chi phí làm thùng). Số tiền phải trả cho xà lan sẽ là\\n0.1 400\\nxyz = 40\\nxyz = 40x−1y−1z−1 (0.1 ở đây là 0.1 triệu đồng).\\n• Chi phí làm thùng. Diện tích xung quanh của thùng là2(x+y)z. Diện tích đáy làxy. Vậy\\ntổng chi phí làm thùng là2(x+ y)z+ 2xy= 2(xy+ yz+ zx).\\nTổng toàn bộ chi phí làf(x,y,z ) = 40 x−1y−1z−1 + 2(xy+ yz + zx). Điều kiện ràng buộc\\nduy nhất là kích thước thùng phải là các số dương. Vậy ta có bài toán tối ưu sau đây.\\nBài toán vận chuyển:\\n(x,y) = arg min\\nx,y,z\\n40x−1y−1z−1 + 2(xy+ yz+ zx)\\nthoả mãn:x,y,z > 0\\n(24.3)\\nBài toán này thuộc loạigeometric programming (GP). Định nghĩa của GP và cách dùng\\ncông cụ tối ưu sẽ được trình bày trong phần sau của chương.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 314, 'page_label': '303'}, page_content='303 CHƯƠNG 24. BÀI TOÁN TỐI ƯU LỒI\\nBảng 24.1: Bảng các thuật ngữ và ký hiệu trong các bài toán tối ưu.\\nKý hiệu Tiếng Anh Tiếng Việt\\nx ∈Rn optimization variable biến tối ưu\\nf0 : Rn →R objective/loss/cost/function hàm mục tiêu\\nfi(x) ≤0 inequality constraint bất đẳng thức ràng buộc\\nfi : Rn →R inequality constraint function hàm bất đẳng thức ràng buộc\\nhj(x) = 0 equality constraint đẳng thức ràng buộc\\nhj : Rn →R equality constraint function hàm đẳng thức ràng buộc\\nD= ⋂m\\ni=0 domfi ∩⋂p\\nj=1 domhj domain tập xác định\\nNhận thấy rằng bài này hoàn toàn có thể dùng bất đẳng thức Cauchy để giải được, nhưng\\nchúng ta muốn một lời giải cho bài toán tổng quát sao cho có thể lập trình được.\\n(Lời giải:\\nf(x,y,z ) = 20\\nxyz + 20\\nxyz + 2xy+ 2yz+ 2zx ≥5\\n5√\\n3200\\ndấu bằng xảy ra khi và chỉ khix= y= z =\\n5√\\n10.)\\nNếu có các ràng buộc về kích thước của thùng và trọng lượng mà xà lan tải được thì có thể\\ntìm được lời giải đơn giản như thế này không?\\nNhững bài toán trên đây đều là các bài toán tối ưu. Chính xác hơn nữa, chúng đều là các bài\\ntoán tối ưu lồi (convex optimization problems) như các bạn sẽ thấy ở phần sau của chương.\\nTrước hết, chúng ta cần hiểu các khái niệm về cácbài toán tối ưu lồi convex optimization\\nproblems và tại sao chúng lại quan trọng.\\n24.2 Nhắc lại bài toán tối ưu\\n24.2.1 Các khái niệm cơ bản\\nBài toán tối ưu ở dạng tổng quát:\\nx∗= arg min\\nx\\nf0(x)\\nthoả mãn:fi(x) ≤0, i = 1,2,...,m\\nhj(x) = 0, j = 1,2,...,p\\n(24.4)\\nPhát biểu bằng lời: Tìm giá trị của biếnx để tối thiểu hàmf0(x) trong số các giá trị củax\\nthoả mãn các điệu hiện ràng buộc. Ta có bảng các khái niệm và ký hiệu trong bài toán tối\\nưu bằng cả tiếng Anh và tiếng Việt như trong Bảng 24.1. Ngoài ra,\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 315, 'page_label': '304'}, page_content='CHƯƠNG 24. BÀI TOÁN TỐI ƯU LỒI 304\\n• Khi m= p= 0, bài toán (24.4) được gọi làbài toán tối ưu không ràng buộc(unconstrained\\noptimization problem).\\n• Dlà tập xác định, tức giao của tất cả các tập xác định của mọi hàm số xuất hiện trong\\nbài toán. Tập hợp các điểm thoả mãn mọi điều kiện ràng buộc, thông thường, là một tập\\ncon củaDđược gọi làfeasible sethoặc constraint set. Khifeasible setlà một tập rỗng thì\\nta nói bài toán tối ưu (24.4) làinfeasible (vô nghiệm). Nếu một điểm nằm trongfeasible\\nset, ta gọi điểm đó làfeasible.\\n• Optimal value (giá trị tối ưu) của bài toán tối ưu (24.4) được định nghĩa là:\\np∗= inf{f0(x)|fi(x) ≤0,i = 1,...,m ; hj(x) = 0,j = 1,...,p }\\ntrong đó inf là viết tắt của hàm infimum.p∗có thể nhận các giá trị±∞. Nếu bài toán là\\ninfeasible, tức không có điểm nào thoả mãn tất cả các ràng buộc, ta coip∗ = +∞, Nếu\\nhàm mục tiêu không bị chặn dưới (unbounded below) trong tập xác định, ta coip∗= −∞.\\n24.2.2 Optimal và locally optimal points\\nMột điểmx∗được gọi là một điểmoptimal point(điểm tối ưu), hoặc lànghiệm của bài toán\\n(24.4) nếux∗là feasible vàf0(x∗) = p∗. Tấp họp tất cả cácoptimal pointđược gọi làoptimal\\nset. Nếu optimal set là một tậpkhông rỗng, ta nói bài toán (24.4) làgiải được (solvable).\\nNgược lại, nếuoptimal set là một tập rỗng, ta nóioptimal valuelà không thể đạt được(not\\nattained/ not achieved).\\nVí dụ: xét hàm mục tiêuf(x) = 1/x với ràng buộcx >0. Optimal value của bài toán này\\nlà p∗= 0 nhưng optimal set là một tập rỗng vì không có giá trị nào củax để hàm mục tiêu\\nđạt giá trị 0. Lúc này ta nóigiá trị tối ưulà không đạt được.\\nVới hàm một biến, một điểm làcực tiểucủa hàm số nếu tại đó, hàm số đạt giá trị nhỏ nhất\\ntrong một lân cận (và lân cận này thuộc tập xác định của hàm số). Trong không gian một\\nchiều, lân cận của một điểm được hiểu là tập các điểm cách điểm đó một khoảng rất nhỏ.\\nTrong không gian nhiều chiều, ta gọi một điểmx là locally optimal nếu tồn tại một giá trị\\nR> 0 sao cho:\\nf0(x) = inf\\n{\\nf0(z)|fi(z) ≤0,i = 1,...,m,\\nhj(z) = 0,j = 1,...,p, ∥z −x∥2 ≤R\\n}\\n(24.5)\\nNếu một điểm feasible x thoả mãn fi(x) = 0 , ta nói rằng bất đẳng thức ràng buộc thứ\\ni: fi(x) = 0 là active. Nếufi(x) <0, ta nói rằng ràng buộc này làinactive tại x.\\n24.2.3 Một vài lưu ý\\nMặc dù trong định nghĩa bài toán tối ưu (24.4) là cho bài toántối thiểu hàm mục tiêuvới\\ncác ràng buộc thoả mãn các điều kiện nhỏ hơn hoặc bằng 0, các bài toán tối ưu vớitối đa\\nhàm mục tiêuvà điều kiện ràng buộc ở dạng khác đều có thể đưa về được dạng này:\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 316, 'page_label': '305'}, page_content='305 CHƯƠNG 24. BÀI TOÁN TỐI ƯU LỒI\\n• max f0(x) ⇔min −f0(x).\\n• fi(x) ≤g(x) ⇔ fi(x) −g(x) ≤0.\\n• fi(x) ≥0 ⇔ −fi(x) ≤0.\\n• a≤fi(x) ≤b⇔ fi(x) −b≤0 và a−fi(x) ≤0.\\n• fi(x) ≤0 ⇔fi(x) + si = 0 và si ≥0. si được gọi làslack variable. Phép biến đổi đơn\\ngiản này trong nhiều trường hợp lại tỏ ra hiệu quả vì bất đẳng thứcsi ≥0 thường dễ giải\\nquyết hơn làfi(x) ≤0.\\n24.3 Bài toán tối ưu lồi\\nTrong toán tối ưu, chúng ta đặc biệt quan tâm tới những bài toán mà hàm mục tiêu là một\\nhàm lồi, vàfeasible setcũng là một tập lồi.\\n24.3.1 Định nghĩa\\nĐịnh nghĩa 24.1: Bài toán tối ưu lồi\\nMột bài toán tối ưu lồi(convex optimization problem) là một bài toán tối ưu có dạng\\nx∗= arg min\\nx\\nf0(x)\\nthoả mãn:fi(x) ≤0, i = 1,2,...,m\\nhj(x) = aT\\nj x −bj = 0,j = 1,...,\\ntrong đóf0,f1,...,f m là các hàm lồi.\\nSo với bài toán tối ưu (24.4), bài toán tối ưu lồi (24.6) có thêm ba điều kiện nữa:\\n• Hàm mục tiêulà mộthàm lồi.\\n• Các hàm bất đẳng thức ràng buộcfi là các hàm lồi.\\n• Hàm đẳng thức ràng buộchj là affine.\\nMột vài nhận xét:\\n• Tập hợp các điểm thoả mãnhj(x) = 0 là một tập lồi vì nó có dạng mộthyperplane.\\n• Khi fi là mộthàm lồi thì tập hợp các điểm thoả mãnfi(x) ≤0 chính là 0–sublevel set\\ncủa fi và là một tập lồi.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 317, 'page_label': '306'}, page_content='CHƯƠNG 24. BÀI TOÁN TỐI ƯU LỒI 306\\n• Như vậy, tập hợp các điểm thoả mãn mọi điều kiện ràng buộc chính là giao điểm của các\\ntập lồi, vì vậy nó là một tập lồi.\\nTrong bài toán tối ưu lồi, ta tối thiểu một hàm mục tiêu lồi trên một tập lồi.\\n24.3.2 Local optimum của bài toán tối ưu lồi chính là global optimum của nó\\nTính chất quan trọng nhất của bài toán tối ưu lồi chính là mọi điểmlocally optimal point\\nchính là một điểm(globally) optimal point (điểm cực tiểu chính là nghiệm của bài toán).\\nViệc này có thể chứng minh bằng phản chứng.. Gọix0 là một điểmlocally optimal:\\nf0(x0) = inf{f0(x)|x ∈ feasible set,∥x −x0∥2 ≤R}\\nvới R> 0 nào đó. Giả sửx0 không phải là một điểmglobally optimal, tức tồn tại một điểm\\nfeasible y sao chof(y) <f (x0) (hiển nhiên rằngy không nằm trong lân cận đang xét). Ta\\ncó thể tìm đượcθ∈[0,1] đủ nhỏ sao choz = (1 −θ)x0 + θy nằm trong lân cận củax0, tức\\n∥z −x0∥2 <R. Việc này có được vì feasible set là một tập lồi. Hơn nữa, vìhàm mục tiêuf0\\nlà một hàm lồi, ta có\\nf0(z) = f0((1 −θ)x0 + θy) (24.6)\\n≤(1 −θ)f0(x0) + θf0(y) (24.7)\\n<(1 −θ)f0(x0) + θf0(x0) = f0(x0) (24.8)\\nđiều này mâu thuẫn với giả thiếtx0 là một điểm cực tiểu. Vậy giả sử sai, tứcx0 chính là\\nglobally optimal pointvà ta có điều phải chứng minh. □\\nChứng minh bằng lời: giả sử một điểm cực tiểu không phải là điểm làm cho hàm số đạt giá\\ntrị nhỏ nhất. Với điều kiệnfeasible set và hàm mục tiêulà lồi, ta luôn tìm được một điểm\\nkhác trong lân cận của điểm cực tiểu đó sao cho giá trị của hàm mục tiêu tại điểm mới này\\nnhỏ hơn giá trị của hàm mục tiêu tại điểm cực tiểu. Sự mâu thuẫn này chỉ ra rằng với một\\nbài toán tối ưu lồi, điểm cực tiểu phải là điểm làm cho hàm số đạt giá trị nhỏ nhất.\\n24.3.3 Điều kiện tối ưu cho hàm mục tiêu khả vi\\nNếu hàm mục tiêuf0 là khả vi, theo first-order condition, với mọix,y ∈domf0, ta có:\\nf0(x) ≥f0(x0) + ∇f0(x0)T(x −x0) (24.9)\\nĐặt Xlà feasible set. Điều kiện cần và đủđể một điểmx0 ∈X là optimal pointlà:\\n∇f0(x0)T(x −x0) ≥0, ∀x ∈X (24.10)\\nPhần chứng minh cho điều kiện này được bỏ qua, bạn đọc có thể tìm trong trang 139-140\\ncủa cuốn Convex Optimization [BV04].\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 318, 'page_label': '307'}, page_content='307 CHƯƠNG 24. BÀI TOÁN TỐI ƯU LỒI\\nx0\\nfeasible set X\\nlevel sets\\n−∇f0(x0)x\\nf0(x\\n0)\\nsupporting hyperplane\\nHình 24.2:Biểu diễn hình học của\\nđiều kiện tối ưu cho hàm mục tiêu\\nkhả vi. Các đường nét đứt có màu\\ntương ứng với các level sets (đường\\nđồng mức).\\nĐiều này chỉ ra rằng nếu∇f0(x0) = 0 thì x0 chính là một điểm optimal của bài toán. Nếu\\n∇f0(x0) ̸= 0 , nghiệm của bài toán sẽ phải nằm trên biên của feasible set. Thật vậy, quan sát\\nHình 24.2, điều kiện này nói rằng nếux0 là một điểm optimal thì với mọix ∈X, vector đi từ\\nx0 tới x hợp với vector−∇f0(x0) một góc tù. Nói cách khác, nếu ta vẽ mặt tiếp tuyến của\\nhàm mục tiêu tạix0 thì mọi điểm feasible nằm về một phía so với mặt tiếp tuyến này. Điều\\nnày chỉ ra rằngx0 phải nằm trên biên của feasible setX. Hơn nữa, feasible set nằm về phía\\nlàm cho hàm mục tiêu đạt giá trị cao hơnf0(x0). Mặt tiếp tuyến này chính làsupporting\\nhyperplane của feasible set tại điểmx0. Nhắc lại rằng khi vẽ các level set, chúng ta dùng\\nmàu lam để chỉ giá trị nhỏ, màu đỏ để chỉ giá trị lớn của hàm.\\n(Một mặt phẳng đi qua một điểm trên biên của một tập hợp sao cho mọi điểm trong tập\\nhợp đó nằm về một phía (hoặc nằm trên) so với mặt phẳng đó được gọi là mộtsiêu phẳng\\nhỗ trợ (supporting hyperplane). Nếu một tập hợp làlồi, tồn tạisupporting hyperplane tại\\nmọi điểm trên biên của nó.)\\n24.3.4 Giới thiệu thư viện CVXOPT\\nCVXOPT là một thư viện miễn phí trên Python đi kèm với cuốn sách Convex Optimization.\\nHướng dẫn cài đặt, tài liệu hướng dẫn, và các ví dụ mẫu của thư viện này cũng có đầy đủ\\ntrên trang web CVXOPT (http://cvxopt.org/ ). Trong phần còn lại của chương, chúng ta\\nsẽ thảo luận ba bài toán cơ bản trong convex optimization: linear programming, quadratic\\nprogramming, và geometric programming. Chúng ta sẽ cùng lập trình để giải các ví dụ đã\\nnêu ở phần đầu bài viết dựa trên thư viện CVXOPT này.\\n24.4 Linear programming\\nChúng ta cùng bắt đầu với lớp các bài toán đơn giản nhất trong convex optimization - linear\\nprogramming (LP). Trong đó, hàm mục tiêuf0(.) và các hàm bất đẳng thức ràng buộc\\nfi(.),i = 1 ,...,m đều là các hàmaffine.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 319, 'page_label': '308'}, page_content='CHƯƠNG 24. BÀI TOÁN TỐI ƯU LỒI 308\\n24.4.1 Dạng tổng quát của linear programming\\nDạng tổng quát (general form) của linear programming\\nx = arg min\\nx\\ncTx + d\\nthoả mãn: Gx ⪯h (24.11)\\nAx = b\\nTrong đóG ∈Rm×n,h ∈Rm, A ∈Rp×n,b ∈Rp, c,x ∈Rn và d∈R.\\nSố vô hướngdchỉ làm thay đổi giá trị của hàm mục tiêu mà không làm thay đổi nghiệm của\\nbài toán nên có thể được lược bỏ. Nhắc lại rằng ký hiệu⪯nghĩa là mỗi phần tử trong vector\\nở vế trái nhỏ hơn hoặc bằng phần tử tương ứng trong vector ở vế phải. Chú ý rằng nhiều\\nbất đẳng thức dạnggix ≤hi, vớigi là các vector hàng, có thể viết gộp dưới dạngGx ⪯h\\ntrong đó mỗi hàng củaG ứng với mộtgi, mỗi phần tử củah tương ứng với mộthi.\\n24.4.2 Dạng tiêu chuẩn của linear programming\\nTrong dạng tiêu chuẩn (standard form) LP, các bất đẳng thức ràng buộc chỉ là điều kiện các\\nnghiệm có thành phần không âm.\\nDạng tiêu chuẩn của linear programming\\nx = arg min\\nx\\ncTx\\nthoả mãn:Ax = b\\nx ⪰0\\n(24.12)\\nDạng tổng quát (24.11) có thể được đưa về dạng tiểu chuẩn (24.12) bằng cách đặt thêm biến\\nslack s.\\nx = arg min\\nx,s\\ncTx\\nthoả mãn:Ax = b\\nGx + s = h\\ns ⪰0\\n(24.13)\\nTiếp theo, nếu ta biểu diễnx dưới dạng hiệu của hai vector mà thành phần của nó đều\\nkhông âm, tức:x = x+ −x−, vớix+,x−⪰0. Ta có thể tiếp tục viết lại (24.13) dưới dạng:\\nx = arg min\\nx+,x−,s\\ncTx+ −cTx−\\nthoả mãn:Ax+ −Ax−= b\\nGx+ −Gx−+ s = h\\nx+ ⪰0,x−⪰0,s ⪰0\\n(24.14)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 320, 'page_label': '309'}, page_content='309 CHƯƠNG 24. BÀI TOÁN TỐI ƯU LỒI\\nfeasible set X\\nLinear Programming\\nx0x1 −c\\nHình 24.3:Biểu diễn hình học của\\nlinear programming.\\nTới đây, bạn đọc có thể thấy rằng (24.14) có thể viết gọn lại như (24.12).\\n24.4.3 Minh hoạ bằng hình học của bài toán linear programming\\nCác bài toán LP có thể được minh hoạ như Hình 24.3. Điểmx0 chính là điểm làm cho hàm\\nmục tiêu đạt giá trị nhỏ nhất, điểmx1 chính là điểm làm cho hàm mục tiêu đạt giá trị lớn\\nnhất. Nghiệm của các bài toán LP, nếu có, thường là một điểm ởđỉnh của polyheron feasible\\nset hoặc là mộtmặt của polyhedron đó (trong trường hợp các đường level sets của hàm mục\\ntiêu song song với mặt đó, và trên mặt đó, hàm mục tiêu đạt giá trị tối ưu).\\nTiếp theo, chúng ta sẽ dùng thư viện CVXOPT để giải các bài toán LP.\\n24.4.4 Giải LP bằng CVXOPT\\nNhắc lại bài toán canh tác\\n(x,y) = arg max\\nx,y\\n5x+ 3y\\nthoả mãn:x+ y≤10\\n2x+ y≤16\\nx+ 4y≤32\\nx,y ≥0\\n(24.15)\\nCác điều kiện ràng buộc có thể viết lại dưới dạngGx ⪯h, trong đó\\nG =\\n\\uf8ee\\n\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8f0\\n1 1\\n2 1\\n1 4\\n−1 0\\n0 −1\\n\\uf8f9\\n\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fb\\nh =\\n\\uf8ee\\n\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8f0\\n10\\n16\\n32\\n0\\n0\\n\\uf8f9\\n\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fb\\nKhi sử dụng CVXOPT, chúng ta lập trình như sau:\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 321, 'page_label': '310'}, page_content='CHƯƠNG 24. BÀI TOÁN TỐI ƯU LỒI 310\\nfrom cvxopt import matrix, solvers\\nc = matrix([-5., -3.]) # since we need to maximize the objective funtion\\nG = matrix([[1., 2., 1., -1., 0.], [1., 1., 4., 0., -1.]])\\nh = matrix([10., 16., 32., 0., 0.])\\nsolvers.options[’show_progress’] = False\\nsol = solvers.lp(c, G, h)\\nprint(’Solution\"’)\\nprint(sol[’x’])\\nKết quả:\\nSolution:\\n[ 6.00e+00]\\n[ 4.00e+00]\\nNghiệm này chính là nghiệm mà chúng ta đã tìm được trong phần đầu của bài viết dựa trên\\nbiểu diễn hình học.\\nMột vài lưu ý:\\n• Hàm solvers.lp của cvxopt giải bài toán (24.13).\\n• Trong bài toán của chúng ta, vì ta cần tìm giá trị lớn nhất nên ta phải đổi hàm mục tiêu\\nvề dạng−5x−3y. Chính vì vậy màc = matrix([−5., −3.]).\\n• Hàm matrix nhận đầu vào là mộtlist (trong Python),list này thể hiện một vector cột.\\nNếu muốn biểu diễn một ma trận, đầu vào củamatrix là mộtlist của list, trong đó mỗi\\nlist bên trong thể hiện một vector cột của ma trận đó.\\n• Các hằng số trong bài toán cần ở dạng số thực. Nếu chúng là các số nguyên, ta cần thêm\\ndấu . vào sau các số đó thể thể hiện đó là số thực.\\n• Với đẳng thức ràng buộcAx = b, solvers.lp lấy giá trị mặc định củaA và b là None, tức\\nnếu không khái báo thì nghĩa là không có đẳng thức ràng buộc nào.\\nVới các tuỳ chọn khác, bạn đọc có thể tìm trong tài liệu của CVXOPT(https://goo.gl/\\nq5CZmz). Việc giải Bài toán NXB bằng CVXOPT xin nhường lại cho bạn đọc.\\n24.5 Quadratic programming\\n24.5.1 Bài toán quadratic programming\\nMột dạng bài toán convex optimization phổ biến khác làquadratic programming(QP). Khác\\nbiệt duy nhất của QP so với LP là hàm mục tiêu códạng toàn phương(quadratic form).\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 322, 'page_label': '311'}, page_content='311 CHƯƠNG 24. BÀI TOÁN TỐI ƯU LỒI\\n−∇f0(x0)\\nfeasible set X\\nQuadratic Programming\\nx0\\nHình 24.4:Biểu diễn hình học của\\nQuadratic Programming.\\nQuadratic Programming\\nx = arg min\\nx\\n1\\n2xTPx + qTx + r\\nthoả mãn:Gx ⪯h\\nAx = b\\n(24.16)\\nTrong đóP là một ma trận vuông nửa xác định dương bậcn, G ∈Rm×n,A ∈Rp×n.\\nĐiều kiện nửa xác định dương củaP để đảm bảo rằng hàm mục tiêu là convex. Trong QP,\\nmột hàm quadratic lồi được tối thiểu trên mộtpolyhedron (Xem Hình 24.4). LP chính là\\nmột trường hợp đặc biệt của QP vớiP = 0.\\n24.5.2 Ví dụ về QP\\nBài toán vui:Có một hòn đảo có dạng một đa giác lồi. Một con thuyền ở ngoài biển thì\\ncần đi theo hướng nào để tới đảo nhanh nhất, giả sử rằng tốc độ của sóng và gió bằng 0. Có\\nthể thấy rằng nghiệm của bài toán chính là một góc của đảo gần con thuyền nhất hoặc hình\\nchiếu vuông góc của thuyền tới cạnh gần nhất của đảo. Đây chính là bài toán tìm khoảng\\ncách từ một điểm tới một polyhedron.\\nBài toán tìm khoảng cách từ một điểm tới một polyhedron: cho một polyhedron là tập hợp\\ncác điểm thoả mãnAx ⪯b, và một điểmu, tìm điểmx thuộc polyhedron đó sao cho khoảng\\ncách Euclidean giữax và u là nhỏ nhất. Đây là một bài toán QP có dạng\\nx = arg min\\nx\\n1\\n2∥x −u∥2\\n2\\nthoả mãn: Gx ⪯h\\nHàm mục tiêu đạt giá trị nhỏ nhất bằng 0 nếuu nằm trong polyheron đó và nghiệm chính\\nlà x = u. Khiu không nằm trong polyhedron, ta viết\\n1\\n2∥x −u∥2\\n2 = 1\\n2(x −u)T(x −u) = 1\\n2xTx −uTx + 1\\n2uTu\\nBiểu thức này có dạng hàm mục tiêu như trong (24.16) vớiP = I,q = −u,r = 1\\n2 uTu, trong\\nđó I là ma trận đơn vị.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 323, 'page_label': '312'}, page_content='CHƯƠNG 24. BÀI TOÁN TỐI ƯU LỒI 312\\nx\\ny\\nx\\n+\\ny\\n= 10\\n2\\nx\\n+\\ny\\n= 16\\nx + 4 y = 32\\n(0 , 0)\\n(10 , 10)\\nHình 24.5: Ví dụ về khoảng\\ncách giữa một điểm và một\\npolyhedron.\\n24.5.3 Giải QP bằng CVXOPT\\nXét bài toán được cho trên Hình 24.5. Ta cần tìm khoảng cách từ điểm có toạ độ(10,10)\\ntới hình đa giác lồi màu xám. Chú ý rằng khoảng cách từ một điểm tới một tập hợp chính\\nlà khoảng cách từ điểm đó tới điểm gần nhất trong tập hợp. Bài toán này được viết dưới\\ndạng QP như sau:\\n(x,y) = arg min\\nx,y\\n(x−10)2 + (y−10)2\\nthoả mãn:\\n\\uf8ee\\n\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8f0\\n1 1\\n2 1\\n1 4\\n−1 0\\n0 −1\\n\\uf8f9\\n\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fb\\n[x\\ny\\n]\\n⪯\\n\\uf8ee\\n\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8f0\\n10\\n16\\n32\\n0\\n0\\n\\uf8f9\\n\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fb\\nFeasible settrong bài toán được lấy từ Bài toán canh tác, vàu = [10,10]T. Bài toán này có\\nthể được giải bằng CVXOPT như sau:\\nfrom cvxopt import matrix, solvers\\nP = matrix([[1., 0.], [0., 1.]])\\nq = matrix([-10., -10.])\\nG = matrix([[1., 2., 1., -1., 0.], [1., 1., 4., 0., -1.]])\\nh = matrix([10., 16., 32., 0., 0])\\nsolvers.options[’show_progress’] = False\\nsol = solvers.qp(P, q, G, h)\\nprint(’Solution:’)\\nprint(sol[’x’])\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 324, 'page_label': '313'}, page_content='313 CHƯƠNG 24. BÀI TOÁN TỐI ƯU LỒI\\nKết quả:\\nSolution:\\n[ 5.00e+00]\\n[ 5.00e+00]\\nNhư vậy, nghiệm của bài toán tối ưu này là điểm có toạ độ(5,5) .\\n24.6 Geometric Programming\\nTrong mục này, chúng ta cùng thảo luận một lớp các bài toánkhông lồi khi quan sát hàm\\nmục tiêu và các hàm ràng buộc, nhưng có thể được biến đổi về dạnglồi bằng một vài kỹ thuật\\nkhông quá phức tạp. Trước hết, ta làm quen với hai khái niệmmonomial và posynomial.\\n24.6.1 Monomial và posynomial\\nMột hàm sốf : Rn →R với tập xác đinh domf = Rn\\n++ (tất cả các phần tử đều là số dương)\\ncó dạng\\nf(x) = cxa1\\n1 xa2\\n2 ...x an\\nn (24.17)\\ntrong đóc> 0 và ai ∈R, được gọi là mộtmonomial function (khái niệm này khá giống với\\nđơn thứctrong chương trình phổ thông, nhưng sách giáo khoa định nghĩa vớicbất kỳ vàai\\nlà các số tự nhiên).\\nTổng của các monomial\\nf(x) =\\nK∑\\nk=1\\nckxa1k\\n1 xa2k\\n2 ...x ank\\nn (24.18)\\ntrong đó cácck >0, được gọi làposynomial function(đa thức), hoặc đơn giản làposynomial.\\n24.6.2 Geometric programming\\nGeometric programming (GP)\\nx = arg min\\nx\\nf0(x)\\nthoả mãn:fi(x) ≤1, i = 1,2,...,m\\nhj(x) = 1, j = 1,2,...,p\\n(24.19)\\ntrong đóf0,f1,...,f m là các posynomials vàh1,...,h p là các monomials.\\nĐiều kiệnx ≻0 đã được ẩn đi.\\nChú ý rằng nếuf là mộtposynomial, h là mộtmonomial thì f/h là mộtposynomial.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 325, 'page_label': '314'}, page_content='CHƯƠNG 24. BÀI TOÁN TỐI ƯU LỒI 314\\nVí dụ, bài toán tối ưu\\n(x,y,z ) = arg min\\nx,y,z\\nx/y\\nthoả mãn: 1 ≤x≤2 (24.20)\\nx3 + 2y/z ≤√y\\nx/y= z\\ncó thể được viết lại dưới dạng GP:\\n(x,y,z ) = arg min\\nx,y,z\\nxy−1\\nthoả mãn: x−1 ≤1 (24.21)\\n(1/2)x≤1\\nx3y−1/2 + 2y1/2z−1 ≤1\\nxy−1z−1 = 1\\nBài toán này rõ ràng làkhông lồi vì cả hàm mục tiêu và điều kiển ràng buộc đều không lồi.\\n24.6.3 Biến đổi GP về dạng bài toán tối ưu lồi\\nGP có thể được biến đổi về dạng lồi bằng cách sau đây. Đặtyi = log(xi), tứcxi = exp(yi).\\nNếu f là mộtmonomial function của x thì:\\nf(x) = c(exp(y1))a1 ... (exp(yn))an = cexp\\n( n∑\\ni=1\\naiyi\\n)\\n= exp(aTy + b)\\nvới b = log(c). Lúc này, hàm sốg(y) = exp( aTy + b) là một hàm lồi theoy. (Bạn đọc có\\nthể chứng minh theo định nghĩa rằng hợp của hai hàm lồi là một hàm lồi. Trong trường hợp\\nnày, hàmexp và hàmaffine trên đều là các hàm lồi.)\\nTương tự như thế,posynomial trong đẳng thức (24.18) có thể được viết dưới dạng\\nf(x) =\\nK∑\\nk=1\\nexp(aT\\nky + bk)\\ntrong đóak = [a1k,...,a nk]T,bk = log(ck) và yi = log(x). Lúc này,posynomial đã được viết\\ndưới dạng tổng của các hàmexp của các hàmaffine, và vì vậy là một hàm lồi theoy, nhắc\\nlại rằng tổng của các hàm lồi là một hàm lồi.\\nBài toán GP (24.19) được viết lại dưới dạng:\\ny = arg min\\ny\\nK0∑\\nk=1\\nexp(aT\\n0ky + b0k)\\nthoả mãn:\\nKi∑\\nk=1\\nexp(aT\\niky + bik) ≤1, i = 1,...,m\\nexp(gT\\nj y + hj) = 1, j= 1,...,p\\n(24.22)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 326, 'page_label': '315'}, page_content='315 CHƯƠNG 24. BÀI TOÁN TỐI ƯU LỒI\\nvới aik ∈Rn, ∀i= 1,...,p và gj ∈Rn, ∀j = 1,...,p .\\nVới chú ý rằng hàm sốlog (∑m\\ni=1 exp(gi(z))) là môt hàmlồi theo z nếu gi là các hàmlồi\\n(xin bỏ qua phần chứng minh), ta có thể viết lại bài toán (24.22) dưới dạnglồi bằng cách\\nlấy log của các hàm như sau.\\nGeometric programming dưới dạng bài toán tối ưu lồi\\nminimizey ˜f0(y) = log\\n(K0∑\\nk=1\\nexp(aT\\n0ky + bi0)\\n)\\nthoả mãn: ˜fi(y) = log\\n(Ki∑\\nk=1\\nexp(aT\\niky + bik)\\n)\\n≤0, i = 1,...,m\\n˜hj(y) = gT\\nj y + hj = 0, j = 1,...,p\\n(24.23)\\nLúc này, ta có thể nói rằng GP tương đương với một bài toán tối ưu lồi vì hàm mục tiêu\\nvà các hàm bất đẳng thức ràng buộc trong (24.23) đều là hàm lồi, đồng thời điều hiện đẳng\\nthức cuối cùng chính là dạngaffine. Dạng này thường được gọi làgeometric program in\\nconvex form(để phân biệt nó với dạng định nghĩa của GP).\\n24.6.4 Giải GP bằng CVXOPT\\nQuay lại ví dụ về Bài toán đóng thùngkhông có ràng buộcvà hàm mục tiêu làf(x,y,z ) =\\n40x−1y−1z−1 + 2xy+ 2yz+ 2zx là một posynomial. Vậy đây là một GP.\\nNghiệm của bài toán có thể được tìm bằng CVXOPT như sau:\\nfrom cvxopt import matrix, solvers\\nfrom math import log, exp# gp\\nfrom numpy import array\\nimport numpy as np\\nK = [4] # number of monomials\\nF = matrix([[-1., 1., 1., 0.],\\n[-1., 1., 0., 1.],\\n[-1., 0., 1., 1.]])\\ng = matrix([log(40.), log(2.), log(2.), log(2.)])\\nsolvers.options[’show_progress’] = False\\nsol = solvers.gp(K, F, g)\\nprint(’Solution:’)\\nprint(np.exp(np.array(sol[’x’])))\\nprint(’\\\\nchecking sol^5’)\\nprint(np.exp(np.array(sol[’x’]))**5)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 327, 'page_label': '316'}, page_content='CHƯƠNG 24. BÀI TOÁN TỐI ƯU LỒI 316\\nKết quả:\\nSolution:\\n[[ 1.58489319]\\n[ 1.58489319]\\n[ 1.58489319]]\\nchecking sol^5\\n[[ 9.9999998]\\n[ 9.9999998]\\n[ 9.9999998]]\\nNghiệm thu được chính làx= y= z =\\n5√\\n10. Bạn đọc được khuyến khích đọc thêm chỉ dẫn\\ncủa hàmsolvers.gp (https://goo.gl/5FEBtn ) để hiểu cách thiết lập và giải bài toán GP.\\n24.7 Tóm tắt\\n• Các bài toán tối ưu xuất hiện rất nhiều trong thực tế, trong đó tối ưu lồi đóng một vai\\ntrò quan trọng. Trong bài toán tối ưu lồi, nếu tìm được cực trị thì cực trị đó chính là một\\nđiểm optimal của bài toán (nghiệm của bài toán).\\n• Có nhiều bài toán tối ưu không được viết dưới dạng lồi nhưng có thể biến đổi về dạng\\nlồi, ví dụ như bài toán geometric programming.\\n• Linear programming và quadratic programming đóng một vài trò quan trọng trong toán\\ntối ưu, được sử dụng nhiều trong các thuật toán Machine Learning.\\n• Thư viện CVXOPT được dùng để tối ưu nhiều bài toán tối ưu lồi, rất dễ sử dụng và thời\\ngian chạy tương đối nhanh. Phù hợp với mục đích học tập và nghiên cứu.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 328, 'page_label': '317'}, page_content='Chương 25\\nDuality\\n25.1 Giới thiệu\\nTrong Chương 23, chúng ta đã làm quen với các khái niệm về tập hợp lồi và hàm số lồi. Tiếp\\ntheo đó, trong Chương 24, chúng ta đã thảo luận các bài toán tối ưu lồi, cách nhận dạng và\\ncách sử dụng thư viện để giải các bài toán tối ưu lồi cơ bản. Trong chương này, chúng ta sẽ\\ntiếp tục tiếp cận một cách sâu hơn: các điều kiện về nghiệm của các bài toán tối ưu, cả lồi\\nvà không lồi;bài toán đối ngẫu(dual problem) và điều kiện KKT.\\nTrước tiên chúng ta xét bài toán mà ràng buộc chỉ là một phương trình:\\nx = arg min\\nx\\nf0(x)\\nthoả mãn:f1(x) = 0\\n(25.1)\\nBài toán này là bài toán tổng quát, không nhất thiết phải lồi. Tức hàm mục tiêu và hàm\\nràng buộc không nhất thiết phải lồi. Bài toán này có thể được giải bằng phương pháp nhân\\ntử Lagrange (xem Phụ Lục A). Cụ thể, xét hàm sốL(x,λ) = f0(x) + λf1(x). Chú ý rằng,\\ntrong hàm số này, chúng ta có thêm một biến nữa làλ, biến này được gọi lànhân tử Lagrange\\n(Lagrange multiplier). Hàm sốL(x,λ) được gọi làhàm hỗ trợ(auxiliary function), haythe\\nLagrangian. Người ta đã chứng minh được rằng, điểmoptimal valuecủa bài toán (25.1) thoả\\nmãn điều kiện∇x,λL(x,λ) = 0. Điều này tương dương với\\n∇xf0(x) + λ∇xf1(x) = 0 (25.2)\\nf1(x) = 0 (25.3)\\nĐể ý rằng điều kiện thứ hai chính là∇λL(x,λ) = 0, và cũng chính là ràng buộc trong bài\\ntoán (25.1). Việc giải hệ phương trình (25.2) - (25.3), trong nhiều trường hợp, đơn giản hơn\\nviệc trực tiếp đi tìmoptimal valuecủa bài toán (25.1). Một vài ví dụ về phương pháp nhân\\ntử Lagrange có thể được tìm thấy tại Phụ Lục A.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 329, 'page_label': '318'}, page_content='CHƯƠNG 25. DUALITY 318\\n25.2 Hàm đối ngẫu Lagrange\\n25.2.1 Lagrangian\\nVới bài toán tối ưu tổng quát\\nx∗= arg min\\nx\\nf0(x)\\nthoả mãn:fi(x) ≤0, i = 1,2,...,m\\nhj(x) = 0, j = 1,2,...,p\\n(25.4)\\nvới miền xác đinhD= (∩m\\ni=0domfi) ∩(∩p\\nj=1domhj). Chú ý rằng, chúng ta đang không giả\\nsử về tính chất lồi của hàm tối ưu hay các hàm ràng buộc ở đây. Giả sử duy nhất ở đây là\\nD̸= ∅(tập rỗng). Bài toán tối ưu này còn được gọi làbài toán chính(primal problem).\\nLagrangian cũng được xây dựng tương tự với mỗi nhân tử Lagrange cho một (bất) phương\\ntrình ràng buộc:\\nL(x,λ,ν) = f0(x) +\\nm∑\\ni=1\\nλifi(x) +\\np∑\\nj=1\\nνjhj(x)\\nvới λ= [λ1,λ2,...,λ m]; ν= [ν1,ν2,...,ν p] là các vectors và được gọi làbiến đối ngẫu(dual\\nvariables) hoặc vector nhân tử Lagrange(Lagrange multiplier vectors). Lúc này nếu biến\\nchính x ∈Rn thì tổng số biến của hàm số này sẽ làn+ m+ p.\\n25.2.2 Hàm đối ngẫu Lagrange\\nHàm đối ngẫu Lagrange(the Lagrange dual function) của bài toán tối ưu (hoặc gọn làhàm\\nsố đối ngẫu) (25.4) là một hàm của các biến đối ngẫuλvàν, được định nghĩa là giá trị nhỏ\\nnhất theox của Lagrangian:\\ng(λ,ν) = inf\\nx∈D\\nL(x,λ,ν) = inf\\nx∈D\\n(\\nf0(x) +\\nm∑\\ni=1\\nλifi(x) +\\np∑\\nj=1\\nνjhj(x)\\n)\\n(25.5)\\nNếu Lagrangian không bị chặn dưới, hàm đối ngẫu tạiλ,ν sẽ lấy giá trị−∞.\\nĐặc biệt quan trọng:\\n• inf được lấy trên miềnx∈D, tức miền xác định của bài toán (là giao của miền xác định\\ncủa mọi hàm trong bài toán). Miền xác định này khác vớifeasible set – là tập hợp các\\nđiểm thoả mãn các ràng buộc.Feasible setlà một tập con của miền xác địnhD.\\n• Với mỗix, Lagrangian là một hàmaffine của (λ,ν), tức là một hàm vừa convex, vừa\\nconcave. Vậy, hàm đối ngẫu chính là một pointwise infimum của (có thể vô hạn) các hàm\\nconcave, tức là một hàm concave. Vậyhàm đối ngẫu của một bài toán tối ưu bất\\nkỳ là một hàm concave, bất kể bài toán ban đầu có phải là convex hay không.\\nNhắc lại rằngpointwise supremumcủa các hàmconvex là một hàmconvex, và một hàm\\nlà concave nếu khi đổi dấu hàm đó, ta được một hàmconvex (xem thêm Mục 23.3.2).\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 330, 'page_label': '319'}, page_content='319 CHƯƠNG 25. DUALITY\\n25.2.3 Chặn dưới của giá trị tối ưu\\nNếu p∗là optimal value (giá trị tối ưu) của bài toán (25.4) thì với các biến đối ngẫuλi ≥0,∀i\\nvà ν bất kỳ, chúng ta sẽ có\\ng(λ,ν) ≤p∗ (25.6)\\nTính chất này có thể được chứng minh như sau. Giả sửx0 là một điểmfeasible bất kỳ của\\nbài toán (25.4), tức thoả mãn các điều kiện ràng buộcfi(x0) ≤0,∀i = 1,...,m ; hj(x0) =\\n0,∀j = 1,...,p , ta sẽ có\\nL(x0,λ,ν) = f0(x0) +\\nm∑\\ni=1\\nλifi(x0)\\ued19 \\ued18\\ued17 \\ued1a\\n≤0\\n+\\np∑\\nj=1\\nνjhj(x0)\\ued19 \\ued18\\ued17 \\ued1a\\n=0\\n≤f0(x0)\\nVì điều này đúng với mọix0 feasible, ta sẽ có tính chất quan trọng sau đây:\\ng(λ,ν) = inf\\nx∈D\\nL(x,λ,ν) ≤L(x0,λ,ν) ≤f0(x0).\\nKhi x0 = x∗ (optimal point), f0(x0) = p∗, ta suy ra bất đẳng thức (25.6). Bất đẳng thức\\nquan trọng này chỉ ra rằng giá trị tối ưu của hàm mục tiêu trong dual problem (25.4) không\\nnhỏ hơn giá trị lớn nhất của hàm đối ngẫu Lagrangeg(λ,ν).\\n25.2.4 Ví dụ\\nVí dụ 1:Xét bài toán tối ưu\\nx= arg min\\nx\\nx2 + 10 sin(x) + 10\\nthoả mãn:(x−2)2 ≤4\\n(25.7)\\nVới bài toán này, miền xác địnhD= R nhưng feasible set là 0 ≤x ≤4. Đồ thị của hàm\\nmục tiêu được minh hoạ bởi đường đậm màu lam trong Hình 25.1a. Hàm số ràng buộc\\nf1(x) = (x−2)2 −4 được cho bởi đường nét đứt màu lục. Optimal value của bài toán này có\\nthể được nhận ra là điểm trên đồ thị có hoành độ bằng 0 (là điểm nhỏ nhất trên đường màu\\nlam trong đoạn[0,4]). Chú ý rằng hàm mục tiêu ở đây không phải là hàm lồi nên bài toán\\ntối ưu này cũng không phải là lồi, mặc dù hàm bất phương trình ràng buộcf1(x) là lồi.\\nLagrangian của bài toàn này có dạng\\nL(x,λ) = x2 + 10 sin(x) + 10 +λ((x−2)2 −4)\\nCác đường dấu chấm màu đỏ trong Hình 25.1a là các đường ứng với cácλkhác nhau. Vùng\\nbị chặn giữa hai đường thẳng đứng màu đen thể hiện miềnfeasible của bài toán tối ưu.\\nVới mỗiλ, dual function được định nghĩa là:\\ng(λ) = inf\\nx\\n(\\nx2 + 10 sin(x) + 10 +λ((x−2)2 −4)\\n)\\n, λ ≥0.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 331, 'page_label': '320'}, page_content='CHƯƠNG 25. DUALITY 320\\n−4 −2 0 2 4 6\\nx\\n−30\\n−20\\n−10\\n0\\n10\\n20\\n30\\n40\\nf0(x)\\nf1(x)\\nf0(x) + λf1(x)\\n(a)\\n0 2 4 6 8\\nλ\\n−7 .5\\n−5.0\\n−2.5\\n0 .0\\n2.5\\n5.0\\n7 .5\\n10.0\\ng(λ)\\np∗ (b)\\nHình 25.1:Ví dụ về dual function. (a) Đường màu lam đậm thể hiện hàm mục tiêu. Đường nét\\nđứt mà lục thể hiện hàm số ràng buộc. Các đường nét đứt màu đỏ thể hiện dual function ứng\\nvới cácλkhác nhau. (b) Đường nét đứt thể hiện giá trị tối ưu của bài toán . Đường màu đỏ thể\\nhiện dual function. Với mọiλ, giá trị của hàm dual function nhỏ hơn hoặc bằng giá trị tối ưu của\\nbài toán gốc (source code cho hình vẽ này có thể được tìm thấy tạihttps://goo.gl/jZiRCp .).\\nTừ Hình 25.1a, ta có thể thấy ngay rằng với cácλ khác nhau, giá củag(λ) hoặc tại điểm\\ncó hoành độ bằng 0 của đường màu lam, hoặc tại một điểm thấp hơn điểm đó. Đồ thị của\\nhàm g(λ) được cho bởi đường liền màu đỏ ở Hình 25.1b. Đường nét đứt màu lam thể hiện\\noptimal value của bài toán tối ưu ban đầu. Ta có thể thấy ngay hai điều:\\n• Đường liền màu đỏ luôn nằm dưới (hoặc có đoạn trùng) với đường nét đứt màu lam.\\n• Hàm g(λ) có dạng một hàm concave, tức nếu talật đồ thị này theo chiều trên-dưới thì\\nđạt được đồ thị của một hàm convex.\\nSource code cho Hình 25.1 có thể được tìm thấy tạihttps://goo.gl/jZiRCp .\\nVí dụ 2 Xét một bài toán linear programming:\\nx= arg min\\nx\\ncTx\\nthoả mãn:Ax = b\\nx ⪰0\\n(25.8)\\nHàm ràng buộc cuối cùng có thể được viết lại là:fi(x) = −xi,i = 1,...,n . Lagrangian của\\nbài toán này là\\nL(x,λ,ν) = cTx −\\nn∑\\ni=1\\nλixi + νT(Ax −b) = −bTν+ (c + ATν−λ)Tx\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 332, 'page_label': '321'}, page_content='321 CHƯƠNG 25. DUALITY\\n(đừng quên điều kiệnλ⪰0.) Dual function của nó là\\ng(λ,ν) = inf\\nx\\nL(x,λ,ν) = −bTν+ inf\\nx\\n(c + ATν−λ)Tx (25.9)\\nNhận thấy rằng một hàm tuyến tínhdTx của x bị chặn dưới khi vào chỉ khid = 0. Vì chỉ\\nnếu một phần tửdi của d khác 0, ta chỉ cần chọnxi rất lớn và ngược dấu vớidi, ta sẽ có\\nmột giá trị nhỏ tuỳ ý. Nói cách khác,g(λ,ν) = −∞trừ khic + ATν−λ= 0. Tóm lại,\\ng(λ,ν) =\\n{\\n−bTν nếu c + ATν−λ= 0\\n−∞ o.w. (25.10)\\nTrường hợp thứ hai khig(λ,ν) = −∞chúng ta sẽ gặp rất nhiều sau này. Trường hợp này\\nkhông nhiều thú vị vì hiển nhiêng(λ,ν) ≤p∗. Vì mục đích chính là đi tìm chặn dưới củap∗\\nnên ta sẽ chỉ quan tâm tới các giá trị củaλvà ν sao chog(λ,ν) càng lớn càng tốt. Trong\\nbài toán này, ta sẽ quan tâm tới cácλvà ν sao choc + ATν−λ= 0.\\n25.3 Bài toán đối ngẫu Lagrange\\nVới mỗi cặp(λ,ν), hàm đối ngẫu Lagrange cho chúng ta một chặn dưới chooptimal value\\np∗ của bài toán gốc (25.4). Câu hỏi đặt ra là: với cặp giá trị nào của(λ,ν), chúng ta sẽ có\\nmột chặn dưới tốt nhất củap∗? Nói cách khác, ta đi cần giải bài toán\\nλ∗,ν∗= arg max\\nλ,ν\\ng(λ,ν)\\nthoả mãn:λ⪰0\\n(25.11)\\nQuan trọng, vì hàmg(λ,ν) là concave và hàm ràng buộcfi(λ) = −λi là các hàmconvex.\\nVậy bài toán (25.11) chính là một bài toán convex. Vì vậy trong nhiều trường hợp, lời giải\\ncó thể dễ tìm hơn là bài toán gốc. Chú ý rằng, bài toán tối ưu này là convex bất kể bài toán\\ngốc (25.4) có là convex hay không.\\nBài toán tối ưu này dược gọi làbài toán đối ngẫu Lagrange(Lagrange dual problem) ứng\\nvới bài toán chính (25.4). Ngoài ra, có một khái niệm nữa được gọi làdual feasible tức là\\nfeasible setcủa bài toán đối ngẫu, bao gồm điều kiệnλ⪰0 và điều kiện ẩng(λ,ν) >−∞\\n(điều kiện này được thêm vào vì ta chỉ quan tâm tới các(λ,ν) sao cho hàm mục tiêu của\\nbài toán đối ngẫu càng lớn càng tốt). Nghiệm của bài toán đối ngẫu (25.11), được ký hiệu\\nlà (λ∗,ν∗), được gọi làdual optimal hoặc optimal Lagrange multipliers.\\nChú ý rằng điều kiện ẩng(λ,ν) > −∞, trong nhiều trường hợp, cũng có thể được viết cụ\\nthể. Quay lại với ví dụ phía trên, điệu kiện ẩn có thể được viết thànhc+ ATν−λ= 0. Đây\\nlà một hàm affine. Vì vậy, khi có thêm ràng buộc này, ta vẫn được một bài toán lồi.\\n25.3.1 Weak duality\\nKý hiệu giá trị tối ưu của bài toán đối ngẫu (25.11) làd∗. Theo (25.6), ta đã biết rằng\\nd∗ ≤p∗. Tính chất đơn giản này được gọi làweak duality. Tuy đơn giản nhưng nó cực kỳ\\nquan trọng.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 333, 'page_label': '322'}, page_content='CHƯƠNG 25. DUALITY 322\\nTa quan sát thấy hai điều:\\n• Nếu bài toán gốc không bị chặn dưới, tứcp∗= −∞, ta phải cód∗= −∞, tức là bài toán\\nđối ngẫu Lagrange làinfeasible (tức không có giá trị nào thoả mãn ràng buộc).\\n• Nếu hàm mục tiêu trong bài toán đối ngẫu không bị chặn trên, tứcd∗ = +∞, chúng ta\\nphải cóp∗= +∞, tức bài toán gốc làinfeasible.\\nGiá trị p∗−d∗ được gọi làoptimal duality gap(dịch thô làkhoảng cách đối ngẫu tối ưu).\\nKhoảng cách này luôn luôn là một số không âm.\\nĐôi khi có những bài toán (lồi hoặc không) rất khó giải, nhưng ít nhất nếu ta có thể tìm\\nđược d∗, ta có thể biết được chặn dưới của bài toán gốc. Việc tìmd∗ thường khả thi vì bài\\ntoán đối ngẫu luôn luôn là lồi.\\n25.3.2 Strong duality và Slater’s constraint qualification\\nNếu đẳng thứcp∗ = d∗ thoả mãn, the optimal duality gapbằng không, ta nói rằngstrong\\nduality xảy ra. Lúc này, việc giải bài toán đối ngẫu đã giúp ta tìm đượcchính xácgiá trị tối\\nưu của bài toán gốc.\\nThật không may,strong dualitykhông thường xuyên xảy ra trong các bài toán tối ưu. Tuy\\nnhiên, nếu bài toán gốc là lồi, tức có dạng\\nx= arg min\\nx\\nf0(x)\\nthoả mãn:fi(x) ≤0,i = 1,2,...,m\\nAx = b\\n(25.12)\\ntrong đóf0,f1,...,f m là các hàm lồi, chúng tathường (không luôn luôn) cóstrong duality.\\nCó rất nhiều nghiên cứu thiết lập các điều kiện, ngoài tính chất lồi, đểstrong duality xảy\\nra. Những điều kiện đó thường có tên làconstraint qualifications.\\nMột trong cácconstraint qualificationđơn giản nhất làSlater’s condition.\\nĐịnh nghĩa 25.1: Strictly feasible\\nMột điểmfeasible của bài toán (25.12) được gọi làstrictly feasiblenếu:\\nfi(x) <0, i= 1,2,...,m, Ax = b\\ntức các dấu bằng trong các bất đẳng thức ràng buộc không xảy ra.\\nĐịnh lý 25.1: Slater\\nNếu tồn tại một điểmstrictly feasible(bài toán gốc là lồi) thìstrong dualityxảy ra.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 334, 'page_label': '323'}, page_content='323 CHƯƠNG 25. DUALITY\\nĐiều kiện khá đơn giản sẽ giúp ích cho nhiều bài toán tối ưu sau này.\\nChú ý:\\n• Strong duality không thường xuyên xảy ra. Với các bài toán lồi, việc này xảy rathường\\nxuyên hơn. Tồn tại những bài toán lồi màstrong dualitykhông xảy ra.\\n• Có những bài toán không lồi nhưngstrong dualityvẫn xảy ra. Ví dụ như bài toán trong\\nHình 25.1 phía trên.\\n25.4 Các điều kiện tối ưu\\n25.4.1 Complementary slackness\\nGiả sử rằngstrong dualityxảy ra. Gọix∗ là một điểmoptimal của bài toán gốc và(λ∗,ν∗)\\nlà cặp điểmoptimal của bài toán đối ngẫu. Ta có\\nf0(x∗) = g(λ∗,ν∗) (25.13)\\n= inf\\nx\\n(\\nf0(x) +\\nm∑\\ni=1\\nλ∗\\nifi(x) +\\np∑\\nj=1\\nν∗\\njhj(x)\\n)\\n(25.14)\\n≤f0(x∗) +\\nm∑\\ni=1\\nλ∗\\nifi(x∗) +\\np∑\\nj=1\\nν∗\\njhj(x∗) (25.15)\\n≤f0(x∗) (25.16)\\nĐẳng thức (25.13) xảy ra dostrong duality. Đẳng thức (25.14) xảy ra do định nghĩa của\\nhàm đối ngẫu. Bất đẳng thức (25.15) là hiển nhiên vì infimum của một hàm nhỏ hơn giá trị\\ncủa hàm đó tại bất kỳ một điểm nào khác. Bất đẳng thức (25.16) xảy ra vì các ràng buộc\\nfi(x∗) ≤0,λi ≥0,i = 1 ,2,...,m và hj(x∗) = 0 . Từ đây có thể thế rằng dấu đẳng thức\\nở (25.15) và (25.16) phải đồng thời xảy ra. Và ta lại có thêm hai quan sát thú vị nữa:\\n• x∗ chính là một điểmoptimal của g(λ∗,ν∗).\\n• Thú vị hơn,\\nm∑\\ni=1\\nλ∗\\nifi(x∗) = 0. Vìλ∗\\ni ≥0,fi ≤0 nên mỗi phần tửλ∗\\nifi(x∗) ≤0. Từ đó ta\\nphải cóλ∗\\nifi(x∗) = 0, ∀i= 1,2,...,m .\\nĐiều kiện cuối cùng này được gọi làcomplementary slackness. Từ đây có thể suy ra\\nλ∗\\ni >0 ⇒fi(x∗) = 0 (25.17)\\nfi(x∗) <0 ⇒λ∗\\ni = 0 (25.18)\\nTức ta luôn có một trong hai giá trị này bằng 0.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 335, 'page_label': '324'}, page_content='CHƯƠNG 25. DUALITY 324\\n25.4.2 Các điều kiện tối ưu KKT\\nTa vẫn giả sử rằng các hàm đang xét có đạo hàm và bài toán tối ưu không nhất thiết là lồi.\\nĐiều kiện KKT cho bài toánkhông lồi\\nGiả sử rằngstrong dualityxảy ra. Gọix∗và(λ∗,ν∗) là bất kỳ primal và dual optimal points.\\nVì x∗ tối ưu hàm khả viL(x,λ∗,ν∗), ta có đạo hàm của Lagrangian tạix∗ phải bằng 0.\\nĐiều kiện Karush-Kuhn-Tucker (KKT) nói rằngx∗,λ∗,ν∗ phải thoả mãn các điều kiện\\nfi(x∗) ≤0,i = 1,2,...,m (25.19)\\nhj(x∗) = 0,j = 1,2,...,p (25.20)\\nλ∗\\ni ≥0,i = 1,2,...,m (25.21)\\nλ∗\\nifi(x∗) = 0,i = 1,2,...,m (25.22)\\n∇xf0(x∗) +\\nm∑\\ni=1\\nλ∗\\ni∇xfi(x∗) +\\np∑\\nj=1\\nν∗\\nj∇xhj(x∗) = 0 (25.23)\\nĐây làđiều kiện cầnđể x∗,λ∗,ν∗ là nghiệm củaprimal problemvà dual problem.\\nCác điều kiện KKT cho bài toán lồi\\nVới các bài toán lồi vàstrong duality xảy ra, các điệu kiện KKT phía trên cũng làđiều\\nkiện đủ. Vậy với các bài toán lồi với hàm mục tiêu và hàm ràng buộc là khả vi, bất kỳ\\nbộ (x∗,λ∗,ν∗) nào thoả mãn các điều kiện KKT đều làprimal và dual optimalcủa primal\\nproblem và dual problem.\\nCần nhớ\\nVới một bài toán lồi và điều kiện Slater thoả mãn (suy ra strong duality) thì các điều\\nkiện KKT là các điều cần và đủ của nghiệm.\\nCác điều kiện KKT rất quan trọng trong tối ưu. Trong một vài trường hợp đặc biệt (chúng\\nta sẽ thấy trong Phần Support Vector Machine), việc giải hệ (bất) phương trình các điều\\nkiện KKT là khả thi. Rất nhiều các thuật toán tối ưu được xây dựng giả trên việc giải hệ\\nđiều kiện KKT.\\nVí dụ:Equality constrained convex quadratic minimization. Xét bài toán:\\nx = arg min\\nx\\n1\\n2xTPx + qTx + r\\nthoả mãn: Ax = b (25.24)\\ntrong đóP là một ma trận nửa nửa xác định dương. Lagrangian của bài toán này là\\nL(x,ν) = 1\\n2xTPx + qTx + r+ νT(Ax −b)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 336, 'page_label': '325'}, page_content='325 CHƯƠNG 25. DUALITY\\nĐiều kiện KKT cho bài toán này là:\\nAx∗= b (25.25)\\nPx∗+ q + ATν∗= 0 (25.26)\\nPhương trình thứ hai chính là phương trình đạo hàm của Lagrangian tạix∗ bằng 0. Hệ\\nphương trình này có thể được viết lại dưới dạng\\n[P AT\\nA 0\\n][x∗\\nν∗\\n]\\n=\\n[−q\\nb\\n]\\nĐây là một phương trình tuyến tính đơn giản!\\n25.5 Tóm tắt\\nGiả sử rằng các hàm số đều khả vi.\\n• Các bài toán tối ưu với chỉ ràng buộc là đẳng thức có thể được giải quyết bằng phương\\npháp nhân tử Lagrange. Ta cũng có định nghĩa về Lagrangian. Điều kiện cần để một điểm\\nlà nghiệm của bài toán tối ưu là nó phải làm cho đạo hàm của Lagrangian bằng 0.\\n• Với các bài toán tối ưu có thêm ràng buộc là bất đẳng thức (không nhất thiết là lồi),\\nchúng ta có Lagrangian tổng quát và các biến Lagrangeλ,ν. Với các giá trị(λ,ν) cố\\nđịnh, ta có định nghĩa vềhàm đối ngẫu Lagrange(Lagrange dual function)g(λ,ν)\\nđược xác định là infimum của Lagrangian khix thay đổi trên miền xác định của bài toán.\\n• Feasible setlà tập con củadomain set (tập xác định).\\n• Với mọi(λ,ν), g(λ,ν) ≤p∗.\\n• Hàm sốg(λ,ν) là convex bất kể bài toán tối ưu gốc cóconvex hay không. Hàm số này\\nđược gọi làdual Lagrange fucntionhay hàm đối ngẫu Lagrange.\\n• Bài toán đi tìm giá trị lớn nhất của hàm đối ngẫu Lagrange với điều kiệnλ⪰0 được\\ngọi làbài toán đối ngẫu(dual problem). Bài toán này làconvex bất kể bài toán gốc có\\nconvex hay không.\\n• Gọi giá trị tối ưu của bài toán đối ngẫu làd∗, ta cód∗≤p∗. Đây được gọi làweak duality.\\n• Strong dualityxảy ra khid∗= p∗. Thường thìstrong dualitykhông xảy ra, nhưng với các\\nbài toán lồi thìstrong dualitythường (không luôn luôn) xảy ra.\\n• Nếu bài toán là lồi và điều kiện Slater thoả mãn, thìstrong dualityxảy ra.\\n• Nếu bài toán lồi và cóstrong duality thì nghiệm của bài toán thoả mãn các điều kiện\\nKKT (điều kiện cần và đủ).\\n• Rất nhiều các bài toán tối ưu được giải quyết thông qua KKT conditions.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 337, 'page_label': '326'}, page_content=''),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 338, 'page_label': '327'}, page_content='Phần VIII\\nSupport vector machines'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 339, 'page_label': '328'}, page_content='Chương 26\\nSupport vector machine\\n26.1 Giới thiệu\\nSupport vector machine (SVM) là một trong những thuật toán phân lớp phổ biến và hiệu\\nquả. Ý tưởng đứng sau SVM khá đơn giản, nhưng để hiểu được cách tìm nghiệm của nó,\\nchúng ta cần một chút kiến thức về tối ưu vàduality.\\nTrước khi đi vào phần ý tưởng chính của SVM, chúng ta cùng ôn lại kiến thức về hình học\\ngiải tích trong chương trình phổ thông.\\n26.1.1 Khoảng cách từ một điểm tới một siêu mặt phẳng\\nTrong không gian hai chiều, khoảng cách từ một điểm có toạ độ(x0,y0) tới đường thẳng có\\nphương trìnhw1x+ w2y+ b= 0 được xác định bởi\\n|w1x0 + w2y0 + b|√\\nw2\\n1 + w2\\n2\\nTrong không gian ba chiều, khoảng cách từ một điểm có toạ độ(x0,y0,z0) tới mộtmặt phẳng\\ncó phương trìnhw1x+ w2y+ w3z+ b= 0 được xác định bởi\\n|w1x0 + w2y0 + w3z0 + b|√\\nw2\\n1 + w2\\n2 + w2\\n3\\nHơn nữa, nếu bỏ dấu trị tuyệt đối ở tử số, ta có thể xác định được điểm đó nằm về phía nào\\ncủa đường thẳng hay mặt phẳng đang xét. Những điểm làm cho biểu thức trong dấu giá trị\\ntuyệt đối mang dấu dương nằm về cùng một phía (tạm gọi làphía dương), những điểm làm\\ncho giá trị này mang dấu âm nằm về phía còn lại (gọi làphía âm). Những điểm nằm trên\\nđường thẳng/mặt phẳngsẽ làm cho tử số có giá trị bằng 0, tức khoảng cách bằng 0.\\nCác công thức này có thể được tổng quát lên cho trường hợp không giand chiều. Khoảng\\ncách từ một điểm (vector) có toạ độ(x10,x20,...,x d0) tới siêu mặt phẳng(hyperplane) có'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 340, 'page_label': '329'}, page_content='329 CHƯƠNG 26. SUPPORT VECTOR MACHINE\\nx1\\nx2\\nHình 26.1: Hai lớp dữ liệu đỏ và\\nxanh làlinearly separable. Có vô số\\ncác đường thằng có thể phân tách\\nchính xác hai lớp dữ liệu này (Xem\\nthêm Chương 13–Perceptron learn-\\ning algorithm).\\nphương trìnhw1x1 + w2x2 + ··· + wdxd + b= 0 được xác định bởi\\n|w1x10 + w2x20 + ··· + wdxd0 + b|√\\nw2\\n1 + w2\\n2 + ··· + w2\\nd\\n= |wTx0 + b|\\n∥w∥2\\nvới x0 = [x10,x20,...,x d0]T,w = [w1,w2,...,w d]T.\\n26.1.2 Nhắc lại bài toán phân chia hai lớp dữ liệu\\nChúng ta cùng quay lại với bài toán phân lớp như đã đề cập trong Chương 13 – Perceptron\\nLearning Algorithm (PLA). Giả sử rằng có hai lớp dữ liệu được mô tả bởi các điểm (feature\\nvector) trong không gian nhiều chiều, hơn nữa, hai lớp dữ liệu này làlinearly separable, tức\\ntồn tại một siêu phẳng phân chia chính xác hai lớp đó. Hãy tìm một siêu phẳng phân chia\\nhai lớp đó đó, tức tất cả các điểm thuộc một lớp nằm về cùng một phía của siêu phẳng đó\\nvà ngược phía với toàn bộ các điểm thuộc lớp còn lại. Chúng ta đã biết rằng, thuật toán\\nPLA có thể làm được việc này nhưng nó có thể cho chúng ta vô số nghiệm như Hình 26.1.\\nCó một câu hỏi được đặt ra ở đây. Trong vô số các mặt phân chia đó, đâu là mặt tốt nhất.\\nTrong ba đường thẳng minh họa trong Hình 26.1, có hai đường thẳng khálệch về phía lớp\\nmàu đỏ. Điều này có thể khiến cho lớp màu đỏkhông vui vì lãnh thổ bị lấn nhiều quá. Việc\\nnày có thể khiến cho các điểm màu đỏ trong tương lai bị phân lớp lỗi thành điểm màu xanh.\\nLiệu có cách nào để tìm được đường phân chia mà cả hai lớp đều cảm thấycông bằng và\\nhạnh phúcnhất hay không?\\nĐể trả lời câu hỏi này, chúng ta cần tìm một tiêu chuẩn để đo sựhạnh phúc của mỗi lớp.\\nNếu ta định nghĩamức độ hạnh phúccủa một lớp tỉ lệ thuận vớikhoảng cách gần nhấttừ\\nmột điểm của lớp đó tới đường/mặt phân chia, ở Hình 26.2a, lớp màu đỏ sẽkhông được hạnh\\nphúc cho lắmvì đường phân chia gần nó hơn lớp màu xanh rất nhiều. Chúng ta cần một\\nđường phân chia sao cho khoảng cách từ điểm gần nhất của mỗi lớp (các điểm được khoanh\\ntròn) tới đường phân chia là như nhau, như thế thì mớicông bằng. Khoảng cách như nhau\\nnày được gọi làbiên hoặc lề (margin).\\nĐã cócông bằngrồi, chúng ta cầnthịnh vượngnữa. công bằngmà cả hai đềukém hạnh phúc\\nnhư nhau thì chưa phải làthịnh vượng cho lắm.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 341, 'page_label': '330'}, page_content='CHƯƠNG 26. SUPPORT VECTOR MACHINE 330\\nx1\\nx2\\n w\\nT x+b= 0\\n+ −\\n(a)\\nmargin (b)\\nHình 26.2:Ý tưởng của SVM.Margin của một lớp được định nghĩa là khoảng cách từ các điểm\\ngần nhất của lớp đó tới mặt phân chia.Margin của hai lớp phải bằng nhau và lớn nhất có thể.\\nXét tiếp Hình 26.2b khi khoảng cách từ đường phân chia tới các điểm gần nhất của mỗi lớp\\nlà như nhau. Xét hai cách phân chia bởi đường nét liền màu đen và đường nét đứt màu lục,\\nđường nào sẽ làm cho cả hai lớphạnh phúc hơn? Rõ ràng đó phải là đường nét liền màu đen\\nvì nó tạo ra mộtmargin rộng hơn.\\nViệc margin rộng hơn sẽ mang lại hiệu ứng phân lớp tốt hơn vìsự phân chia giữa hai lớp là\\nrạch ròi hơn. Bài toán tối ưu trong SVM chính là bài toán đi tìm đường phân chia sao cho\\nmargin giữa hai lớp là lớn nhất. Đây cũng là lý do vì sao SVM còn được gọi làmaximum\\nmargin classifier. Nguồn gốc của tên gọisupport vector machinesẽ sớm được làm sáng tỏ.\\n26.2 Xây dựng bài toán tối ưu cho SVM\\nGiả sử rằng các cặp dữ liệu trong tập huấn luyện là(x1,y1),(x2,y2),..., (xN,yN) với vector\\nxi ∈Rd thể hiệnđầu vào của một điểm dữ liệu vàyi là nhãn của điểm dữ liệu đó,d là số\\nchiều của dữ liệu vàN là số điểm dữ liệu. Giả sử rằngnhãn của mỗi điểm dữ liệu được xác\\nđịnh bởiyi = 1 hoặc yi = −1 giống như trong PLA.\\nĐể dễ hình dung, chúng ta cùng làm với các ví dụ trong không gian hai chiều. Giả sử\\nrằng các điểm màu xanh có nhãn là 1, các điểm tròn đỏ có nhãn là -1 và mặtwTx + b =\\nw1x1 + w2x2 + b= 0 là mặt phân chia giữa hai lớp (Hình 26.3). Hơn nữa, lớp màu xanh nằm\\nvề phía dương, lớp màu đỏ nằm vềphía âm của mặt phân chia. Nếu ngược lại, ta chỉ cần\\nđổi dấu củaw và b. Ta cần đi tìm siêu phẳng được mô tả bởi các hệ sốw và b.\\nTa quan sát thấy một điểm quan trọng như sau. Với cặp dữ liệu(xn,yn) bất kỳ, khoảng cách\\ntừ điểm đó tới mặt phân chia là\\nyn(wTxn + b)\\n∥w∥2\\nĐiều này có thể được nhận thấy vì theo giả sử ở trên,yn luôn cùng dấu vớiphía của xn. Từ\\nđó suy rayn cùng dấu với(wTxn+ b), vì vậy tử số luôn là một đại lượng không âm. Với mặt\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 342, 'page_label': '331'}, page_content='331 CHƯƠNG 26. SUPPORT VECTOR MACHINE\\n+ −\\nw\\nT x+\\nb= 0\\nw\\nT x+\\nb= 1\\nw\\nT x+\\nb=\\n−1\\nHình 26.3: Giả sử mặt phân chia\\ncó phương trình wTx + b = 0 .\\nKhông mất tính tổng quát, bằng\\ncách nhân các hệ số w và b với\\ncác hằng số phù hợp, ta có thể\\ngiả sử rằng điểm gần nhất của lớp\\nmàu xanh tới mặt này thoả mãn\\nwTx+b= 1.Khiđó,điểmgầnnhất\\ncủa lớp đỏ thoả mãnwTw + b =\\n−1.\\nphân chia này,margin được tính là khoảng cách gần nhất từ một điểm (trong cả hai lớp, vì\\ncuối cùngmargin của cả hai lớp sẽ như nhau) tới mặt đó, tức là\\nmargin = min\\nn\\nyn(wTxn + b)\\n∥w∥2\\nBài toán tối ưu của SVM chính là việc tìmw và b sao chomargin này đạt giá trị lớn nhất:\\n(w,b) = arg max\\nw,b\\n{\\nmin\\nn\\nyn(wTxn + b)\\n∥w∥2\\n}\\n= arg max\\nw,b\\n{ 1\\n∥w∥2\\nmin\\nn\\nyn(wTxn + b)\\n}\\n(26.1)\\nCó một nhận xét quan trọng là nếu ta thay vector hệ sốw bởi kw và bbởi kb trong đók là\\nmột hằng số dươngbất kỳthì mặt phân chia không thay đổi, tức khoảng cách từ từng điểm\\nđến mặt phân chia không đổi, tứcmargin không đổi. Vì vậy, ta có thể giả sử\\nyn(wTxn + b) = 1\\nvới những điểm nằm gần mặt phân chia nhất(được khoanh tròn trong Hình 26.3).\\nNhư vậy, với mọin ta luôn có\\nyn(wTxn + b) ≥1\\nVậy bài toán tối ưu (26.1) có thể đưa về bài toán tối ưu có ràng buộc có dạng\\n(w,b) = arg max\\nw,b\\n1\\n∥w∥2\\nthoả mãn:yn(wTxn + b) ≥1,∀n= 1,2,...,N\\n(26.2)\\nBằng một biến đổi đơn giản, ta có thể đưa bài toán này về dạng\\n(w,b) = arg min\\nw,b\\n1\\n2∥w∥2\\n2\\nthoả mãn:1 −yn(wTxn + b) ≤0,∀n= 1,2,...,N\\n(26.3)\\nỞ đây, chúng ta đã lấy nghịch đảo hàm mục tiêu, bình phương nó để được một hàm khả vi,\\nvà nhân với1\\n2 để biểu thức đạo hàm đẹp hơn.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 343, 'page_label': '332'}, page_content='CHƯƠNG 26. SUPPORT VECTOR MACHINE 332\\nCó một quan sát rất quan trọng.Trong bài toán (26.3), hàm mục tiêu là một norm,\\nnên là một hàm lồi. Các hàm bất đẳng thức ràng buộc là các hàm tuyến tính theow và\\nb, nên chúng cũng là các hàm lồi. Vậy bài toán tối ưu (26.3) có hàm mục tiêu là lồi, và\\ncác hàm ràng buộc cũng là lồi, nên nó là một bài toán lồi. Hơn nữa, nó là một quadratic\\nprogramming vì hàm mục tiêu là mộtquadratic form. Thậm chí, hàm mục tiêu làstrictly\\nconvex vì |w|2\\n2 = wTIw và mathbfI là ma trận đơn vị – là một ma trận xác định dương.\\nTừ đây có thể suy ra nghiệm cho SVM làduy nhất.\\nĐến đây thì bài toán này có thể giải được bằng các công cụ hỗ trợ tìm nghiệm cho quadratic\\nprograming, ví dụ CVXOPT. Tuy nhiên, việc giải bài toán này trở nên phức tạp khi số chiều\\nd của không gian dữ liệu và số điểm dữ liệuN tăng lên cao. Thay vào đó, người ta thường\\ngiải bài toán đối ngẫu của bài toán này. Thứ nhất, bài toán đối ngẫu có những tính chất thú\\nvị hơn khiến nó được giải một cách hiệu quả hơn. Thứ hai, trong quá trình xây dựng bài\\ntoán đối ngẫu, người ta thấy rằng SVM có thể được áp dụng cho những bài toán mà dữ liệu\\nkhông nhất thiếtlinearly separable, như chúng ta sẽ thấy ở các chương sau của phần này.\\nXác định lớp cho một điểm dữ liệu mới\\nSau khi đã tìm được mặt phân cáchwTx + b = 0, nhãn của bất kỳ một điểm nào sẽ được\\nxác định đơn giản bằng\\nclass(x) = sgn(wTx + b)\\n26.3 Bài toán đối ngẫu của SVM\\nNhắc lại rằng bài toán tối ưu (26.3) là một bài toán lồi. Chúng ta biết rằng nếu một bài\\ntoán lồi thoả mãn tiêu chuẩn Slater thìstrong duality thoả mãn (xem Mục 25.3.2. Và nếu\\nstrong duality thoả mãn thì nghiệm của bài toán chính là nghiệm của hệ điều kiện KKT\\n(xem Mục 25.4.2).\\n26.3.1 Kiểm tra tiêu chuẩn Slater\\nTrong bước này, chúng ta sẽ chứng minh bài toán tối ưu (26.3) thoả mãn điều kiện Slater.\\nĐiều kiện Slater nói rằng, nếu tồn tạiw,b thoả mãn:\\n1 −yn(wTxn + b) <0, ∀n= 1,2,...,N\\nthì strong duality thoả mãn. Việc kiểm tra này không quá phức tạp. Vì ta biết rằng luôn\\nluôn có một siêu phẳng phân chia hai lớp nếu hai lớp đó làlinearly separable, tức bài toán\\ncó nghiệm, nênfeasible setcủa bài toán tối ưu (26.3) phải khác rỗng. Tức luôn luôn tồn tại\\ncặp (w0,b0) sao cho\\n1 −yn(wT\\n0 xn + b0) ≤0, ∀n= 1,2,...,N (26.4)\\n⇔2 −yn(2wT\\n0 xn + 2b0) ≤0, ∀n= 1,2,...,N (26.5)\\nVậy ta chỉ cần chọnw1 = 2w0 và b1 = 2b0, ta sẽ có:\\n1 −yn(wT\\n1 xn + b1) ≤−1 <0, ∀n= 1,2,...,N\\nTừ đó suy ra điều kiện Slater thoả mãn.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 344, 'page_label': '333'}, page_content='333 CHƯƠNG 26. SUPPORT VECTOR MACHINE\\n26.3.2 Lagrangian của bài toán SVM\\nLagrangian của bài toán (26.3) là\\nL(w,b, λ) = 1\\n2∥w∥2\\n2 +\\nN∑\\nn=1\\nλn(1 −yn(wTxn + b)) (26.6)\\nvới λ= [λ1,λ2,...,λ N]T và λn ≥0, ∀n= 1,2,...,N .\\n26.3.3 Hàm đối ngẫu Lagrange\\nTheo định nghĩa, hàm đối ngẫu Lagrange là\\ng(λ) = min\\nw,b\\nL(w,b, λ)\\nvới λ ⪰0. Việc tìm giá trị nhỏ nhất của hàm này theow và b có thể đựợc thực hiện bằng\\ncách giải hệ phương trình đạo hàm củaL(w,b, λ) theo w và b bằng 0:\\n∇wL(w,b, λ) = w −\\nN∑\\nn=1\\nλnynxn = 0 ⇒w =\\nN∑\\nn=1\\nλnynxn (26.7)\\n∇bL(w,b, λ) =\\nN∑\\nn=1\\nλnyn = 0 (26.8)\\nThay (26.7) và (26.8) vào (26.6) ta thu đượcg(λ)1:\\ng(λ) =\\nN∑\\nn=1\\nλn −1\\n2\\nN∑\\nn=1\\nN∑\\nm=1\\nλnλmynymxT\\nnxm (26.9)\\nHàm g(λ) trong (26.9)là hàm số quan trọng nhất trong SVM, chúng ta sẽ thấy rõ hơn\\ntrong chương Kernel SVM.\\nBằng cách ký hiệu ma trận\\nV =\\n[\\ny1x1,y2x2,...,y NxN\\n]\\nvà vector1 = [1,1,..., 1]T, ta có thể viết lạig(λ) dưới dạng2\\ng(λ) = −1\\n2λTVTVλ+ 1Tλ. (26.10)\\nNếu đặtK = VTV thì K là một ma trận nửa xác định dương. Thật vậy, với mọi vectorλ,\\nta cóλTKλ= λTVTVλ= ∥Vλ∥2\\n2 ≥0. Vậyg(λ) = −1\\n2 λTKλ+ 1Tλlà một hàmconcave.\\n1 Phần chứng minh coi như một bài tập nhỏ cho bạn đọc.\\n2 Phần chứng minh coi như một bài tập nhỏ khác cho bạn đọc.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 345, 'page_label': '334'}, page_content='CHƯƠNG 26. SUPPORT VECTOR MACHINE 334\\n26.3.4 Bài toán đối ngẫu Lagrange\\nTừ đó, kết hợp hàm đối ngẫu Lagrange và các điều kiện ràng buộc củaλ, ta sẽ thu được bài\\ntoán đối ngẫu Lagrange của bài toán (26.3) có dạng\\nλ= arg max\\nλ\\ng(λ)\\nthoả mãn:λ⪰0\\nN∑\\nn=1\\nλnyn = 0\\n(26.11)\\nRàng buộc thứ hai được lấy từ (26.8). Đây là một bài toán lồi vì ta đang đi tìm giá trị lớn\\nnhất của một hàm mục tiêu làconcave trên mộtpolyhedron3. Hơn nữa, bài toán này là một\\nquadratic programming và cũng có thể được giải bằng các thư viện như CVXOPT.\\nTrong bài toán đối ngẫu này, số lượng tham số phải tìm làN, là chiều củaλ, cũng chính là\\nsố điểm dữ liệu. Trong khi đó, với bài toán gốc (26.3), số tham số phải tìm làd+ 1, là tổng\\nsố chiều củaw và b, tức số chiều của mỗi điểm dữ liệu cộng với 1. Trong rất nhiều trường\\nhợp, số điểm dữ liệu có được trong tập huấn luyện lớn hơn số chiều dữ liệu rất nhiều. Nếu\\ngiải trực tiếp bằng các công cụ giải quadratic programming, có thể bài toán đối ngẫu còn\\nphức tạp hơn (tốn thời gian hơn) so với bài toàn gốc. Tuy nhiên, điều hấp dẫn của bài toán\\nđối ngẫu này đến từ cấu trúc đặc biệt của hệ điều kiện KKT. Ngoài ra, dạng đặc biệt của\\nbài toán đối ngẫu giúp các nhà khoa học đã phát triển thêm một dạng tổng quả của SVM,\\nkhiến nó hoạt động cả với trường hợp dữ liệu hai lớp là khônglinear separable. Chúng ta sẽ\\nbàn kỹ tới trường hợp này trong chương Kernel SVM.\\n26.3.5 Điều kiện KKT\\nQuay trở lại bài toán, vì đây là một bài toán lồi vàstrong dualitythoả mãn, nghiệm của bài\\ntoán sẽ thoả mãn hệ điều kiện KKT sau đây với biến số làw,b và λ.\\n1 −yn(wTxn + b) ≤0, ∀n= 1,2,...,N (26.12)\\nλn ≥0, ∀n= 1,2,...,N (26.13)\\nλn(1 −yn(wTxn + b)) = 0, ∀n= 1,2,...,N (26.14)\\nw =\\nN∑\\nn=1\\nλnynxn (26.15)\\nN∑\\nn=1\\nλnyn = 0 (26.16)\\nTrong những điều kiện trên, điều kiện (26.14) là thú vị nhất. Từ đó ta có thể suy ra ngay, với\\nnbất kỳ, hoặcλn = 0 hoặc 1−yn(wTxn+b) = 0. Trường hợp thứ hai chính làwTxn+b= yn,\\nvới chú ý rằngy2\\nn = 1, ∀n.\\n3 Không chỉ riêng với bài toán tối ưu của SVM, các bài toán đối ngẫu luôn là bài toán lồi. Ở đây chúng ta chỉ khẳng\\nđịnh lại tính chất đó.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 346, 'page_label': '335'}, page_content='335 CHƯƠNG 26. SUPPORT VECTOR MACHINE\\nNhững điểm thoả mãn (26.3.5) chính là những điểm nằm gần mặt phân chia nhất, là những\\nđiểm được khoanh tròn trong Hình 26.3. Hai đường thẳngwTxn + b= ±1 tựa lên các điểm\\nthoả mãn (26.3.5). Những điểm (vector) thoả mãn (26.3.5) còn được gọi là cácsupport vector.\\nVà từ đó, cái tênsupport vector machinera đời.\\nMột quan sát khác, số lượng những điểm thoả mãn (26.3.5) thường chiếm số lượng rất nhỏ\\ntrong sốN điểm của tập huấn luyện. Chỉ cần dựa trên nhữngsupport vectornày, chúng ta\\nhoàn toàn có thể xác định được mặt phân cách cần tìm. Nói cách khác, hầu hết cácλn bằng\\n0, tứcλlà mộtsparse vector. Support vector machine vì vậy còn được xếp vàosparse models.\\nCác sparse models thường có cách giải hiệu quả hơn các mô hình tương tự với nghiệm là\\ndense (hầu hết các phần tử khác 0). Đây chính là lý do thứ hai của việc bài toán đối ngẫu\\nSVM được quan tâm nhiều hơn là bài toán gốc.\\nTiếp tục phân tích, với những bài toán có số điểm dữ liệuN nhỏ, ta có thể giải hệ điều\\nkiện KKT phía trên bằng cách xét các trường hợpλn = 0 hoặc λn ̸= 0 . Tổng số trường\\nhợp phải xét là2N. VớiN >50 (thường là như thế), đây là một con số rất lớn, giải bằng\\ncách này sẽ không khả thi. Phương pháp thường được dùng để giải hệ này làsequential\\nminimal optimization (SMO) [Pla98,ZYX+08]. Trong phương pháp này, các cặp hai nhân\\ntử Lagrange (hai thành phần củaλ) được chọn ra để tối ưu tại mỗi vòng lặp. Trong các bài\\nbáo trên, việc chọn cặp như thế nào được nêu rõ. Việc này được thực hiện nhiều lần cho tới\\nkhi thuật toán hội tụ [Bis06].\\nChúng ta sẽ không đi sâu tiếp vào việc giải hệ KKT như thế nào, trong phần tiếp theo chúng\\nta sẽ giải bài toán tối ưu (26.11) bằng CVXOPT với một ví dụ nhỏ và bằng thư việnsklearn\\n(có thể áp dụng cho trường hợp nhiều điểm dữ liệu và nhiều chiều dữ liệu hơn).\\nSau khi tìm đượcλ từ bài toán (26.11), ta có thể suy ra đượcw dựa vào (26.15) vàb dựa\\nvào (26.14) và (26.16). Rõ ràng ta chỉ cần quan tâm tớiλn ̸= 0.\\nĐặt S= {n: λn ̸= 0}và NS là số phần tử của tậpS. Theo (26.15),w được tính bằng\\nw =\\n∑\\nm∈S\\nλmymxm (26.17)\\nVới mỗin∈S, ta có\\n1 = yn(wTxn + b) ⇔b= yn −wTxn\\nMặc dù từ chỉ một cặp(xn,yn), ta có thể suy ra ngay đượcbnếu đã biếtw, một phiên bản\\nkhác để tínhbthường được sử dụng và được cho làổn định hơn trong tính toán(numerically\\nmore stable) là trung bình cộng4 của tất cả cácb tính được theo mỗin∈S\\nb= 1\\nNS\\n∑\\nn∈S\\n(yn −wTxn) = 1\\nNS\\n∑\\nn∈S\\n(\\nyn −\\n∑\\nm∈S\\nλmymxT\\nmxn\\n)\\n(26.18)\\n4 Việc này cũng giống như cách làm trong các thí nghiệm vật lý. Để đo một đại lượng, người ta thường thực hiện\\nviệc đo nhiều lần rồi lấy kết quả trung bình để tránh sai số. Ở đây, về mặt toán học,b phải như nhau theo mọi\\ncách tính; tuy nhiên, khi tính toán bằng máy tính, chúng ta có thể gặp các sai số nhỏ. Việc lấy trung bình sẽ làm\\ngiảm sai số đó.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 347, 'page_label': '336'}, page_content='CHƯƠNG 26. SUPPORT VECTOR MACHINE 336\\nĐể xác định một điểmx mới thuộc vào lớp nào, ta cần xác định dấu của biểu thức\\nwTx + b=\\n∑\\nm∈S\\nλmymxT\\nmx + 1\\nNS\\n∑\\nn∈S\\n(\\nyn −\\n∑\\nm∈S\\nλmymxT\\nmxn\\n)\\nBiểu thức này phụ thuộc vào cách tính tích vô hướng giữax và từngxm ∈S. Nhận xét quan\\ntrọng này sẽ giúp ích cho chúng ta trong chương Kernal SVM.\\n26.4 Lập trình tìm nghiệm cho SVM\\nTrong mục này, chúng ta cùng tìm nghiệm cho SVM bằng hai cách khác nhau. Cách thứ\\nnhất dựa theo bài toán (26.11) và các công thức (26.18) và (26.17). Cách thứ hai sử dụng\\ntrực tiếp thư việnsklearn. Cách thứ nhất giúp chứng minh tính đúng đắn của các công thức\\nđã xây dựng. Cách thứ hai sẽ giúp các bạn biết cách áp dụng SVM vào dữ liệu thực tế.\\n26.4.1 Tìm nghiệm theo công thức\\nTrước tiên chúng ta gọi các thư viện cần dùng và tạo dữ liệu giả (dữ liệu này được sử dụng\\ntrong các hình vẽ từ đầu chương. Ta thấy rằng hai class làlinearly separable).\\nfrom __future__ import print_function\\nimport numpy as np\\nnp.random.seed(22)\\n# simulated samples\\nmeans = [[2, 2], [4, 2]]\\ncov = [[.3, .2], [.2, .3]]\\nN = 10\\nX0 = np.random.multivariate_normal(means[0], cov, N) # blue class data\\nX1 = np.random.multivariate_normal(means[1], cov, N) # red class data\\nX = np.concatenate((X0, X1), axis = 0) # all data\\ny = np.concatenate((np.ones(N), -np.ones(N)), axis = 0) # label\\n# solving the dual problem (variable: lambda)\\nfrom cvxopt import matrix, solvers\\nV = np.concatenate((X0, -X1), axis = 0) # V in the book\\nQ = matrix(V.dot(V.T))\\np = matrix(-np.ones((2*N, 1))) # objective function 1/2 lambda^T*Q*lambda - 1^T*lambda\\n# build A, b, G, h\\nG = matrix(-np.eye(2*N))\\nh = matrix(np.zeros((2*N, 1)))\\nA = matrix(y.reshape(1, -1))\\nb = matrix(np.zeros((1, 1)))\\nsolvers.options[’show_progress’] = False\\nsol = solvers.qp(Q, p, G, h, A, b)\\nl = np.array(sol[’x’]) # solution lambda\\n# calculate w and b\\nw = Xbar.T.dot(l)\\nS = np.where(l > 1e-8)[0] # support set, 1e-8 to avoid small value of l.\\nb = np.mean(y[S].reshape(-1, 1) - X[S,:].dot(w))\\nprint(’Number of suport vectors = ’, S.size)\\nprint(’w = ’, w.T)\\nprint(’b = ’, b)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 348, 'page_label': '337'}, page_content='337 CHƯƠNG 26. SUPPORT VECTOR MACHINE\\nHình 26.4: Minh hoạ nghiệm tìm\\nđược bởi SVM. Tất cả các điểm\\nnằm trong vùng có nền màu lam\\nnhạt sẽ được phân vào cùng lớp với\\ncác điểm màu lam. Điều tương tự\\nxảy ra với các điểm nằm trên nền\\nmàu đỏ nhạt.\\nKết quả:\\nNumber of suport vectors = 3\\nw = [[-2.00984382 0.64068336]]\\nb = 4.66856068329\\nNhư vậy trong số 20 điểm dữ liệu của cả hai lớp, chỉ có ba điểm nằm trongsupport set, tức\\ncó ba điểm đóng vai trò là cácsupport vector. Ba điểm này giúp xây dựng đường thằng phân\\nchia vớiw và b như đã tính được. Kết quả tìm được được minh hoạ trong Hình 26.4. Đường\\nmàu đen đậm ở giữa chính là mặt phân cách tìm được bằng SVM. Các đường đen mảnh thể\\nhiện các đường thẳngtựa lên cácsupport vectorđược khoanh tròn.\\nCác hình vẽ và source code trong bài có thể được tìm thấy tạihttps://goo.gl/VKBgVG .\\n26.4.2 Tìm nghiệm theo thư viện\\nChúng ta sẽ sử dụng hàmsklearn.svm.SVC ở đây. Các bài toán thực tế thường sử dụng thư\\nviện libsvm được viết trên ngôn ngữ C, có API cho Python và Matlab.\\nNếu dùng thư viện thì sẽ như sau:\\n# solution by sklearn\\nfrom sklearn.svm import SVC\\nmodel = SVC(kernel = ’linear’, C = 1e5) # just a big number\\nmodel.fit(X, y)\\nw = model.coef_\\nb = model.intercept_\\nprint(’w = ’, w)\\nprint(’b = ’, b)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 349, 'page_label': '338'}, page_content='CHƯƠNG 26. SUPPORT VECTOR MACHINE 338\\nKết quả:\\nw = [[-2.00971102 0.64194082]]\\nb = [ 4.66595309]\\nKết quả này khá giống với kết quả chúng ta tìm được ở phần trên, với cách làm đơn giản\\nhơn rất nhiều. Có rất nhiều tuỳ chọn cho SVM, trong đó có thuộc tínhkernel, các bạn sẽ\\ndần thấy trong các chương sau.\\n26.5 Tóm tắt và thảo luận\\n• Với bài toán phân lớp nhị phân mà hai lớp dữ liệu làlinearly separable, có vô số các mặt\\nphân cách phẳng giúp phân chia hai lớp đó. Khoảng cách gần nhất từ một điểm dữ liệu\\ntới mặt phân cách ấy được gọi làmargin của bộ phân lớp với ranh giới là mặt phẳng đó.\\n• Support vector machine là bài toán đi tìm mặt phân cách sao chomargin có được là lớn\\nnhất, đồng nghĩa với việc các điểm dữ liệu có mộtkhoảng cách an toàntới mặt phân cách.\\n• Bài toán tối ưu trong SVM là một bài toánconvex với hàm mục tiêu làstricly convex, vì\\nvậy,local optimumcũng làglobal optimumcủa bài toán. Hơn nữa, bài toán tối ưu đó là\\nmột quadratic programming(QP).\\n• Mặc dù có thể trực tiếp giải SVM qua bài toánprimal, thông thường người ta thường\\ngiải bài toándual. Bài toándual cũng là một QP nhưng nghiệm làsparse nên có những\\nphương pháp giải hiệu quả hơn.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 350, 'page_label': '339'}, page_content='Chương 27\\nSoft-margin support vector machine\\n27.1 Giới thiệu\\nGiống như perceptron learning algorithm (PLA), support vector machine (SVM)thuần chỉ\\nlàm việc khi dữ liệu của hai lớp làlinearly separable. Một cách tự nhiên, chúng ta cũng\\nmong muốn rằng SVM có thể làm việc với dữ liệugần linearly separablegiống như logistic\\nregression đã làm được.\\nXét hai ví dụ trong Hình 27.1. Có hai trường hợp dễ nhận thấy SVM làm việc không hiệu\\nquả hoặc thậm chí không làm việc\\n1. Trường hợp 1: Dữ liệu vẫnlinearly separablenhư Hình 27.1a nhưng có một điểmnhiễu\\ncủa lớp đỏ ở quá gần so với lớp xanh. Trong trường hợp này, nếu ta sử dụng SVMthuần\\nthì sẽ tạo ra mộtmargin rất nhỏ. Ngoài ra, đường phân lớp nằm quá gần với các điểm ở\\nlớp xanh và quá xa các điểm thuộc lớp đỏ. Trong khi đó, nếu tahy sinhđiểm nhiễu này\\nthì ta được mộtmargin tốt hơn rất nhiều được mô tả bởi các đường nét đứt. SVMthuần\\nvì vậy còn được coi lànhạy cảm với nhiễu(sensitive to noise).\\n2. Trường hợp 2: Dữ liệu không linearly separable nhưng gần linearly separable như\\nHình 27.1b. Trong trường hợp này, không tồn tại đường thẳng nào hoàn thoàn phân\\nchia hai lớp dữ liệu, vì vậy bài toán tối ưu SVM trở nên vô nghiệm. Tuy nhiên, nếuchịu\\nhy sinh một chút những điểm ở gần khu vực biên giới giữa hai lớp, ta vẫn có thể tạo\\nđược một đường phân chia khá tốt như đường nét đứt đậm. Cácđường support đường\\nnét đứt mảnh vẫn giúp tạo được mộtmargin lớn cho bộ phân lớp này. Với mỗi điểm nằm\\nlấn sang phía bên kia của cácđường suporttương ứng, ta gọi điểm đó rơi vàovùng không\\nan toàn. Như trong hình, hai điểm màu đỏ nằm phía bên tráiđường supportcủa lớp đỏ\\nđược xếp vào loại không an toàn, mặc dù có một điểm đỏ vẫn nằm trong khu vực nền\\nmàu đỏ. Hai điểm màu xanh ở phía phải củađường support của lớp xanh thậm chí đều\\nlấn sang phần có nền màu đỏ.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 351, 'page_label': '340'}, page_content='CHƯƠNG 27. SOFT-MARGIN SUPPORT VECTOR MACHINE 340\\nnoise\\n(a) Khi có nhiễu nhỏ.\\nalmost linearly separable (b) Khi dữ liệugần linearly separable.\\nHình 27.1:Hai trường hơp khi support vector machinethuần làm việc không hiệu quả. (a) Hai\\nlớp vẫn linearly separable nhưng một điểm thuộc class này quá gần class kia, điểm này có thể là\\nnhiễu. (b) Dữ liệu hai lớp khônglinearly separable, mặc dù chúng đãgần linearly separable.\\nTrong cả hai trường hợp trên,margin tạo bởi đường phân chia và đường nét đứt mảnh còn\\nđược gọi làsoft-margin (biên mềm). Để phân biệt, SVMthuần còn được gọi làhard-margin\\nSVM (SVM biên cứng). SVMchấp nhận một vài điểm trong tập huấn luyện bị phân lớp lỗi\\nnày được gọi làsoft-margin SVM.\\nCó hai cách xây dựng và giải quyết bài toán tối ưu chosoft-margin SVM, cả hai đều mang\\nlại những kết quả thú vị và có thể phát triển tiếp thành các thuật toán SVM phức tạp và\\nhiệu quả hơn như sẽ được thấy ở các chương sau của cuốn sách này. Cách giải quyết thứ\\nnhất là giải một bài toán tối ưu có ràng buộc bằng cách giải bài toán đối ngẫu giống như\\nhard-margin SVM; cách giải dựa vào bài toán đối ngẫu này là cơ sở cho phương phápKernel\\nSVM cho dữ liệu thực sự khônglinearly separablesẽ được đề cập trong chương tiếp theo.\\nCách giải quyết thứ hai là đưa về một bài toán tối ưukhông ràng buộc. Bài toán này có thể\\ngiải bằng các phương pháp gradient descent. Nhờ đó, cách giải quyết này có thể được áp\\ndụng cho các bài toán large-scale. Ngoài ra, trong cách giải này, chúng ta sẽ làm quen với\\nmột hàm mất mát mới có tên làhinge loss. Hàm mất mát này có thể mở rộng ra cho bài toán\\nmulti-class classification sẽ được đề cập trong chương (multi-class SVM). Cách phát triển\\ntừ soft-margin SVM thành multi-class SVM có thể so sánh với cách phát triển từ logistic\\nregression thành softmax regression. Tiếp theo, chúng ta cùng đi phân tích bài toán tối ưu\\ncho soft-margin SVM.\\n27.2 Phân tích toán học\\nNhư đã đề cập phía trên, để có mộtmargin lớn hơn trongsoft margin SVM, ta cầnhy sinh\\nmột vài điểm dữ liệu bằng cách chấp nhận cho chúng rơi vào vùngkhông an toàn. Tất nhiên,\\nviệc hy sinhnày cần được hạn chế, nếu không, ta có thể tạo ra một biên cực lớn bằng cách\\nhy sinh hầu hết các điểm. Vậy hàm mục tiêu nên là một sự kết hợp để tối đamargin cũng\\nnhư tối thiểusự hy sinh.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 352, 'page_label': '341'}, page_content='341 CHƯƠNG 27. SOFT-MARGIN SUPPORT VECTOR MACHINE\\nξ1\\nξ2\\nξ3\\nx1\\nx2\\nx3\\nw\\nT x+b= 0\\nw\\nT x+b= 1\\nw\\nT x+b=−1\\nHình 27.2: Giới thiệu các biến slackξn.\\nVới các điểm nằm ở khu vực an toàn,\\nξn = 0 . Những điểm nằm trong vùng\\nkhông an toàn, nhưng vẫn đúng phía so\\nvới đường ranh giới (đường nét đứt đậm),\\ntương ứng với các0 < ξn <1, ví dụx2.\\nNhữngđiểmnằmngượcphíavớiclasscủa\\nchúng so với đường boundary ứng với các\\nξn >1, ví dụ nhưx1 và x3.\\nGiống như vớihard-margin SVM, việc tối đamargin có thể đưa về việc tối thiểu∥w∥2\\n2. Để\\nđong đếmsự hy sinh, chúng ta cùng theo dõi Hình 27.2. Với mỗi điểmxn trong tập toàn bộ\\ndữ liệu huấn luyện, tagiới thiệu thêm một biến đosự hy sinhξn tương ứng. Biến này còn\\nđược gọi làslack variable. Với những điểmxn nằm trongvùng an toàn(nằm đúng vào màu\\nnền tương ứng và nằm ngoài khu vựcmargin), ξn = 0, tức không có sựhy sinh mất mátnào\\nxảy ra. Với mỗi điểm nằm trongvùng không an toànnhư x1,x2 hay x3, ta cần cóξi >0, tức\\nmất mát đã xảy ra. Đại lượng này nên tỉ lệ với khoảng cách từ điểm vi phạm tương ứng tới\\nbiên giới an toàn. Nhận thấy rằng nếuyi = ±1 là nhãn của xi trong vùng không an toànthì\\nξi có thể được định nghĩa là\\nξi = |wTxi + b−yi| (27.1)\\n(ở đây, ta đã bỏ mẫu số∥w∥2 đi vì ta chỉ cần một đại lượng tỉ lệ thuận.) Nhắc lại bài toán\\ntối ưu chohard-margin SVM:\\n(w,b) = arg min\\nw,b\\n1\\n2∥w∥2\\n2\\nthoả mãn:yn(wTxn + b) ≥1, ∀n= 1,2,...,N\\n(27.2)\\nVới soft-margin SVM, hàm mục tiêu sẽ có thêm một số hạng nữa giúp tối thiểutổng sự hy\\nsinh. Từ đó ta có hàm mục tiêu\\n1\\n2∥w∥2\\n2 + C\\nN∑\\nn=1\\nξn (27.3)\\ntrong đóC là một hằng số dương.Điều kiện ràng buộc được thay đổi một chút. Với mỗi cặp\\ndữ liệu(xn,yn), thay vì ràng buộccứng yn(wTxn + b) ≥1, ta sử dụng ràng buộcmềm:\\nyn(wTxn + b) ≥1 −ξn ⇔1 −ξn −yn(wTxn + b) ≤0, ∀n= 1,2,...,n\\nVà ràng buộc phụξn ≥0, ∀n= 1,2,...,N .\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 353, 'page_label': '342'}, page_content='CHƯƠNG 27. SOFT-MARGIN SUPPORT VECTOR MACHINE 342\\nTóm lại, ta sẽ có bài toán tối ưuprimal cho soft-margin SVM như sau đây.\\n(w,b,ξ ) = arg min\\nw,b,ξ\\n1\\n2∥w∥2\\n2 + C\\nN∑\\nn=1\\nξn\\nthoả mãn:1 −ξn −yn(wTxn + b) ≤0,∀n= 1,2,...,N\\n−ξn ≤0, ∀n= 1,2,...,N\\n(27.4)\\nNhận xét:\\n• Nếu C nhỏ, việcsự hy sinhcao hay thấp không gây ảnh hưởng nhiều tới giá trị của hàm\\nmục tiêu, thuật toán sẽ điều chỉnh sao cho∥w∥2\\n2 là nhỏ nhất, tứcmargin là lớn nhất, điều\\nnày sẽ dẫn tới∑N\\nn=1 ξn sẽ lớn theo vì vùng an toàn bị nhỏ đi. Ngược lại, nếuC quá lớn, để\\nhàm mục tiêu đạt giá trị nhỏ nhất, thuật toán sẽ tập trung vào làm giảm∑N\\nn=1 ξn. Trong\\ntrường hợpC rất rất lớn và hai lớp làlinearly separable, ta sẽ thu được∑N\\nn=1 ξn = 0. Chú\\ný rằng giá trị này không thể nhỏ hơn 0. Điều này đồng nghĩa với việc không có điểm nào\\nphải hy sinh, tức ta thu được nghiệm chohard-margin SVM. Nói cách khác,hard-margin\\nSVM chính là một trường hợp đặc biệt củasoft-margin SVM.\\n• Bài toán tối ưu (27.4) có thêm sự xuất hiện của các biếnslack ξn. Cácξn = 0 tương ứng\\nvới những điểm dữ liệu nằm trongvùng an toàn. Các 0 < ξn ≤1 tương ứng với những\\nđiểm nằm trongvùng không an toànnhưng vẫn được phân loại đúng, tức vẫn nằm về\\nđúng phía so với đường phân chia. Cácξn >1 tương ứng với các điểm bị phân lớp sai.\\n• Hàm mục tiêu trong bài toán tối ưu (27.4) là một hàm lồi vì nó là tổng của hai hàm\\nlồi: hàm norm và hàm tuyến tính. Các hàm ràng buộc cũng là các hàm tuyến tính theo\\n(w,b,ξ ). Vì vậy bải toán tối ưu (27.4) là một bài toán lồi, hơn nữa nó có thể biểu diễn\\ndưới dạng một quadratic programming (QP).\\nDưới đây, chúng ta sẽ cùng giải quyết bài toán tối ưu (27.4) bằng hai cách khác nhau.\\n27.3 Bài toán đối ngẫu Lagrange\\nChú ý rằng bài toán này có thể giải trực tiếp bằng các toolbox hỗ trợ QP, nhưng giống như\\nvới hard-margin SVM, chúng ta sẽ quan tâm hơn tới bài toán đối ngẫu của nó.\\nTrước kết, ta cần kiểm tra tiêu chuẩn Slater cho bài toán tối ưu lồi (27.4). Nếu tiêu chuẩn\\nnày được thoả mãn,strong dualitysẽ thoả mãn, và ta sẽ có nghiệm của bài toán tối ưu (27.4)\\nlà nghiệm của hệ điều kiện KKT (xem Chương 25).\\n27.3.1 Kiểm tra tiêu chuẩn Slater\\nRõ ràng là với mọin = 1,2,...,N và mọi (w,b), ta luôn có thể tìm được các sốdương\\nξn,n = 1,2,...,N, đủ lớn sao choyn(wTxn+ b) +ξn >1, ∀n= 1,2,...,N . Vì vậy, bài toán\\nnày thoả mãn tiêu chuẩn Slater.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 354, 'page_label': '343'}, page_content='343 CHƯƠNG 27. SOFT-MARGIN SUPPORT VECTOR MACHINE\\n27.3.2 Lagrangian của bài toán Soft-margin SVM\\nLagrangian cho bài toán (27.4) là\\nL(w,b, ξ,λ,µ) = 1\\n2∥w∥2\\n2 + C\\nN∑\\nn=1\\nξn +\\nN∑\\nn=1\\nλn(1 −ξn −yn(wTxn + b)) −\\nN∑\\nn=1\\nµnξn (27.5)\\nvới λ= [λ1,λ2,...,λ N]T ⪰0 và µ= [µ1,µ2,...,µ N]T ⪰0 là các biến đối ngẫu Lagrange.\\n27.3.3 Bài toán đối ngẫu\\nHàm số đối ngẫu của bài toán tối ưu (27.4) là:\\ng(λ,µ) = min\\nw,b,ξ\\nL(w,b, ξ,λ,µ)\\nVới mỗi cặp(λ,µ), chúng ta sẽ quan tâm tới(w,b, ξ) thoả mãn điều kiện đạo hàm của\\nLagrangian bằng 0:\\n∇wL= 0 ⇔w =\\nN∑\\nn=1\\nλnynxn (27.6)\\n∇bL= 0 ⇔\\nN∑\\nn=1\\nλnyn = 0 (27.7)\\n∇ξnL= 0 ⇔λn = C−µn (27.8)\\nTừ (27.8) ta thấy rằng ta chỉ quan tâm tới những cặp(λ,µ) sao cho λn = C −µn. Từ\\nđây ta cũng suy ra0 ≤λn,µn ≤C,n = 1,2,...,N . Thay các biểu thức này vào biểu thức\\nLagrangian (27.5), ta thu được hàm mục tiêu của bài toán đối ngẫu1\\ng(λ,µ) =\\nN∑\\nn=1\\nλn −1\\n2\\nN∑\\nn=1\\nN∑\\nm=1\\nλnλmynymxT\\nnxm (27.9)\\nChú ý rằng hàm này không phụ thuộc vàoµnhưng ta cần lưu ý ràng buộc (27.8), ràng buộc\\nnày và điều kiện không âm củaλcó thể được viết gọn lại thành0 ≤λn ≤C, khi đó ta đã\\ngiảm được biếnµ. Lúc này, bài toán đối ngẫu trở thành\\nλ= arg max\\nλ\\ng(λ)\\nthoả mãn:\\nN∑\\nn=1\\nλnyn = 0 (27.10)\\n0 ≤λn ≤C, ∀n= 1,2,...,N (27.11)\\nBài toán này gần giống với bài toán đối ngẫu củahard-margin SVM, chỉ khác là có thêm\\nràng buộc mỗiλn bị chặn trên bởiC. KhiC rất lớn, ta có thể coi hai bài toán là như nhau.\\n1 Bạn đọc hãy coi đây như là một bài tập nhỏ.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 355, 'page_label': '344'}, page_content='CHƯƠNG 27. SOFT-MARGIN SUPPORT VECTOR MACHINE 344\\nRàng buộc (27.11) còn được gọi làbox constraintvì không gian các điểmλthoả mãn ràng\\nbuộc này giống như một hình hộp chữ nhật trong không gian nhiều chiều. Bài toán này cũng\\nhoàn toàn giải được bằng các công cụ giải QP thông thường, ví dụ CVXOPT như tôi đã\\nthực hiện trong bàihard-margin SVM. Sau khi tìm đượcλ của bài toán đối ngẫu, ta vẫn\\nphải quay lại tìm nghiệm(w,b, ξ) của bài toán gốc. Trước hết, chúng ta cùng xem xét hệ\\nđiều kiện KKT và các tính chất của nghiệm.\\n27.3.4 Hệ điều kiện KKT\\n(Bạn đọc không muốn đi sâu vào toán có thể bỏ qua mục này)\\nHệ điều kiện KKT2 của bài toán tối ưusoft-margin SVM là, với mọin= 1,2,...,N :\\n1 −ξn −yn(wTxn + b) ≤0 (27.12)\\n−ξn ≤0 (27.13)\\nλn ≥0 (27.14)\\nµn ≥0 (27.15)\\nλn(1 −ξn −yn(wTxn + b)) = 0 (27.16)\\nµnξn = 0 (27.17)\\nw =\\nN∑\\nn=1\\nλnynxn (27.6)\\nN∑\\nn=1\\nλnyn = 0 (27.7)\\nλn = C−µn (27.8)\\nTừ (27.8) ta thấy chỉ có nhữngn ứng vớiλn >0 mới đóng góp vào nghiệmw của bài toán.\\nTập hợpS= {n: λn >0}được gọi làsupport set, và{xn,n ∈S} được gọi là tập các điểm\\nsupport vectors.\\nKhi λn >0, (27.16) chỉ ra rằng\\nyn(wTxn + b) = 1 −ξn (27.18)\\nNếu có thêm điều kiện0 <λn <C , (27.11) nói rằngµn = C−λn >0, kết hợp với (27.17),\\nta thu đượcξn = 0. Tiếp tục kết hợp với (27.18), ta suy rayn(wTxn+ b) = 1. Nói cách khác,\\nwTxn + b= yn, ∀n: 0 <λn <C (27.19)\\nTóm lại, khi0 < λn < C, các điểmxn nằm chính xác trên cácmargin (hai đường nét đứt\\nmảnh trong Hình 27.2). Tương tự như vớihard-margin SVM, giá trịbcó thể được tính theo\\ncông thức (numerical stable solution):\\nb= 1\\nNM\\n∑\\nm∈M\\n(\\nym −wTxm\\n)\\n(27.20)\\n2 Để cho dễ hình dung, các điều kiện (27.6) (27.7) (27.8) đã được nhắc lại trong hệ này.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 356, 'page_label': '345'}, page_content='345 CHƯƠNG 27. SOFT-MARGIN SUPPORT VECTOR MACHINE\\nvới M= {m: 0 < λm < C}và NM là số phần tử củaS. Nghiệm của bài toánsoft-margin\\nSVM được cho bởi (27.8) và (27.20).\\nNghiệm của bài toánsoft-margin SVM\\nw =\\n∑\\nm∈S\\nλmymxm (27.21)\\nb= 1\\nNM\\n∑\\nn∈M\\n(yn −wTxn) = 1\\nNM\\n∑\\nn∈M\\n(\\nyn −\\n∑\\nm∈S\\nλmymxT\\nmxn\\n)\\n(27.22)\\nCũng từ (27.18) và (27.16) ta suy rayn(wTxn+b) ≤1 với những điểm tương ứng vớiλn = C.\\nTức những điểm này nằm giữa hoặc trên hai đườngmargin. Như vậy, dựa trên các giá trị\\ncủa λn ta có thể dự đoán được vị trí tương đối củaxn so với hai đườngmargin.\\nMục đích cuối cùng là xác định nhãn cho một điểm mới hơn là tính cụ thểw và b. Vì vậy,\\nta quan tâm hơn tới cách xác định giá trị của biểu thức sau đây vớix bất kỳ:\\nwTx + b=\\n∑\\nm∈S\\nλmymxT\\nmx + 1\\nNM\\n∑\\nn∈M\\n(\\nyn −\\n∑\\nm∈S\\nλmymxT\\nmxn\\n)\\n(27.23)\\nTrong cách tính này, nếu biết cách tính các tích vô hướngxT\\nmx và xT\\nmxn, ta có thể xác định\\nđược bộ phân lớp. Trong chương tiếp theo, ta sẽ thấy rằng bằng cách sử dụng cácphép biến\\nđổi phi tuyến(nonlinear transformation) để thay đổi tích vô hướng bằng các hàm khác, ta\\nsẽ thu được các bộ phân lớp làm việc hiệu quả với dữ liệu khônglinear separable.\\n27.4 Bài toán tối ưu không ràng buộc chosoft-margin SVM\\nTrong mục này, chúng ta sẽ đưa bài toán tối ưu có ràng buộc (27.4) về một bài toán tối\\nưu không ràng buộc, và có có khả năng giải được bằng các phương pháp gradient descent\\ngiống như các neural network. Đây cũng là nên tảng để kết hợp mộtmulti-class SVM vào\\ncác neural network, như sẽ được trình bày trong Chương 29.\\n27.4.1 Bài toán tối ưu không ràng buộc tương đương\\nĐể ý thấy rằng điều kiện ràng buộc thứ nhất:\\n1 −ξn −yn(wTx + b) ≤0 ⇔ξn ≥1 −yn(wTx + b) (27.24)\\nKết hợp với điều kiệnξn ≥0 ta sẽ thu được bài toán ràng buộc tương đương với bài toán\\n(27.4) như sau:\\n(w,b,ξ ) = arg min\\nw,b,ξ\\n1\\n2∥w∥2\\n2 + C\\nN∑\\nn=1\\nξn\\nthoả mãn:ξn ≥max(0,1 −yn(wTx + b)), ∀n= 1,2,...,N\\n(27.25)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 357, 'page_label': '346'}, page_content='CHƯƠNG 27. SOFT-MARGIN SUPPORT VECTOR MACHINE 346\\nTiếp theo, để đưa bài toán (27.25) về dạng không ràng buộc, chúng ta sẽ chứng minh nhận\\nxét sau đây bằng phương pháp phản chứng. Nếu(w,b,ξ ) là nghiệm của bài toán tối ưu\\n(27.25), tức tại đó hàm mục tiêu đạt giá trị nhỏ nhất, thì\\nξn = max(0,1 −yn(wTxn + b)), ∀n= 1,2,...,N (27.26)\\nThật vậy, giả sử ngược lại, tồn tạin sao cho\\nξn >max(0,1 −yn(wTxn + b)),\\nchọn ξ′\\nn = max(0,1 −yn(wTxn+ b)), ta sẽ thu được một giá trị thấp hơn của hàm mục tiêu,\\ntrong khi tất cả các ràng buộc vẫn được thoả mãn. Điều này mâu thuẫn với việc hàm mục\\ntiêu đã đạt giá trị nhỏ nhất! Điều mâu thuẫn này chỉ ra rằng nhận xét (27.26) là chính xác.\\nKhi đó, bằng cách thay toàn bộ các giá trị củaξn trong (27.26) vào hàm mục tiêu, ta thu\\nđược bài toán tối ưu\\n(w,b,ξ ) = arg min\\nw,b,ξ\\n1\\n2∥w∥2\\n2 + C\\nN∑\\nn=1\\nmax(0,1 −yn(wTxn + b))\\nthoả mãn:ξn = max(0,1 −yn(wTxn + b)), ∀n= 1,2,...,N\\n(27.27)\\nTừ đây ta thấy rằng biến sốξ không còn quan trọng trong bài toán này nữa, ta có thể lược\\nbỏ rằng buộc này mà không làm thay đổi nghiệm của bài toán.\\nBài toán (27.27) tương đương với\\n(w,b) = arg min\\nw,b\\n{\\n1\\n2∥w∥2\\n2 + C\\nN∑\\nn=1\\nmax(0,1 −yn(wTxn + b)) ≜J(w,b)\\n}\\n(27.28)\\nĐây là một bài toán tối ưu không ràng buộc với hàm mất mátJ(w,b). Bài toán này có thể\\ngiải được bằng các phương pháp gradient descent. Nhưng trước hết, chúng ta cùng xem xét\\nhàm mất mát này từ một góc nhìn khác. Góc nhìn mới này giúp xây dựng hàm mất mát\\nJ(w,b) một cáchtự nhiên hơn bằng cách sử dụng một hàm số có tên làhinge loss.\\n27.4.2 Hinge loss\\nNhắc lại một chút về hàmcross entropy. Với mỗi cặp hệ số(w,b) và cặp dữ liệu(xn,yn), đặt\\nzn = wTxn+ bvàan = σ(zn) (σ là sigmoid function). Hàmcross entropyđược định nghĩa là\\nJ1\\nn(w,b) = −(ynlog(an) + (1−yn) log(1−an)) (27.29)\\nHàm cross entropyđạt giá trị càng nhỏ nếu xác suấtan càng gần vớiyn (0 <an <1).\\nỞ đây, chúng ta làm quen với một hàm số khác cũng được sử dụng nhiều trong các bộ phân\\nlớp. Hàm số này có dạng\\nJn(w,b) = max(0,1 −ynzn)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 358, 'page_label': '347'}, page_content='347 CHƯƠNG 27. SOFT-MARGIN SUPPORT VECTOR MACHINE\\n-3 -2 -1 0 1 2 3\\n-1\\n1\\n2\\n3\\nyz\\nh(yz)\\nHình 27.3:Hinge loss (màu xanh)\\nvà zeros-one loss (màu đen). Với\\nzero-one loss, những điểm nằm\\nxa margin (hoành độ bằng 1) và\\nboundary (hoành độ bằng 0) được\\nđối xử như nhau. Trong khi đó, với\\nhinge loss, những điểm ở xa về phía\\ntrái gây ra mất mát nhiều hơn.\\nHàm này có tên làhinge loss. Trong đó,zn = wTxn + b có thể được coi làscore của xn\\nứng với cặp hệ số(w,b), yn chính là đầu ra mong muốn. Chúng ta sẽ sớm thấy ý nghĩa của\\nhàm này thông qua đồ thị của hàm tương ứng. Hình 27.3 mô tả đồ thị hàm sốhinge loss3\\nf(yz) = max(0 ,1 −yz) và so sánh với hàmzero-one loss. Hàmzero-one losslà hàmđếm số\\nđiểm bị phân lớp lỗi. Trong Hình 27.5, biến số làyz là tích của đầu ra mong muốn (ground\\ntruth) vàscore z. Những điểm ở phía phải của trục tung ứng với những điểm được phân\\nloại đúng, tứcz tìm được cùng dấu vớiy. Những điểm ở phía trái của trục tung ứng với các\\nđiểm bị phân loại sai. Ta có các nhận xét sau đây:\\n• Với hàmzero-one loss, các điểm cóscore ngược dấu với đầu ra mong muốn (yz <0) sẽ\\ngây ra mất mát như nhau (bằng 1), bất kể chúng ở gần hay xa đường ranh giới (trục\\ntung). Đây là một hàm rời rạc, rất khó tối ưu và ta cũng khó có thể đo đếm đượcsự hy\\nsinh như đã định nghĩa ở phần đầu.\\n• Với hàmhinge loss, những điểm nằm trong vùng an toàn, ứng vớiys ≥1, sẽ không gây\\nra mất mát gì. Những điểm nằm giữa margin của lớp tương ứng và đường ranh giới ứng\\nvới 0 < y <1. Những điểm này gây ra một mất mát nhỏ (nhỏ hơn 1). Những điểm bị\\nmisclassifed, tứcyz <0 sẽ gây ra mất mát lớn hơn. Vì vậy, khi tối thiểu hàm mất mát,\\nta sẽ hạn chế được những điểm bịmisclassifed và lấn sang phầnlãnh thổ của lớp còn lại\\nquá nhiều. Đây chính là một ưu điểm của hàmhinge loss.\\n• Hàmhinge losslàmộthàmliêntục,và có đạo hàm tại gần như mọi nơi(almost everywhere\\ndifferentiable) trừ điểm có hoành độ bằng 1. Ngoài ra, đạo hàm của hàm này cũng rất dễ\\nxác định: bằng -1 tại các điểm nhỏ hơn 1 và bằng 0 tại các điểm lớn hơn 1. Tại 1, ta có\\nthể coi như đạo hàm của nó bằng 0 giống như cách tính đạo hàm của hàm ReLU.\\n27.4.3 Xây dựng hàm mất mát\\nXét bài toánsoft-margin SVM bằng cách sử dụnghinge loss, với mỗi cặp(w,b), đặt\\nLn(w,b) = max(0 ,1 −ynzn) = max(0 ,1 −yn(wTxn + b)) (27.30)\\n3 Đồ thị của hàm số này có hình giống chiếc bản lề. Trong tiếng Anh,hinge nghĩa là bản lề.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 359, 'page_label': '348'}, page_content='CHƯƠNG 27. SOFT-MARGIN SUPPORT VECTOR MACHINE 348\\nLấy trung bình cộng của cácloss này theo mọi điểm dữ liệu trong tập huấn luyện ta được\\nL(w,b) = 1\\nN\\nN∑\\nn=1\\nLn = 1\\nN\\nN∑\\nn=1\\nmax(0,1 −yn(wTxn + b))\\nCâu hỏi đặt ra là, nếu ta trực tiếp tối ưu trung bình các hinge loss này thì điều gì sẽ xảy ra?\\nTrong trường hợp dữ liệu của hai lớp làlinearly separable, ta sẽ có giá trị tối ưu tìm được\\ncủa L(w,b) sẽ bằng 0. Điều này có nghĩa là:\\n1 −yn(wTxn + b) ≤0, ∀n= 1,2,...,N (27.31)\\nNhân cả hai về với một hằng sốa> 1 ta có:\\na−yn(awTxn + ab) ≤0, ∀n= 1,2,...,N (27.32)\\n⇒1 −yn(awTxn + ab) ≤1 −a< 0, ∀n= 1,2,...,N (27.33)\\nĐiều này nghĩa là(aw,ab) cũng là nghiệm của bài toán. Nếu không có điều kiện gì thêm,\\nbài toán có thể dẫn tới nghiệm không ổn định vì các hệ số của nghiệm có thể lớn tuỳ ý!\\nĐể tránhbug này, chúng ta cần thêm một số hạng nữa vàoL(w,b) gọi là số hạngregulariza-\\ntion, giống như cách chúng ta đã làm để tránhoverfitting trong neural networks. Lúc này,\\nta sẽ có hàm mất mát tổng cộng là\\nJ(w,b) = L(w,b) + λR(w,b)\\nvới λ là một số dương, gọi làregularization parameter, hàmR() sẽ giúp hạn chế việc các hệ\\nsố (w,b) trở nên quá lớn. Có nhiều cách chọn hàmR(), nhưng cách phổ biến nhất làl2, khi\\nđó hàm mất mát củasoft-margin SVM trở thành\\nJ(w,b) = 1\\nN\\n\\uf8eb\\n\\uf8ec\\uf8ec\\uf8ec\\uf8ec\\uf8ed\\nN∑\\nn=1\\nmax(0,1 −yn(wTxn + b))\\n\\ued19 \\ued18\\ued17 \\ued1a\\nhinge loss\\n+ λ\\n2 ∥w∥2\\n2\\n\\ued19 \\ued18\\ued17 \\ued1a\\nregularization\\n\\uf8f6\\n\\uf8f7\\uf8f7\\uf8f7\\uf8f7\\uf8f8\\n(27.34)\\nKỹ thuật này còn gọi làweight decay. Chú ý rằng weight decay thường không được\\náp dụng lên thành phần biasb.\\nTa thấy rằng hàm mất mát (27.34) giống với hàm mất mát (27.28) vớiλ= 1\\nC, và thay việc\\nlấy trung bình cộng bằng việc tính tổng.\\nTrong phần tiếp theo của mục này, chúng ta sẽ quan tâm tới bài toán tối ưu hàm mất mát\\nđược cho trong (27.34). Trước hết, đây là một hàm lồi theow,b vì các lý do sau:\\n• 1 −yn(wTxn + b) là một hàm tuyến tính theow,b nên nó là một hàm lồi. Hàm lấy giá\\ntrị lớn hơn trong hai hàm lồi là một hàm lồi, vì vậy,hingle loss là một hàm lồi.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 360, 'page_label': '349'}, page_content='349 CHƯƠNG 27. SOFT-MARGIN SUPPORT VECTOR MACHINE\\n• Hàm norm cũng là một hàm lồi.\\n• Tổng của hai hàm lồi là một hàm lồi.\\nVì hàm mất mát là lồi, các thuật toán gradient descent vớilearning ratephù hợp sẽ giúp\\ntìm được nghiệm của bài toán.\\n27.4.4 Tối ưu hàm mất mát\\nVì việc tối ưu hàm mất mát dựa trên gradient descent, việc chính của mục này là tính đạo\\nhàm của hàm mất mát theow và b.\\nĐạo hàm của phầnhinge loss không quá phức tạp:\\n∇w\\n(\\nmax(0,1 −yn(wTxn + b))\\n)\\n=\\n{\\n−ynxn nếu 1 −yn(wTxn + b) ≥0\\n0 o.w. (27.35)\\n∇b\\n(\\nmax(0,1 −yn(wTxn + b))\\n)\\n=\\n{\\n−yn nếu 1 −yn(wTxn + b) ≥0\\n0 o.w. (27.36)\\nPhần regularization cũng có đạo hàm tương đối đơn giản:\\n∇w\\n(λ\\n2 ∥w∥2\\n2\\n)\\n= λw; ∇b\\n(λ\\n2 ∥w∥2\\n2\\n)\\n= 0 (27.37)\\nNếu cập nhật bằng gradient descent thông qua chỉ một điểm dữ liệu(xn,yn) (stochastic\\ngradient descent). Nếu1 −yn(wTxn+ b) <0, ta không cập nhật gì và chuyển sang điểm tiếp\\ntheo. Ngược lại biểu thức cập nhật chow,b được cho bởi\\nw ←w −η(−ynxn + λw); b←b+ ηyn nếu 1 −yn(wTxn + b) ≥0) (27.38)\\nw ←w −ηλw; b←b o.w. (27.39)\\nvới η là learning rate. Vớimini-batch gradient descenthoặc batch gradient descent, các biểu\\nthức đạo hàm trên đây hoàn toàn có thể được lập trình bằng các kỹ thuậtvectorization, như\\nchúng ta sẽ thấy trong mục tiếp theo.\\n27.5 Lập trình vớisoft-margin SVM\\nTrong mục này, chúng ta sẽ đi tìm nghiệm của một bài toánsoft-margin SVMbằng ba cách\\nkhác nhau: sử dụng thư viện sklearn, giải bài toán đối ngẫu bằng CVXOPT, và tối ưu hàm\\nmất mát không ràng buộc bằng phương pháp gradient descent. Giá trịC được sử dụng là\\n100. Nếu mọi tính toán ở trên là chính xác, nghiệm của ba cách làm này sẽ gần giống nhau,\\nkhác nhau có thể một chút bởi sai số trong tính toán4. Chúng ta cũng sẽ thayC bởi những\\ngiá trị khác nhau và cùng xem cácmargin thay đổi như thế nào.\\n4 Ta có thể khẳng định việc này vì bài toán tối ưusoft-margin SVM là lồi.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 361, 'page_label': '350'}, page_content='CHƯƠNG 27. SOFT-MARGIN SUPPORT VECTOR MACHINE 350\\nKhai báo thư viện và tạo dữ liệu giả\\nfrom __future__ import print_function\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\nnp.random.seed(22)\\nmeans = [[2, 2], [4, 2]]\\ncov = [[.7, 0], [0, .7]]\\nN = 20 # number of samplers per class\\nX0 = np.random.multivariate_normal(means[0], cov, N) # each row is a data point\\nX1 = np.random.multivariate_normal(means[1], cov, N)\\nX = np.concatenate((X0, X1))\\ny = np.concatenate((np.ones(N), -np.ones(N)))\\nCác điểm màu xanh và đỏ trên Hình 27.4 minh hoạ các điểm dữ liệu của hai lớp. Dữ liệu\\nnày làgần linearly separable.\\n27.5.1 Giải bài toán bằng thư viện sklearn\\nfrom sklearn.svm import SVC\\nC = 100\\nclf = SVC(kernel = ’linear’, C = C)\\nclf.fit(X, y)\\nw_sklearn = clf.coef_.reshape(-1, 1)\\nb_sklearn = clf.intercept_[0]\\nprint(w_sklearn.T, b_sklearn)\\nKết quả:\\nw_sklearn = [[-1.87461946 -1.80697358]]\\nb_sklearn = 8.49691190196\\n27.5.2 Tìm nghiệm bằng cách giải bài toán đối ngẫu\\nĐoạn code dưới đây tương tự như việc giải bài toánhard-margin SVM, chỉ khác rằng ta có\\nthêm ràng buộc về chặn trên của các nhân tử Lagrange:\\nfrom cvxopt import matrix, solvers\\n# build K\\nV = np.concatenate((X0, -X1), axis = 0) # V[n,:] = y[n]*X[n]\\nK = matrix(V.dot(V.T))\\np = matrix(-np.ones((2*N, 1)))\\n# build A, b, G, h\\nG = matrix(np.vstack((-np.eye(2*N), np.eye(2*N))))\\nh = np.vstack((np.zeros((2*N, 1)), C*np.ones((2*N, 1))))\\nh = matrix(np.vstack((np.zeros((2*N, 1)), C*np.ones((2*N, 1)))))\\nA = matrix(y.reshape((-1, 2*N)))\\nb = matrix(np.zeros((1, 1))) # continue on next page\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 362, 'page_label': '351'}, page_content='351 CHƯƠNG 27. SOFT-MARGIN SUPPORT VECTOR MACHINE\\nsolvers.options[’show_progress’] = False\\nsol = solvers.qp(K, p, G, h, A, b)\\nl = np.array(sol[’x’]).reshape(2*N) # lambda vector\\n# support set\\nS = np.where(l > 1e-5)[0]\\nS2 = np.where(l < .999*C)[0]\\n# margin set\\nM = [val for val in S if val in S2] # intersection of two lists\\nVS = V[S] # shape (NS, d)\\nlS = l[S] # shape (NS,)\\nw_dual = lS.dot(VS) # shape (d,)\\nyM = y[M] # shape(NM,)\\nXM = X[M] # shape(NM, d)\\nb_dual = np.mean(yM - XM.dot(w_dual)) # shape (1,)\\nprint(’w_dual = ’, w_dual)\\nprint(’b_dual = ’, b_dual)\\nKết quả:\\nw_dual = [-1.87457279 -1.80695039]\\nb_dual = 8.49672109814\\nKết quả này gần giống với kết quả tìm được bằng sklearn.\\n27.5.3 Tìm nghiệm bằng giải bài toán tối ưu không ràng buộc\\nTrong phương pháp này, chúng ta cần tính gradient của hàm mất mát. Như thường lệ, chúng\\nta cần kiểm chứng này bằng cách so sánh vớinumerical gradient. Chú ý rằng trong phương\\npháp này, ta cần dùng tham sốlam = 1/C. Trước hết ta viết các hàm tính giá trị hàm mất\\nmát và đạo hàm theow và b.\\nlam = 1./C\\ndef loss(X, y, w, b):\\n\"\"\"\\nX.shape = (2N, d), y.shape = (2N,), w.shape = (d,), b is a scalar\\n\"\"\"\\nz = X.dot(w) + b # shape (2N,)\\nyz = y*z\\nreturn (np.sum(np.maximum(0, 1 - yz)) + .5*lam*w.dot(w))/X.shape[0]\\ndef grad(X, y, w, b):\\nz = X.dot(w) + b # shape (2N,)\\nyz = y*z # element wise product, shape (2N,)\\nactive_set = np.where(yz <= 1)[0] # consider 1 - yz >= 0 only\\n_yX = - X*y[:, np.newaxis] # each row is y_n*x_n\\ngrad_w = (np.sum(_yX[active_set], axis = 0) + lam*w)/X.shape[0]\\ngrad_b = (-np.sum(y[active_set]))/X.shape[0]\\nreturn (grad_w, grad_b) ## continue on next page\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 363, 'page_label': '352'}, page_content='CHƯƠNG 27. SOFT-MARGIN SUPPORT VECTOR MACHINE 352\\ndef num_grad(X, y, w, b):\\neps = 1e-10\\ngw = np.zeros_like(w)\\ngb = 0\\nfor i in xrange(len(w)):\\nwp = w.copy()\\nwm = w.copy()\\nwp[i] += eps\\nwm[i] -= eps\\ngw[i] = (loss(X, y, wp, b) - loss(X, y, wm, b))/(2*eps)\\ngb = (loss(X, y, w, b + eps) - loss(X, y, w, b - eps))/(2*eps)\\nreturn (gw, gb)\\nw = .1*np.random.randn(X.shape[1])\\nb = np.random.randn()\\n(gw0, gb0) = grad(X, y, w, b)\\n(gw1, gb1) = num_grad(X, y, w, b)\\nprint(’grad_w difference = ’, np.linalg.norm(gw0 - gw1))\\nprint(’grad_b difference = ’, np.linalg.norm(gb0 - gb1))\\nKết quả:\\ngrad_w difference = 1.27702840067e-06\\ngrad_b difference = 4.13701854995e-08\\nSự sai khác giữa hai cách tính là nhỏ; vậy ta có thể tin tưởng sử dụng hàmgrad trong\\ngradient descent.\\ndef softmarginSVM_gd(X, y, w0, b0, eta):\\nw = w0\\nb = b0\\nit = 0\\nwhile it < 10000:\\nit = it + 1\\n(gw, gb) = grad(X, y, w, b)\\nw -= eta*gw\\nb -= eta*gb\\nif (it % 1000) == 0:\\nprint(’iter %d’ %it + ’ loss: %f’ %loss(X, y, w, b))\\nreturn (w, b)\\nw0 = .1*np.random.randn(X.shape[1])\\nb0 = .1*np.random.randn()\\nlr = 0.05\\n(w_hinge, b_hinge) = softmarginSVM_gd(X, y, w0, b0, lr)\\nprint(’w_hinge = ’, w_dual)\\nprint(’b_hinge = ’, b_dual)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 364, 'page_label': '353'}, page_content='353 CHƯƠNG 27. SOFT-MARGIN SUPPORT VECTOR MACHINE\\nx1\\nx2\\nSolution found by sklearn\\n(a)\\nx1\\nx2\\nSolution found by dual (b)\\nx1\\nx2\\nSolution found by hinge (c)\\nHình 27.4: Các đường phân chia tìm được bởi ba cách khác nhau: a) Thư viện sklearn, b) Giải\\nbài toán đối ngẫu bằng CVXOPT, c) Hàm hinge loss. Các kết quả tìm được gần như giống nhau.\\nKết quả:\\niter 1000 loss: 0.436460\\niter 2000 loss: 0.405307\\niter 3000 loss: 0.399860\\niter 4000 loss: 0.395440\\niter 5000 loss: 0.394562\\niter 6000 loss: 0.393958\\niter 7000 loss: 0.393805\\niter 8000 loss: 0.393942\\niter 9000 loss: 0.394005\\niter 10000 loss: 0.393758\\nw_hinge = [-1.87457279 -1.80695039]\\nb_hinge = 8.49672109814\\nTa thấy rằngloss giảm dần và hội tụ theo thời gian, chứng tỏlearning rate là phù hợp.\\nNghiệm tìm được cũng gần giống nghiệm của hai cách làm phía trên.\\nHình 27.4 mình hoạ các nghiệm tìm được bằng ba phương pháp phía trên. Ta thấy rằng các\\nnghiệm tìm được gần như giống nhau.\\n27.5.4 Ảnh hưởng củaC lên nghiệm\\nHình 27.5 minh hoạ nghiệm tìm được bằng sklearn với các giá trịC khác nhau. Quan sát\\nthấy khiC càng lớn, biên càng nhỏ đi. Điều này phù hợp với các suy luận ở đầu chương.\\n27.6 Tóm tắt và thảo luận\\n• SVM thuần (hard-margin SVM) hoạt động không hiệu quả khi có nhiễu ở gần ranh giới\\nhoặc thậm chí khi dữ liệu giữa hai lớp gầnlinearly separable. Soft-margin SVM có thể\\ngiúp khắc phục điểm này.\\n• Trong soft-margin SVM, chúng ta chấp nhận lỗi xảy ra ở một vài điểm dữ liệu. Lỗi này\\nđược xác định bằng khoảng cách từ điểm đó tới đườngmargin tương ứng. Bài toán tối\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 365, 'page_label': '354'}, page_content='CHƯƠNG 27. SOFT-MARGIN SUPPORT VECTOR MACHINE 354\\nx1\\nx2\\nC = 0.100000\\nx1\\nx2\\nC = 1\\nx1\\nx2\\nC = 10\\nx1\\nx2\\nC = 100\\nHình 27.5:Ảnh hưởng củaC lên nghiệm của soft-margin SVM.C càng lớn, biên càng nhỏ, và\\nngược lại.\\nưu sẽ tối thiểu lỗi này bằng cách sử dụng thêm các biến được gọi làslack varaibles. Để\\ngiải bài toán tối ưu, có hai cách khác nhau.\\n• Cách thứ nhất là giải bài toán đối ngẫu. Bài toán đối ngẫu của soft margin SVM rất\\ngiống với bài toán đối ngẫu của hard-margin SVM, chỉ khác ở ràng buộc chặn trên của\\ncác nhân tử Laggrange. Ràng buộc này còn được gọi làbox costraint.\\n• Cách thứ hai là đưa bài toán về dạng không ràng buộc dựa trên một hàm mới gọi làhinge\\nloss. Với cách này, hàm mất mát thu được là một hàm lồi và có thể giải được một cách\\nhiệu quả bằng các phương pháp gradient descent.\\n• Soft-margin SVM yêu cầu chọn hằng sốC. Hướng tiếp cận này còn được gọi là C-SVM.\\nNgoài ra, còn có một hướng tiếp cận khác cũng hay được sử dụng, gọi làν-SVM [SSWB00].\\n• Source code cho chương này có thể được tìm thấy tạihttps://goo.gl/PuWxba .\\n• LIBSVM là một thư viện SVM phổ biến (https://goo.gl/Dt7o7r ).\\n• Đọc thêm: L. Rosasco et al.,. Are Loss Functions All the Same? (https://goo.gl/\\nQH2Cgr). Neural Computation.2004 [RDVC+04].\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 366, 'page_label': '355'}, page_content='Chương 28\\nKernel support vector machine\\n28.1 Giới thiệu\\nCó một sự tương ứng thú vị giữa hai nhóm thuật toán phân lớp phổ biến nhất, neural\\nnetwork và support vector machine. Chúng đều bắt đầu từ bài toán phân lớp với hai lớp dữ\\nliệu linearly separable, tiếp theo đến hai lớpgần như linear separable, đến bài toán với nhiều\\nlớp dữ liệu, rồi các bài toán với các lớp hoàn toàn khônglinearly separable. Sự tương ứng\\nđược cho trong Bảng 28.1\\nBảng 28.1: Sự tương đồng giữa neural network và support vector machine\\nNeural network Support vector machine Tính chất chung\\nPLA Hard-margin SVM Hai lớp làlinearly separable\\nLogistic regression Soft-margin SVM Hai lớp làgần linearly separable\\nSoftmax regression Multi-class SVM Nhiều lớp dữ liệu (ranh giới là các siêu phẳng)\\nMulti-layer perceptron Kernel SVM Bài toán phân lớp với biên khônglinearly separable\\nTrong chương này, chúng ta cùng thảo luận về Kernel SVM, tức việc áp dụng SVM lên bài\\ntoán mà dữ liệu giữa hai lớp là hoàn toànkhông linear separable. Bài toán phân biệt nhiều\\nlớp dữ liệu sẽ được thảo luận trong chương tiếp theo.\\nÝ tưởng cơ bản của Kernel SVM và các phương pháp kernel nói chung là tìm một phép biến\\nđổi dữ liệukhông linearly separableở một không gian sang một không gian mới. Ở không\\ngian mới này, dữ liệu trở nênlinearly separablehoặc gần linearly separable, và vì vậy, bài\\ntoán phân lớp có thể được giải quyết bằng hard/soft-margin SVM.\\nXét ví dụ trên Hình 28.1 với việc biến dữ liệu khônglinearly separable trong không gian\\nhai chiều thànhlinearly separabletrong không gian ba chiều bằng cách giới thiệu thêm một'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 367, 'page_label': '356'}, page_content='CHƯƠNG 28. KERNEL SUPPORT VECTOR MACHINE 356\\n(a)\\n(b)\\n(c)\\nHình 28.1: Ví dụ về Kernel SVM. (a) Dữ liệu của hai lớp làkhông phân biệt tuyến tínhtrong\\nkhông gian hai chiều. (b) Nếu coi thêm chiều thứ ba là một hàm số của hai chiều còn lại\\nz = x2 + y2, các điểm dữ liệu sẽ được phân bố trên một mặt parabolic và đã hai lớp trở nên\\nlinearly separable. Mặt phẳng màu vàng là mặt phân chia, có thể tìm được bởi một hard/soft-\\nmargin SVM. (c) Giao điểm của mặt phẳng tìm được và mặt parabolic là một đường ellipse, khi\\nchiếu toàn bộ dữ liệu cũng như đường ellipse này xuống không gian hai chiều ban đầu, ta đã tìm\\nđược đường phân chia hai lớp.\\nchiều mới. Để xem ví dụ này một cách sinh động hơn, bạn có thể xem clip đi kèm với blog\\nMachine Learning cơ bảntại https://goo.gl/3wMHyZ .\\nNói một cách toán học, kernel SVM là phương pháp đi tìm một hàm số biến đổi dữ liệux\\ntừ không gian đặc trưng ban đầu thành dữ liệu trong một không gian mới bằng một hàm\\nsố Φ(x). Trong ví dụ này, hàmΦ() đơn giản là giới thiệu thêm một chiều dữ liệu mới là\\nmột hàm số của các thành phần đặc trưng đã biết. Hàm số này cần thỏa mãn: trong không\\ngian mới, dữ liệu giữa hai lớp làlinearly separablehoặc gần như linearly separable. Khi đó,\\nta có thể dùng các bộ phân lớp tuyến tính thông thường như PLA, logistic regression, hay\\nhard/soft margin SVM.\\nCác hàmΦ(x) thường tạo ra dữ liệu mới có số chiều cao hơn số chiều của dữ liệu ban đầu,\\nthậm chí là vô hạn chiều. Nếu tính toán các hàm này trực tiếp, chắc chắn chúng ta sẽ gặp\\ncác vấn đề về bộ nhớ và hiệu năng tính toán. Có một cách tiếp cận là sử dụng các hàm\\nkernel mô tả quan hệ giữa hai điểm dữ liệu bất kỳ trong không gian mới, thay vì đi tính\\ntoán trực tiếp biến đổi của từng điểm dữ liệu trong không gian mới. Kỹ thuật này được xây\\ndựng dựa trên quan sát về các bài toán đối ngẫu của hard/soft margin SVM.\\nNếu phải so sánh, ta có thể thấy rằng các hàmkernel có chức năng tương tự như các hàm\\nactivation trong neural network vì chúng đều giúp giải quyết các bài toán với dữ liệu không\\nlinearly separable. Trong Mục 28.2, chúng ta cùng tìm hiểu cơ sở toán học của Kernel SVM,\\nMục 28.3 sẽ giới thiệu một số hàmkernel thường được sử dụng.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 368, 'page_label': '357'}, page_content='357 CHƯƠNG 28. KERNEL SUPPORT VECTOR MACHINE\\n28.2 Cơ sở toán học\\nCùng nhắc lại bài toán đối ngẫu trong soft-margin SVM cho dữ liệugần linearly separable:\\nλ= arg max\\nλ\\nN∑\\nn=1\\nλn −1\\n2\\nN∑\\nn=1\\nN∑\\nm=1\\nλnλmynymxT\\nnxm\\nthoả mãn:\\nN∑\\nn=1\\nλnyn = 0\\n0 ≤λn ≤C, ∀n= 1,2,...,N\\n(28.1)\\ntrong đó,N là số cặp điểm dữ liệu trong tập huấn luyện;xn là vector đặc trưng của dữ liệu\\nthứ n trong tập training;yn là nhãn của điểm dữ liệu thứn, bằng 1 hoặc -1;λn là nhân tử\\nLagrange ứng với điểm dữ liệu thứn; vàC là một hằng số dương giúp cân đối độ lớn của\\nmargin vàsự hy sinhcủa các điểm nằm trong vùngkhông an toàn. KhiC = ∞hoặc rất lớn,\\nsoft-margin SVM trở thành hard-margin SVM.\\nSau khi giải đượcλ cho bài toán (28.1),nhãn của một điểm dữ liệu mới sẽ được xác định\\nbởi\\nclass(x) = sgn\\n{∑\\nm∈S\\nλmymxT\\nmx + 1\\nNM\\n∑\\nn∈M\\n(\\nyn −\\n∑\\nm∈S\\nλmymxT\\nmxn\\n)}\\n(28.2)\\ntrong đó, M= {n : 0 < λn < C}là tập hợp những điểm nằm trên cácmargin; S= {n :\\n0 <λn}là tập hợp cácsupport vector; vàNM là số phần tử củaM.\\nVới dữ liệu thực tế, rất khó để có dữ liệugần phân biệt tuyến tính, vì vậy nghiệm của bài\\ntoán (28.1) có thể không thực sự tạo ra một bộ phân lớp tốt. Giả sử rằng ta có thể tìm được\\nhàm sốΦ() sao cho sau khi được biến đổi sang không gian mới, mỗi điểm dữ liệux trở thành\\nΦ(x), và trong không gian mới này, dữ liệu trở nêngần phân biệt tuyến tính. Lúc này,hy\\nvọng rằngnghiệm của bài toán soft-margin SVM sẽ cho chúng ta một bộ phân lớp tốt hơn.\\nTrong không gian mới, bài toán (28.1) trở thành:\\nλ= arg max\\nλ\\nN∑\\nn=1\\nλn −1\\n2\\nN∑\\nn=1\\nN∑\\nm=1\\nλnλmynymΦ(xn)TΦ(xm)\\nthoả mãn:\\nN∑\\nn=1\\nλnyn = 0\\n0 ≤λn ≤C, ∀n= 1,2,...,N\\n(28.3)\\nvà nhãn của một điểm dữ liệu mới được xác định bởi dấu của biểu thức\\nwTΦ(x) + b=\\n∑\\nm∈S\\nλmymΦ(xm)TΦ(x) + 1\\nNM\\n∑\\nn∈M\\n(\\nyn −\\n∑\\nm∈S\\nλmymΦ(xm)TΦ(xn)\\n)\\n(28.4)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 369, 'page_label': '358'}, page_content='CHƯƠNG 28. KERNEL SUPPORT VECTOR MACHINE 358\\nNhư đã nói ở trên, việc tính toán trực tiếpΦ(x) cho mỗi điểm dữ liệu có thể sẽ tốn rất nhiều\\nbộ nhớ và thời gian vì số chiều củaΦ(x) thường là rất lớn, có thể là vô hạn. Thêm nữa, để\\ntìm nhãn của một điểm dữ liệu mớix, ta lại phải tìm biến đổi của nóΦ(x) trong không\\ngian mới rồi lấy tích vô hướng của nó với tất cả cácΦ(xm) với mtrong tập hợp support. Để\\ntránh việc này, ta quan sát thấy một điều thú vị sau đây.\\nTrong bài toán (28.3) và biểu thức (28.4), chúng ta không cần tính trực tiếpΦ(x) cho\\nmọi điểm dữ liệu. Chúng ta chỉ cần tính đượcΦ(x)TΦ(z) dựa trên hai điểm dữ liệux,z\\nbất kỳ. Vì vậy, ta có thể không cần xác định hàmΦ(.) mà chỉ cần xác định một hàm\\nk(x,z) = Φ(x)TΦ(z). Kỹ thuật này còn được gọi làkernel trick. Những phương pháp dựa\\ntrên kỹ thuật này, tức thay vì trực tiếp tính tọa độ của một điểm trong không gian mới, ta\\nđi tính tích vô hướng giữa hai điểm trong không gian mới, được gọi chung làkernel method.\\nLúc này, bằng cách định nghĩahàm kernel k(x,z) = Φ(x)TΦ(z), ta có thể viết lại bài toán\\n(28.3) và biểu thức (28.4) như sau:\\nλ= arg max\\nλ\\nN∑\\nn=1\\nλn −1\\n2\\nN∑\\nn=1\\nN∑\\nm=1\\nλnλmynymk(xn,xm)\\nthoả mãn:\\nN∑\\nn=1\\nλnyn = 0\\n0 ≤λn ≤C, ∀n= 1,2,...,N\\n(28.5)\\nvà\\n∑\\nm∈S\\nλmymk(xm,x) + 1\\nNM\\n∑\\nn∈M\\n(\\nyn −\\n∑\\nm∈S\\nλmymk(xm,xn)\\n)\\n(28.6)\\nVí dụ:Xét phép biến đổi một điểm dữ liệu trong không gian hai chiềux = [x1,x2]T thành\\nmột điểm trong không gian 5 chiềuΦ(x) = [1,\\n√\\n2x1,\\n√\\n2x2,x2\\n1,\\n√\\n2x1x2,x2\\n2]T. Ta có:\\nΦ(x)TΦ(z) = [1,\\n√\\n2x1,\\n√\\n2x2,x2\\n1,\\n√\\n2x1x2,x2\\n2][1,\\n√\\n2z1,\\n√\\n2z2,z2\\n1,\\n√\\n2z1z2,z2\\n2]T (28.7)\\n= 1 + 2x1z1 + 2x2z2 + x2\\n1x2\\n2 + 2x1z1x2z2 + x2\\n2z2\\n2 (28.8)\\n= (1 + x1z1 + x2z2)2 = (1 + xTz)2 = k(x,z) (28.9)\\nTrong ví dụ này, rõ ràng rằng việc tính toán hàm kernelk(x,z) = (1 + xTz)2 cho hai điểm\\ndữ liệu dễ dàng hơn việc tính từngΦ(.) rồi nhân chúng với nhau. Hơn nữa, giá trị thu được\\nlà một số vô hướng thay vì phải lưu hai vector năm chiềuΦ(x),Φ(z).\\nVậy những hàm số kernel cần có những tính chất gì, và những hàm như thế nào được sử\\ndụng trong thực tế?\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 370, 'page_label': '359'}, page_content='359 CHƯƠNG 28. KERNEL SUPPORT VECTOR MACHINE\\n28.3 Hàm số kernel\\n28.3.1 Tính chất của các hàm kernel\\nKhông phải hàmk() bất kỳ nào cũng được sử dụng. Các hàm kernel cần có các tính chất:\\n• Đối xứng:k(x,z) = k(z,x), vì tích vô hướng của hai vector có tính đối xứng.\\n• Về lý thuyết, hàm kernel cần thỏa mãn điều kiện Mercer1:\\nN∑\\nn=1\\nN∑\\nm=1\\nk(xm,xn)cncm ≥0, ∀ci ∈R,i = 1,2,...,N (28.10)\\nVới mọi tập hữu hạn các vectorx1,..., xn. Tính chất này để đảm bảo cho việc hàm mục\\ntiêu của bài toán đối ngẫu (28.5) làlồi. Thật vậy, nếu một hàm kernel thỏa mãn điều\\nkiện (28.10), xétcn = ynλn, ta sẽ có:\\nλTKλ=\\nN∑\\nn=1\\nN∑\\nm=1\\nk(xm,xn)ynymλnλm ≥0, ∀λn (28.11)\\nvới K là một ma trận đối xứng mà phần tử ở hàng thứn cột thứ m của nó được định\\nnghĩa bởi knm = ynymk(xn,xm) Từ (28.11) ta suy raK là một ma trận nửa xác định\\ndương. Vì vậy, bài toán tối ưu (28.5) có ràng buộc là lồi và hàm mục tiêu là một hàm lồi\\n(một quadratic form). Vì vậy chúng ta có thể giải quyết bài toán này một cách hiệu quả.\\n• Trong thực hành, có một vài hàm sốk() không thỏa mãn điều kiện Merrcer nhưng vẫn\\ncho kết quả chấp nhận được. Những hàm số này vẫn được gọi là kernel. Trong bài viết\\nnày, chúng ta chỉ tập trung vào các hàm kernel thông dụng và có sẵn trong các thư viện.\\nViệc giải quyết bài toán (28.5) hoàn toàn tương tự như bài toán đối ngẫu của soft-margin\\nSVM, chúng ta sẽ không bàn tới trong chương này. Thay vào đó, các hàm kernel thông dụng\\nvà hiệu năng của chúng trong các bài toán thực tế sẽ được thảo luận. Việc này sẽ được thực\\nhiện thông qua các ví dụ và cách sử dụng thư viện sklearn.\\n28.3.2 Một số hàm kernel thông dụng\\nLinear\\nĐây là trường hợp đơn giản với kernel chính tích vô hướng của hai vector:k(x,z) = xTz.\\nHàm số này, như đã chứng minh trong Chương 26, thỏa mãn điều kiện (28.10).\\nKhi sử dụngsklearn.svm.SVC, kernel này được chọn bằng cách chọnkernel = ’linear’.\\n1 Xem Kernel method–Wikipedia(https://goo.gl/YXct7F )\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 371, 'page_label': '360'}, page_content='CHƯƠNG 28. KERNEL SUPPORT VECTOR MACHINE 360\\nPolynomial\\nHàm kernel của polynomial có dạng\\nk(x,z) = (r+ γxTz)d (28.12)\\nVới d là một số dương, là bậc của đa thức.d có thể không là số tự nhiên vì mục đích chính\\ncủa ta không phải là bậc của đa thức mà là cách tính kernel. Polynomial kernel có thể được\\ndùng để mô tả hầu hết các đa thức có bậc không vượt quád nếu d là một số tự nhiên.\\nKhi sử dụng thư việnsklearn, kernel này được chọn bằng cách đặtkernel = ’poly’. Bạn đọc\\nđược khuyến khích đọc tài liệu chính thức trong scikit-learn tạihttps://goo.gl/QvtFc9 .\\nRadial basic function\\nRadial basic function (RBF) kernel hay Gaussian kernel được sử dụng nhiều nhất trong thực\\ntế, và là lựa chọn mặc định trong sklearn. Nó được định nghĩa bởi\\nk(x,z) = exp(−γ∥x −z∥2\\n2), γ >0 (28.13)\\nTrongsklearn, kernel này được lựa chọn bằng cách đặtkernel = ’rbf’.\\nSigmoid\\nHàm dạng sigmoid cũng được sử dụng làm kernel, với\\nk(x,z) = tanh(γxTz + r) (28.14)\\nTrongsklearn, kernel này được lựa chọn bằngkernel = ’sigmoid’.\\nBảng tóm tắt các kernel thông dụng\\nBảng 28.2 tóm tắt các kernel thông dụng và cách sử dụng chúng trongsklearn.\\nBảng 28.2: Bảng các kernel thông dụng\\nTên kernel Công thức Thiết lập hệ số\\n’linear’ xT z không có hệ số\\n’poly’ (r+ γxT z)d d: degree, γ: gamma, r: coef0\\n’sigmoid’ tanh(γxT z + r) γ: gamma, r: coef0\\n’rbf’ exp(−γ&x −z&2\\n2) γ >0: gamma\\nNếu bạn muốn sử dụng các thư viện cho C/C++, các bạn có thể tham khảo LIBSVM\\n(https://goo.gl/Dt7o7r ) và LIBLINEAR (https://goo.gl/ctD7a3 ).\\nKernel tự định nghĩa\\nNgoài các hàm kernel thông dụng như trên, chúng ta cũng có thể tự định nghĩa các kernel\\ncủa mình như trong hướng dẫn tạihttps://goo.gl/A9ajzp .\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 372, 'page_label': '361'}, page_content='361 CHƯƠNG 28. KERNEL SUPPORT VECTOR MACHINE\\nsigmoid\\n(a) sigmoid kernel.\\npoly (b) poly kernel.\\nrbf (c) rbf kernel.\\nHình 28.2:Sử dụng kernel SVM để giải quyết bài toán XOR. (a) sigmoid kernel. (b) polynomial\\nkernel. (c) RBF kernel. Các đường nét liền là các đường phân lớp, ứng với giá trị của biểu thức\\n(28.6) bằng 0. Các đường nét đứt là các đường đồng mức ứng với giá trị của biểu thức(28.6)\\nbằng ±0.5. Trong ba phương pháp, RBF cho kết quả tốt nhất vì chúng cho kết quả đối xứng,\\nhợp lý với dữ liệu bài toán.\\n28.4 Ví dụ minh họa\\n28.4.1 Bài toán XOR\\nChúng ta cùng quay lại với bài toán XOR. Chúng ta biết rằng bài toán XOR không thể giải\\nquyết nếu chỉ dùng một bộ phân lớp tuyến tính. Chúng ta cùng giải quyết bài toán này bằng\\nSVM với các kernel khác nhau. Kết quả được minh hoạ trong Hình 28.2.\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\nfrom sklearn import svm\\n# XOR dataset and targets\\nX = np.array([[0, 0], [1, 1], [1, 0], [0, 1]])\\ny = np.array([0, 0, 1, 1])\\n# fit the model\\nfor kernel in (’sigmoid’, ’poly’, ’rbf’):\\nclf = svm.SVC(kernel=kernel, gamma=4, coef0 = 0)\\nclf.fit(X, y)\\nTa có các nhận xét đối với mỗi kernel như sau:\\n• sigmoid: nghiệm tìm được không thật tốt vì có ba trong bốn điểm nằm chính xác trên\\nđường phân chia. Nói cách khác, nghiệm này sẽ rấtnhạy cảm với nhiễu.\\n• poly: Nghiệm này có tốt hơn nghiệm củasigmoid nhưng kết quả có phầnoverfitting.\\n• rbf: Dữ liệu được tạo ra một cách đối xứng, đường phân lớp tìm được cũng tạo ra các\\nvùng đối xứng với mỗi lớp. Nghiệm này được cho làhợp lý hơn. Trên thực tế, cácrbf\\nkernel được sử dụng nhiều nhất và cũng là lựa chọn mặc định trong hàmsklearn.svm.SVC.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 373, 'page_label': '362'}, page_content='CHƯƠNG 28. KERNEL SUPPORT VECTOR MACHINE 362\\nsigmoid\\n(a) sigmoid kernel.\\npoly (b) poly kernel.\\nrbf (c) rbf kernel.\\nHình 28.3: Sử dụng kernel SVM để giải quyết bài toán với dữ liệugần phân biệt tuyến tính. a)\\nsigmoid kernel. b) polynomial kernel. c) RBF kernel. Các đường nét liền là các đường phân lớp,\\nứng với giá trị của biểu thức(6) bằng 0. Các đường nét đứt là các đường đồng mức ứng với giá\\ntrị của biểu thức(6) bằng ±0.5. Với bài toán này, polynomial kernel cho kết quả tốt hơn.\\n28.4.2 Dữ liệu gần linearly separable\\nXét một ví dụ khác với dữ liệu giữa hai lớp làgần linearly separablenhư Hình 28.3.\\nTrong ví dụ này,kernel = ’poly’ cho kết quả tốt hơnkernel = ’rbf’ vì trực quan cho ta thấy\\nrằng nửa bên phải của mặt phẳng nên hoàn thoàn thuộc vào class xanh.sigmoid kernel cho\\nkết quả không thực sự tốt và ít được sử dụng.\\n28.4.3 Kernel SVM cho MNIST\\nTiếp theo, chúng ta cùng làm một thí nghiệm nhỏ bằng cách áp dụng SVM với RBF kernel\\nvào bài toán phân loại 4 chữ số0, 1, 2, 3 của tập MNIST. Trước hết, chúng ta cần lấy ra\\ndữ liệu thuộc các chữ số này. Dữ liệu được chuẩn hoá về đoạn[0,1] bằng cách chia toàn bộ\\ncác thành phần cho 255 (giá trị cao nhất của mỗi pixel)\\nfrom __future__ import print_function\\nimport numpy as np\\nfrom sklearn import svm\\nfrom sklearn.datasets import fetch_mldata\\ndata_dir = ’../../data’ # path to your data folder\\nmnist = fetch_mldata(’MNIST original’, data_home=data_dir)\\nX_all = mnist.data/255. # data normalization\\ny_all = mnist.target\\ndigits = [0, 1, 2, 3]\\nids = []\\nfor d in digits:\\nids.append(np.where(y_all == d)[0])\\nselected_ids = np.concatenate(ids, axis = 0)\\nX = X_all[selected_ids]\\ny = y_all[selected_ids]\\nprint(’Number of samples = ’, X.shape[0])\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 374, 'page_label': '363'}, page_content='363 CHƯƠNG 28. KERNEL SUPPORT VECTOR MACHINE\\nKết quả:\\nNumber of samples = 28911\\nNhư vậy, có khoảng 29000 điểm dữ liệu tổng cộng. Chúng ta lấy ra 24000 điểm làm tập kiểm\\nthử, còn lại là tập huấn luyện. Bộ phân lớp kernel SVM với RBF sẽ được sử dụng.\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import accuracy_score\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 24000)\\nmodel = svm.SVC(kernel=’rbf’, gamma=.1, coef0 = 0)\\nmodel.fit(X_train, y_train)\\ny_pred = model.predict(X_test)\\nprint(\"Accuracy: %.2f %%\" %(100*accuracy_score(y_test, y_pred)))\\nKết quả:\\nAccuracy: 94.22 %\\nKết quả thu được là khoảng 94%. Nếu chọn nhiều điểm dữ liệu để huấn luyện và thay đổi\\ncác tham sốgamma, coef0, bạn đọc có thể sẽ thu được các kết quả tốt hơn. Đây là một bài\\ntoán multi-class classification, và cách giải quyết của thư viện này làone-vs-rest. Như đã đề\\ncập trong Chương 14,one-vs-rest có nhiều hạn chế vì phải huấn luyện nhiều bộ phân lớp.\\nHơn nữa, với kernel SVM, việc tính toán các kernel cũng trở nên phức tạp khi lượng dữ liệu\\nvà số chiều dữ liệu tăng lên.\\n28.5 Tóm tắt\\n• Trong bài toán phân lớp nhị phân, nếu dữ liệu của hai lớp làkhông linearly section, chúng\\nta có thể tìm cách biến đổi dữ liệu sang một không gian mới sao cho trong không gian\\nmới ấy, dữ liệu của hai lớp là(gần) linearly separable.\\n• Việc tính toán trực tiếp hàmΦ() đôi khi phức tạp và tốn nhiều bộ nhớ. Thay vào đó, ta\\ncó thể sử dụngkernel trick. Trong cách tiếp cận này, ta chỉ cần tính tích vô hướng của\\nhai vector bất kỳ trong không gian mới:k(x,z) = Φ(x)TΦ(z). Thông thường, các hàm\\nk(.,.) thỏa mãn điều kiện Merrcer, và được gọi làkernel. Cách giải bài toán SVM với\\nkernel hoàn toàn giống với cách giải bài toán soft-margin SVM.\\n• Có bốn loại kernel thông dụng:linear, poly, rbf, sigmoid. Trong đó,rbf được sử dụng\\nnhiều nhất và là lựa chọn mặc định trong các thư viện SVM.\\n• Source code cho chương này có thể được tìm thấy tạihttps://goo.gl/6sbds5 .\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 375, 'page_label': '364'}, page_content='Chương 29\\nMulti-class support vector machine\\n29.1 Giới thiệu\\n29.1.1 Từ Binary classification tới multi-class classification\\nCác phương pháp support vector machine đã đề cập (hard-margin, soft-margin, kernel) đều\\nđược xây dựng nhằm giải quyết bài toánbinary classification, tức bài toán phân lớp với chỉ\\nhai lớp dữ liệu (C = 2). Một cách tự nhiên để mở rộng các mô hình này áp dụng cho các bài\\ntoán multi-class classification, tức có nhiều lớp dữ liệu khác nhau (C >2), là sử dụng nhiều\\nbinary classifier và các kỹ thuật nhưone-vs-one hoặc one-vs-rest. Cách làm này có những\\nhạn chế như đã trình bày trong Chương 14.\\nSoftmax regression(xem Chương 15), là một phương pháp tổng quát củalogistic regression,\\nđược sử dụng phổ biến nhất trong các mô hình phân lớp hiện nay. Về cơ bản, thuật toán\\nhuấn luyện softmax regression đi tìm ma trận hệ sốW ∈Rd×C và vector biasb ∈RC sao\\ncho với một điểm dữ liệu được mô tả bởi một vector đặc trưngdchiều, vectorz = WTx + b\\ncó thành phần lớn nhất nằm ở chỉ số tương ứng với nhãn chính xác củax. Vectorz, còn\\nđược gọi làscore vector, tiếp tục được đưa qua hàmsoftmax để ước lượng xác suất để điểm\\ndữ liệux rơi vào mỗi lớp.\\nTrong chương này, chúng ta sẽ thảo luận một phương pháp phổ biến khác cũng được dùng\\ncho các bài toánmulti-class classification có tên làmulti-class SVM. Trong đó, ta cũng phải\\nđi tìm ma trận hệ sốW và vector biasb sao cho với một điểm dữ liệux, vectorWTx + b\\ncũng có thành phần cao nhất tại chỉ số tương ứng với nhãn củax. Tuy nhiên, hàm mất\\nmát để ép việc này xảy ra trên tập huấn luyện được xây dựng dựa trên hàmhingle loss\\n(của softmax regression làcross entropy loss). Thuật toán tối ưu hàm mất mát này của\\nmulti-class SVM cũng dựa trên gradient descent. Vàmult-class SVM cũng có thể được tích\\nhợp vào layer cuối cùng của các neural network để tạo ra một bộ phân lớp khá hiệu quả.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 376, 'page_label': '365'}, page_content='365 CHƯƠNG 29. MULTI-CLASS SUPPORT VECTOR MACHINE\\nHình 29.1: Ví dụ về các bức ảnh trong 10 lớp của bộ dữ liệu CIFAR10.\\nTrong chương này, chúng ta sẽ tìm hiểumulti-class SVM thông qua một ví dụ về bài toán\\nphân loại các bức ảnh thuộc 10 lớp khác nhau trong bộ cơ sở dữ liệu CIFAR10 (https:\\n//goo.gl/9KKbQu ).\\n29.1.2 Bộ cơ sở dữ liệu CIFAR10\\nBộ cơ sở dữ liệu CIFAR10 gồm 60000 ảnh khác nhau thuộc 10 lớp dữ liệu:plane, car, bird,\\ncat, deer, dog, frog, horse, ship, và truck. Mỗi bức ảnh có kích thước32×32 pixel. Một vài ví\\ndụ cho mỗi lớp được cho trong Hình 29.1. Tập huấn luyên bao gồm 50000 bức ảnh, tập kiểm\\nthử bao gồm 10000 ảnh còn lại. Trong số 50000 ảnh huấn luyện, 1000 ảnh sẽ được lấy ra ngẫu\\nnghiên để làm tập validation. Đây là một bộ cơ sở dữ liệu tương đối khó vì kích thước của\\ncác bức ảnh là nhỏ và các bức ảnh trong cùng một lớp biến đổi rất nhiều về màu sắc, hình\\ndáng, kích thước. Thuật toán tốt nhất hiện nay cho bài toán này đã đạt được độ chính xác\\ntrên 96% (https://goo.gl/w1sgK4 ), sử dụng mộtconvolutional neural networknhiều layer\\nkết hợp với softmax regression ở layer cuối cùng. Trong chương này, chúng ta sẽ sử dụng\\nmột mô hình neural network đơn giản không có hidden layer nào và layer cuối cùng là một\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 377, 'page_label': '366'}, page_content='CHƯƠNG 29. MULTI-CLASS SUPPORT VECTOR MACHINE 366\\nmulti-class SVM để giải quyết bài toán. Độ chính xác đạt được là khoảng 40%, nhưng cũng\\nlà đã rất ấn tượng. Chúng ta cùng phân tích multi-class SVM và lập trình mà không sử dụng\\nmột thư viện đặc biệt nào ngoài numpy. Bài toán này cũng như nội dung chính của chương\\nđược lấy từ Lecture notesLinear Classifier II – CS231n 2016(https://goo.gl/y3QsDP ) và\\nAssignment #1 – CS231n 2016(https://goo.gl/1Qh84b ).\\nTrước khi đi vào mục xây dựng và tối ưu hàm mất mát cho multi-class SVM, chúng ta cần\\nlàm một chútfeature engineeringđể tạo ra vector đặc trưng cho mỗi ảnh. Cách làm này có\\nthể được sử dụng kèm với các bộ phân lớp khác, không nhất thiết là chỉ multi-class SVM.\\n29.1.3 Xây dựng vector đặc trưng\\nChúng ta sẽ sử dụng phương phápfeature engineeringđơn giản nhất: lấy trực tiếp tất cả\\ncác pixel trong mỗi ảnh và thêm một chútchuẩn hoá dữ liệu(data normalization).\\n• Mỗi ảnhmàu của CIFAR-10 đã có kích thước giống nhau32 ×32 pixel, vì vậy việc đầu\\ntiên chúng ta cần làm làkéo dàimỗi trong ba channel Red, Green, Blue của bức ảnh ra\\nthành một vector có kích thước là3 ×32 ×32 = 3072.\\n• Vì mỗi pixel có giá trị là một số tự nhiên từ 0 đến 255 nên chúng ta cần một chút chuẩn\\nhóa dữ liệu. Trong Machine Learning, một cách đơn giản nhất để chuẩn hóa dữ liệu là\\ncenter data, tức làm cho mỗi feature có trung bình cộng bằng 0. Một cách đơn giản để\\nlàm việc này là ta tính trung bình cộng của tất cả các ảnh trong tập training để được\\nảnh trung bình, sau đó trừ từ tất cả các ảnh điảnh trung bìnhnày. Tương tự, ta cũng\\ndùng ảnh trung bìnhnày để chuẩn hoá dữ liệu trongvalidation set và test set.\\n29.1.4 Bias trick\\nThông thường, với một ma trận hệ sốW ∈Rd×C, một đầu vàox ∈Rd và vector bias\\nb ∈RC, chúng ta có thể tính được đầu ra của layer này là:\\nf(x,W,b) = WTx + b (29.1)\\nĐể cho biểu thức trên đơn giản hơn, ta có thể thêm một phần từ bằng 1 vào cuối củax và\\nghép vector b vào ma trậnW như ví dụ trong Hình 29.2. Bây giờ thì ta chỉ còn một biến\\ndữ liệu làW thay vì hai biến dữ liệu như trước. Từ giờ trở đi, khi viếtW và x, chúng ta\\nngầm hiểu là biến mới và dữ liệu mới như ở phần bên phải của Hình 29.2.\\nTiếp theo, chúng ta viết chương trình lấy dữ liệu từ tập CIFAR10, chuẩn hoá dữ liệu và\\nthêm đặc trưng bằng 1 vào cuối mỗi vector. Đồng thời, 1000 dữ liệu từ tập huấn luyện cũng\\nđược tách ra làm tập validation.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 378, 'page_label': '367'}, page_content='367 CHƯƠNG 29. MULTI-CLASS SUPPORT VECTOR MACHINE\\n0.3 1 -0.1 2\\n1.5 -2 0.7 -0.1\\n-0.3 0.1 -1.2 1.5\\nW T\\n×\\n-12\\n45\\n-50\\n120\\nx\\n+\\n-1.1\\n0.5\\n0.7\\nb\\n⇔\\n0.3 1 -0.1 2\\n1.5 -2 0.7 -0.1\\n-0.3 0.1 -1.2 1.5\\nW T\\n-1.1\\n0.5\\n0.7\\nb\\n×\\n-12\\n45\\n-50\\n120\\n1\\nNew W T\\nNew x\\nHình 29.2: Bias trick.\\nfrom __future__ import print_function\\nimport numpy as np\\n# need cs231 folder from https://goo.gl/cgJgcG\\nfrom cs231n.data_utils import load_CIFAR10\\n# Load CIFAR 10 dataset\\ncifar10_dir = ’cs231n/datasets/cifar-10-batches-py’\\nX_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\\n# Extract a validation from X_train\\nfrom sklearn.model_selection import train_test_split\\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size= 1000)\\n# mean image of all training images\\nimg_mean = np.mean(X_train, axis = 0)\\ndef feature_engineering(X):\\nX -= img_mean # zero-centered\\nN = X.shape[0] # number of data point\\nX = X.reshape(N, -1) # vectorizetion\\nreturn np.concatenate((X, np.ones((N, 1))), axis = 1) # bias trick\\nX_train = feature_engineering(X_train)\\nX_val = feature_engineering(X_val)\\nX_test = feature_engineering(X_test)\\nprint(’X_train shape = ’, X_train.shape)\\nprint(’X_val shape = ’, X_val.shape)\\nprint(’X_test shape = ’, X_test.shape)\\nKết quả:\\nX_train shape = (49000, 3073)\\nX_val shape = (1000, 3073)\\nX_test shape = (10000, 3073)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 379, 'page_label': '368'}, page_content='CHƯƠNG 29. MULTI-CLASS SUPPORT VECTOR MACHINE 368\\n.3 1 -0.1 2 -1.1\\n1.5 -2 0.7 -0.1 .05\\n-0.3 0.1 -1.2 1.5 0.7\\nW\\nT\\n×\\n-12\\n45\\n-50\\n120\\n1\\nx\\n=\\n285.3\\n-154.5\\n248.8\\nscore vector z\\ncat score\\nfrog score\\ndog score\\ninput image\\n(normalized) vectorization of input followed by 1\\nHình 29.3: Ví dụ về cách tính score vector. Khi test, nhãn của dữ liệu được xác định dựa trên\\nclass có score cao nhất.\\n29.2 Xây dựng hàm mất mát\\n29.2.1 Hinge losss tổng quát cho multi-class SVM\\nTrong multi-class SVM, khi kiểm thử, nhãn của một điểm dữ liệu mới được xác định bởi\\nthành phần có giá trị lớn nhất trong score vectorz = WTx (xem Hình 29.3). Điều này giống\\nvới softmax regression. Softmax regression sử dụngcross-entropy lossđể ép hai vector xác\\nsuất bằng nhau, tức ép phần tử tương ứng vớinhãn đúng (correct class) trong vector xác\\nsuất gần với 1, đồng thời khiến các phần tử còn lại trong vector đó gần với 0. Nói cách khác,\\ncách làm này khiến cho phần tử tương ứng vớicorrect classcàng lớn hơn các phần tử còn\\nlại càng tốt. Trong khi đó, multi-class SVM sử dụng mộtchiến thuật khác cho mục đích\\ntương tự dựa trênscore vector. Điểm khác biệt là multi-class SVM xây dựng hàm mất mát\\ndựa trên định nghĩa củabiên an toàn, giống như trong hard/soft-margin SVM với hai lớp\\ndữ liệu. Multi-class SVMép thành phần ứng vớicorrect classcủa score vectorlớn hơn các\\nphần tử khác, không những thế, nó còn lớn hơn một đại lượng∆ >0 gọi làbiên an toàn,\\nnhư được mô tả trong Hình 29.4.\\nNếu score tương ứng vớicorrect classlớn hơn các score khác một khoảng bằng mộtbiên an\\ntoàn ∆thì không có mất mát nào xảy ra, tức sự mất mát bằng 0. Nói cách khác, những score\\nnằm ở bên trái điểm×màu đỏ không gây ra mất mát nào. Ngược lại, các điểm có score\\nnằm phía phải của điểm×sẽ bịxử phạt, và càng vi phạm nhiều sẽ bị xử lý ở mức càng cao.\\nĐể mô tả các mức vi phạm này dưới dạng toán học, trước hết ta giả sử rằng các thành\\nphần của score vector được đánh số thứ tự từ 1. Các lớp dữ liệu cũng được đánh số thứ tự\\ntừ 1. Giả sử rằng điểm dữ liệux đang xét thuộc classy và score vector của nó là vector\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 380, 'page_label': '369'}, page_content='369 CHƯƠNG 29. MULTI-CLASS SUPPORT VECTOR MACHINE\\nscorez i\\nz y\\nz jscores for other classes scores for the correct class\\nmargin =∆\\n×\\nlevel of violation\\nHình 29.4:Mô tả hinge loss trong multi-class SVM. Multi-class SVMép score củacorrect class,\\nđược minh hoạ bởi điểm màu lam, cao hơn các score khác, minh hoạ bởi các điểm màu lục, một\\nkhoảng cách an toàn∆ là đoạn màu đỏ. Những score khác nằm trong vùng an toàn (phía trái\\ncủa điểm x màu đỏ) sẽ không gây ra mất mát gì, những scores nằm trong hoặc bên phải vùng\\nmàu đỏ đãvi phạmquy tắc và cần đượcxử phạt.\\nz = WTx. Như vậy, score củacorrect classlà zy, score của các lớp khác là cáczi,i ̸= y.\\nTrong Hình 29.4, các scorezi nằm trong vùng an toàn vàzj trong vùng vi phạm. Với mỗi\\nscore zi trong vùng an toàn,loss bằng 0. Với mỗi socrezj vượt quá điểm an toàn (điểm×),\\nloss do nó gây ra được tính bằng lượng vượt quá so với điểm×đó, đại lượng này có thể\\ntính được làzj −(zy −∆) =∆−zy + zj.\\nTóm lại, với một scorezj,j ̸= y, loss do nó gây ra có thể được viết gọn thành\\nmax(0,∆ −zy + zj) = max(0,∆ −wT\\nyx + wT\\nj x) (29.2)\\ntrong đó wj là cột thứ j của ma trận hệ sốW. Như vậy, với một điểm dữ liệuxn,n =\\n1,2,...,N vỡi nhãnyn, tổng cộngloss do nó gây ra là\\nLn =\\n∑\\nj̸=yn\\nmax(0,∆ −zn\\nyn + zn\\nj)\\nvới zn = WTxn = [zn\\n1 ,zn\\n2 ,...,z n\\nC]T ∈RC×1 là score vector tương ứng với điểm dữ liệuxn.\\nVới toàn bộ các điểm dữ liệuX = [x1,x2,..., xN], loss được định nghĩa là\\nL(X,y,W) =1\\nN\\nN∑\\nn=1\\n∑\\nj̸=yn\\nmax(0,∆ −zn\\nyn + zn\\nj) (29.3)\\nvới y = [y1,y2,...,y N] là vector chứacorect classcủa toàn bộ các điểm trong training set.\\n29.2.2 Regularization\\nĐiều gì sẽ xảy ra nếu nghiệm tìm đượcW là một nghiệmhoàn hảo, tức không có score nào\\nvi phạm và hàm mất mát (29.3) đạt giá trị bằng 0? Nói cách khác,\\n∆−zn\\nyn + zn\\nj ≤0 ⇔∆≤wT\\nynxn −wT\\nj xn ∀n= 1,2,...,N ;j = 1,2,...,C ;j ̸= yn\\nĐiều này có nghĩa làkW cũng là một nghiệm của bài toán vớik >1 bất kỳ. Việc bài toán\\ncó vô số nghiệm và có những nghiệm có những phần tử tiến tới vô cùng khiến cho bài toán\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 381, 'page_label': '370'}, page_content='CHƯƠNG 29. MULTI-CLASS SUPPORT VECTOR MACHINE 370\\nrất không ổn đinh(unstable) khi tối ưu. Một phương pháp quen thuộc để tránh hiện tượng\\nnày là cộng thêm số hạngregularization vào hàm mất mát. Số hạng này giúpngăn chặnviệc\\ncác hệ số củaW trở nên quá lớn. Và để cho hàm mất mát vẫn có đạo hàm đơn giản, chúng\\nta lại sử dụngl2 regularization\\nL(X,y,W) = 1\\nN\\nN∑\\nn=1\\n∑\\nj̸=yn\\nmax(0,∆ −wT\\nynxn + wT\\nj xn)\\n\\ued19 \\ued18\\ued17 \\ued1a\\ndata loss\\n+ λ\\n2 ∥W∥2\\nF\\n\\ued19 \\ued18\\ued17 \\ued1a\\nregularization loss\\n(29.4)\\nvới λ là một giá trị dương giúp cân bằng giữadata loss và regularization loss, thường được\\nchọn bằng cross-validation.\\n29.2.3 Hàm mất mát của multi-class SVM\\nCó haihyperparametertrong hàm mất mát (29.4) là∆vàλ, câu hỏi đặt ra là làm thế nào để\\nchọn ra cặp giá trị hợp lý nhất cho từng bài toán. Liệu chúng ta có cần làm cross-validation\\ncho từng giá trị không? Trên thực tế, người ta nhận thấy rằng∆ có thể được chọn bằng\\n1 mà không ảnh hưởng nhiều tới chất lượng của nghiệm (https://goo.gl/NSyfQi ). Từ đó,\\nhàm mất mát cuối cùng cho multi-class SVM có dạng\\nL(X,y,W) = 1\\nN\\nN∑\\nn=1\\n∑\\nj̸=yn\\nmax(0,1 −wT\\nynxn + wT\\nj xn) + λ\\n2 ∥W∥2\\nF (29.5)\\nMột lần nữa, chúng ta có thể dùng gradient descent để tìm nghiệm cho bài toán tối ưu không\\nràng buộc này. Việc này sẽ được thảo luận kỹ trong Mục 29.3.\\n29.2.4 Soft-margin SVM là một trường hợp đặc biệt của multi-class SVM\\nĐiều này có thể được nhận ra bằng cách xét từng điểm dữ liệu. Trong (29.5), nếu số lớp dữ\\nliệu C = 2, tạm bỏ quaregularization loss, hàm mất mát tại mỗi điểm dữ liệu trở thành\\nLn =\\n∑\\nj̸=yn\\nmax(0,1 −wT\\nynxn + wT\\nj xn) (29.6)\\nXét hai trường hợp:\\n• yn = 1 ⇒Ln = max(0,1 −wT\\n1 xn + wT\\n2 xn) = max(0,1 −(1)(w1 −w2)Tx)\\n• yn = 2 ⇒Ln = max(0,1 −wT\\n2 xn + wT\\n1 xn) = max(0,1 −(−1)(w1 −w2)Tx)\\nNếu ta thayyn = −1 cho dữ liệu thuộc lớp có nhãn bằng 2, và đặt¯ w= w1 −w2, hai trường\\nhợp trên có thể được viết gọn thành\\nLn = max(0,1 −yn¯ wTxn)\\nĐây chính là hinge loss cho soft-margin SVM.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 382, 'page_label': '371'}, page_content='371 CHƯƠNG 29. MULTI-CLASS SUPPORT VECTOR MACHINE\\n29.3 Tính toán hàm mất mát và đạo hàm của nó\\nVì hàm mất mát của multi-class SVMhơi phức tạp một chút, đạo hàm của nó theoW cũng\\nkhó có thể được suy ra dễ dàng. Chúng ta cần kiểm tra liệu đạo hàm tính được có thực\\nsự chính xác không trước khi thực hiện gradient desenct. Phương pháp quen thuộc được sử\\ndụng là tínhnumerical gradient descent. Để thực hiện phương pháp này, chúng ta cũng cần\\ntính giá trị của hàm mất mát tại một điểmW bất kỳ.\\nViệc tính toán giá trị của hàm mất mát và đạo hàm của nó tạiW bất kỳ không những cần\\nsự chính xác mà còn cần được thực hiện một cách hiệu quả. Để đạt được việc này, chúng ta\\nsẽ làm từng bước một. Bước thứ nhất là đảm bảo rằng các tính toán làchính xác, dù cách\\ntính có thể rất chậm. Bước thứ hai, ta phải đảm bảo có một cách tínhhiệu quả để thuật\\ntoán chạy nhanh hơn. Hai bước này nên được thực hiện trên một lượng dữ liệu nhỏ để có\\nthể nhanh chóng thấy được kết quả. Việc tínhnumerical gradient trên dữ liệu lớn thường\\ntốn rất nhiều thời gian. Các quy tắc này cũng được áp dụng với các bài toán tối ưu khác có\\nsử dụng đạo hàm trong quá trình tìm nghiệm.\\nHai mục tiếp theo sẽ mô tả hai bước đã nêu ở trên.\\n29.3.1 Tính hàm mất mát và đạo hàm một cách chính xác\\nDưới đây là cách tính đơn giản cho hàm mất mát và đạo hàm trong (29.5) với hai vòngfor.\\nChú ý thành phầnregularization.\\ndef svm_loss_naive(W, X, y, reg):\\n’’’ calculate loss and gradient of the loss function at W. Naive way\\nW: 2d numpy array of shape (d, C). The weight matrix.\\nX: 2d numpy array of shape (N, d). The training data\\ny: 1d numpy array of shape (N,). The training label\\nreg: a positive number. The regularization parameter\\n’’’\\nd, C, N = W.shape, X.shape[0] # data dim, number of classes, number of points\\nloss = 0\\ndW = np.zeros_like(W)\\nfor n in xrange(N):\\nxn = X[n]\\nscore = xn.dot(W)\\nfor j in xrange(C):\\nif j == y[n]:\\ncontinue\\nmargin = 1 - score[y[n]] + score[j]\\nif margin > 0:\\nloss += margin\\ndW[:, j] += xn\\ndW[:, y[n]] -= xn\\nloss /= N\\nloss += 0.5*reg*np.sum(W * W)\\ndW /= N\\ndW += reg*W\\nreturn loss, dW ## continue on next page\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 383, 'page_label': '372'}, page_content='CHƯƠNG 29. MULTI-CLASS SUPPORT VECTOR MACHINE 372\\n# random, small data\\nd, C, N = 100, 3, 300\\nreg = .1\\nW_rand = np.random.randn(d, C)\\nX_rand = np.random.randn(N, d)\\ny_rand = np.random.randint(0, C, N)\\n# sanity check\\nprint(’Loss with reg = 0 :’, svm_loss_naive(W_rand, X_rand, y_rand, 0)[0])\\nprint(’Loss with reg = 0.1:’,svm_loss_naive(W_rand, X_rand, y_rand, .1)[0])\\nKết quả:\\nLoss with reg = 0 : 12.5026818221\\nLoss with reg = 0.1: 27.7805360552\\nCách tính với hai vòngfor lồng nhau như trên mô tả lại chính xác biểu thức (29.5) nên sai\\nsót, nếu có, có thể được kiểm tra và sửa lại dễ dàng. Việc kiểm tra ở cuối cho cái nhìn ban\\nđầu về hàm mất mát: dương và không córegularization sẽ cóloss tổng cộng nhỏ hơn.\\nCách tính đạo hàm cho phầndata loss phía trên dựa trên nhận xét sau đây:\\n∇wyn max(0,1 −wT\\nynxn + wT\\nj xn) =\\n{ 0 nếu 1 −wT\\nynxn + wT\\nj xn <0\\n−xn nếu 1 −wT\\nynxn + wT\\nj xn >0 (29.7)\\n∇wj max(0,1 −wT\\nj xn + wT\\nj xn) =\\n{ 0 nếu 1 −wT\\nynxn + wT\\nj xn <0\\nxn nếu 1 −wT\\nynxn + wT\\nj xn >0 (29.8)\\nRõ ràng là các đạo hàm này không xác định tại các điểm mà1 −wT\\nynxn + wT\\nj xn = 0. Tuy\\nnhiên, khi thực hành, ta có thể giả sử rằng tại 0, các đạo hàm này cũng bằng 0.\\nĐể kiểm tra lại cách tính đạo hàm như trên dựa vào (29.7) và (29.8) có chính xác không,\\nchúng ta cần làm một bước quen thuộc là so sánh nó vớinumerical gradient. Nếu sự sai\\nkhác là nhỏ, nhỏ hơn1e−7 thì ta có thể coi làgradient tính được là chính xác. Bạn đọc có\\nthế tự coi đây như một bài tập nhỏ.\\nKhi sự khác nhau giữa hai cách tính đạo hàm là nhỏ, chúng ta có thể yên tâm khi nói rằng\\ncách tínhgradient đã thỏa mãn sựchính xác, chúng ta cần tính nó một cáchhiệu quả nữa.\\n29.3.2 Tính hàm mất mát và đạo hàm một cách hiệu quả\\nCác cách tính hiệu quả thường không chứa các vòngfor mà được viết gọn lại dưới dạng ma\\ntrận và vector (vectorization). Để dễ hình dung, chúng ta cùng quan sát Hình 29.5. Ở đây,\\nchúng ta tạm quên phầnregularization lossđi vì cảloss và đạo hàm của phần này đều có\\ncách tính đơn giản. Với phầndata loss, chúng ta cũng bỏ qua hệ số1\\nN.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 384, 'page_label': '373'}, page_content='373 CHƯƠNG 29. MULTI-CLASS SUPPORT VECTOR MACHINE\\n\\uf8ee\\n\\uf8ef\\n\\uf8ef\\n\\uf8f0\\nw T\\n1\\nw T\\n2\\nw T\\n3\\nw T\\n4\\n\\uf8f9\\n\\uf8fa\\n\\uf8fa\\n\\uf8fb\\n[\\nx 1 x 2 x 3\\n]\\n=\\ny = [1 , 3 , 2]\\n2\\n1.5\\n-0.2\\n1.7\\n0.1\\n1.5\\n2.5\\n1.8\\n-0.2\\n2.5\\n3.0\\n1.0\\nZ = WT X max(0, 1 −zn\\nyn + zn\\nj )\\n0\\n0.5\\n0\\n0.7\\n0\\n0\\n0\\n0.3\\n0\\n0\\n1.5\\n0\\nLdata = 0 .5 + 0.7 + 0.3 + 1.5 = 3 .0\\n-2\\n1\\n0\\n1\\n0\\n0\\n-1\\n1\\n0\\n-1\\n1\\n0\\n→\\n∂ L data\\n∂ w 1\\n= −2 x 1\\n→\\n∂ L data\\n∂ w 2\\n= x 1 − x 3\\n→\\n∂ L data\\n∂ w 3\\n= −x 2 + x 3\\n→\\n∂ L data\\n∂ w 4\\n= x 1 + x 2\\nHình 29.5: Mô phỏng cách tính giá trị và đạo hàm của hàm mất mát trong multi-class SVM.\\nGiả sử rằng có bốn lớp dữ liệu và mini-batchX gồm có ba điểm dữ liệuX =\\n[\\nx1 x2 x3\\n]\\n. Ba\\nđiểm này lần lượt thuộc vào các lớp 1, 3, 2 (vectory). Các ô có nền màu đỏ nhạt ở mỗi cột\\ntương ứng vớicorrect classcủa điểm dữ liệu của cột đó. Các bước tínhloss và gradient có\\nthể được hình dung như sau:\\n• Bước 1:Tính score matrixZ = WTX.\\n• Bước 2:Với mỗi ô, tínhmax(0,1 −wT\\nynxn+ wT\\nj xn). Chú ý rằng ta không cần tính các ô\\ncó nền màu đỏ nhạt và có thể coi chúng bằng 0 vì biểu thứcdata losskhông chứa thành\\nphần j = yn. Sau khi tính được giá trị của từng ô, ta chỉ quan tâm tới các ô có giá trị\\nlớn hơn 0 - là các ô được tô nền màu xanh lục. Lấy tổng của tất cả các phần tử ở các ô\\nxanh lục, ta sẽ đượcdata loss. Ví dụ, nhìn vào ma trận màu ở giữa, giá trị ở hàng thứ\\nhai, cột thứ nhất bằng bằngmax(0,1 −2 + 1.5) = max(0,.5) =.5. Giá trị ở hàng thứ ba,\\ncột thứ nhất bằngmax(0,1 −2 + (−0.2)) = max(0,−1.2) = 0. Giá trị ở hàng thứ tư, cột\\nthứ nhất bằngmax(0,1 −2 + 1.7) = 0.7. Tương tự như thế với các cột còn lại.\\n• Bước 3:Theo công thức (29.7) và (29.8), với ô màu lục ở hàng thứ hai, cột thứ nhất\\n(ứng với điểm dữ liệux1), đạo hàm theo vector hệ sốw2 sẽ được cộng thêm một lượng\\nx1 và đạo hàm theo vector hệ sốw1 sẽ bị trừ đi một lượngx1. Như vậy, trong cột thứ\\nnhất, có bao nhiêu ô màu lục thì có bấy nhiêu lần đạo hàm củaw1 bị trừ đi một lượng\\nx1. Xét ma trận màu bên phải, giá trị ở ô trong hàng thứi, cột thứj là hệ số của đạo\\nhàm theowi gây ra bởi điểm dữ liệuxj. Tất cả các ô màu lục đều có giá trị bằng 1. Ô\\nmàu đỏ ở cột thứ nhất phải bằng -2 vì cột đó có hai ô màu lục. Tương tự với các ô màu\\nlục và đỏ còn lại.\\n• Bước 4:Bây giờ cộng theo các hàng, ta sẽ được đạo hàm theo hệ số của lớp tương ứng.\\nTrong đoạn code dưới đây,correct_class_score chính là tập hợp các giá trị trong các ô màu\\nđỏ ở khối thứ nhất.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 385, 'page_label': '374'}, page_content='CHƯƠNG 29. MULTI-CLASS SUPPORT VECTOR MACHINE 374\\n# more efficient way to compute loss and grad\\ndef svm_loss_vectorized(W, X, y, reg):\\nd, C = W.shape\\nN = X.shape[0]\\nloss = 0\\ndW = np.zeros_like(W)\\nZ = X.dot(W) # shape of (N, C)\\nid0 = np.arange(Z.shape[0])\\ncorrect_class_score = Z[id0, y].reshape(N, 1) # shape of (N, 1)\\nmargins = np.maximum(0, Z - correct_class_score + 1) # shape of (N, C)\\nmargins[id0, y] = 0\\nloss = np.sum(margins)\\nloss /= N\\nloss += 0.5 * reg * np.sum(W * W)\\nF = (margins > 0).astype(int)# shape of (N, C)\\nF[np.arange(F.shape[0]), y] = np.sum(-F, axis = 1)\\ndW = X.T.dot(F)/N + reg*W\\nreturn loss, dW\\nĐoạn code phía trên không chứa vòngfor nào. Để kiểm tra tính chính xác và hiệu quả của\\nhàm này, chúng ta cần kiểm chứng ba điều. (i) Giá trị hàm mất mát đã chính xác chưa. (ii)\\nGiá trị đạo hàm đã chính xác chưa. (iii) Cách tính đã thực sự hiệu quả chưa. Ba điều này\\ncó thể được kiểm chứng thông qua đoạn code dưới đây.\\nd, C = 3073, 10\\nW_rand = np.random.randn(d, C)\\nimport time\\nt1 = time.time()\\nl1, dW1 = svm_loss_naive(W_rand, X_train, y_train, reg)\\nt2 = time.time()\\nl2, dW2 = svm_loss_vectorized(W_rand, X_train, y_train, reg)\\nt3 = time.time()\\nprint(’Naive -- run time:’, t2 - t1, ’(s)’)\\nprint(’Vectorized -- run time:’, t3 - t2, ’(s)’)\\nprint(’loss difference:’, np.linalg.norm(l1 - l2))\\nprint(’gradient difference:’, np.linalg.norm(dW1 - dW2))\\nKết quả:\\nNaive -- run time: 7.34640693665 (s)\\nVectorized -- run time: 0.365024089813 (s)\\nloss difference: 8.73114913702e-11\\ngradient difference: 1.87942037251e-10\\nKết quả cho thấy cách tínhvectorization nhanh hơn so với cách tínhnaive khoảng 20 lần.\\nHơn nữa, sự chênh lệch giữa kết quả của hai cách tính là rất nhỏ, đều nhỏ hơn1e−10; ta có\\nthể sử dụng cách tínhvectorization để cập nhật nghiệm sử dụng mini-batch gradient descent.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 386, 'page_label': '375'}, page_content='375 CHƯƠNG 29. MULTI-CLASS SUPPORT VECTOR MACHINE\\n29.3.3 Mini-batch gradient descent cho multi-class SVM\\nVới các hàm đã viết, chúng ta có thể thực hiện việc huấn luyện multi-class SVM bằng đoạn\\ncode dưới đây.\\n# Mini-batch gradient descent\\ndef multiclass_svm_GD(X, y, Winit, reg, lr=.1, \\\\\\nbatch_size = 1000, num_iters = 50, print_every = 10):\\nW = Winit\\nloss_history = []\\nfor it in xrange(num_iters):\\nmix_ids = np.random.permutation(X.shape[0])\\nn_batches = int(np.ceil(X.shape[0]/float(batch_size)))\\nfor ib in range(n_batches):\\nids = mix_ids[batch_size*ib: min(batch_size*(ib+1), X.shape[0])]\\nX_batch = X[ids]\\ny_batch = y[ids]\\nlossib, dW = svm_loss_vectorized(W, X_batch, y_batch, reg)\\nloss_history.append(lossib)\\nW -= lr*dW\\nif it % print_every == 0 and it > 0:\\nprint(’it %d/%d, loss = %f’ %(it, num_iters, loss_history[it]))\\nreturn W, loss_history\\nd, C = X_train.shape[1], 10\\nreg = .1\\nW = 0.00001*np.random.randn(d, C)\\nW, loss_history = multiclass_svm_GD(X_train, y_train, W, reg, lr = 1e-8, num_iters =\\n50, print_every = 5)\\nKết quả:\\nepoch 5/50, loss = 5.482782\\nepoch 10/50, loss = 5.204365\\nepoch 15/50, loss = 4.885159\\nepoch 20/50, loss = 5.051539\\nepoch 25/50, loss = 5.060423\\nepoch 30/50, loss = 4.691241\\nepoch 35/50, loss = 4.841132\\nepoch 40/50, loss = 4.643097\\nepoch 45/50, loss = 4.691177\\nTa thấy rằng giá trịloss có xu hướng giảm và hội tụ. Giá trị này sau mỗi vòng lặp được\\nminh hoạ trong Hình 29.6.\\nSau khi đã tìm được ma trận hệ sốW đại diện cho mô hình multi-class SVM, chúng ta cần\\nviết các hàm xác định nhãn của các điểm dữ liệu mới và đánh giá độ chính xác của mô hình\\nnhư dưới đây:\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 387, 'page_label': '376'}, page_content='CHƯƠNG 29. MULTI-CLASS SUPPORT VECTOR MACHINE 376\\n0 500 1000 1500 2000 2500\\nnumber of iterations\\n4\\n5\\n6\\n7\\n8\\n9loss function\\nHình 29.6: Lịch sử lossqua\\ncác vòng lặp. Ta thấy rằng\\nloss có xu hướng giảm và hội\\ntụ khá nhanh.\\ndef multisvm_predict(W, X):\\nZ = X.dot(W)\\nreturn np.argmax(Z, axis=1)\\ndef evaluate(W, X, y):\\ny_pred = multisvm_predict(W, X)\\nacc = 100*np.mean(y_pred == y)\\nreturn acc\\nViệc tiếp theo là sử dụng tập validation để chọn ra các bộ tham số mô hình phù hợp. Có hai\\ntham số trong thuật toán tối ưu multi-class SVM:regularization và learning rate. Hai tham\\nsố này sẽ được tìm dựa trên các cặp giá trị cho trước. Bộ giá trị khiến cho độ chính xác của\\nmô hình trên tập validation cao nhất sẽ được dùng để đánh giá tập kiểm thử.\\nlrs = [1e-9, 1e-8, 1e-7, 1e-6]\\nregs = [0.1, 0.01, 0.001, 0.0001]\\nbest_W = 0\\nbest_acc = 0\\nfor lr in lrs:\\nfor reg in regs:\\nW, loss_history = multiclass_svm_GD(X_train, y_train, W, reg, \\\\\\nlr = 1e-8, num_iters = 100, print_every = 1e20)\\nacc = evaluate(W, X_val, y_val)\\nprint(’lr = %e, reg = %e, loss = %f, validation acc = %.2f’ %(lr, reg,\\nloss_history[-1], acc))\\nif acc > best_acc:\\nbest_acc = acc\\nbest_W = W\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 388, 'page_label': '377'}, page_content='377 CHƯƠNG 29. MULTI-CLASS SUPPORT VECTOR MACHINE\\nKết quả:\\nlr = 1.000000e-09, reg = 1.000000e-01, loss = 4.422479, validation acc = 40.30\\nlr = 1.000000e-09, reg = 1.000000e-02, loss = 4.474095, validation acc = 40.70\\nlr = 1.000000e-09, reg = 1.000000e-03, loss = 4.240144, validation acc = 40.90\\nlr = 1.000000e-09, reg = 1.000000e-04, loss = 4.257436, validation acc = 41.40\\nlr = 1.000000e-08, reg = 1.000000e-01, loss = 4.482856, validation acc = 41.50\\nlr = 1.000000e-08, reg = 1.000000e-02, loss = 4.036566, validation acc = 41.40\\nlr = 1.000000e-08, reg = 1.000000e-03, loss = 4.085053, validation acc = 41.00\\nlr = 1.000000e-08, reg = 1.000000e-04, loss = 3.891934, validation acc = 41.40\\nlr = 1.000000e-07, reg = 1.000000e-01, loss = 3.947408, validation acc = 41.50\\nlr = 1.000000e-07, reg = 1.000000e-02, loss = 4.088984, validation acc = 41.90\\nlr = 1.000000e-07, reg = 1.000000e-03, loss = 4.073365, validation acc = 41.70\\nlr = 1.000000e-07, reg = 1.000000e-04, loss = 4.006863, validation acc = 41.80\\nlr = 1.000000e-06, reg = 1.000000e-01, loss = 3.851727, validation acc = 41.90\\nlr = 1.000000e-06, reg = 1.000000e-02, loss = 3.941015, validation acc = 41.80\\nlr = 1.000000e-06, reg = 1.000000e-03, loss = 3.995598, validation acc = 41.60\\nlr = 1.000000e-06, reg = 1.000000e-04, loss = 3.857822, validation acc = 41.80\\nNhư vậy, độ chính xác cao nhất cho tập validation là 41.9%. Ma trận hệ sốW tốt nhất đã\\nđược lưu trong biếnbest_W. Áp dụng mô hình này lên tập kiểm thử:\\nacc = evaluate(best_W, X_test, y_test)\\nprint(’Accuracy on test data = %2f %%’%acc)\\nKết quả:\\nAccuracy on test data = 39.88 %\\nNhư vậy, kết quả đạt được rơi vào khoảng gần 40 %. Bạn đọc có thể thử với các bộ tham số\\nkhác và có thể đạt được kết quả tốt hơn một vài phần trăm.\\n29.3.4 Minh họa nghiệm tìm được\\nĐể ý rằng mỗiwi có chiều giống như chiều của dữ liệu. Bằng cách bỏ ra các hệ số tương\\nứng với bias vàsắp xếp lại các điểm của mỗi trong 10 vector hệ số tìm được, chúng ta sẽ\\nthu được cácbức ảnh cũng có kích thước3 ×32 ×32 như mỗi ảnh nhỏ trong cơ sở dữ liệu.\\nHình 29.7 mô tả hệ số tìm được của mỗiwi.\\nTa thấy rằng hệ số tương ứng với mỗi lớp mô tả hình dạng khá giống với các bức ảnh trong\\nlớp tương ứng, ví dụ nhưcar và truck trông khá giống với các bức ảnh trong lớpcar và\\ntruck. Hệ số củaship vàplane có mang màu xanh của nước biển và bầu trời. Trong khihorse\\ntrông giống như một con ngựa hai đầu; điều này dễ hiểu vì trong tập training, các con ngựa\\ncó thể quay đầu về hai phía. Có thể nói theo một cách khác rằng các hệ số tìm được được\\ncoi như là cácảnh đại diệncho mỗi lớp. Vì sao chúng ta có thể nói như vậy?\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 389, 'page_label': '378'}, page_content='CHƯƠNG 29. MULTI-CLASS SUPPORT VECTOR MACHINE 378\\nHình 29.7: Minh họa hệ số tìm được dưới dạng các bức ảnh.\\nCùng xem lại cách xác định class cho một dữ liệu mới được thực hiện bằng cách tìm vị trí\\ncủa giá trị lớn nhất trongscore vectorWTx, tức\\nclass(x) = arg max\\ni=1,2,...,C\\nwT\\ni x\\nĐể ý rằng tích vô hướng chính là đại lượng đo sự tương quan giữa hai vector. Đại lượng này\\ncàng lớn thì sự tương quan càng cao, tức hai vector càng giống nhau. Như vậy, việc đi tìm\\nnhãn của một bức ảnh mới chính là việc đi tìm bức ảnh đó gần với bức ảnhđại diện cho\\nlớp nào nhất. Việc này khá giống với K-nearest neighbors, nhưng thay vì thực hiện KNN\\ntrên toàn bộ training data, chúng ta chỉ thực hiện trên 10bức ảnh đại diện tìm được bằng\\nmulti-class SVM. Lập luận này cũng được áp dụng với softmax regression.\\n29.4 Thảo luận\\n• Giống như softmax regression, multi-class SVM vẫn được coi là một bộ phân lớp tuyến\\ntính vì đường ranh giới giữa các lớp là các đường tuyến tính.\\n• Kernel SVM cũng hoạt động khá tốt, nhưng việc tính toán ma trận kernel có thể tốn nhiều\\nthời gian và bộ nhớ. Hơn nữa, việc mở rộng nó ra cho bài toán multi-class classification\\nthường không hiệu quả bằng multi-class SVM vì kỹ thuật được sử dụng vẫn là one-vs-rest.\\nMột ưu điểm nữa của multi-class SVM là nó có thể được tối ưu bằng các phương pháp\\ngradient descent, phù hợp với các bài toán với dữ liệu lớn. Việc đường ranh giới giữa các\\nlớp là tuyến tính có thể được giải quyết bằng cách kết hợp nó với các deep neurel network.\\n• Có một cách nữa mở rộnghinge loss cho bài toán multi-class classification là dùngloss:\\nmax(0,1 −wT\\nynxn + maxj̸=yn wT\\nj xn). Đây chính làvi phạm lớn nhất, so vớitổng vi pham\\nmà chúng ta sử dụng trong bài này.\\n• Trên thực tế, multi-class SVM và softmax regression có hiệu quả tương đương nhau (xem\\nhttps://goo.gl/xLccj3 ). Có thể trong một bài toán cụ thể, phương pháp này tốt hơn\\nphương pháp kia, nhưng điều ngược lại xảy ra trong các bài toán khác. Khi thực hành,\\nnếu có thể, ta có thể thử cả hai phương pháp rồi chọn phương pháp cho kết quả tốt hơn.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 390, 'page_label': '379'}, page_content='Phụ lục A\\nPhương pháp nhân tử Lagrange\\nViệc tối thiểu (tối đa) một hàm số một biến liên tục, khả vi, với tập xác định là một tập\\nmở1 thường được thực hiện dựa trên việc giải phương trình đạo hàm của hàm số đó. Gọi\\nhàm số đó làf(x) : R →R, giá trị nhỏ nhất hoặc lớn nhất nếu có của nó thường được tìm\\nbằng cách giải phương trìnhf′(x) = 0. Chú ý rằng điều ngược lại không đúng, tức một điểm\\nthoả mãn đạo hàm bằng không chưa chắc đã làm cho hàm số đạt giá trị nhỏ nhất hoặc lớn\\nnhất. Ví dụ hàmf(x) = x3 có 0 là một điểm dừng nhưng không phải là điểm cực trị. Với\\nhàm nhiều biến, ta cũng có thể áp dụng quan sát này. Tức chúng ta cần đi tìm nghiệm của\\nphương trình đạo hàmtheo mỗi biếnbằng không.\\nCách làm trên đây được áp dụng vào các bài toán tối ưu không ràng buộc, tức không có\\nđiều kiện nào của biếnX. Với bài toán mà ràng buộc là một phương trình:\\nx = arg minx f0(x)\\nthoả mãn: f1(x) = 0 (A.1)\\nta cũng có một phương pháp để đưa nó về bài toán không ràng buộc. Phương pháp này có\\ntên là phương pháp nhân tử Lagrange.\\nXét hàm sốL(x,λ) = f0(x) + λf1(x) với biến λ được gọi lànhân tử Lagrange(Lagrange\\nmultiplier). Hàm sốL(x,λ) được gọi làhàm hỗ trợ(auxiliary function), haythe Lagrangian.\\nNgười ta đã chứng minh được rằng, điểmoptimal value của bài toán (A.1) thoả mãn điều\\nkiện ∇x,λL(x,λ) = 0. Điều này tương đương với:\\n∇xL(x,λ) = ∇xf0(x) + λ∇xf1(x) = 0 (A.2)\\n∇λL(x,λ) = f1(x) = 0 (A.3)\\nĐể ý rằng điều kiện thứ hai chính là ràng buộc trong bài toán (A.1).\\n1 Xem thêm:Open sets, closed sets and sequences of real numbers(https://goo.gl/AgKhCn ).'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 391, 'page_label': '380'}, page_content='PHỤ LỤC A. PHƯƠNG PHÁP NHÂN TỬ LAGRANGE 380\\nViệc giải hệ phương trình (A.2) - (A.3), trong nhiều trường hợp, đơn giản hơn việc trực tiếp\\nđi tìm nghiệm của bài toán (A.1).\\nVí dụ 1:\\nTìm giá trị lớn nhất và nhỏ nhất của hàm sốf0(x,y) = x+ y, biết rằngx,y thoả mãn điều\\nkiện f1(x,y) = x2 + y2 = 2.\\nLời giải:Điều kiện ràng buộc có thể được viết lại dưới dạngx2 + y2 −2 = 0. Lagrangian\\ncủa bài toán này là:L(x,y,λ ) = x+y+λ(x2 +y2 −2). Các điểm cực trị của hàm số Lagrange\\nphải thoả mãn điều kiện\\n∇x,y,λL(x,y,λ ) = 0 ⇔\\n\\uf8f1\\n\\uf8f2\\n\\uf8f3\\n1 + 2λx = 0\\n1 + 2λy= 0\\nx2 + y2 = 2\\n(A.4)\\nTừ hai phương trình đầu của (A.4) ta suy rax= y= −1\\n2λ. Thay vào phương trình cuối ta sẽ\\ncó λ2 = 1\\n4 ⇒λ= ±1\\n2 . Vậy ta được 2 cặp nghiệm(x,y) ∈{(1,1),(−1,−1)}. Bằng cách thay\\ncác giá trị này vào hàm mục tiêu, ta tìm được giá trị nhỏ nhất và lớn nhất của bài toán.\\nVí dụ 2: ℓ2 norm của ma trậnChúng ta đã quen thuộc vớiℓ2 norm của một vector\\nx : ∥x∥2 =\\n√\\nxTx. Dựa trênℓ2 norm của vector,ℓ2 norm của một ma trậnA ∈Rm×n được\\nký hiệu là∥A∥2 và được định nghĩa như sau:\\n∥A∥2 = max ∥Ax∥2\\n∥x∥2\\n= max\\n√\\nxTATAx\\nxTx ,với x ∈Rn (A.5)\\nBài toán tối ưu này tương đương với:\\nmax\\n(\\nxTATAx\\n)\\nthoả mãn:xTx = 1 (A.6)\\nLagrangian của bài toán này là\\nL(x,λ) = xTATAx + λ(1 −xTx) (A.7)\\nCác điểm cực trị của hàm số Lagrange phải thoả mãn\\n∇xL= 2ATAx −2λx = 0 (A.8)\\n∇λL= 1 −xTx = 0 (A.9)\\nTừ (A.8) ta cóATAx = λx. Vậyx phải là một vector riêng củaATA vàλchính là trị riêng\\ntương ứng. Nhân cả hai vế của biểu thức này vớixT vào bên trái và sử dụng (A.9), ta thu\\nđược\\nxTATAx = λxTx = λ (A.10)\\nTừ đó suy ra∥Ax∥2 đạt giá trị lớn nhất khiλđạt giá trị lớn nhất. Nói cách khác,λphải là\\ntrị riêng lớn nhất củaATA. Vậy,∥A∥2 = λmax(ATA).\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 392, 'page_label': '381'}, page_content='381 PHỤ LỤC A. PHƯƠNG PHÁP NHÂN TỬ LAGRANGE\\nCác trị riêng củaATA còn được gọi làsingular valuecủa A. Tóm lại,ℓ2 norm của một ma\\ntrận là singular value lớn nhất của ma trận đó.\\nHoàn toàn tương tự, nghiệm của bài toán\\nmin\\n∥x∥≤1\\n∥Ax∥2 (A.11)\\nchính là một vector riêng ứng với singular value nhỏ nhất củaA.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 393, 'page_label': '382'}, page_content=''),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 394, 'page_label': '383'}, page_content='Tài liệu tham khảo\\nAKA91. David W Aha, Dennis Kibler, and Marc K Albert. Instance-based learning algorithms.Machine learning,\\n6(1):37–66, 1991.\\nAM93. Sunil Arya and David M Mount. Algorithms for fast vector quantization. In Data Compression Confer-\\nence, 1993. DCC’93., pages 381–390. IEEE, 1993.\\nAMMIL12. Yaser S Abu-Mostafa, Malik Magdon-Ismail, and Hsuan-Tien Lin.Learning from data, volume 4. AML-\\nBook New York, NY, USA:, 2012.\\nAV07. David Arthur and Sergei Vassilvitskii. k-means++: The advantages of careful seeding. In Proceedings\\nof the eighteenth annual ACM-SIAM symposium on Discrete algorithms, pages 1027–1035. Society for\\nIndustrial and Applied Mathematics, 2007.\\nBis06. Christopher M Bishop. Pattern recognition and machine learning. springer, 2006.\\nBL14. Artem Babenko and Victor Lempitsky. Additive quantization for extreme vector compression. In Pro-\\nceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 931–938, 2014.\\nBle08. David M Blei. Hierarchical clustering. 2008.\\nBMV+12. Bahman Bahmani, Benjamin Moseley, Andrea Vattani, Ravi Kumar, and Sergei Vassilvitskii. Scalable\\nk-means++. Proceedings of the VLDB Endowment, 5(7):622–633, 2012.\\nBTVG06. Herbert Bay, Tinne Tuytelaars, and Luc Van Gool. Surf: Speeded up robust features.Computer vision–\\nECCV 2006, pages 404–417, 2006.\\nBV04. Stephen Boyd and Lieven Vandenberghe. Convex optimization. Cambridge university press, 2004.\\nCDF+04. Gabriella Csurka, Christopher Dance, Lixin Fan, Jutta Willamowski, and Cédric Bray. Visual catego-\\nrization with bags of keypoints. InWorkshop on statistical learning in computer vision, ECCV, volume 1,\\npages 1–2. Prague, 2004.\\nCLMW11. Emmanuel J Candès, Xiaodong Li, Yi Ma, and John Wright. Robust principal component analysis?\\nJournal of the ACM (JACM), 58(3):11, 2011.\\nCyb89. George Cybenko. Approximation by superpositions of a sigmoidal function. Mathematics of Control,\\nSignals, and Systems (MCSS), 2(4):303–314, 1989.\\nDFK+04. Petros Drineas, Alan Frieze, Ravi Kannan, Santosh Vempala, and V Vinay. Clustering large graphs via\\nthe singular value decomposition.Machine learning, 56(1):9–33, 2004.\\ndGJL05. Alexandred’Aspremont,LaurentEGhaoui, MichaelIJordan,and GertRLanckriet. Adirectformulation\\nfor sparse pca using semidefinite programming. InAdvances in neural information processing systems,\\npages 41–48, 2005.\\nDHS11. John Duchi, Elad Hazan, and Yoram Singer. Adaptive subgradient methods for online learning and\\nstochastic optimization. Journal of Machine Learning Research, 12(Jul):2121–2159, 2011.\\nDT05. Navneet Dalal and Bill Triggs. Histograms of oriented gradients for human detection. In Computer\\nVision and Pattern Recognition, 2005. CVPR 2005. IEEE Computer Society Conference on, volume 1,\\npages 886–893. IEEE, 2005.\\nERK+11. MichaelDEkstrand,JohnTRiedl,JosephAKonstan,etal. Collaborativefilteringrecommendersystems.\\nFoundations and Trends® in Human–Computer Interaction, 4(2):81–173, 2011.\\nFHT01. Jerome Friedman, Trevor Hastie, and Robert Tibshirani. The elements of statistical learning, volume 1.\\nSpringer series in statistics New York, 2001.\\nFuk13. Keinosuke Fukunaga. Introduction to statistical pattern recognition. Academic press, 2013.\\nGBC16. Ian Goodfellow, Yoshua Bengio, and Aaron Courville. Deep Learning. MIT Press, 2016. http://www.\\ndeeplearningbook.org.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 395, 'page_label': '384'}, page_content='Tài liệu tham khảo 384\\nGR70. Gene H Golub and Christian Reinsch. Singular value decomposition and least squares solutions. Nu-\\nmerische mathematik, 14(5):403–420, 1970.\\nHNO06. Per Christian Hansen, James G Nagy, and Dianne P O’leary.Deblurring images: matrices, spectra, and\\nfiltering. SIAM, 2006.\\nHZRS16. Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition.\\nIn Proceedings of the IEEE conference on computer vision and pattern recognition, pages 770–778, 2016.\\nJDJ17. Jeff Johnson, Matthijs Douze, and Hervé Jégou. Billion-scale similarity search with gpus.arXiv preprint\\narXiv:1702.08734, 2017.\\nJDS11. Herve Jegou, Matthijs Douze, and Cordelia Schmid. Product quantization for nearest neighbor search.\\nIEEE transactions on pattern analysis and machine intelligence, 33(1):117–128, 2011.\\nKA04. Shehroz S Khan and Amir Ahmad. Cluster center initialization algorithm for k-means clustering.Pattern\\nrecognition letters, 25(11):1293–1302, 2004.\\nKB14. Diederik Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint\\narXiv:1412.6980, 2014.\\nKBV09. Yehuda Koren, Robert Bell, and Chris Volinsky. Matrix factorization techniques for recommender sys-\\ntems. Computer, 42(8), 2009.\\nKH92. Anders Krogh and John A Hertz. A simple weight decay can improve generalization. In Advances in\\nneural information processing systems, pages 950–957, 1992.\\nKSH12. Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. Imagenet classification with deep convolutional\\nneural networks. InAdvances in neural information processing systems, pages 1097–1105, 2012.\\nLCB10. Yann LeCun, Corinna Cortes, and Christopher JC Burges. Mnist handwritten digit database. AT&T\\nLabs [Online]. Available: http://yann. lecun. com/exdb/mnist, 2, 2010.\\nLCD04. Anukool Lakhina, Mark Crovella, and Christophe Diot. Diagnosing network-wide traffic anomalies. In\\nACM SIGCOMM Computer Communication Review, volume 34, pages 219–230. ACM, 2004.\\nLow99. David G Lowe. Object recognition from local scale-invariant features. In Computer vision, 1999. The\\nproceedings of the seventh IEEE international conference on, volume 2, pages 1150–1157. Ieee, 1999.\\nLSP06. Svetlana Lazebnik, Cordelia Schmid, and Jean Ponce. Beyond bags of features: Spatial pyramid matching\\nfor recognizing natural scene categories. InComputer vision and pattern recognition, 2006 IEEE computer\\nsociety conference on, volume 2, pages 2169–2178, 2006.\\nLW+02. Andy Liaw, Matthew Wiener, et al. Classification and regression by randomforest. R news, 2(3):18–22,\\n2002.\\nM+97. Tom M Mitchell et al. Machine learning. wcb, 1997.\\nMSS+99. Sebastian Mika, Bernhard Sch¨ olkopf, Alex J Smola, Klaus-Robert M¨ uller, Matthias Scholz, and Gunnar\\nR¨ atsch. Kernel pca and de-noising in feature spaces. InAdvances in neural information processing\\nsystems, pages 536–542, 1999.\\nNes07. Yurii Nesterov. Gradient methods for minimizing composite objective function, 2007.\\nNF13. Mohammad Norouzi and David J Fleet. Cartesian k-means. In Proceedings of the IEEE Conference on\\nComputer Vision and Pattern Recognition, pages 3017–3024, 2013.\\nNJW02. Andrew Y Ng, Michael I Jordan, and Yair Weiss. On spectral clustering: Analysis and an algorithm. In\\nAdvances in neural information processing systems, pages 849–856, 2002.\\nPat07. Arkadiusz Paterek. Improving regularized singular value decomposition for collaborative filtering. In\\nProceedings of KDD cup and workshop, volume 2007, pages 5–8, 2007.\\nPla98. John Platt. Sequential minimal optimization: A fast algorithm for training support vector machines.\\n1998.\\nPri12. Simon JD Prince. Computer vision: models, learning, and inference. Cambridge University Press, 2012.\\nRDVC+04. Lorenzo Rosasco, Ernesto De Vito, Andrea Caponnetto, Michele Piana, and Alessandro Verri. Are loss\\nfunctions all the same?Neural Computation, 16(5):1063–1076, 2004.\\nRey15. Douglas Reynolds. Gaussian mixture models. Encyclopedia of biometrics, pages 827–832, 2015.\\nRos57. F Rosemblat. The perceptron: A perceiving and recognizing automation. Cornell Aeronautical Laboratory\\nReport, 1957.\\nRud16. Sebastian Ruder. An overview of gradient descent optimization algorithms. arXiv preprint\\narXiv:1609.04747, 2016.\\nSCSC03. Mei-Ling Shyu, Shu-Ching Chen, Kanoksri Sarinnapakorn, and LiWu Chang. A novel anomaly detection\\nscheme based on principal component classifier. Technical report, MIAMI UNIV CORAL GABLES FL\\nDEPT OF ELECTRICAL AND COMPUTER ENGINEERING, 2003.\\nSFHS07. J Ben Schafer, Dan Frankowski, Jon Herlocker, and Shilad Sen. Collaborative filtering recommender\\nsystems. In The adaptive web, pages 291–324. Springer, 2007.\\nSHK+14. Nitish Srivastava, Geoffrey E Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov.\\nDropout: a simple way to prevent neural networks from overfitting.Journal of machine learning re-\\nsearch, 15(1):1929–1958, 2014.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 396, 'page_label': '385'}, page_content='385 Tài liệu tham khảo\\nSKKR00. BadrulSarwar,GeorgeKarypis,JosephKonstan,andJohnRiedl. Applicationofdimensionalityreduction\\nin recommender system-a case study. Technical report, Minnesota Univ Minneapolis Dept of Computer\\nScience, 2000.\\nSKKR02. Badrul Sarwar, George Karypis, Joseph Konstan, and John Riedl. Incremental singular value decomposi-\\ntion algorithms for highly scalable recommender systems. InFifth International Conference on Computer\\nand Information Science, pages 27–28. Citeseer, 2002.\\nSLJ+15. Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir Anguelov, Dumitru\\nErhan, Vincent Vanhoucke, and Andrew Rabinovich. Going deeper with convolutions. InProceedings of\\nthe IEEE conference on computer vision and pattern recognition, pages 1–9, 2015.\\nSSWB00. Bernhard Sch¨ olkopf, Alex J Smola, Robert C Williamson, and Peter L Bartlett. New support vector\\nalgorithms. Neural computation, 12(5):1207–1245, 2000.\\nSWY75. Gerard Salton, Anita Wong, and Chung-Shu Yang. A vector space model for automatic indexing.Com-\\nmunications of the ACM, 18(11):613–620, 1975.\\nSZ14. Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for large-scale image recog-\\nnition. arXiv preprint arXiv:1409.1556, 2014.\\nTH12. Tijmen Tieleman and Geoffrey Hinton. Lecture 6.5-rmsprop: Divide the gradient by a running average\\nof its recent magnitude.COURSERA: Neural networks for machine learning, 4(2):26–31, 2012.\\nVJG14. João Vinagre, Alípio Mário Jorge, and João Gama. Fast incremental matrix factorization for recom-\\nmendation with positive-only feedback. InInternational Conference on User Modeling, Adaptation, and\\nPersonalization, pages 459–470. Springer, 2014.\\nVL07. Ulrike Von Luxburg. A tutorial on spectral clustering. Statistics and computing, 17(4):395–416, 2007.\\nVM16. Tiep Vu and Vishal Monga. Learning a low-rank shared dictionary for object classification. InProceedings\\nIEEE Int. Conference on Image Processing, pages 4428–4432. IEEE, 2016.\\nVM17. Tiep Vu and Vishal Monga. Fast low-rank shared dictionary learning for image classification. IEEE\\nTransactions on Image Processing, 26(11):5160–5175, Nov 2017.\\nVMM+16. Tiep Vu, Hojjat Seyed Mousavi, Vishal Monga, Ganesh Rao, and UK Arvind Rao. Histopathological im-\\nage classification using discriminative feature-oriented dictionary learning.IEEE transactions on medical\\nimaging, 35(3):738–751, 2016.\\nWYG+09. John Wright, Allen Y Yang, Arvind Ganesh, S Shankar Sastry, and Yi Ma. Robust face recognition via\\nsparse representation. IEEE transactions on pattern analysis and machine intelligence, 31(2):210–227,\\n2009.\\nXWCL15. Bing Xu, Naiyan Wang, Tianqi Chen, and Mu Li. Empirical evaluation of rectified activations in convo-\\nlutional network.arXiv preprint arXiv:1505.00853, 2015.\\nYZFZ11. M. Yang, L. Zhang, X. Feng, and D. Zhang. Fisher discrimination dictionary learning for sparse repre-\\nsentation. pages 543–550, Nov. 2011.\\nZDW14. Ting Zhang, Chao Du, and Jingdong Wang. Composite quantization for approximate nearest neighbor\\nsearch. InICML, number 2, pages 838–846, 2014.\\nZF14. Matthew D Zeiler and Rob Fergus. Visualizing and understanding convolutional networks. In European\\nconference on computer vision, pages 818–833. Springer, 2014.\\nZWFM06. Sheng Zhang, Weihong Wang, James Ford, and Fillia Makedon. Learning from incomplete ratings using\\nnon-negative matrix factorization. InProceedings of the 2006 SIAM International Conference on Data\\nMining, pages 549–553. SIAM, 2006.\\nZYK06. Haitao Zhao, Pong Chi Yuen, and James T Kwok. A novel incremental principal component analysis\\nand its application for face recognition.IEEE Transactions on Systems, Man, and Cybernetics, Part B\\n(Cybernetics), 36(4):873–886, 2006.\\nZYX+08. Zhi-Qiang Zeng, Hong-Bin Yu, Hua-Rong Xu, Yan-Qi Xie, and Ji Gao. Fast training support vector ma-\\nchines using parallel sequential minimal optimization. InIntelligent System and Knowledge Engineering,\\n2008. ISKE 2008. 3rd International Conference on, volume 1, pages 997–1001. IEEE, 2008.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 397, 'page_label': '386'}, page_content='Index\\nα–sublevel sets, 294\\nactivation fuction\\nsigmoid fuction, 167\\ntanh fuction, 167\\nactivation function, 162\\nReLU, 199\\nactivation function–hàm kích hoạt, 197\\naffine function, 290\\nback substitution, 16\\nbackpropagation, 200\\nbag of words, 75\\ndictionary, 76\\nbasic, 19\\northogonal, 20\\northonormal, 20\\nbatch gradient descent, 152\\nBayes’ rule - quy tắc Bayes, 44\\nbias, 86\\nbias trick, 86, 366\\nbinary classification, 156\\nclass boundary, 156\\nclassification–phân lớp, 65\\nclosed-form solution, 97\\ncluster, 110\\ncomplementary slackness, 323\\nconditional probability - xác suất có điều kiện, 44\\nconjugate distributions, 59\\nconjugate prior, 59\\nconstraints, 282\\ncontours, 293\\nconvex, 282\\ncombination, 287\\nfunction, 288\\ndomain, 288\\nfunctions\\nfirst-order condition, 296\\nSecond-order condition, 297\\nhull, 287\\noptimization problems, 305\\nsets, 283\\nstrictly convex functions, 289\\nconvex optimization, 282\\ncosine similarity, 228\\ncross entropy, 184\\nCVXOPT, 307\\ndata point - điểm dữ liệu, 64\\ndeterminant, 16\\ndiagonal matrix, 15\\ndimensionality reduction, 75\\ndimensionality reduction – giảm chiều dữ liệu, 245\\nduality, 317\\nearly stopping, 96\\neigenvalues, 22\\neigenvectors, 22\\nelbow method, 123\\nelement-wise, 197\\nepoch, 153\\nexpectation - kỳ vọng, 45\\nfeasible points, 282\\nfeasible sets, 282\\nfeature engineering, 71\\nfeature extraction, 245\\nfeature selection, 97, 245\\nfeature vector, 71\\nfeature vector - vector đặc trưng, 64\\nFisher’s linear discriminant, 273\\nforward substitution, 16\\nGaussian naive Bayes, 128\\nGaussion mixture model, 124\\nGD, see gradient descent\\ngeneralization, 91\\nGeometric Programming, 313\\nGeometric programming\\nconvex form, 315\\nglobal minimum, 140\\ngradient descent, 140\\nstopping criteria – điều kiện dừng, 155\\nbatch size, 154\\nmomentum, 148\\nNesterov accelerated gradient, 151\\ngradient–đạo hàm, 30'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 398, 'page_label': '387'}, page_content='387 Index\\nfirst-order gradient–đạo hàm bậc nhất, 30\\nnumerical gradient, 36\\nsecond-order gradient–đạo hàm bậc hai, 30\\nground truth, 83\\nHadamard product, 202, 203\\nhalfspace, 285\\nhand-crafted feature, 79\\nHermitian, 13\\nhidden layer, 162\\nhierarchical, 176\\nhierarchical clustering, 120\\nhinge loss, 346\\nhinge loss tổng , 368\\nHuber loss, 89\\nhyperparameter, 60\\nhyperplane, 156\\nhyperplane – siêu mặt phẳng, 285\\nhyperpolygon–siêu đa diện, 111\\nidentity matrix - ma trận đơn vị, 14\\ninfeasible sets, 282\\ninner product – tích vô hướng, 14\\ninput layer, 162\\ninverse matrix - ma trận nghịch đảo, 15\\niteration, 153\\njoint probability - xác suất đồng thời, 41\\nK-means clustering, 110\\nK-nearest neighbor, 100\\nKernel, 358\\nKernel trick, 358\\nLinear, 359\\nMercer conditions, 359\\nPolynomial, 360\\nRadial Basic Function (RBF), 360\\nSigmoid, 360\\nKKT conditions, 324\\nKNN, xem K-nearest neighbor, 100\\nLagrange\\ndual function, 318\\ndual problem, 321\\nLagrangian, 318\\nLagrange/Lagrangian\\ndual functions, 318\\nLaplace smoothing, 129\\nlarge-scale, 101\\nlasso regression, 97\\nlazy learning, 100\\nLDA, 269\\nlearning rate, 141\\nlemmatization, 133\\nlevel sets, 293\\nlevel sets–đường đồng mức, 147\\nlikelihood, 53\\nlinear combination, 17\\nlinear dependece, 17\\nlinear discriminant analysis, 269\\nlinear independence, 17\\nlinear programming, 307\\ngeneral form, 308\\nstandard form, 308\\nlinear regression–hồi quy tuyến tính, 83\\nlinearly separable, 156\\nLing-Spam dataset, 132\\nlocal minimum, 140\\nlog-likelihood, 53\\nloss function–hàm mất mát, 69\\nMAP, 58\\nmarginal probability - xác suất biên, 43\\nmarginalization, 43\\nmatrix calculus, 30\\nmatrix completion, 216\\nmatrix factorization: phân tích ma trận thành nhân tử,\\n236\\nmaximum a posteriori, 58\\nmaximum entropy classifier, 191\\nmaximum likelihood estimation, 53\\nmaximum margin classifier, 330\\nmean squared error, 93\\nmini-batch gradient descent, 154\\nmisclassified point–điểm bị phân lớp lỗi, 158\\nMLE, 53\\nMNIST, 117\\nmodel parameter–tham số mô hình, 69\\nmodel parameters, 69\\nmonomial, 313\\nmulti-class classification, 175\\nmultinomial logistic regression, 191\\nmultinomial naive Bayes, 129\\nnaive Bayes classifier, 127\\nNBC, 127\\nneural network, 162\\nnon-word, 133\\nnorm, 26\\nℓ1 norm, 27\\nℓ2 norm, 27\\nℓp norm, 27\\nEuclidean norm, 27\\nFrobenius norm, 28\\nnorm balls, 285\\nnull space, 19\\nnumpy, iv\\noffline learning, 67\\none-hot coding, 111\\none-vs-one, 176\\none-vs-rest, 177\\nonline learning, 67, 152\\northogonal matrix, 20\\northogonality, 20\\noutput layer, 162\\noverfitting, 91\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 399, 'page_label': '388'}, page_content='Index 388\\npartial derivative–đạo hàm riêng, 30\\npatch, 77\\nPCA–xem principle component analysis, 254\\npdf, xem probability density function, 40\\nperceptron learning algorithm, 156\\nPLA, 156\\npocket algorithm, 163\\npolynomial regression, 89, 92\\npositive definite matrix, 24\\nnegative definite, 24\\nnegative semidefinite, 24\\npositive semidefinite, 24\\nposterior probability, 58\\nposynomial, 313\\npredicted output, 83\\nprincipal component analysis, 254\\nprior, 58\\nprobability density function - hàm mật độ xác suất, 40\\nprobability distribution - phân phối xác suất, 47\\nBernoulli distribution, 47\\nBeta distribution, 50\\nCategorical distribution, 48\\nDirichlet distribution, 51\\nmultivariate normal distribution, 50\\nunivariate normal distribution, 49\\nprojection matrix, 75, 269\\npseudo inverse, 85\\nquadratic\\nforms, 291\\nQuadratic programming, 310\\nquasiconvex, 296\\nrandom projection, 75\\nrandom variable - biến ngẫu nhiên, 40\\nrange space, 19\\nrank, 19\\nrecommendation system\\ncollaborative filtering, 215\\ncontent-based, 214, 215\\nitem, 214\\nitem-item collaborative filtering, 230\\nlong tail, 214\\nsimilarity matrix, 228\\nuser, 214\\nuser-user collaborative filtering, 226\\nutility matrix, 215\\nregression–hồi quy, 65\\nregularization, 96\\nℓ1 regularization, 97\\nℓ2 regularization, 97\\nregularization parameter, 97\\nregularized loss function, 97\\nregularized neural network, 209\\nreinforcement learning - học củng cố, 68\\nridge regression, 90, 97\\nrobust, 97\\nscikit-learn, iv\\nsemi-supervised learning–học bán giám sát, 68\\nSeparating hyperplane theorem, 288\\nSGD, see stochastic gradient descent\\nsigmoid, 198\\nsklearn, iv\\nSlater’s constraint qualification, 322\\nsoftmax function, 181\\nsoftmax regression, 180\\nspam filtering, 132\\nspan, 17\\nsparsity, 97\\nspectral clustering, 124\\nstate-of-the-art, 74\\nstochastic gradient descent, 152\\nstop word, 133\\nstrong duality, 322\\nsubmatrix\\nleading principal matrix, 25\\nleading principal minor, 25\\nprincipal minor, 25\\nprincipal submatrix, 25\\nsupervised learning–học có giám sát, 67\\nSupport Vector Machine, 328\\nHard Margin SVM, 328\\nSupport vector machine\\nKernel SVM, 355\\nsoft-margin SVM, 339\\nsupport vector machine\\nmargin, 329\\nmulti-class SVM, 364\\nsymmetric matrix, 13\\ntanh, 198\\ntask, 64\\ntensor, 64\\ntest set - tập kiểm thử, 67\\ntraining error, 93\\ntraining set - tập huấn luyện, 67\\ntransfer learning, 80\\ntriangular matrix, 16\\nlower, 16\\nupper, 16\\nunderfitting, 92\\nunitary matrix, 21\\nunsupervised learning–học không giám sát, 68\\nvalidation, 94\\ncross-validation, 95\\nk-fold cross-validation, 95\\nleave-one-out, 95\\nvector-valued function, 31\\nvectorization–vector hoá, 74\\nweak duality, 321\\nweight decay, 97\\nweight vector–vector trọng số, 83\\nMachine Learning cơ bản https://machinelearningcoban.com')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_chunks = text_split(extracted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "533"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 0, 'page_label': '1'}, page_content='Vũ Hữu Tiệp \\nMachine Learning \\ncơ bản \\nmachinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 1, 'page_label': '2'}, page_content='Vũ Hữu Tiệp\\nMachine Learning cơ bản\\nOrder ebook tạihttps://machinelearningcoban.com/ebook/\\nBlog: https://machinelearningcoban.com\\nFacebook Page:https://www.facebook.com/machinelearningbasicvn/\\nFacebook Group:https://www.facebook.com/groups/machinelearningcoban/\\nInteractive Learning:https:fundaml.com\\nLast update:\\nMarch 27, 2018'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 2, 'page_label': 'i'}, page_content='Chương 0\\nLời tác giả\\nNhững năm gần đây,trí tuệ nhân tạo(artificial intelligence–AI) nổi lên như một bằng chứng\\ncủa cuộc cách mạng công nghiệp lần thứ tư (1–động cơ hơi nước, 2–năng lượng điện, 3–công\\nnghệ thông tin). Trí tuệ nhân tạo đã và đang trở thành thành phần cốt lõi trong các hệ\\nthống công nghệ cao. Nó đã len lỏi vào hầu hết các lĩnh vực trong đời sống mà có thể chúng\\nta không nhận ra. Xe tự hành của Google và Tesla, hệ thống tự tag khuôn mặt trong ảnh\\ncủa Facebook; trợ lý ảo Siri của Apple, hệ thống gợi ý sản phẩm của Amazon, hệ thống gợi\\ný phim của Netflix, hệ thống dịch đa ngôn ngữ Google Translate, máy chơi cờ vây AlphaGo\\nvà gần đây là AlphaGo Zero của Google DeepMind, v.v., chỉ là một vài ứng dụng nổi bật\\ntrong vô vàn những ứng dụng của trí tuệ nhân tạo.\\nHọc máy (machine learning–ML) là một tập con của trí tuệ nhân tạo. Nó là một lĩnh vực\\nnhỏ trong khoa học máy tính, có khả năng tự học hỏi dựa trên dữ liệu được đưa vào mà\\nkhông cần phải được lập trình cụ thể (Machine Learning is the subfiled of computer science,\\nthat “gives computers the ability to learn without being explicitly programmed”–Wikipedia).\\nNhững năm gần đây, sự phát triển của các hệ thống tính toán cùng với lượng dữ liệu khổng\\nlồ được thu thập bởi các hãng công nghệ lớn đã giúp machine learning tiến thêm một bước\\ndài. Một lĩnh vực mới được ra đời được gọi làhọc sâu(deep learning–DL). Deep learning đã\\ngiúp máy tính thực thi những việc tưởng chừng như không thể vào mười năm trước: phân\\nloại cả ngàn vật thể khác nhau trong các bức ảnh, tự tạo chú thích cho ảnh, bắt chước giọng\\nnói và chữ viết của con người, giao tiếp với con người, chuyển đổi ngôn ngữ, hay thậm chí\\ncả sáng tác văn thơ hay âm nhạc1.\\nMối quan hệ AI-ML-DL\\nDeep learning là một tập con của machine learning. Machine learning là một tập con\\ncủa artificial intelligence (xem Hình 0.1).\\n1 Đọc thêm:8 Inspirational Applications of Deep Learning(https://goo.gl/Ds3rRy )'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 3, 'page_label': 'ii'}, page_content='CHƯƠNG 0. LỜI TÁC GIẢ ii\\nHình 0.1: Mối quan hệ giữa artificial intelligence, machine learning, và deep learning (Nguồn\\nWhat’s the Difference Between Artificial Intelligence, Machine Learning, and Deep Learning?–\\nhttps://goo.gl/NNwGCi ).\\n0.1 Mục đích của cuốn sách\\nNhững phát triển thần kỳ của trí tuệ nhân tạo dẫn đến nhu cầu cao về nhân lực những\\nngành khoa học dữ liệu, machine learning, và các ngành liên quan trên toàn thế giới cũng\\nnhư ở Việt Nam trong những năm sắp tới. Đó cũng là động lực để tôi bắt đầu viết blog\\nMachine Learning cơ bản (https://machinelearningcoban.com) từ đầu năm 2017. Tính tới\\nthời điểm tôi viết những dòng này, trang blog đã có hơn 650 ngàn lượt ghé thăm. Facebook\\npage Machine Learning cơ bản (https://goo.gl/wyUEjr ) của blog cũng đã có hơn 10 nghìn\\nlượt likes, Forum Machine Learning cơ bản (https://goo.gl/gDPTKX ) có gần 8 nghìn thành\\nviên. Trong quá trình viết blog và duy trì các trang Facebook, tôi nhận được rất nhiều những\\nủng hộ của bạn đọc về tinh thần cũng như vật chất. Ngoài ra, rất nhiều bạn đọc đã khuyến\\nkhích tôi tổng hợp những kiến thức trên blog lại thành một cuốn sách cho cộng đồng những\\nngười làm machine learning sử dụng tiếng Việt. Những sự ủng hộ và lời động viên đó là động\\nlực lớn cho tôi bắt tay vào thực hiện và hoàn thành cuốn sách này.\\nLĩnh vực machine learning và deep learning là cực kỳ rộng lớn và có nhiều nhánh nhỏ. Để\\nđi sâu vào từng nhánh, một cuốn sách chắc chắn không thể bao quát được mọi vấn đề. Mục\\nđích chính của cuốn sách này là cung cấp cho các bạn những khái niệm, kỹ thuật chung và\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 4, 'page_label': 'iii'}, page_content='iii CHƯƠNG 0. LỜI TÁC GIẢ\\ncác thuật toán cơ bản nhất của machine learning. Từ đó, bạn đọc muốn đi sâu vào từng vấn\\nđề cụ thể có thể tìm đọc thêm các tài liệu, cuốn sách, và khoá học liên quan.\\nHãy luôn nhớ rằngđơn giản trước hết. Khi bắt tay vào giải quyết một bài toán machine\\nlearning hay bất cứ bài toán nào, chúng ta nên bắt đầu từ những thuật toán đơn giản nhất.\\nKhông nên nghĩ rằng chỉ có những thuật toán phức tạp mới có thể giải quyết được vấn đề.\\nNhững thuật toán phức tạp thường yêu cầu độ tính toán cao và nhạy cảm với cách chọn\\ncác tham số đầu vào. Thêm vào đó, những thuật toán đơn giản giúp chúng ta sớm có một\\nmô hình tổng quát cho mỗi bài toán. Kết quả của các thuật toán đơn giản, thường được gọi\\nlà baseline, cũng giúp chúng ta có cái nhìn ban đầu về sự phức tạp của mỗi bài toán. Việc\\ncải thiện kết quả sẽ được dần thực hiện ở các bước sau. Cuốn sách này sẽ giúp các bạn có\\nnhững cái nhìn đầu tiên và các hướng giải quyết cho các bài toán machine learning. Để có\\ncác sản phẩm thực tiễn, chúng ta sẽ phải học hỏi và thực hành thêm rất nhiều.\\n0.2 Hướng tiếp cận của cuốn sách\\nĐể giải quyết mỗi bài toán machine learning, chúng ta cần chọn một mô hình phù hợp. Mô\\nhình này được mô tả bởi bộ các tham số, có thể lên tới cả triệu tham số, mà chúng ta cần\\nđi tìm. Thông thường, bộ các tham số này được tìm bằng cách giải một bài toán tối ưu.\\nKhi viết về các thuật toán machine learning, tôi sẽ bắt đầu bằng những ý tưởng trực quan,\\ntheo sau bởi một mô hình toán học mô tả ý tưởng đó. Các tham số mô hình được tìm bằng\\ncách tối ưu mô hình toán học đó. Các suy luận toán học và các ví dụ mẫu trên Python ở\\ncuối mỗi bài sẽ giúp bạn đọc hiểu rõ hơn về nguồn gốc, ý nghĩa, và cách sử dụng mỗi thuật\\ntoán. Xen kẽ giữa các phần về các thuật toán machine learning, tôi cũng sẽ giới thiệu các\\nkỹ thuật tối ưu cơ bản, với hy vọng giúp bạn đọc hiểu rõ hơn về bản chất của vấn đề.\\n0.3 Đối tượng của cuốn sách\\nCuốn sách được thực hiện hướng đến nhiều nhóm độc giả khác nhau. Nếu bạn không thực'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 4, 'page_label': 'iii'}, page_content='kỹ thuật tối ưu cơ bản, với hy vọng giúp bạn đọc hiểu rõ hơn về bản chất của vấn đề.\\n0.3 Đối tượng của cuốn sách\\nCuốn sách được thực hiện hướng đến nhiều nhóm độc giả khác nhau. Nếu bạn không thực\\nsự muốn đi sâu vào phần toán, bạn vẫn có thể tham khảo source code và cách sử dụng các\\nthư viện. Nhưng để sử dụng các thư viện một cách hiệu quả, bạn cũng cần hiểu nguồn gốc\\ncủa mô hình và ý nghĩa của các tham số. Nếu bạn thực sự muốn tìm hiểu nguồn gốc, ý nghĩa\\ncủa các thuật toán, bạn có thể học được nhiều điều từ cách xây dựng và tối ưu các mô hình.\\nPhần tổng hợp các kiến thức toán cần thiết trong Phần I sẽ là một nguồn tham khảo súc\\ntích bất cứ khi nào bạn có thắc mắc về các dẫn giải toán học trong sách2. Phần VII được\\ndành riêng để nói về tối ưu lồi–một mảng rất quan trọng trong tối ưu, phù hợp với các bạn\\nthực sự muốn đi sâu thêm về tối ưu.\\nRất nhiều hình vẽ trong cuốn sách được vẽ dưới dạng vector graphics (độ phân giải rất cao),\\ncó thể được dùng trong các bài giảng hoặc thuyết trình. Các kiến thức trong sách cũng được\\nsắp xếp theo thứ tự từ dễ đến khó, vì vậy cuốn sách cũng được hy vọng là một cuốn giáo\\ntrình cho các khoá học machine learning tiếng Việt.\\n2 Bạn đọc chưa quen với nhiều khái niệm toán học trong phần này có thể đọc từ Phần II và quay lại bất cứ khi nào\\nbạn gặp khó khăn.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 5, 'page_label': 'iv'}, page_content='CHƯƠNG 0. LỜI TÁC GIẢ iv\\nCác dẫn giải toán học được xây dựng phù hợp với chương trình toán phổ thông và đại học ở\\nViệt Nam. Các từ khoá khi được dịch sang tiếng Việt đều dựa trên những tài liệu tôi được\\nhọc trong nhiều năm học toán tại Việt Nam. Các thuật ngữ tiếng Anh cũng thường xuyên\\nđược sử dụng, với hy vọng giúp bạn đọc dần làm quen với các tài liệu tiếng Anh, và giúp\\ncác bạn học đại học ở nước ngoài có thể tiếp cận. Phần cuối cùng của sách có mục Index\\ncác thuật ngữ quan trọng bằng tiếng Anh và nghĩa tiếng Việt đi kèm nếu tôi tìm được cách\\ndịch phù hợp.\\n0.4 Yêu cầu về kiến thức\\nĐể có thể bắt đầu đọc cuốn sách này, bạn cần có một kiến thức nhất định về đại số tuyến\\ntính, giải tích ma trận, xác suất thống kê, và kỹ năng lập trình.\\nPhần I của cuốn sách ôn tập lại các kiến thức toán quan trọng cho machine learning. Bất\\ncứ khi nào bạn đọc gặp khó khăn về toán, bạn được khuyến khích đọc lại các chương trong\\nphần này.\\nNgôn ngữ lập trình được sử dụng trong cuốn sách là Python. Lý do tôi sử dụng ngôn ngữ\\nnày vì đây là một ngôn ngữ lập trình miễn phí, có thể được cài đặt dễ dàng trên các nền tảng\\nhệ điều hành khác nhau. Quan trọng hơn, có rất nhiều các thư viện hỗ trợ machine learning\\ncũng như deep learning được viết cho Python. Có hai thư viện python chính thường được\\nsử dụng trong cuốn sách là numpy và scikit-learn. Numpy (http://www.numpy.org/ ) là một\\nthư viện phổ biến giúp xử lý các phép toán liên quan đến các mảng nhiều chiều, với các hàm\\ngần gũi với đại số tuyến tính. Nếu bạn đọc chưa quen thuộc với numpy, bạn có thể tham gia\\nmột khoá học ngắn miễn phí trên trang web kèm theo cuốn sách này (https://fundaml.com).\\nBạn sẽ được làm quen với cách xử lý các mảng nhiều chiều với nhiều ví dụ và bài tập thực\\nhành trực tiếp trên trình duyệt. Các kỹ thuật xử lý mảng trong cuốn sách này đều được\\nđề cập tại đây. Scikit-learn, hay sklearn, (http://scikit-learn.org/ ) là một thư viện chứa rất'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 5, 'page_label': 'iv'}, page_content='hành trực tiếp trên trình duyệt. Các kỹ thuật xử lý mảng trong cuốn sách này đều được\\nđề cập tại đây. Scikit-learn, hay sklearn, (http://scikit-learn.org/ ) là một thư viện chứa rất\\nnhiều các thuật toán machine learning cơ bản và rất dễ sử dụng. Tài liệu của scikit-learn\\ncũng là một nguồn chất lượng cho các bạn làm machine learning. Scikit-learn sẽ được dùng\\ntrong cuốn sách như một cách kiểm chứng lại các kết quả mà chúng ta thực hiện dựa trên\\nsuy luận toán học cũng như lập trình thông qua numpy.\\nTất nhiên, các thư viện machine learning hiện nay rất phổ biến và có những bạn có thể tạo\\nra sản phẩm bằng cách chỉ sử dụng những thư viện này mà không cần nhiều kiến thức toán.\\nTuy nhiên, cuốn sách này không hướng tới việc sử dụng các thư viện sẵn có mà không hiểu\\nbản chất đằng sau của chúng. Việc sử dụng các thư viện cũng yêu cầu những kiến thức nhất\\nđịnh về việc lựa chọn và điều chỉnh tham số mô hình.\\n0.5 Source code đi kèm\\nToànbộsourcecodetrongcuốnsáchcóthểđượctìmthấytại https://github.com/tiepvupsu/\\nebookML_src. Các file có đuôi.ipynb là các file chứa code (Jupyter notebook). Các file có\\nđuôi .pdf, .png là các hình tạo được từ file.ipynb.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 6, 'page_label': 'v'}, page_content='v CHƯƠNG 0. LỜI TÁC GIẢ\\n0.6 Bố cục của cuốn sách\\nCuốn sách này được chia thành 8 phần và sẽ tiếp tục được cập nhật:\\nPhần I ôn tập lại cho bạn đọc những kiến thức quan trọng trong đại số tuyến tính, giải tích\\nma trận, xác suất, và hai phương pháp phổ biến trong việc ước lượng tham số cho các mô\\nhình machine learning thống kê.\\nPhần II giới thiệu các khái niệm cơ bản trong machine learning, kỹ thuật xây dựng vector\\nđặc trưng cho dữ liệu, một mô hình machine learning cơ bản–linear regression, và một hiện\\ntượng cần tránh khi xây dựng các mô hình machine learning.\\nPhần III giúp các bạn làm quen với các mô hình machine learning rất trực quan, không yêu\\ncầu nhiều kiến thức toán phức tạp. Qua đây, bạn đọc sẽ có cái nhìn đầu tiên về việc xây\\ndựng các mô hình machine learning.\\nPhần IV đề cập tới một lớp các thuật toán machine learning phổ biến nhất–neural networks,\\nlà nền tảng cho các mô hình deep learning phức tạp hiện nay. Phần này cũng giới thiệu một\\nkỹ thuật cơ bản và hữu dụng trong việc giải quyết các bài toán tối ưu không ràng buộc.\\nPhần V giới thiệu về các kỹ thuật thường dùng trong các hệ thống khuyến nghị sản phầm.\\nPhần VI giới thiệu các kỹ thuật giảm chiều dữ liệu.\\nPhần VII mang lại cho các bạn một cái nhìn bao quát hơn về tối ưu, đặc biệt là tối ưu lồi.\\nCác bài toán tối ưu lồi có ràng buộc cũng được giới thiệu trong phần này.\\nPhần VIII giới thiệu các thuật toán phân lớp dựa trên ý tưởng của support vector machine.\\n0.7 Các lưu ý về ký hiệu\\nCác ký hiệu toán học trong sách được mô tả ở Bảng 0.1 và đầu Chương 1. Các khung với\\nfont chữ có chiều rộng các ký tự như nhau được dùng để chứa các đoạn source code.\\ntext in a box with constant width represents source codes.\\nCác đoạn ký tự vớiconstant width, deep red, ’string, dark green’ được dùng để chỉ các\\nbiến, hàm số, chuỗi, v.v., trong các đoạn code.\\nĐóng khung và in nghiêng\\nCác khái niệm, định nghĩa, định lý, và lưu ý quan trọng được đóng khung và in nghiêng.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 6, 'page_label': 'v'}, page_content='biến, hàm số, chuỗi, v.v., trong các đoạn code.\\nĐóng khung và in nghiêng\\nCác khái niệm, định nghĩa, định lý, và lưu ý quan trọng được đóng khung và in nghiêng.\\nKý tự phân cách giữa phần nguyên và phần thập phân của các số thực là dấu chấm,\\n‘.’, thay vì dấu phẩy, ‘,’, như trong các tài liệu tiếng Việt khác. Cách làm này thống\\nnhất với các tài liệu tiếng Anh và các ngôn ngữ lập trình.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 7, 'page_label': 'vi'}, page_content='CHƯƠNG 0. LỜI TÁC GIẢ vi\\n0.8 Tham khảo thêm\\nCó rất nhiều những cuốn sách, khoá học, website hay về machine learning cũng như deep\\nlearning, trong đó, có một số mà tôi muốn đặc biệt nhấn mạnh:\\n0.8.1 Khoá học\\n1. Khóa họcMachine Learningcủa Andrew Ng trên Coursera (https://goo.gl/WBwU3K ).\\n2. Khoá học mới Deep Learning Specialization cũng của Andrew Ng ( https://goo.gl/\\nssXfYN).\\n3. Các khoá CS224n: Natural Language Processing with Deep Learning(https://goo.gl/\\n6XTNkH); CS231n: Convolutional Neural Networks for Visual Recognition (http://\\ncs231n.stanford.edu/); CS246: Mining Massive Data Sets (https://goo.gl/TEMQ9H )\\ncủa Stanford.\\n4. Introduction to Computer Science and Programming Using Python (https://goo.gl/\\n4nNXvJ) của MIT.\\n0.8.2 Sách\\n1. C. Bishop,Pattern Recognition and Machine Learning(https://goo.gl/pjgqRr ), Springer,\\n2006 [Bis06].\\n2. I. Goodfellowet al.,Deep Learning(https://goo.gl/sXaGwV ), MIT press, 2016 [GBC16].\\n3. J. Friedman et al., The Elements of Statistical Learning (https://goo.gl/Qh9EkB ),\\nSpringer, 2001 [FHT01].\\n4. Y. Abu-Mostafa et al., Learning from data(https://goo.gl/SRfNFJ ), AMLBook New\\nYork, 2012 [AMMIL12].\\n5. S.JDPrince, Computer Vision: Models, Learning, and Inference(https://goo.gl/9Fchf3 ),\\nCambridge University Press, 2012 [Pri12].\\n6. S. Boydet al., Convex Optimization (https://goo.gl/NomDpC ), Cambridge university\\npress, 2004 [BV04].\\nNgoài ra, các website Machine Learning Mastery (https://goo.gl/5DwGbU ), Pyimage-\\nsearch (https://goo.gl/5DwGbU ). Kaggle (https://www.kaggle.com/ ), Scikit-learn (http:\\n//scikit-learn.org/ ) cũng là các nguồn thông tin rất hữu ích.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 8, 'page_label': 'vii'}, page_content='vii CHƯƠNG 0. LỜI TÁC GIẢ\\n0.9 Đóng góp ý kiến\\nMọi ý kiến đóng góp, phản hồi, báo lỗi cho nội dung của cuốn sách được tốt hơn đều\\nđáng quý. Các bạn có thể gửi ý kiến tớivuhuutiep@gmail.com hoặc tạo mộtissue mới tại\\nhttps://goo.gl/zPYWKV .\\nCuốn sách sẽ tiếp tục được chỉnh sửa và thêm các chương mớicho tới khi bản sách giấy được\\nra mắt. Tất cả các bạn đã đặt ebook sẽ nhận được các bản cập nhật và một bản sách giấy\\n(dự tính vào giữa năm 2018).\\n0.10 Vấn đề bản quyền\\nToàn bộ nội dung trên blog cũng như cuốn sách này (bao gồm cả source code và hình ảnh\\nminh hoạ) đều thuộc bản quyền của tôi–Vũ Hữu Tiệp.\\nTôi rất mong muốn kiến thức của mình tạo ra đến được với nhiều bạn đọc. Tuy nhiên, tôi\\nkhông ủng hộ bất kỳ một hình thức sao chép không trích nguồn nào. Mọi trích dẫn cần được\\nnêu rõ tên cuốn sách, tên tác giả (Vũ Hữu Tiệp), và link gốc tới blog. Các bài viết trích dẫn\\nquá 25% toàn văn bất kỳ một post nào trên blog hoặc một chương trong cuốn sách này đều\\nkhông được phép, trừ trường hợp có sự đồng ý của tác giả.\\nMọi vấn đề liên quan đến sao chép, phân phát, đăng tải, sử dụng sách và blog, cũng như\\ntrao đổi, cộng tác, xin vui lòng liên hệ với tôi tại địa chỉ email vuhuutiep@gmail.com.\\n0.11 Lời cảm ơn\\nTrước hết, tôi xin cảm ơn bạn bè trong friend list Facebook của tôi đã nhiệt tình ủng hộ và\\nchia sẻ blog ngay ngày đầu blog được ra mắt. Tôi cũng xin chân thành cảm ơn bạn đọc blog\\nMachine Learning cơ bản và Facebook page Machine Learning cơ bản đã đồng hành cùng\\ntôi trong suốt một năm qua. Không có độc giả, chắc chắn tôi không có đủ động lực viết hơn\\n30 bài trên blog và rất nhiều các ghi chép nhanh trên Facebook page.\\nTrong quá trình viết blog, tôi nhận được rất rất nhiều sự ủng hộ của bạn đọc về cả vật chất\\nlẫn tinh thần. Không có những sự ủng hộ đó và những lời động viên viết sách, dự án này sẽ\\nkhông thể được bắt đầu. Khi tôi đã bắt đầu, số lượng pre-order cuốn sách này tăng lên từng\\nngày. Tôi thực sự biết ơn các bạn đã pre-order cũng những lời nhắn gửi ấm áp. Quan trọng'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 8, 'page_label': 'vii'}, page_content='không thể được bắt đầu. Khi tôi đã bắt đầu, số lượng pre-order cuốn sách này tăng lên từng\\nngày. Tôi thực sự biết ơn các bạn đã pre-order cũng những lời nhắn gửi ấm áp. Quan trọng\\nhơn hết, số lượng sách được đặt trước khi tôi hoàn thành khiến tôi tin rằng sản phẩm mình\\ntạo ra đã mang lại những giá trị nhất định cho cộng đồng. Những điều đó góp phần tôi duy\\ntrì tinh thần làm việc và cố gắng hết mình để tạo ra một sản phẩm chất lượng.\\nTôi may mắn nhận được những phản hồi tích cực cũng như các góp ý từ các thầy cô trong\\ncác trường đại học lớn trong và ngoài nước. Tôi xin được gửi lời cảm ơn tới thầy Phạm Ngọc\\nNam và cô Nguyễn Việt Hương (ĐH Bách Khoa Hà Nội), thầy Chế Viết Nhật Anh (ĐH\\nBách Khoa Tp.HCM), thầy Nguyễn Thanh Tùng (ĐH Thuỷ Lợi), thầy Trần Duy Trác (ĐH\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 9, 'page_label': 'viii'}, page_content='CHƯƠNG 0. LỜI TÁC GIẢ viii\\nJohns Hopkins), và anh Nguyễn Hồng Lâm (người hướng dẫn trong thời gian tôi thực tập\\ntại U.S. Army Research Lab).\\nTôi đặc biệt cảm ơn bạn Nguyễn Hoàng Linh và Hoàng Đức Huy, Đại học Waterloo–Canada,\\nnhững người bạn đã nhiệt tình giúp tôi xây dựng trang FundaML.com giúp bạn đọc có thể\\nhọc Python/Numpy trực tiếp trên trình duyệt. Tôi cũng xin cảm ơn bạn Lê Việt Hải–nghiên\\ncứu sinh ngành toán ứng dụng tại Penn State, và Đinh Hoàng Phong–kỹ sư phần mềm tại\\nFacebook–đã góp ý sửa đổi rất nhiều điểm về ngôn ngữ và toán trong các bản nháp. Tôi tin\\nrằng cuốn sách đã được sửa đổi rất nhiều so với phiên bản trên blog.\\nTôi xin cảm ơn ba người bạn thân–Nguyễn Tiến Cường, Nguyễn Văn Giang, Vũ Đình Quyền–\\nđã luôn động viên tôi và đóng góp nhiều phản hồi quý giá cho cuốn sách. Ngoài ra, tôi xin\\ncảm ơn những người bạn thân thiết khác của tôi tại Penn State đã luôn bên cạnh tôi trong\\nthời gian tôi thực hiện dự án, bao gồm gia đình anh Triệu Thanh Quang, gia đình anh\\nTrần Quốc Long, bạn thân (cũng là một blogger) Nguyễn Phương Chi, và các đồng nghiệp\\nJohn McKay, Tiantong Guo, Hojjat Mousavi, Omar Aldayel, và Mohammad Tofighi trong\\nPhòng nghiên cứu Xử lý Thông tin và Thuật toán (Information Processing and Algorithm\\nLaboratory–iPAL), ĐH bang Pennsylvania.\\nCuối cùng và quan trọng nhất, tôi xin cảm ơn gia đình tôi, những người luôn ủng hộ tôi vô\\nđiều kiện và hỗ trợ tôi hết mình trong quá trình tôi thực hiện dự án này.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 10, 'page_label': 'ix'}, page_content='ix CHƯƠNG 0. LỜI TÁC GIẢ\\n0.12 Bảng các ký hiệu\\nCác ký hiệu sử dụng trong sách được liệt kê trong Bảng 0.1\\nBảng 0.1: Bảng các ký hiệu\\nKý hiệu Ý nghĩa\\nx,y,N,k in nghiêng, thường hoặc hoa, là các số vô hướng\\nx,y in đậm, chữ thường, là các vector\\nX,Y in đậm, chữ hoa, là các ma trận\\nR tập hợp các số thực\\nN tập hợp các số tự nhiên\\nC tập hợp các số phức\\nRm tập hợp các vector thực cóm phần tử\\nRm×n tập hợp các ma trận thực cóm hàng, n cột\\nSn tập hợp các ma trận vuông đối xứng bậcn\\nSn\\n+ tập hợp các ma trận nửa xác định dương bậcn\\nSn\\n++ tập hợp các ma trận xác định dương bậcn\\n∈ phần tử thuộc tập hợp\\n∃ tồn tại\\n∀ mọi\\n≜ ký hiệu là/bởi. Ví dụa≜f(x) nghĩa là “ký hiệuf(x) bởi a”.\\nxi phần tử thứi (tính từ 1) của vectorx\\nsgn(x) hàm xác định dấu. Bằng 1 nếux≥0, bằng -1 nếux< 0.\\nexp(x) ex\\nlog(x) logarit tự nhiên của số thực dươngx\\naij phần tử hàng thứi, cột thứj của ma trậnA\\nAT chuyển vị của ma trậnA\\nAH chuyển vị liên hợp (Hermitian) của ma trận phứcA\\nA−1 nghịch đảo của ma trận vuôngA, nếu tồn tại\\nA† giả nghịch đảo của ma trận không nhất thiết vuôngA\\nA−T chuyển vị của nghịch đảo của ma trậnA, nếu tồn tại\\n∥x∥p ℓp norm của vectorx\\n∥A∥F Frobenius norm của ma trậnA\\ndiag(A) đường chéo chính của ma trậnA\\ntrace(A) trace của ma trậnA\\ndet(A) định thức của ma trận vuôngA\\nrank(A) hạng của ma trậnA\\no.w otherwise – trong các trường hợp còn lại\\n∂f\\n∂x đạo hàm của hàm sốf theo x∈R\\n∇xf gradient (đạo hàm) của hàm sốf theo x (x là vector hoặc ma trận)\\n∇2\\nxf đạo hàm bậc hai của hàm sốf theo x, còn được gọi làHessian\\n⊙ Hadamard product (elemenwise product). Phép nhân từng phần tử của hai vector hoặc ma trận cùng kích thước.\\n∝ tỉ lệ với\\nv.v. vân vân\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 12, 'page_label': '1'}, page_content='Mục lục\\nLời tác giả................................................................. i\\n0.1 Mục đích của cuốn sách ............................................... ii\\n0.2 Hướng tiếp cận của cuốn sách .......................................... iii\\n0.3 Đối tượng của cuốn sách............................................... iii\\n0.4 Yêu cầu về kiến thức .................................................. iv\\n0.5 Source code đi kèm ................................................... iv\\n0.6 Bố cục của cuốn sách ................................................. v\\n0.7 Các lưu ý về ký hiệu .................................................. v\\n0.8 Tham khảo thêm ..................................................... vi\\n0.9 Đóng góp ý kiến...................................................... vii\\n0.10 Vấn đề bản quyền .................................................... vii\\n0.11 Lời cảm ơn .......................................................... vii\\n0.12 Bảng các ký hiệu ..................................................... ix\\nPhần I Kiến thức toán cơ bản cho machine learning\\n1 Ôn tập Đại số tuyến tính............................................... 12\\n1.1 Lưu ý về ký hiệu ..................................................... 12'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 13, 'page_label': '2'}, page_content='Mục lục 2\\n1.2 Chuyển vị và Hermitian ............................................... 12\\n1.3 Phép nhân hai ma trận................................................ 13\\n1.4 Ma trận đơn vị và ma trận nghịch đảo................................... 14\\n1.5 Một vài ma trận đặc biệt khác ......................................... 15\\n1.6 Định thức ........................................................... 16\\n1.7 Tổ hợp tuyến tính, không gian sinh ..................................... 17\\n1.8 Hạng của ma trận .................................................... 19\\n1.9 Hệ trực chuẩn, ma trận trực giao ....................................... 20\\n1.10 Biễu diễn vector trong các hệ cơ sở khác nhau ............................ 21\\n1.11 Trị riêng và vector riêng ............................................... 22\\n1.12 Chéo hoá ma trận .................................................... 23\\n1.13 Ma trận xác định dương ............................................... 24\\n1.14 Chuẩn của vector và ma trận........................................... 26\\n2 Giải tích ma trận....................................................... 30\\n2.1 Đạo hàm của hàm trả về một số vô hướng ............................... 30\\n2.2 Đạo hàm của hàm trả về một vector .................................... 31\\n2.3 Tính chất quan trọng của đạo hàm ..................................... 32\\n2.4 Đạo hàm của các hàm số thường gặp ................................... 33\\n2.5 Bảng các đạo hàm thường gặp ......................................... 36\\n2.6 Kiểm tra đạo hàm .................................................... 36\\n3 Ôn tập Xác Suất ....................................................... 40\\n3.1 Xác Suất ............................................................ 40\\n3.2 Một vài phân phối thường gặp ......................................... 47\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 14, 'page_label': '3'}, page_content='3 Mục lục\\n4 Maximum Likelihood và Maximum A Posteriori........................ 52\\n4.1 Giới thiệu ........................................................... 52\\n4.2 Maximum likelihood estimation......................................... 53\\n4.3 Maximum a Posteriori................................................. 58\\n4.4 Tóm tắt ............................................................. 62\\nPhần II Tổng quan về machine learning\\n5 Các khái niệm cơ bản................................................... 64\\n5.1 Nhiệm vụ, T ......................................................... 64\\n5.2 Phép đánh giá, P..................................................... 67\\n5.3 Kinh nghiệm, E ...................................................... 67\\n5.4 Hàm mất mát và tham số mô hình...................................... 69\\n6 Giới thiệu về feature engineering....................................... 71\\n6.1 Giới thiệu ........................................................... 71\\n6.2 Mô hình chung cho các bài toán Machine Learning ....................... 72\\n6.3 Một số ví dụ về Feature Engineering .................................... 74\\n6.4 Transfer Learning cho bài toán phân loại ảnh............................. 79\\n6.5 Chuẩn hoá vector đặc trưng............................................ 81\\n6.6 Đọc thêm ........................................................... 82\\n7 Linear regression ....................................................... 83\\n7.1 Giới thiệu ........................................................... 83\\n7.2 Xây dựng và tối ưu hàm mất mát....................................... 84\\n7.3 Ví dụ trên Python .................................................... 86\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 15, 'page_label': '4'}, page_content='Mục lục 4\\n7.4 Thảo luận ........................................................... 89\\n8 Overfitting ............................................................. 91\\n8.1 Giới thiệu ........................................................... 91\\n8.2 Validation ........................................................... 94\\n8.3 Regularization ....................................................... 96\\n8.4 Đọc thêm ........................................................... 97\\nPhần III Khởi động\\n9 K-nearest neighbors .................................................... 100\\n9.1 Giới thiệu ........................................................... 100\\n9.2 Phân tích toán học ................................................... 101\\n9.3 Ví dụ trên cơ sở dữ liệu Iris ............................................ 105\\n9.4 Thảo luận ........................................................... 108\\n10 K-means clustering..................................................... 110\\n10.1 Giới thiệu ........................................................... 110\\n10.2 Phân tích toán học ................................................... 111\\n10.3 Ví dụ trên Python .................................................... 114\\n10.4 Phân nhóm chữ số viết tay ............................................ 117\\n10.5 Tách vật thể trong ảnh ................................................ 121\\n10.6 Image Compression (nén ảnh và nén dữ liệu nói chung) .................... 122\\n10.7 Thảo luận ........................................................... 123\\n11 Naive Bayes classifier................................................... 127\\n11.1 Naive Bayes classifier ................................................. 127\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 16, 'page_label': '5'}, page_content='5 Mục lục\\n11.2 Các phân phối thường dùng trong NBC ................................. 128\\n11.3 Ví dụ .............................................................. 130\\n11.4 Thảo luận ........................................................... 137\\nPhần IV Neural networks\\n12 Gradient descent....................................................... 140\\n12.1 Giới thiệu ........................................................... 140\\n12.2 GD cho hàm một biến................................................. 141\\n12.3 GD cho hàm nhiều biến ............................................... 145\\n12.4 GD với momentum ................................................... 148\\n12.5 Nesterov accelerated gradient .......................................... 151\\n12.6 Stochastic gradient descent ............................................ 152\\n12.7 Thảo luận ........................................................... 155\\n13 Perceptron learning algorithm.......................................... 156\\n13.1 Giới thiệu ........................................................... 156\\n13.2 Thuật toán perceptron ................................................ 157\\n13.3 Ví dụ và minh hoạ trên Python ........................................ 160\\n13.4 Mô hình neural network đầu tiên ....................................... 162\\n13.5 Thảo Luận .......................................................... 163\\n14 Logistic regression...................................................... 165\\n14.1 Giới thiệu ........................................................... 165\\n14.2 Hàm mất mát và phương pháp tối ưu ................................... 167\\n14.3 Triển khai thuật toán trên Python ...................................... 169\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 17, 'page_label': '6'}, page_content='Mục lục 6\\n14.4 Tính chất của logistic regression ........................................ 172\\n14.5 Bài toán phân biệt hai chữ số viết tay .................................. 174\\n14.6 Bộ phân lớp nhị phân cho bài toán phân lớp đa lớp ....................... 175\\n14.7 Thảo luận .......................................................... 177\\n15 Softmax regression ..................................................... 180\\n15.1 Giới thiệu ........................................................... 180\\n15.2 Softmax function .................................................... 181\\n15.3 Hàm mất mát và phương pháp tối ưu ................................... 184\\n15.4 Ví dụ trên Python .................................................... 189\\n15.5 Thảo luận .......................................................... 191\\n16 Multilayer neural network và backpropagation.......................... 193\\n16.1 Giới thiệu ........................................................... 193\\n16.2 Các ký hiệu và khái niệm .............................................. 196\\n16.3 Activation function–Hàm kích hoạt ..................................... 197\\n16.4 Backpropagation ..................................................... 200\\n16.5 Ví dụ trên Python .................................................... 204\\n16.6 Tránh overfitting cho neural network bằng weight decay ................... 209\\n16.7 Đọc thêm ........................................................... 211\\nPhần V Recommendation systems–Hệ thống khuyến nghị\\n17 Content-based recommendation system................................. 214\\n17.1 Giới thiệu ........................................................... 214\\n17.2 Utility matrix ........................................................ 215\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 18, 'page_label': '7'}, page_content='7 Mục lục\\n17.3 Content-based recommendation......................................... 217\\n17.4 Bài toán với cơ sở dữ liệu MovieLens 100k ............................... 220\\n17.5 Thảo luận ........................................................... 224\\n18 Neighborhood-based collaborative filtering.............................. 225\\n18.1 Giới thiệu ........................................................... 225\\n18.2 User-user collaborative filtering ........................................ 226\\n18.3 Item-item collaborative filtering ........................................ 230\\n18.4 Lập trình trên Python ................................................ 232\\n18.5 Thảo luận ........................................................... 235\\n19 Matrix factorization collaborative filtering.............................. 236\\n19.1 Giới thiệu ........................................................... 236\\n19.2 Xây dựng và tối ưu hàm mất mát....................................... 238\\n19.3 Lập trình Python .................................................... 240\\n19.4 Thảo luận ........................................................... 243\\nPhần VI Dimensionality reduction–Giảm chiều dữ liệu\\n20 Singular value decomposition........................................... 246\\n20.1 Giới thiệu ........................................................... 246\\n20.2 Singular value decomposition........................................... 247\\n20.3 SVD cho image compression ........................................... 252\\n20.4 Thảo luận ........................................................... 253\\n21 Principal component analysis........................................... 254\\n21.1 Principal component analysis........................................... 254\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 19, 'page_label': '8'}, page_content='Mục lục 8\\n21.2 Các bước thực hiện PCA .............................................. 259\\n21.3 Mối quan hệ giữa PCA và SVD......................................... 259\\n21.4 Làm thế nào để chọn số chiều của dữ liệu mới ............................ 261\\n21.5 Lưu ý về tính PCA trong các bài toán thực tế ............................ 262\\n21.6 Một vài ứng dụng của PCA ............................................ 263\\n21.7 Thảo luận ........................................................... 266\\n22 Linear discriminant analysis............................................ 268\\n22.1 Giới thiệu ........................................................... 268\\n22.2 LDA cho bài toán phân lớp nhị phân .................................... 270\\n22.3 LDA cho bài toán phân lớp nhiều lớp ................................... 273\\n22.4 Ví dụ trên Python .................................................... 276\\n22.5 Thảo luận ........................................................... 278\\nPhần VII Convex optimization–Tối ưu lồi\\n23 Tập lồi và hàm lồi...................................................... 282\\n23.1 Giới thiệu ........................................................... 282\\n23.2 Tập lồi – Convex sets ................................................. 283\\n23.3 Convex functions ..................................................... 288\\n23.4 Tóm tắt ............................................................. 298\\n24 Bài toán tối ưu lồi...................................................... 299\\n24.1 Giới thiệu ........................................................... 299\\n24.2 Nhắc lại bài toán tối ưu ............................................... 303\\n24.3 Bài toán tối ưu lồi .................................................... 305\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 20, 'page_label': '9'}, page_content='9 Mục lục\\n24.4 Linear programming .................................................. 307\\n24.5 Quadratic programming ............................................... 310\\n24.6 Geometric Programming............................................... 313\\n24.7 Tóm tắt ............................................................. 316\\n25 Duality................................................................. 317\\n25.1 Giới thiệu ........................................................... 317\\n25.2 Hàm đối ngẫu Lagrange ............................................... 318\\n25.3 Bài toán đối ngẫu Lagrange ............................................ 321\\n25.4 Các điều kiện tối ưu .................................................. 323\\n25.5 Tóm tắt ............................................................. 325\\nPhần VIII Support vector machines\\n26 Support vector machine................................................ 328\\n26.1 Giới thiệu ........................................................... 328\\n26.2 Xây dựng bài toán tối ưu cho SVM ..................................... 330\\n26.3 Bài toán đối ngẫu của SVM ........................................... 332\\n26.4 Lập trình tìm nghiệm cho SVM ........................................ 336\\n26.5 Tóm tắt và thảo luận ................................................. 338\\n27 Soft-margin support vector machine.................................... 339\\n27.1 Giới thiệu ........................................................... 339\\n27.2 Phân tích toán học ................................................... 340\\n27.3 Bài toán đối ngẫu Lagrange ........................................... 342\\n27.4 Bài toán tối ưu không ràng buộc chosoft-margin SVM ................... 345\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 21, 'page_label': '10'}, page_content='Mục lục 10\\n27.5 Lập trình vớisoft-margin SVM......................................... 349\\n27.6 Tóm tắt và thảo luận ................................................. 353\\n28 Kernel support vector machine......................................... 355\\n28.1 Giới thiệu ........................................................... 355\\n28.2 Cơ sở toán học ...................................................... 357\\n28.3 Hàm số kernel ....................................................... 359\\n28.4 Ví dụ minh họa ...................................................... 361\\n28.5 Tóm tắt ............................................................ 363\\n29 Multi-class support vector machine..................................... 364\\n29.1 Giới thiệu ........................................................... 364\\n29.2 Xây dựng hàm mất mát .............................................. 368\\n29.3 Tính toán hàm mất mát và đạo hàm của nó ............................. 371\\n29.4 Thảo luận .......................................................... 378\\nA Phương pháp nhân tử Lagrange........................................ 379\\nTài liệu tham khảo......................................................... 383\\nIndex ...................................................................... 386\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 22, 'page_label': '11'}, page_content='Phần I\\nKiến thức toán cơ bản cho machine learning'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 23, 'page_label': '12'}, page_content='Chương 1\\nÔn tập Đại số tuyến tính\\n1.1 Lưu ý về ký hiệu\\nTrong các bài viết của tôi, các số vô hướng được biểu diễn bởi các chữ cái viết ở dạng in\\nnghiêng, có thể viết hoa, ví dụx1,N,y,k . Các vector được biểu diễn bằng các chữ cái thường\\nin đậm, ví dụy,x1. Nếu không giải thích gì thêm, các vector được mặc định hiểu là các\\nvector cột. Các ma trận được biểu diễn bởi các chữ viết hoa in đậm, ví dụX,Y,W.\\nĐối với vector,x = [x1,x2,...,x n] được hiểu là một vector hàng, vàx = [x1; x2; ... ; xn] được\\nhiểu là vector cột. Chú ý sự khác nhau giữa dấu phẩy (,) và dấu chấm phẩy (;). Đây chính\\nlà ký hiệu được Matlab sử dụng. Nếu không giải thích gì thêm, một chữ cái viết thường in\\nđậm được hiểu là một vector cột.\\nTương tự, trong ma trận,X = [x1,x2,..., xn] được hiểu là các vector cộtxj được đặt cạnh\\nnhau theo thứ tự từ trái qua phải để tạo ra ma trậnX. Trong khiX = [x1; x2; ... ; xm] được\\nhiểu là các vectorxi được đặt chồng lên nhau theo thứ tự từ trên xuống dưới dể tạo ra ma\\ntrận X. Các vector được ngầm hiểu là có kích thước phù hợp để có thể xếp cạnh hoặc xếp\\nchồng lên nhau. Phần tử ở hàng thứi, cột thứj được ký hiệu làxij.\\nCho một ma trậnW, nếu không giải thích gì thêm, chúng ta hiểu rằngwi là vector cột\\nthứ i của ma trận đó. Chú ý sự tương ứng giữa ký tự viết hoa và viết thường.\\n1.2 Chuyển vị và Hermitian\\nMột toán tử quan trọng của ma trận hay vector là toán tửchuyển vị (transpose).\\nCho A ∈Rm×n, ta nóiB ∈Rn×m là chuyển vị củaA nếu bij = aji, ∀1 ≤i≤n,1 ≤j ≤m.\\nMột cách ngắn gọn, chuyển vị của một ma trận là một ma trận nhận được từ ma trận cũ\\nthông qua phép phản xạ gương qua đường chéo chính của ma trận ban đầu. Toán tử chuyển'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 24, 'page_label': '13'}, page_content='13 CHƯƠNG 1. ÔN TẬP ĐẠI SỐ TUYẾN TÍNH\\nvị thường được ký hiểu bởi chữT, thoặc ký tự⊤. Trong cuốn sách này, chúng ta sẽ sử dụng\\nchữ cáiT. Ví dụ, chuyển vị của một vectorx được ký hiệu làxT; chuyển vị của một ma trận\\nA được ký hiệu làAT. Cụ thể:\\nx =\\n\\uf8ee\\n\\uf8ef\\uf8ef\\uf8ef\\uf8f0\\nx1\\nx2\\n...\\nxm\\n\\uf8f9\\n\\uf8fa\\uf8fa\\uf8fa\\uf8fb⇒xT =\\n[\\nx1 x2 ...x m\\n]\\n; A =\\n\\uf8ee\\n\\uf8ef\\uf8ef\\uf8ef\\uf8f0\\na11 a12 ... a1n\\na21 a22 ... a2n\\n... ... ... ...\\nam1 am2 ...a mn\\n\\uf8f9\\n\\uf8fa\\uf8fa\\uf8fa\\uf8fb⇒AT =\\n\\uf8ee\\n\\uf8ef\\uf8ef\\uf8ef\\uf8f0\\na11 a21 ...a m1\\na12 a22 ...a m2\\n... ... ... ...\\na1n a2n ...a mn\\n\\uf8f9\\n\\uf8fa\\uf8fa\\uf8fa\\uf8fb\\nNếu A ∈Rm×n thì AT ∈Rn×m. NếuAT = A, ta nóiA là mộtma trận đối xứng(symmetric\\nmatrix).\\nTrong trường hợp vector hay ma trận có các phần tử là số phức, việc lấy chuyển vị thường\\nđi kèm với việc lấy liên hợp phức. Tức là ngoài việc đổi vị trí của các phần tử, ta còn lấy\\nliên hợp phức của các phần tử đó. Tên gọi của phép toán chuyển vị và lấy liên hợp này còn\\nđược gọi làchuyển vị liên hợp(conjugate transpose), và thường được ký hiệu bằng chữH\\nthay cho chữT. Chuyển vị liên hợp của một ma trậnA được ký hiệu làAH (cũng được đọc\\nlà A Hermitian).\\nCho A ∈Cm×n, ta nóiB ∈Cn×m là chuyển vị liên hợp củaA nếu bij = aji, ∀1 ≤i≤n,1 ≤\\nj ≤m, trong đóa là liên hiệp phức củaa.\\nVí dụ:\\nA =\\n[1 + 2i 3 −4i\\ni 2\\n]\\n⇒AH =\\n[1 −2i −i\\n3 + 4i 2\\n]\\n; x =\\n[2 + 3i\\n2i\\n]\\n⇒xH =\\n[\\n2 −3i −2i\\n]\\n(1.1)\\nNếu A,x là các ma trận và vector thực thìAH = AT,xH = xT.\\nNếu chuyển vị liên hợp của một ma trận phức bằng với chính nó,AH = A, thì ta nói ma\\ntrận đó làHermitian.\\n1.3 Phép nhân hai ma trận\\nCho hai ma trậnA ∈Rm×n,B ∈Rn×p, tích của hai ma trận được ký hiệu làC = AB ∈Rm×p\\ntrong đó phần tử ở hàng thứi, cột thứj của ma trận kết quả được tính bởi:\\ncij =\\nn∑\\nk=1\\naikbkj, ∀1 ≤i≤m,1 ≤j ≤p (1.2)\\nĐể nhân được hai ma trận, số cột của ma trận thứ nhất phải bằng số hàng của ma trận thứ\\nhai. Trong ví dụ trên, chúng đều bằngn.\\nMột vài tính chất của phép nhân hai ma trận (giả sử kích thước các ma trận là phù hợp để\\ncác phép nhân ma trận tồn tại):\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 25, 'page_label': '14'}, page_content='CHƯƠNG 1. ÔN TẬP ĐẠI SỐ TUYẾN TÍNH 14\\n1. Phép nhân ma trận không có tính chất giao hoán. Thông thường (không phải luôn luôn),\\nAB ̸= BA. Thậm chí, trong nhiều trường hợp, các phép tính này không tồn tại vì kích\\nthước các ma trận lệch nhau.\\n2. Phép nhân ma trận có tính chất kết hợp:ABC = (AB)C = A(BC)\\n3. Phép nhân ma trận có tính chất phân phối đối với phép cộng:A(B + C) = AB + AC.\\n4. Chuyển vị của một tích bằng tích các chuyển vị theo thứ tự ngược lại. Điều tương tự xảy\\nra với Hermitian của một tích:\\n(AB)T = BTAT; ( AB)H = BHAH (1.3)\\nTheo định nghĩa trên, bằng cách coi vector là một trường hợp đặc biệt của ma trận, tích vô\\nhướng của hai vector (inner product) x,y ∈Rn được định nghĩa là:\\nxTy = yTx =\\nn∑\\ni=1\\nxiyi (1.4)\\nChú ý,xHy = (yHx)H = yHx. Chúng bằng nhau khi và chỉ khi chúng là các số thực. Nếu\\ntích vô hướng của hai vector khác không bằng không, hai vector đó vuông góc với nhau.\\nxHx ≥0, ∀x ∈Cn vì tích của một số phức với liên hiệp của nó luôn là một số không âm.\\nPhép nhân của một ma trậnA ∈Rm×n với một vectorx ∈Rn là một vectorb ∈Rm:\\nAx = b, với bi = A:,ix (1.5)\\nvới A:,i là vector hàng thứi của A.\\nNgoài ra, một phép nhân khác được gọi làHadamard (hay element-wise) hay được sử dụng\\ntrong Machine Learning. Tích Hadamard của hai ma trậncùng kích thướcA,B ∈Rm×n,\\nký hiệu làC = A ⊙B ∈Rm×n, trong đó:\\ncij = aijbij (1.6)\\n1.4 Ma trận đơn vị và ma trận nghịch đảo\\n1.4.1 Ma trận đơn vị\\nĐường chéo chínhcủa một ma trận là tập hợp các điểm có chỉ số hàng và cột là như nhau.\\nCách định nghĩa này cũng có thể được định nghĩa cho một ma trận không vuông. Cụ thể, nếu\\nA ∈Rm×n thì đường chéo chính củaA bao gồm{a11,a22,...,a pp}, trong đóp= min{m,n}.\\nMột ma trận đơn vị bậcn là một ma trận đặc biệt trongRn×n với các phần tử trên đường\\nchéo chính bằng 1, các phần tử còn lại bằng 0. Ma trận đơn vị thường được ký hiệu làI\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 26, 'page_label': '15'}, page_content='15 CHƯƠNG 1. ÔN TẬP ĐẠI SỐ TUYẾN TÍNH\\n(identity matrix). Nếu làm việc với nhiều ma trận đơn vị với bậc khác nhau, ta thường ký\\nkiệu In cho ma trận đơn vị bậcn. Dưới đây là ma trận đơn vị bậc 3 và bậc 4:\\nI3 =\\n\\uf8ee\\n\\uf8f0\\n1 0 0\\n0 1 0\\n0 0 1\\n\\uf8f9\\n\\uf8fb, I4 =\\n\\uf8ee\\n\\uf8ef\\uf8ef\\uf8f0\\n1 0 0 0\\n0 1 0 0\\n0 0 1 0\\n0 0 0 1\\n\\uf8f9\\n\\uf8fa\\uf8fa\\uf8fb (1.7)\\nMa trận đơn vị có tính chất đặc biệt trong phép nhân. NếuA ∈Rm×n,B ∈Rn×m và I là\\nma trận đơn vị bậcn, ta có:AI = A, IB = B.\\nVới mọi vectorx ∈Rn, ta cóInx = x.\\n1.4.2 Ma trận nghịch đảo\\nCho một ma trận vuôngA ∈Rn×n, nếu tồn tại ma trận vuôngB ∈Rn×n sao choAB = In,\\nthì ta nóiA là khả nghịch (invertible, nonsingular hoặc nondegenerate), vàB được gọi là\\nma trận nghịch đảo(inverse matrix ) củaA. Nếu không tồn tại ma trậnB thoả mãn điều\\nkiện trên, ta nói rằng ma trậnA là không khả nghịch (singular hoặc degenerate).\\nNếu A là khả nghịch, ma trận nghịch đảo của nó thường được ký hiệu làA−1. Ta cũng có:\\nA−1A = AA−1 = I (1.8)\\nMa trận nghịch đảo thường được sử dụng để giải hệ phương trình tuyến tính. Giả sử rằng\\nA ∈Rn×n là một ma trận khả nghịch và một vector bất kỳb ∈Rn. Khi đó, phương trình:\\nAx = b (1.9)\\ncó nghiệm duy nhất làx = A−1b. Thật vậy, nhân bên trái cả hai vế của phương trình với\\nA−1, ta cóAx = b ⇔A−1Ax = A−1b ⇔x = A−1b.\\nNếu A không khả nghịch, thậm chí không vuông, phương trình tuyến tính (1.9) có thể không\\ncó nghiệm hoặc có vô số nghiệm.\\nGiả sử các ma trận vuôngA,B là khả nghịch, khi đó tích của chúng cũng khả nghịch, và\\n(AB)−1 = B−1A−1. Quy tắc này cũng khá giống với cách tính ma trận chuyển vị của tích\\ncác ma trận.\\n1.5 Một vài ma trận đặc biệt khác\\n1.5.1 Ma trận đường chéo\\nMa trận đường chéo(diagonal matrix) là ma trận chỉ có các thành phần trên đường chéo\\nchính là khác không. Định nghĩa này cũng có thể được áp dụng lên các ma trận không vuông.\\nMa trận không (tất cả các phần tử bằng 0) và đơn vị là các ma trận đường chéo. Một vài ví\\ndụ về các ma trận đường chéo\\n[\\n1\\n]\\n,\\n[2 0\\n0 0\\n]\\n,\\n[1 0 0\\n0 2 0\\n]\\n,\\n\\uf8ee\\n\\uf8f0\\n−1 0\\n0 2\\n0 0\\n\\uf8f9\\n\\uf8fb.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 27, 'page_label': '16'}, page_content='CHƯƠNG 1. ÔN TẬP ĐẠI SỐ TUYẾN TÍNH 16\\nVới các ma trận đường chéo vuông, thay vì viết cả ma trận, ta có thể chỉ liệt kê các thành\\nphần trên đường chéo. Ví dụ, một ma trận đường chéo vuôngA ∈Rm×m có thể được ký\\nhiệu là diag(a11,a22,...,a mm) với aii là phần tử hàng thứi, cột thứi của ma trậnA.\\nTích, tổng của hai ma trận đường chéo vuông cùng bậc là một ma trận đường chéo. Một\\nma trận đường chéo vuông là khả nghịch nếu và chỉ nếu mọi phần tử trên đường chéo chính\\nlà khác không. Nghịch đảo của một ma trận đường chéo khả nghịch cũng là một ma trận\\nđường chéo. Cụ thể hơn,(diag(a1,a2,...,a n))−1 = diag(a−1\\n1 ,a−1\\n2 ,...,a −1\\nn ).\\n1.5.2 Ma trận tam giác\\nMột ma trận vuông được gọi làma trận tam giác trên(upper triangular matrix) nếu tất cả\\ncác thành phầnnằm phía dưới đường chéo chính bằng 0. Tương tự, một ma trận vuông được\\ngọi làma trận tam giác dưới(lower triangular matrix) nếu tất cả các thành phầnnằm phía\\ntrên đường chéo chính bằng 0.\\nCác hệ phương trình tuyến tính mà ma trận hệ số có dạng tam giác thường được quan tâm\\nvì chúng có thể được giải với chi phí tính toán thấp (low computational cost). Xét hệ:\\n\\uf8f1\\n\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f2\\n\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f3\\na11x1+ a12x2+ ···+ a1,n−1xn−1+ a1nxn = b1\\na22x2+ ···+ a2,n−1xn−2+ a2nxn = b2\\n... ... ... ...\\nan−1,n−1xn−1+ an−1,nxn = bn−1\\nannxn = bn\\n(1.10)\\nHệ này có thể được viết gọn dưới dạngAx = b với A là một ma trận tam giác trên. Nhận\\nthấy rằng phương trình này có thể giải mà không cần tính ma trận nghịch đảoA−1 (quá\\ntrình tính ma trận nghịch đảo thường tốn khá nhiều thời gian), thay vào đó, ta có thể giải\\nxn dựa vào phương trình cuối cùng. Sau khi cóxn, ta có thể thay nó vào phương trình gần\\ncuối để suy raxn−1. Tiếp tục quá trình này, ta sẽ có nghiệm cuối cùngx. Quá trình giải từ\\ncuối lên đầu và thay toàn bộ các thành phần đã tìm được vào phương trình hiện tại được\\ngọi làback substitution. Nếu ma trận hệ số là một ma trận tam giác dưới, hệ phương trình\\ncó thể được giải bằng một quá trình ngược lại – lần lượt tínhx1 rồi x2,...,x n, quá trình'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 27, 'page_label': '16'}, page_content='gọi làback substitution. Nếu ma trận hệ số là một ma trận tam giác dưới, hệ phương trình\\ncó thể được giải bằng một quá trình ngược lại – lần lượt tínhx1 rồi x2,...,x n, quá trình\\nnày được gọi làforward substitution.\\n1.6 Định thức\\n1.6.1 Định nghĩa\\nĐịnh thức của một ma trận vuôngA được ký hiệu làdet(A) hoặc det A. Có nhiều cách\\nđịnh nghĩa khác nhau củađịnh thức (determinant). Chúng ta sẽ sử dụng cách định nghĩa\\ndựa trên quy nạp theo bậcn của ma trận.\\nVới n= 1, det(A) chính là phần tử duy nhất của ma trận đó.\\nVới một ma trận vuông bậcn> 1:\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 28, 'page_label': '17'}, page_content='17 CHƯƠNG 1. ÔN TẬP ĐẠI SỐ TUYẾN TÍNH\\nA =\\n\\uf8ee\\n\\uf8ef\\uf8ef\\uf8ef\\uf8f0\\na11 a12 ... a1n\\na21 a22 ... a2n\\n... ... ... ...\\nam1 am2 ...a mn\\n\\uf8f9\\n\\uf8fa\\uf8fa\\uf8fa\\uf8fb⇒det(A) =\\nn∑\\nj=1\\n(−1)i+jaij det(Aij) (1.11)\\nTrong đó1 ≤i≤n bất kỳ vàAij là phần bù đại số củaA ứng với phần tử ở hàngi, cộtj.\\nPhần bù đại số này là mộtma trận concủa A nhận được từA bằng cách xoá hàng thứi\\nvà cột thứj của nó. Đây chính là cách tính định thức dựa trên cách khai triển hàng thứi\\ncủa ma trận1.\\n1.6.2 Tính chất\\n1. det(A) = det(AT): Một ma trận bất kỳ và chuyển vị của nó có định thức như nhau.\\n2. Định thức của một ma trận đường chéo (và vuông) bằng tích các phần tử trên đường chéo\\nchính. Nói cách khác, nếuA = diag(a1,a2,...,a n), thìdet(A) = a1a2 ...a n.\\n3. Định thức của một ma trận đơn vị bằng 1.\\n4. Định thức của một tích bằng tích các định thức.\\ndet(AB) = det(A) det(B) (1.12)\\nvới A,B là hai ma trận vuông cùng chiều.\\n5. Nếu một ma trận có một hàng hoặc một cột là một vector0, thì định thức của nó bằng 0.\\n6. Một ma trận là khả nghịch khi và chỉ khi định thức của nó khác 0.\\n7. Nếu một ma trận khả nghịch, định thức của ma trận nghịch đảo của nó bằng nghịch đảo\\nđịnh thức của nó.\\ndet(A−1) = 1\\ndet(A) vì det(A) det(A−1) = det(AA−1) = det(I) = 1. (1.13)\\n1.7 Tổ hợp tuyến tính, không gian sinh\\n1.7.1 Tổ hợp tuyến tính\\nCho các vector khác khônga1,..., an ∈Rm và các số thựcx1,...,x n ∈R, vector:\\nb = x1a1 + x2a2 + ··· + xnan (1.14)\\nđược gọi là mộttổ hợp tuyến tính(linear combination) củaa1,..., an. Xét ma trậnA =\\n[a1,a2,..., an] ∈Rm×n và x = [x1,x2,...,x n]T, biểu thức (1.14) có thể được viết lại thành\\nb = Ax. Ta có thể nói rằngb là một tổ hợp tuyến tính các cột củaA.\\n1 Việc ghi nhớ định nghĩa này không thực sự quan trọng bằng việc ta cần nhớ một vài tính chất của nó.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 29, 'page_label': '18'}, page_content='CHƯƠNG 1. ÔN TẬP ĐẠI SỐ TUYẾN TÍNH 18\\nTập hợp tất cả các vector có thể biểu diễn được dưới dạng một tổ hợp tuyến tính của các\\ncột của một ma trận được gọi làkhông gian sinh(span space, hoặc gọn làspan) các cột của\\nma trận đó. Không gian sinh của một hệ các vector thường được ký hiệu là span(a1,..., an).\\nNếu phương trình:\\n0 = x1a1 + x2a2 + ··· + xnan (1.15)\\ncó nghiệm duy nhấtx1 = x2 = ··· = xn = 0, ta nói rằng hệ{a1,a2,..., an}là một hệđộc\\nlập tuyến tính (linear independence). Ngược lại, Nếu tồn tạixi ̸= 0 sao cho phương trình\\ntrên thoả mãn, ta nói rằng đó là một hệphụ thuộc tuyến tính(linear dependence).\\n1.7.2 Tính chất\\n1. Một hệ là phụ thuộc tuyến tính nếu và chỉ nếu tồn tại một vector trong hệ đó là tổ hợp\\ntuyến tính của các vector còn lại.Thật vậy, giả sử phương trình (1.15) có nghiệm khác\\nkhông. Giả sử hệ số khác không làxi, ta sẽ có:\\nai = −x1\\nxi\\na1 + ··· + −xi−1\\nxi\\nai−1 + −xi+1\\nxi\\nai+1 + ... −xn\\nxi\\nan (1.16)\\ntức ai là một tổ hợp tuyến tính của các vector còn lại.\\n2. Tập con khác rỗng của một hệ độc lập tuyến tính là một hệ độc lập tuyến tính.\\n3. Tập hợp các cột của một ma trận khả nghịch tạo thành một hệ độc lập tuyến tính.\\nGiả sử ma trậnA khả nghịch, phương trìnhAx = 0 có nghiệmduy nhấtx = A−10 = 0.\\nVì vậy, các cột củaA tạo thành một hệ độc lập tuyến tính.\\n4. Nếu A là một ma trận cao (tall matrix), tức số hàng lớn hơn số cột,m >n, thì tồn tại\\nvector b sao choAx = b vô nghiệm.\\nViệc này có thể dễ hình dung trong không gian ba chiều. Không gian sinh của một vector\\nlà một đường thẳng, không gian sinh của hai vector độc lập tuyến tính là một mặt phẳng,\\ntức chỉ biểu diễn được các vector nằm trong mặt phẳng đó.\\nTa cũng có thể chứng minh tính chất này bằng phản chứng. Giả sử mọi vector trong\\nkhông gianm chiều đều nằm trong không gian sinh của một hện<m vector là các cột\\ncủa một ma trậnA. Xét các cột của ma trận đơn vị bậcm. Vì mọi cột của ma trận này\\nđều có thể biểu diễn dưới dạng một tổ hợp tuyến tính củan vector đã cho nên phương'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 29, 'page_label': '18'}, page_content='của một ma trậnA. Xét các cột của ma trận đơn vị bậcm. Vì mọi cột của ma trận này\\nđều có thể biểu diễn dưới dạng một tổ hợp tuyến tính củan vector đã cho nên phương\\ntrình AX = I có nghiệm. Nếu ta thêm các vào các cột bằng 0 và các hàng bằng 0 vàoA\\nvà X để được các ma trận vuông, ta sẽ có\\n[\\nA 0\\n][X\\n0\\n]\\n= I. Việc này chỉ ra rằng\\n[\\nA 0\\n]\\nlà\\nmột ma trận khả nghịch trong khi nó có các cột bằng 0. Đây là một điều vô lý vì theo\\ntính chất của định thức, định thức của\\n[\\nA 0\\n]\\nbằng 0.\\n5. Nếu n > m, thì n vector bất kỳ trong không gianm chiều tạo thành một hệ phụ thuộc\\ntuyến tính. Xin được bỏ qua phần chứng minh.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 30, 'page_label': '19'}, page_content='19 CHƯƠNG 1. ÔN TẬP ĐẠI SỐ TUYẾN TÍNH\\n1.7.3 Cơ sở của một không gian\\nMột hệ các vector{a1,..., an}trong không gian vectormchiều V = Rm được gọi là mộtcơ\\nsở (basic) nếu hai điều kiện sau được thoả mãn:\\n1. V ≡span(a1,..., an)\\n2. {a1,..., an}là một hệ độc lập tuyến tính.\\nKhi đó, mọi vectorb ∈V đều có thể biểu diễnduy nhất dưới dạng một tổ hợp tuyến tính\\ncủa cácai.\\nTừ hai tính chất cuối ở mục trước, ta có thể suy ra rằngm= n.\\n1.7.4 Range và Null space\\nVới mỗi ma trậnA ∈Rm×n, có hai không gian con quan trọng ứng với ma trận này.\\n1. Range củaA. Range củaA, được định nghĩa là:\\nR(A) = {y ∈Rm : ∃x ∈Rn,Ax = y} (1.17)\\nNói cách khác,R(A) là tập hợp các điểm là tổ hợp tuyến tính của các cột củaA, hay\\nchính là không gian sinh (span) của các cột củaA.R(A) là một không gian con củaRm\\nvới số chiều chính bằng sô lượng lớn nhất các cột củaA độc lập tuyến tính.\\n2. Null củaA, ký hiệu làN(A), được định nghĩa là:\\nN(A) = {x ∈Rn : Ax = 0} (1.18)\\nMỗi vector trongN(A) chính là một bộ các hệ số làm cho tổ hợp tuyến tính các cột của\\nA tạo thành một vector 0.N(A) có thể được chứng minh là một không gian con trong\\nRn. Khi các cột củaA là độc lập tuyến tính, theo định nghĩa,N(A) = {0}(chỉ gồm\\nvector 0).\\nR(A) và N(A) là các không gian con vector với số chiều lần lượt là dim(R(A)) và\\ndim(N(A)), ta có tính chất quan trọng sau đây:\\ndim(R(A)) + dim(N(A)) = n (1.19)\\n1.8 Hạng của ma trận\\nXét một ma trậnA ∈Rm×n. Hạng (rank) của ma trận này, ký hiệu là rank(A), được định\\nnghĩa là số lượng lớn nhất các cột của nó tạo thành một hệ độc lập tuyến tính.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 31, 'page_label': '20'}, page_content='CHƯƠNG 1. ÔN TẬP ĐẠI SỐ TUYẾN TÍNH 20\\nCác tính chất quan trọng của hạng:\\n1. Một ma trận có hạng bằng 0 khi và chỉ khi nó là ma trận 0.\\n2. rank(A) = rank(AT). Hạng của một ma trận bằng hạng của ma trận chuyển vị. Nói cách\\nkhác, số lượng lớn nhất các cột độc lập tuyến tính của một ma trận bằng với số lượng\\nlớn nhất các hàng độc lập tuyến tính của ma trận đó. Từ đây ta suy ra:\\n3. Nếu A ∈Rm×n, thì rank(A) ≤min(m,n) vì theo định nghĩa, hạng của một ma trận\\nkhông thể lớn hơn số hàng hoặc số cột của nó.\\n4. rank(AB) ≤min(rank(A),rank(B))\\n5. rank(A + B) ≤rank(A) + rank(B). Điều này chỉ ra rằng một ma trận có hạng bằngk\\nkhông được biểu diễn dưới dạng ít hơnkma trận có hạng bằng 1. Đến bài Singular Value\\nDecomposition, chúng ta sẽ thấy rằng một ma trận có hạng bằngkcó thể biểu diễn được\\ndưới dạng đúngk ma trận có hạng bằng 1.\\n6. Bất đẳng thức Sylvester về hạng: NếuA ∈Rm×n,B ∈Rn×k, thì\\nrank(A) + rank(B) −n≤rank(AB)\\nXét một ma trận vuôngA ∈Rn×, hai điều kiện bất kỳ dưới đây là tương đương:\\n1. A là một ma trận khả nghịch.\\n2. Các cột củaA tạo thành một cơ sở trong\\nkhông giann chiều.\\n3. det(A) ̸= 0.\\n4. rank(A) = n\\n1.9 Hệ trực chuẩn, ma trận trực giao\\n1.9.1 Định nghĩa\\nMột hệ cơ sở{u1,u2,..., um ∈Rm}được gọi làtrực giao (orthogonal) nếu mỗi vector là\\nkhác 0 và tích của hai vector khác nhau bất kỳ bằng 0:\\nui ̸= 0; uT\\ni uj = 0 ∀1 ≤i̸= j ≤m (1.20)\\nMột hệ cơ sở{u1,u2,..., um ∈Rm}được gọi làtrực chuẩn(orthonormal) nếu nó là một hệ\\ntrực giaovà độ dài Euclidean (xem thêm phầnℓ2 norm) của mỗi vector bằng 1:\\nuT\\ni uj =\\n{\\n1 nếu i= j\\n0 o.w. (1.21)\\n(o.w. là cách viết ngắn gọn củatrong các trường hợp còn lai(viết tắt củaotherwise).)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 32, 'page_label': '21'}, page_content='21 CHƯƠNG 1. ÔN TẬP ĐẠI SỐ TUYẾN TÍNH\\nGọi U = [u1,u2,..., um] với {u1,u2,..., um ∈Rm}là trực chuẩn, từ (1.21) có thể suy ra:\\nUUT = UTU = I (1.22)\\ntrong đóI là ma trận đơn vị bậcm. Nếu một ma trận thoả mãn điều kiện 1.22, ta gọi nó\\nlà ma trận trực giao(orthogonal matrix). Ma trận loại này không không được gọi là ma trận\\ntrực chuẩn, không có định nghĩa cho ma trận trực chuẩn.\\nNếu một ma trận vuông phứcU thoả mãn UUH = UHU = I, ta nói rằngU là một ma\\ntrận unitary(unitary matrix).\\n1.9.2 Tính chất của ma trận trực giao\\n1. U−1 = UT: nghịch đảo của một ma trận trực giao chính là chuyển vị của nó.\\n2. Nếu U là ma trận trực giao thì chuyển vị của nóUT cũng là một ma trận trực giao.\\n3. Định thức của ma trận trực giao bằng1 hoặc −1. Điều này có thể suy ra từ việcdet(U) =\\ndet(UT) và det(U) det(UT) = det(I) = 1.\\n4. Ma trận trực giao thể hiện cho phép xoay một vector (xem thêm mục 1.10). Giả sử có\\nhai vectorx,y ∈Rm và một ma trận trực giaoU ∈Rm×m. Dùng ma trận này để xoay\\nhai vector trên ta đượcUx,Uy. Tích vô hướng của hai vector mới là:\\n(Ux)T(Uy) = xTUTUy = xTy (1.23)\\nnhư vậyphép xoay không làm thay đổi tích vô hướng giữa hai vector.\\n5. Giả sửˆU ∈Rm×r,r <m là môt ma trận con của ma trận trực giaoU được tạo bởir cột\\ncủa U, ta sẽ cóˆUT ˆU = Ir. Việc này có thể được suy ra từ (1.21).\\n1.10 Biễu diễn vector trong các hệ cơ sở khác nhau\\nTrong không gianm chiều, toạ độ của mỗi điểm được xác định dựa trên một hệ toạ độ nào\\nđó. Ở các hệ toạ độ khác nhau, hiển nhiên là toạ độ của mỗi điểm cũng khác nhau.\\nTập hợp các vectore1,..., em mà mỗi vectorei có đúng 1 phần tử khác 0 ở thành phần thứ\\nivà phần tử đó bằng 1, được gọi là hệ cơ sở đơn vị (hoặc hệ đơn vị, hoặc hệ chính tắc) trong\\nkhông gianm chiều. Nếu xếp các vectorei,i = 1,2,...,m theo đúng thứ tự đó, ta sẽ được\\nma trận đơn vịm chiều.\\nMỗi vector cộtx = [x1,x2,...,x m] ∈Rm có thể coi là một tổ hợp tuyến tính của các vector\\ntrong hệ cơ sở chính tắc:\\nx = x1e1 + x2e2 + ··· + xmem (1.24)'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 32, 'page_label': '21'}, page_content='ma trận đơn vịm chiều.\\nMỗi vector cộtx = [x1,x2,...,x m] ∈Rm có thể coi là một tổ hợp tuyến tính của các vector\\ntrong hệ cơ sở chính tắc:\\nx = x1e1 + x2e2 + ··· + xmem (1.24)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 33, 'page_label': '22'}, page_content='CHƯƠNG 1. ÔN TẬP ĐẠI SỐ TUYẾN TÍNH 22\\nO\\ne1\\ne2\\nu1\\nu2\\nx1\\nx2\\ny1\\ny2\\nx\\nHình 1.1:Chuyển đổi toạ độ trong\\ncác hệ cơ sở khác nhau. Trong\\nhệ toạ độ Oe1e2, x có toạ độ là\\n(x1,x2). Trong hệ toạ độOu1u2,\\nx có toạ độ là(y2,y2).\\nGiả sử có một hệ cơ sở khácu1,u2,..., um (các vector này độc lập tuyến tính), biểu diễn\\ncủa vectorx trong hệ cơ sở mới này có dạng:\\nx = y1u1 + y2u2 + ··· + ymum = Uy (1.25)\\nvới U =\\n[\\nu1 ... um\\n]\\n. Lúc này, vectory = [y1,y2,...,y m]T chính là biểu diễn củax trong hệ\\ncơ sở mới. Biểu diễn này là duy nhất vìy = U−1x.\\nTrong các ma trận đóng vai trò như hệ cơ sở, các ma trận trực giao, tứcUTU = I, được quan\\ntâm nhiềuhơn vì nghịch đảocủa chúngchính là chuyển vị củachúng:U−1 = UT. Khi đó,y có\\nthể được tính một cách nhanh chóngy = UTx. Từ đó suy ra:yi = xTui = uT\\ni x,i = 1,...,m .\\nDưới góc nhìn hình học, hệ trực giao tạo thành một hệ trục toạ độ Descartes vuông góc mà\\nchúng ta đã quen thuộc trong không gian hai chiều hoặc ba chiều.\\nCó thể nhận thấy rằng vector0 được biểu diễn như nhau trong mọi hệ cơ sở. Hình 1.1 là\\nmột ví dụ về việc chuyển hệ cơ sở trong không gian hai chiều.\\nViệc chuyển đổi hệ cơ sở sử dụng ma trận trực giao có thể được coi như một phép xoay\\ntrục toạ độ. Nhìn theo một cách khác, đây cũng chính là một phép xoay vector dữ liệu theo\\nchiều ngược lại, nếu ta coi các trục toạ độ là cố định. Trong chương Principle Component\\nAnalysis, chúng ta sẽ thấy được một ứng dụng quan trọng của việc đổi hệ cơ sở.\\n1.11 Trị riêng và vector riêng\\n1.11.1 Định nghĩa\\nCho một ma trận vuôngA ∈Rn×n, một vectorx ∈Rn(x ̸= 0) và một số vô hướng (có\\nthể thực hoặc phức)λ. NếuAx = λx, thì ta nóiλ và x là một cặptrị riêng, vector riêng\\n(eigenvalue, eigenvector) của ma trậnA.\\nTừ định nghĩa ta cũng có(A −λI)x = 0, tứcx nằm trong null space củaA −λI. Vìx ̸= 0,\\nA −λI là một ma trận không khả nghịch. Nói cách khácdet(A −λI) = 0, tứcλ là nghiệm\\ncủa phương trìnhdet(A −tI) = 0. Định thức này là một đa thức bậcn của t, được gọi là'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 33, 'page_label': '22'}, page_content='A −λI là một ma trận không khả nghịch. Nói cách khácdet(A −λI) = 0, tứcλ là nghiệm\\ncủa phương trìnhdet(A −tI) = 0. Định thức này là một đa thức bậcn của t, được gọi là\\nđa thức đặc trưng(characteristic polynomial) củaA, được ký hiệu làpA(t). Tập hợp tất cả\\ncác trị riêng của một ma trận vuông còn được gọi làphổ (spectrum) của ma trận đó.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 34, 'page_label': '23'}, page_content='23 CHƯƠNG 1. ÔN TẬP ĐẠI SỐ TUYẾN TÍNH\\n1.11.2 Tính chất\\n1. Nếu x là một vector riêng củaA ứng vớiλ thì kx, ∀k ̸= 0 cũng là vector riêng ứng với\\ntrị riêng đó. Nếux1,x2 là hai vector riêng ứng với cùng trị riêngλ, thì tổng của chúng\\ncũng là một vector ứng với trị riêng đó. Từ đó suy ra tập hợp các vector riêng ứng với\\nmột trị riêng của một ma trận vuông tạo thành một không gian vector con, thường được\\ngọi làkhông gian riêng(eigenspace) ứng với trị riêng đó.\\n2. Mọi ma trận vuông bậcn đều cón trị riêng (kể cả lặp) và có thể là các số phức.\\n3. Tích của tất cả các trị riêng của một ma trận bằng định thức của ma trận đó. Tổng tất\\ncả các trị riêng của một ma trận bằng tổng các phần tử trên đường chéo của ma trận đó.\\n4. Phổ của một ma trận bằng phổ của ma trận chuyển vị của nó.\\n5. Nếu A,B là các ma trận vuông cùng bậc thìpAB(t) = pBA(t). Điều này nghĩa là, mặc\\ndù tích của hai ma trận không có tính chất giao hoán, đa thức đặc trưng củaAB vàBA\\nlà như nhau. Tức phổ của hai tích này là trùng nhau.\\n6. Với ma trận đối xứng (hoặc tổng quát, Hermitian), tất cả các trị riêng của nó đều là các\\nsố thực. Thật vậy, giả sửλ là một trị riêng của một ma trận HermitianA và x là một\\nvector riêng ứng với trị riêng đó. Từ định nghĩa ta suy ra:\\nAx = λx ⇒(Ax)H = ¯λxH ⇒¯λxH = xHA (1.26)\\nvới ¯λ là liên hiệp phức của số vô hướngλ. Nhân cả hai vế vào bên phải vớix ta có:\\n¯λxHx = xHAx = λxHx ⇒(λ−¯λ)xHx = 0 (1.27)\\nvì x ̸= 0 nên xHx ̸= 0. Từ đó suy ra¯λ= λ, tứcλ phải là một số thực.\\n7. Nếu(λ,x) là một cặp trị riêng, vector riêng của một ma trận khả nghichA, thì(1\\nλ,x) là\\nmột cặp trị riêng, vector riêng củaA−1, vìAx = λx ⇒1\\nλx = A−1x.\\n1.12 Chéo hoá ma trận\\nViệc phân tích một đại lượng toán học ra thành các đại lượng nhỏ hơn mang lại nhiều hiệu\\nquả. Phân tích một số thành tích các thừa số nguyên tố giúp kiểm tra một số có bao nhiêu\\nước số. Phân tích đa thức thành nhân tử giúp tìm nghiệm của đa thức. Việc phân tích một\\nma trận thành tích của các ma trận có dạng đặc biệt khác (quá trình này được gọi làmatrix'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 34, 'page_label': '23'}, page_content='ước số. Phân tích đa thức thành nhân tử giúp tìm nghiệm của đa thức. Việc phân tích một\\nma trận thành tích của các ma trận có dạng đặc biệt khác (quá trình này được gọi làmatrix\\ndecomposition) cũng mang lại nhiều lợi ích trong việc giải hệ phương trình một cách hiệu\\nquả, tính luỹ thừa của ma trận, xấp xỉ ma trận, nén dữ liệu, phân cụm dữ liệu, v.v. Trong\\nmục này, chúng ta sẽ ôn lại một phương pháp matrix decomposition quen thuộc–phương\\npháp chéo hoá ma trận (diagonalization hoặc eigendecomposition).\\nGiả sử x1,..., xn ̸= 0 là các vector riêng của một ma trận vuôngA ứng với các trị riêng\\nλ1,...,λ n (có thể lặp hoặc là các số phức) của nó. Tức làAxi = λixi, ∀i= 1,...,n .\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 35, 'page_label': '24'}, page_content='CHƯƠNG 1. ÔN TẬP ĐẠI SỐ TUYẾN TÍNH 24\\nĐặt Λ= diag(λ1,λ2,...,λ n), vàX =\\n[\\nx1,x2,..., xn\\n]\\n, ta sẽ cóAX = XΛ. Hơn nữa, nếu\\ncác trị riêngx1,..., xn là độc lập tuyến tính, ma trậnX là một ma trận khả nghịch. Khi đó\\nta có thể viêtA dưới dạng tích của ba ma trận:\\nA = XΛX−1 (1.28)\\nCác vector riêng xi thường được chọn sao cho xT\\ni xi = 1 . Cách biểu diễn một ma trận\\nnhư (1.28) được gọi làeigendecompositionvì nó tách ra thành tích của các ma trận đặc biệt\\ndựa trên vector riêng (eigenvectors) và trị riêng (eigenvalues). Ma trận các trị riêngΛ là\\nmột ma trận đường chéo. Vì vậy, cách khai triển này cũng có tên gọi là chéo hoá ma trận.\\nTính chất:\\n1. Khái niệm chéo hoá ma trận chỉ áp dụng với ma trận vuông. Vì không có định nghĩa\\nvector riêng hay trị riêng cho ma trận không vuông.\\n2. Không phải ma trận vuông nào cũng có thểchéo hoá được(diagonalizable). Một ma trận\\nvuông bậcn là chéo hoá được nếu và chỉ nếu nó có đủn trị riêng độc lập tuyến tính.\\n3. Nếu một ma trận là chéo hoá được, có nhiều hơn một cách chéo hoá ma trận đó. Chỉ cần\\nđổi vị trí của cácλi và vị trí tương ứng các cột củaX, ta sẽ có một cách chéo hoá mới.\\n4. NếuA có thể viết được dưới dạng (1.28), khi đó các luỹ thừa có nó cũng chéo hoá được.\\nCụ thể:\\nA2 = (XΛX−1)(XΛX−1) = XΛ2X−1; Ak = XΛkX−1, ∀k∈N (1.29)\\nXin chú ý rằng nếuλ và x là một cặp (trị riêng, vector riêng) củaA, thìλk và x là một\\ncặp (trị riêng, vector riêng) củaAk. Thật vậy,Akx = Ak−1(Ax) = λAk−1x = ··· = λkx.\\n5. Nếu A khả nghịch, thìA−1 = (XΛX−1)−1 = XΛ−1X−1. Vậy chéo hoá ma trận cũng có\\ních trong việc tính ma trận nghịch đảo.\\n1.13 Ma trận xác định dương\\n1.13.1 Định nghĩa\\nMột ma trận đối xứng2 A ∈Rn×n được gọi làxác định dương(positive definite) nếu:\\nxTAx >0,∀x ∈Rn,x ̸= 0. (1.30)\\nMột ma trận đối xứngA ∈Rn×n được gọi lànửa xác định dương(positive semidefinite) nếu:\\nxTAx ≥0,∀x ∈Rn,x ̸= 0. (1.31)\\nTrên thực tế, ma trận nửa xác định dương, dược viết tắt làPSD, được sử dụng nhiều hơn.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 35, 'page_label': '24'}, page_content='xTAx ≥0,∀x ∈Rn,x ̸= 0. (1.31)\\nTrên thực tế, ma trận nửa xác định dương, dược viết tắt làPSD, được sử dụng nhiều hơn.\\n2 Chú ý, tồn tại những ma trận không đối xứng thoả mãn điều kiện (1.30). Ta sẽ không xét những ma trận này.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 36, 'page_label': '25'}, page_content='25 CHƯƠNG 1. ÔN TẬP ĐẠI SỐ TUYẾN TÍNH\\nMa trậnxác định âm(negative definite) vànửa xác định âm(negative semi-definite) cũng\\nđược định nghĩa tương tự.\\nKý hiệu A ≻0,⪰0,≺0,⪯0 được dùng để chỉ một ma trận là xác định dương, nửa xác\\nđịnh dương, xác định âm, nửa xác định âm, theo thứ tự đó. Ký hiệuA ≻B cũng được dùng\\nđể chỉ ra rằngA −B ≻0.\\nMở rộng, một ma trận phức, HermitianA ∈Cn×n được gọi là xác định dương nếu:\\nxHAx >0,∀x ∈Cn,x ̸= 0. (1.32)\\nVí dụ,A =\\n[1 −1\\n−1 1\\n]\\nlà nửa xác định dương vì với mọi vectorx =\\n[u\\nv\\n]\\n, ta có:\\nxTAx =\\n[\\nuv\\n][1 −1\\n−1 1\\n][u\\nv\\n]\\n= u2 + v2 −2uv= (u−v)2 ≥0,∀u,v ∈R (1.33)\\n1.13.2 Tính chất\\n1. Mọi trị riêng của một ma trận xác định dương đều là một số thực dương.\\nTrước hết, các trị riêng của các ma trận dạng này là số thực vì các ma trận đều là đối\\nxứng. Để chứng minh chúng là các số thực dương, ta giả sửλ là một trị riêng của một\\nma trận xác định dươngA và x ̸= 0 là một vector riêng ứng với trị riêng đó. Nhân vào\\nbên trái cả hai vế củaAx = λx với xH ta có:\\nλxHx = xHAx >0 (1.34)\\n(ở đây Hermitian được dùng để xét tổng quát cho cả trường hợp ma trận phức). VìxHx\\nluôn dương với mọix nên ta phải cóλ >0. Tương tự, ta có thể chứng minh được rằng\\nmọi trị riêng của một ma trận nửa xác định dương là không âm.\\n2. Mọi ma trận xác định dương là khả nghịch. Hơn nữa, định thức của nó là một số dương.\\nĐiều này được trực tiếp suy ra từ tính chất 1. Nhắc lại rằng định thức của một ma trận\\nbằng tích tất cả các trị riêng của nó.\\n3. Tiêu chuẩn Sylvester:Một ma trận Hermitian là xác định dương nếu và chỉ nếu mọi\\nleading principal minors của nó là dương. Một ma trận Hermitian là nửa xác định dương\\nnếu mọi principal minors của nó là không âm. Đây là một tiêu chuẩn để kiểm tra một ma\\ntrận HermitianA ∈Rn có là (nửa) xác định dương hay không. Ở đây,leading principal\\nminors và principal minorsđược định nghĩa như sau:\\nGọi Ilà một tập con bất kỳ của{1,2,...,n }, AI là ma trận con củaA nhận được bằng\\ncách trích ra các hàng và cột có chỉ số nằm trongIcủa A. Khi đó,AI và det(AI) lần'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 36, 'page_label': '25'}, page_content='Gọi Ilà một tập con bất kỳ của{1,2,...,n }, AI là ma trận con củaA nhận được bằng\\ncách trích ra các hàng và cột có chỉ số nằm trongIcủa A. Khi đó,AI và det(AI) lần\\nlượt được gọi là mộtma trận con chính(principal submatrix) vàprincipal minorcủa A.\\nNếu Ichỉ bao gồm các số tự nhiên liên tiếp từ1 đến k ≤n, ta nóiAI và det(AI) lần\\nlượt là mộtleading principal submatrixvà leading principal minorbậc k của A.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 37, 'page_label': '26'}, page_content='CHƯƠNG 1. ÔN TẬP ĐẠI SỐ TUYẾN TÍNH 26\\n4. A = BHB là nửa xác định dương với mọi ma trậnB (B không nhất thiết vuông).\\nThật vậy, với mọi vectorx ̸= 0 với chiều phù hợp,xHAx = xHBHBx = (Bx)H(Bx) ≥0.\\n5. Khai triển Cholesky (Cholesky decomposition):Mọi ma trận Hermitian, nửa xác định\\ndương A đều biểu diễn được duy nhất dưới dạngA = LLH, trong đóL là một ma trận\\ntam giác dưới với các thành phần trên đường chéo là thực dương.\\n6. Nếu A là một ma trận nửa xác định dương, thìxTAx = 0 ⇔Ax = 0.\\nNếu Ax = 0 ⇒xTAx = 0 một cách hiển nhiên.\\nNếu xTAx = 0. Với vectory ̸= 0 bất kỳ có cùng kích thước vớix, xét hàm số sau đây:\\nf(λ) = (x + λy)TA(x + λy) (1.35)\\nHàm số này không âm với mọiλ vì A là một ma trận nửa xác định dương. Đây là một\\ntam thức bậc hai củaλ:\\nf(λ) = yTAyλ2 + 2yTAxλ+ xTAx = yTAyλ2 + 2yTAxλ (1.36)\\nXét hai trường hợp:\\n• yTAy = 0. Khi đó,f(λ) = 2yTAxλ≥0,∀λ nếu và chỉ nếuyTAx = 0.\\n• yTAy >0. Khi đó tam thức bậc haif(λ) ≥0,∀λ nếu và chỉ nếu∆′= (yTAx)2 ≤0\\nvì hệ số ứng với thành phần bậc hai bằngyTAy >0. Điều này cũng đồng nghĩa với\\nviệc yTAx = 0\\nTóm lại,yTAx = 0, ∀y ̸= 0. Điều này chỉ xảy ra nếuAx = 0. □\\n1.14 Chuẩn của vector và ma trận\\nTrong không gian một chiều, khoảng cách giữa hai điểm là trị tuyệt đối của hiệu giữa hai giá\\ntrị đó. Trong không gian hai chiều, tức mặt phẳng, chúng ta thường dùng khoảng cách Euclid\\nđể đo khoảng cách giữa hai điểm. Khoảng cách này chính là đại lượng chúng ta thường nói\\nbằng ngôn ngữ thông thường làđường chim bay. Đôi khi, để đi từ một điểm này tới một\\nđiểm kia, con người chúng ta không thể đi bằng đường chim bay được mà còn phụ thuộc\\nvào việc đường đi nối giữa hai điểm có dạng như thế nào.\\nViệc đo khoảng cách giữa hai điểm dữ liệu nhiều chiều, tức hai vector, là rất cần thiết trong\\nMachine Learning. Và đó chính là lý do mà khái niệmchuẩn (norm) ra đời. Để xác định\\nkhoảng cách giữa hai vectory và z, người ta thường áp dụng một hàm số lên vector hiệu\\nx = y −z. Hàm số này cần có một vài tính chất đặc biệt.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 37, 'page_label': '26'}, page_content='khoảng cách giữa hai vectory và z, người ta thường áp dụng một hàm số lên vector hiệu\\nx = y −z. Hàm số này cần có một vài tính chất đặc biệt.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 38, 'page_label': '27'}, page_content='27 CHƯƠNG 1. ÔN TẬP ĐẠI SỐ TUYẾN TÍNH\\nx\\ny\\nz\\nx1 y1\\nx2\\ny2\\n∥x −y∥2\\n|x1 −y1|\\n|x2−y2|\\n∥x −y∥1 = |x1 −y1|+ |x2 −y2|\\nHình 1.2:Minh họaℓ1 norm vàℓ2\\nnorm trong không gian hai chiều.ℓ2\\nnorm chính là khoảng cách giữa hai\\nđiểm trong mặt phẳng. Trong khi\\nđó ℓ1 norm là quãng đường ngắn\\nnhất giữa hai điểm nếu chỉ được đi\\ntheo các đường song song với các\\ntrục toạ độ.\\nĐịnh nghĩa 1.1: Norm\\nMột hàm sốf :Rn →R được gọi là một norm nếu nó thỏa mãn ba điều kiện sau đây:\\n1. f(x)≥0. Dấu bằng xảy ra⇔x = 0.\\n2. f(αx) =|α|f(x), ∀α∈R\\n3. f(x1) +f(x2)≥f(x1 + x2), ∀x1,x2 ∈Rn\\nĐiều kiện thứ nhấtlà dễ hiểu vì khoảng cách không thể là một số âm. Hơn nữa, khoảng\\ncách giữa hai điểmy vàz bằng 0 nếu và chỉ nếu hai điểm nó trùng nhau, tứcx = y −z = 0.\\nĐiều kiện thứ haicũng có thể được lý giải như sau. Nếu ba điểmy,v và z thẳng hàng,\\nhơn nữav −y = α(v −z)thì khoảng cách giữav vày gấp |α|lần khoảng cách giữav vàz.\\nĐiều kiện thứ bachính là bất đẳng thức tam giác nếu ta coix1 = y −w,x2 = w −z với\\nw là một điểm bất kỳ trong cùng không gian.\\n1.14.1 Một số chuẩn vector thường dùng\\nĐộ dài Euclid của một vectorx ∈Rn chính là một norm, norm này được gọi làℓ2 norm hoặc\\nEuclidean norm:\\n∥x∥2 =\\n√\\nx2\\n1 + x2\\n2 + ··· + x2\\nn (1.37)\\nBình phương củaℓ2 norm chính là tích vô hướng của một vector với chính nó,∥x∥2\\n2 = xTx.\\nVới p là một số không nhỏ hơn 1bất kỳ, hàm số:\\n∥x∥p = (|x1|p + |x2|p + ... |xn|p)\\n1\\np (1.38)\\nđược chứng minh thỏa mãn ba điều kiện của norm, và được gọi làℓp norm.\\nCó một vài giá trị củap thường được dùng:\\n1. Khi p= 2chúng ta cóℓ2 norm như ở trên.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 39, 'page_label': '28'}, page_content='CHƯƠNG 1. ÔN TẬP ĐẠI SỐ TUYẾN TÍNH 28\\n2. Khi p = 1 chúng ta cóℓ1 norm: ∥x∥1 = |x1|+ |x2|+ ··· + |xn|là tổng các trị tuyệt đối\\ncủa từng phần tử củax. Hình 1.2 là một ví dụ sánhℓ1 norm vàℓ2 norm trong không\\ngian hai chiều. Norm 2 (màu xanh) chính là đường thằngchim baynối giữa hai vectorx\\nvà y. Khoảng cáchℓ1 norm giữa hai điểm này (màu đỏ) có thể diễn giải như là đường đi\\ntừ x tới y trong một thành phố mà đường phố tạo thành hình bàn cờ. Chúng ta chỉ có\\ncách đi dọc theo cạnh của bàn cờ mà không được đi thẳng như đường chim bay.\\n3. Khi p→∞, giả sửi= arg maxj=1,2,...,n|xj|. Khi đó:\\n∥x∥p = |xi|\\n(\\n1 +\\n⏐⏐⏐⏐\\nx1\\nxi\\n⏐⏐⏐⏐\\np\\n+ ··· +\\n⏐⏐⏐⏐\\nxi−1\\nxi\\n⏐⏐⏐⏐\\np\\n+\\n⏐⏐⏐⏐\\nxi+1\\nxi\\n⏐⏐⏐⏐\\np\\n+ ··· +\\n⏐⏐⏐⏐\\nxn\\nxi\\n⏐⏐⏐⏐\\np)1\\np\\n(1.39)\\nTa thấy rằng:\\nlim\\np→∞\\n(\\n1 +\\n⏐⏐⏐⏐\\nx1\\nxi\\n⏐⏐⏐⏐\\np\\n+ ··· +\\n⏐⏐⏐⏐\\nxi−1\\nxi\\n⏐⏐⏐⏐\\np\\n+\\n⏐⏐⏐⏐\\nxi+1\\nxi\\n⏐⏐⏐⏐\\np\\n+ ··· +\\n⏐⏐⏐⏐\\nxn\\nxi\\n⏐⏐⏐⏐\\np)1\\np\\n= 1 (1.40)\\nvì đại lượng trong dấu ngoặc đơn không vượt quán, ta sẽ có:\\n∥x∥∞≜lim\\np→∞\\n∥x∥p = |xi|= max\\nj=1,2,...,n\\n|xj| (1.41)\\n1.14.2 Chuẩn Frobenius của ma trận\\nVới một ma trậnA ∈Rm×n, chuẩn thường được dùng nhất là chuẩn Frobenius, ký hiệu là\\n∥A∥F là căn bậc hai của tổng bình phương tất cả các phần tử của ma trận đó.\\n∥A∥F =\\n\\ued6a\\ued6b\\ued6b√\\nm∑\\ni=1\\nn∑\\nj=1\\na2\\nij\\nChú ý rằngℓ2 norm ∥A∥2 là một norm khác của ma trận, không phổ biến bằng Frobenius\\nnorm. Bạn đọc có thể xemℓ2 norm của ma trận trong Phụ lục A.\\n1.14.3 Vết của ma trận\\nVết (trace) của một ma trận vuông là tổng tất cả cả phần tử trên đường chéo chính của nó.\\nVết của một ma trận đượcA được ký hiệu là trace(A). Hàm số trace xác định trên tập các\\nma trận vuông được sử dụng rất nhiều trong tối ưu vì những tính chất đẹp của nó.\\nCác tính chất quan trọng của hàm trace, với giả sử rằng các ma trận trong hàm trace là\\nvuông và các phép nhân ma trận thực hiện được:\\n• Một ma trận vuông bất kỳ và chuyển vị của nó có trace bằng nhautrace(A) = trace(AT).\\nViệc này khá hiển nhiên vì phép chuyển vị không làm thay đổi các phần tử trên đường\\nchéo chính của một ma trận.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 40, 'page_label': '29'}, page_content='29 CHƯƠNG 1. ÔN TẬP ĐẠI SỐ TUYẾN TÍNH\\n• trace của một tổng bằng tổng các trace: trace(∑k\\ni=1 Ai) = ∑k\\ni=1 trace(Ai).\\n• trace(kA) = ktrace(A) với k là một số vô hướng bất kỳ.\\n• trace(A) = ∑D\\ni=1 λi với A là một ma trận vuông vàλi,i = 1,2,...,N là toàn bộ các trị\\nriêng của nó, có thể phức hoặc lặp. Việc chứng minh tính chất này có thể được dựa trên\\nma trận đặc trưng củaA và định lý Viète.\\n• trace(AB) = trace(BA). Đẳng thức này được suy ra từ việc đa thức đặc trưng củaAB\\nvà BA là như nhau. Bạn đọc cũng có thể chứng minh bằng cách tính trực tiếp các phần\\ntử trên đường chéo chính củaAB và BA.\\n• trace(ABC) = trace(BCA) nhưng trace(ABC) không đồng nhất với trace(ACB).\\n• Nếu X là một ma trận khả nghịch cùng chiều vớiA:\\ntrace(XAX−1) = trace(X−1XA) = trace(A) (1.42)\\n• ∥A∥2\\nF = trace(ATA) = trace(AAT) với A là một ma trận bất kỳ. Từ đây ta cũng suy ra\\ntrace(AAT) ≥0 với mọi ma trậnA.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 41, 'page_label': '30'}, page_content='Chương 2\\nGiải tích ma trận\\nTrong chương này, nếu không nói gì thêm, chúng ta giả sử rằng các đạo hàm tồn tại. Tài\\nliệu tham khảo chính của chương làMatrix calculus–Stanford(https://goo.gl/BjTPLr ).\\n2.1 Đạo hàm của hàm trả về một số vô hướng\\nĐạo hàm bậc nhất(first-order gradient) hay viết gọn làđạo hàm (gradient) của một hàm\\nsố f(x) : Rn →R theo x được định nghĩa là\\n∇xf(x) ≜\\n\\uf8ee\\n\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8f0\\n∂f(x)\\n∂x1\\n∂f(x)\\n∂x2\\n...\\n∂f(x)\\n∂xn\\n\\uf8f9\\n\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fb\\n∈Rn (2.1)\\ntrong đó∂f(x)\\n∂xi\\nlà đạo hàm riêng(partial derivative) của hàm số theo thành phần thứicủa\\nvector x. Đạo hàm này được lấy khi tất cả các biến, ngoàixi, được giả sử là hằng số. Nếu\\nkhông có thêm biến nào khác,∇xf(x) thường được viết gọn là∇f(x). Đạo hàm của hàm\\nsố này là một vector có cùng chiều với vector đang được lấy đạo hàm. Tức nếu\\nvector được viết ở dạng cột thì đạo hàm cũng phải được viết ở dạng cột.\\nĐạo hàm bậc hai(second-order gradient) của hàm số trên còn được gọi làHessian và được\\nđịnh nghĩa như sau, vớiSn ∈Rn×n là tập các ma trận vuông đối xứng bậcn.\\n∇2f(x) ≜\\n\\uf8ee\\n\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8f0\\n∂2f(x)\\n∂x2\\n1\\n∂2f(x)\\n∂x1∂x2\\n... ∂2f(x)\\n∂x1∂xn\\n∂2f(x)\\n∂x2∂x1\\n∂2f(x)\\n∂x2\\n2\\n... ∂2f(x)\\n∂x2∂xn\\n... ... ... ...\\n∂2f(x)\\n∂xn∂x1\\n∂2f(x)\\n∂xn∂x2\\n... ∂2f(x)\\n∂x2\\nn\\n\\uf8f9\\n\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fb\\n∈Sn (2.2)'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 42, 'page_label': '31'}, page_content='31 CHƯƠNG 2. GIẢI TÍCH MA TRẬN\\nĐạo hàm của một hàm sốf(X) : Rn×m →R theo ma trậnX được định nghĩa là\\n∇f(X) =\\n\\uf8ee\\n\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8f0\\n∂f(X)\\n∂x11\\n∂f(X)\\n∂x12\\n... ∂f(X)\\n∂x1m\\n∂f(X)\\n∂x21\\n∂f(X)\\n∂x22\\n... ∂f(X)\\n∂x2m\\n... ... ... ...\\n∂f(X)\\n∂xn1\\n∂f(X)\\n∂xn2\\n... ∂f(X)\\n∂xnm\\n\\uf8f9\\n\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fb\\n∈Rn×m (2.3)\\nChiều của đạo hàm\\nĐạo hàm của hàm sốf : Rm×n →R là một ma trận trongRm×n, ∀m,n ∈N∗.\\nCụ thể, để tính đạo hàm của một hàmf : Rm×n →R, ta tính đạo hàm riêng của hàm số đó\\ntheo từng thành phần của ma trậnkhi toàn bộ các thành phần khác được giả sử là hằng số.\\nTiếp theo, ta sắp xếp các đạo hàm riêng tính được theo đúng thứ tự trong ma trận.\\nVí dụ:Xét hàm sốf : R2 →R, f(x) = x2\\n1 + 2x1x2 + sin(x1) + 2.\\nĐạo hàm bậc nhất theox của hàm số đó là\\n∇f(x) =\\n\\uf8ee\\n\\uf8ef\\uf8ef\\uf8f0\\n∂f(x)\\n∂x1\\n∂f(x)\\n∂x2\\n\\uf8f9\\n\\uf8fa\\uf8fa\\uf8fb=\\n\\uf8ee\\n\\uf8ef\\uf8ef\\uf8f0\\n2x1 + 2x2 + cos(x1)\\n2x1\\n\\uf8f9\\n\\uf8fa\\uf8fa\\uf8fb\\nĐạo hàm bậc hai theox, hayHessian là ∇2f(x) =\\n\\uf8ee\\n\\uf8ef\\uf8ef\\uf8ef\\uf8f0\\n∂2f(x)\\n∂x2\\n1\\n∂f2(x)\\n∂x1∂x2\\n∂2f(x)\\n∂x2∂x1\\n∂f2(x)\\n∂x2\\n2\\n\\uf8f9\\n\\uf8fa\\uf8fa\\uf8fa\\uf8fb=\\n\\uf8ee\\n\\uf8ef\\uf8ef\\uf8f0\\n2 −sin(x1) 2\\n2 0\\n\\uf8f9\\n\\uf8fa\\uf8fa\\uf8fb\\nChú ý rằngHessian luôn là một ma trận đối xứng.\\n2.2 Đạo hàm của hàm trả về một vector\\nNhững hàm số trả về một vector, hoặc gọn hơnhàm trả về vectorđược gọi làvector-valued\\nfunction trong tiếng Anh.\\nXét một hàm trả về vector vớiđầu vào là một số thựcv(x) : R →Rn:\\nv(x) =\\n\\uf8ee\\n\\uf8ef\\uf8ef\\uf8ef\\uf8f0\\nv1(x)\\nv2(x)\\n...\\nvn(x)\\n\\uf8f9\\n\\uf8fa\\uf8fa\\uf8fa\\uf8fb (2.4)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 43, 'page_label': '32'}, page_content='CHƯƠNG 2. GIẢI TÍCH MA TRẬN 32\\nĐạo hàm của hàm số này theox là mộtvector hàngnhư sau:\\n∇v(x) ≜\\n[\\n∂v1(x)\\n∂x\\n∂v2(x)\\n∂x ... ∂vn(x)\\n∂x\\n]\\n(2.5)\\nĐạo hàm bậc hai của hàm số này có dạng\\n∇2v(x) ≜\\n[\\n∂2v1(x)\\n∂x2\\n∂2v2(x)\\n∂x2 ... ∂2vn(x)\\n∂x2\\n]\\n(2.6)\\nVí dụ:Cho một vectora ∈Rn và một hàm sốvector-valued v(x) = xa, đạo hàm bậc nhất\\nvà Hession của nó lần lượt là\\n∇v(x) = aT, ∇2v(x) = 0 ∈R1×n (2.7)\\nXét một hàm trả về vector vớiđầu vào là một vectorh(x) : Rk →Rn, đạo hàm bậc nhất\\ncủa nó là\\n∇h(x) ≜\\n\\uf8ee\\n\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8f0\\n∂h1(x)\\n∂x1\\n∂h2(x)\\n∂x1\\n... ∂hn(x)\\n∂x1\\n∂h1(x)\\n∂x2\\n∂h2(x)\\n∂x2\\n... ∂hn(x)\\n∂x2\\n... ... ... ...\\n∂h1(x)\\n∂xk\\n∂h2(x)\\n∂xk\\n... ∂hn(x)\\n∂xk\\n\\uf8f9\\n\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fb\\n=\\n[\\n∇h1(x) ∇h2(x) ... ∇hn(x)\\n]\\n∈Rk×n (2.8)\\nNếu một hàm sốg: Rm →Rn, thì đạo hàm của nó là một ma trận thuộcRm×n.\\nĐạo hàm bậc hai của hàm số trên là mộtmảng ba chiều, chúng ta sẽ không nhắc đến ở đây.\\nTrước khi đến phần tính đạo hàm của các hàm số thường gặp, chúng ta cần biết hai tính\\nchất quan trọng khá giống với đạo hàm của hàm một biến.\\n2.3 Tính chất quan trọng của đạo hàm\\n2.3.1 Quy tắc tích (Product rule)\\nĐể cho tổng quát, ta giả sử biến đầu vào là một ma trận. Giả sử rằng các hàm số có chiều\\nphù hợp để các phép nhân thực hiện được. Ta có:\\n∇\\n(\\nf(X)Tg(X)\\n)\\n= (∇f(X)) g(X) + (∇g(X)) f(X) (2.9)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 44, 'page_label': '33'}, page_content='33 CHƯƠNG 2. GIẢI TÍCH MA TRẬN\\nBiểu thức này giống như biểu thức chúng ta đã quen thuộc:\\n(f(x)g(x))′= f′(x)g(x) + g′(x)f(x)\\nChú ý rằng với tích của vector và ma trận, ta không được sử dụng tính chất giao hoán.\\n2.3.2 Quy tắc chuỗi (Chain rule)\\nKhi có các hàm hợp thì\\n∇Xg(f(X)) = (∇Xf)T(∇fg) (2.10)\\nQuy tắc này cũng giống với quy tắc trong hàm một biến:\\n(g(f(x)))′= f′(x)g′(f)\\nMột lưu ý nhỏ nhưng quan trọng khi làm việc với tích các ma trận là sự phù hợp về kích\\nthước của các ma trận trong tích.\\n2.4 Đạo hàm của các hàm số thường gặp\\n2.4.1 f(x) = aTx\\nGiả sửa,x ∈Rn, ta viết lại f(x) = aTx = a1x1 + a2x2 + ··· + anxn\\nCó thể nhận thấy rằng ∂f(x)\\n∂xi\\n= ai, ∀i= 1,2 ...,n .\\nVậy,∇(aTx) =\\n[\\na1 a2 ...a n\\n]T\\n= a. Ngoài ra, vìaTx = xTa nên ∇(xTa) = a.\\n2.4.2 f(x) = Ax\\nĐây là một hàm trả về vectorf : Rn →Rm với x ∈Rn,A ∈Rm×n. Giả sử rằngai là hàng\\nthứ i của ma trậnA. Ta có\\nAx =\\n\\uf8ee\\n\\uf8ef\\uf8ef\\uf8ef\\uf8f0\\na1x\\na2x\\n...\\namx\\n\\uf8f9\\n\\uf8fa\\uf8fa\\uf8fa\\uf8fb\\nTheo định nghĩa (2.8), và công thức đạo hàm củaaix, ta có thể suy ra\\n∇x(Ax) =\\n[\\naT\\n1 aT\\n2 ... aT\\nm\\n]\\n= AT (2.11)\\nTừ đây ta có thể suy ra đạo hàm của hàm sốf(x) = x = Ix, vớiI là ma trận đơn vị, là\\n∇x = I\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 45, 'page_label': '34'}, page_content='CHƯƠNG 2. GIẢI TÍCH MA TRẬN 34\\n2.4.3 f(x) = xTAx\\nvới x ∈Rn,A ∈Rn×n. Áp dụng quy tắc tích (2.9) ta có\\n∇f(x) = ∇\\n((\\nxT)\\n(Ax)\\n)\\n= (∇(x)) Ax + (∇(Ax)) x\\n= IAx + ATx\\n= (A + AT)x (2.12)\\nTừ (2.12) và (2.11), ta có thể suy ra∇2xTAx = AT + A\\nNếu A là một ma trận đối xứng, ta sẽ có∇xTAx = 2Ax, ∇2xTAx = 2A\\nNếu A là ma trận đơn vị, tứcf(x) = xTIx = xTx = ∥x∥2\\n2, ta có\\n∇∥x∥2\\n2 = 2x, ∇2∥x∥2\\n2 = 2I (2.13)\\n2.4.4 f(x) = ∥Ax −b∥2\\n2\\nCó hai cách tính đạo hàm của hàm số này:\\nCách 1:Trước hết, biến đổi\\nf(x) = ∥Ax −b∥2\\n2 = (Ax −b)T(Ax −b) = (xTAT −bT)(Ax −b)\\n= xTATAx −2bTAx + bTb\\nLấy đạo hàm cho từng số hạng rồi cộng lại ta có\\n∇∥Ax −b∥2\\n2 = 2ATAx −2ATb = 2AT(Ax −b)\\nCách 2:Sử dụng∇(Ax −b) = AT và ∇∥x∥2\\n2 = 2x và quy tắc chuỗi (2.10), ta cũng sẽ thu\\nđược kết quả tương tự.\\n2.4.5 f(x) = aTxxTb\\nBằng cách viết lạif(x) = (aTx)(xTb), ta có thể dùng Quy tắc tích (2.9) và có kết quả\\n∇(aTxxTb) = axTb + baTx = abTx + baTx = (abT + baT)x,\\nở đây ta đã sử dụng tính chấtyTz = zTy.\\n2.4.6 f(X) = trace(AX)\\nGiả sửA ∈Rn×m,X = Rm×n, vàB = AX ∈Rn×n. Theo định nghĩa của trace,\\nf(X) = trace(AX) = trace(B) =\\nn∑\\nj=1\\nbjj =\\nn∑\\nj=1\\nn∑\\ni=1\\najixji (2.14)\\nTừđâytathấyrằng ∂f(X)\\n∂xij\\n= aji.Sửdụngđịnhnghĩa(2.3)tađạtđược ∇Xtrace(AX) = AT.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 46, 'page_label': '35'}, page_content='35 CHƯƠNG 2. GIẢI TÍCH MA TRẬN\\nBảng 2.1: Bảng các đạo hàm cơ bản.\\nf(x) ∇f(x) f(X) ∇Xf(X)\\nx I trace(X) I\\naTx a trace(ATX) A\\nxTAx (A + AT)x trace(XTAX) (A + AT)X\\nxTx = ∥x∥2\\n2 2x trace(XTX) = ∥X∥2\\nF 2X\\n∥Ax −b∥2\\n2 2AT(Ax −b) ∥AX −B∥2\\nF 2AT(AX −B)\\naTxTxb 2aTbx aTXb abT\\naTxxTb (abT + baT)x trace(ATXB) ABT\\n2.4.7 f(X) = aTXb\\nGiả sử rằnga ∈Rm,X ∈Rm×n,b ∈Rn. Bạn đọc có thể chứng minh được\\nf(X) =\\nm∑\\ni=1\\nn∑\\nj=1\\nxijaibj\\nTừ đó, sử dụng định nghĩa (2.3) ta sẽ có∇X(aTXbT) =\\n\\uf8ee\\n\\uf8ef\\uf8ef\\uf8ef\\uf8f0\\na1b1 a1b2 ... a1bn\\na2b1 a2b2 ... a2bn\\n... ... ... ...\\namb1 amb2 ...a mbn\\n\\uf8f9\\n\\uf8fa\\uf8fa\\uf8fa\\uf8fb= abT.\\n2.4.8 f(X) = ∥X∥2\\nF\\nGiả sử X ∈Rn×n, bằng cách viết lại∥X∥2\\nF = ∑n\\ni=1\\n∑n\\nj=1 x2\\nij, ta có thể suy ra∂f\\n∂xij\\n= 2xij.\\nVà vì vậy,∇∥X∥2\\nF = 2X.\\n2.4.9 f(X) = trace(XTAX)\\nGiả sử rằngX =\\n[\\nx1 x2 ... xm\\n]\\n∈Rm×n,A ∈Rm×m. Bằng cách khai triển\\nXTAX =\\n\\uf8ee\\n\\uf8ef\\uf8ef\\uf8ef\\uf8f0\\nxT\\n1\\nxT\\n2\\n...\\nxT\\nn\\n\\uf8f9\\n\\uf8fa\\uf8fa\\uf8fa\\uf8fbA\\n[\\nx1 x2 ..., xn\\n]\\n=\\n\\uf8ee\\n\\uf8ef\\uf8ef\\uf8ef\\uf8f0\\nxT\\n1 Ax1 xT\\n1 Ax2 ... xT\\n1 Axn\\nxT\\n2 Ax1 xT\\n2 Ax2 ... xT\\n2 Axn\\n... ... ... ...\\nxT\\nnAx1 xT\\nnAx2 ... xT\\nnAxn\\n\\uf8f9\\n\\uf8fa\\uf8fa\\uf8fa\\uf8fb, (2.15)\\nta tính được trace(XTAX) = ∑n\\ni=1 xT\\ni Axi. Nhắc lại rằng∇xixT\\ni Axi = (A + AT)xi, ta có\\n∇Xtrace(XTAX) = (A + AT)\\n[\\nx1 x2 ... xn\\n]\\n= (A + AT)X (2.16)\\nBằng cách thayA = I, ta cũng thu được∇Xtrace(XTX) = ∇X∥X∥2\\nF = 2X.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 47, 'page_label': '36'}, page_content='CHƯƠNG 2. GIẢI TÍCH MA TRẬN 36\\n2.4.10 f(X) = ∥AX −B∥2\\nF\\nBằng kỹ thuật hoàn toàn tương tự như đã làm trong mục 2.4.4, ta thu được\\n∇X∥AX −B∥2\\nF = 2AT(AX −B)\\n2.5 Bảng các đạo hàm thường gặp\\nBảng 2.1 bao gồm đạo hàm của các hàm số thường gặp với biến là vector hoặc đạo hàm.\\n2.6 Kiểm tra đạo hàm\\nViệc tính đạo hàm của hàm nhiều biến thông thường khá phức tạp và rất dễ mắc lỗi. Trong\\nthực nghiệm, có một cách để kiểm tra liệu đạo hàm tính được có chính xác không. Cách này\\ndựa trên định nghĩa của đạo hàm cho hàm một biến.\\n2.6.1 Xấp xỉ đạo hàm của hàm một biến\\nTheo định nghĩa,\\nf′(x) = lim\\nε→0\\nf(x+ ε) −f(x)\\nε (2.17)\\nMột cách thường được sử dụng là lấy một giá trịεrất nhỏ, ví dụ10−6, và sử dụng công thức\\nf′(x) ≈f(x+ ε) −f(x−ε)\\n2ε (2.18)\\nCách tính này được gọi lànumerical gradient. Biểu thức (2.18) được sử dụng rộng rãi hơn\\nđể tínhnumerical gradient. Có hai cách giải thích cho vấn đề này.\\nBằng giải tích\\nChúng ta cùng quay lại một chút với khai triển Taylor. Vớiε rất nhỏ, ta có hai xấp xỉ sau:\\nf(x+ ε) ≈f(x) + f′(x)ε+ f”(x)\\n2 ε2 + f(3)\\n6 ε3 + ... (2.19)\\nf(x−ε) ≈f(x) −f′(x)ε+ f”(x)\\n2 ε2 −f(3)\\n6 ε3 + ... (2.20)\\nTừ đó ta có:\\nf(x+ ε) −f(x)\\nε ≈f′(x) + f”(x)\\n2 ε+ ··· = f′(x) + O(ε) (2.21)\\nf(x+ ε) −f(x−ε)\\n2ε ≈f′(x) + f(3)(x)\\n6 ε2 + ··· = f′(x) + O(ε2) (2.22)\\ntrong đóO() là Big O notation.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 48, 'page_label': '37'}, page_content='37 CHƯƠNG 2. GIẢI TÍCH MA TRẬN\\nε\\nε\\nf(x0) − f(x0 − ε)\\nf(x0 + ε) − f(x0)\\nf(x0 + ε) − f(x0 − ε)\\n2ε\\nHình 2.1: Giải thích\\ncách xấp xỉ đạo hàm\\nbằng hình học.\\nTừ đó, nếu xấp xỉ đạo hàm bằng công thức (2.21) (xấp xỉ đạo hàm phải), sai số sẽ làO(ε).\\nTrong khi đó, nếu xấp xỉ đạo hàm bằng công thức (2.22) (xấp xỉ đạo hàm hai phía), sai số\\nsẽ làO(ε2). Khiε rất nhỏ,O(ε2) ≪O(ε), tức cách đánh giá sử dụng công thức 2.22 có sai\\nsố nhỏ hơn, và vì vậy nó được sử dụng nhiều hơn.\\nChúng ta cũng có thể giải thích điều này bằng hình học.\\nBằng hình học\\nQuan sát Hình 2.1, vector màu đỏ là đạo hàmchính xác của hàm số tại điểm có hoành độ\\nbằng x0. Vector màu xanh lam và xanh lục lần lượt thể hiện cách xấp xỉ đạo hàm phía phải\\nvà phía trái. Vector màu nâu thể hiện cách xấp xỉ đạo hàm hai phía. Trong ba vector xấp\\nxỉ đó, vector xấp xỉ hai phía màu nâu là gần với vector đỏ nhất nếu xét theo hướng.\\nSự khác biệt giữa các cách xấp xỉ còn lớn hơn nữa nếu tại điểmx, hàm số bịbẻ congmạnh\\nhơn. Khi đó, xấp xỉ trái và phải sẽ khác nhau rất nhiều. Xấp xỉ hai bên sẽổn định hơn.\\nTừ đó ta thấy rằng xấp xỉ đạo hàm hai phía là xấp xỉ tốt hơn.\\n2.6.2 Xấp xỉ đạo hàm của hàm nhiều biến\\nVới hàm nhiều biến, công thức (2.22) được áp dụng cho từng biến khi các biến khác cố định.\\nCụ thể, ta sử dụng định nghĩa của hàm số nhận đầu vào là một ma trận như công thức (2.3).\\nMỗi thành phần của ma trận kết quả là đạo hàm của hàm số tại thành phần đó khi ta coi\\ncác thành phần còn lại cố định. Chúng ta sẽ thấy rõ điều này hơn ở cách lập trình so sánh\\nhai cách tính đạo hàm ngay phía dưới.\\nCách tính xấp xỉ đạo hàm theo phương phápnumerical thường cho giá trị khá chính xác.\\nTuy nhiên, cách này không được sử dụng để tính đạo hàm vì độ phức tạp quá cao so với\\ncách tính trực tiếp. Tại mỗi thành phần, ta cần tính giá trị của hàm số tại phía trái và phía\\nphải, như vậy sẽ không khả thi với các ma trận lớn. Khi so sánh đạo hàmnumerical này\\nvới đạo hàm tính theo công thức, người ta thường giảm số chiều dữ liệu và giảm số điểm dữ'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 48, 'page_label': '37'}, page_content='phải, như vậy sẽ không khả thi với các ma trận lớn. Khi so sánh đạo hàmnumerical này\\nvới đạo hàm tính theo công thức, người ta thường giảm số chiều dữ liệu và giảm số điểm dữ\\nliệu để thuận tiện cho tính toán. Nếu công thức đạo hàm ta tính được là chính xác, nó sẽ\\nrất gần với đạo hàmnumerical.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 49, 'page_label': '38'}, page_content='CHƯƠNG 2. GIẢI TÍCH MA TRẬN 38\\nĐoạn Code 2.1 giúp kiểm tra đạo hàm của một hàm số khả vif : Rm×n →R, có kèm theo\\nhai ví dụ. Để sử dụng hàm kiểm tracheck_grad này, ta cần viết hai hàm. Hàm thứ nhất là\\nhàm fn(X) tính giá trị của hàm số tạiX. Hàm thứ hai là hàmgr(X) tính giá trị của đạo hàm\\nmà ta cần kiểm tra.\\nfrom __future__ import print_function\\nimport numpy as np\\ndef check_grad(fn, gr, X):\\nX_flat = X.reshape(-1) # convert X to an 1d array -> 1 for loop needed\\nshape_X = X.shape # original shape of X\\nnum_grad = np.zeros_like(X) # numerical grad, shape = shape of X\\ngrad_flat = np.zeros_like(X_flat) # 1d version of grad\\neps = 1e-6 # a small number, 1e-10 -> 1e-6 is usually good\\nnumElems = X_flat.shape[0] # number of elements in X\\n# calculate numerical gradient\\nfor i in range(numElems): # iterate over all elements of X\\nXp_flat = X_flat.copy()\\nXn_flat = X_flat.copy()\\nXp_flat[i] += eps\\nXn_flat[i] -= eps\\nXp = Xp_flat.reshape(shape_X)\\nXn = Xn_flat.reshape(shape_X)\\ngrad_flat[i] = (fn(Xp) - fn(Xn))/(2*eps)\\nnum_grad = grad_flat.reshape(shape_X)\\ndiff = np.linalg.norm(num_grad - gr(X))\\nprint(’Difference between two methods should be small:’, diff)\\n# ==== check if grad(trace(A*X)) == A^T ====\\nm, n = 10, 20\\nA = np.random.rand(m, n)\\nX = np.random.rand(n, m)\\ndef fn1(X):\\nreturn np.trace(A.dot(X))\\ndef gr1(X):\\nreturn A.T\\ncheck_grad(fn1, gr1, X)\\n# ==== check if grad(x^T*A*x) == (A + A^T)*x ====\\nA = np.random.rand(m, m)\\nx = np.random.rand(m, 1)\\ndef fn2(x):\\nreturn x.T.dot(A).dot(x)\\ndef gr2(x):\\nreturn (A + A.T).dot(x)\\ncheck_grad(fn2, gr2, x)\\nCode 2.1: Kiểm tra đạo hàm bằng phương pháp numerical.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 50, 'page_label': '39'}, page_content='39 CHƯƠNG 2. GIẢI TÍCH MA TRẬN\\nKết quả:\\nDifference between two methods should be small: 2.02303323394e-08\\nDifference between two methods should be small: 2.10853872281e-09\\nKết quả cho thấy sự khác nhau giữa Frobenious norm (mặc định củanp.linalg.norm) của\\nkết quả của hai cách tính là rất nhỏ. Sau khi chạy lại đoạn code với các giá trịm, n khác\\nnhau và biếnX khác nhau, nếu sự khác nhau vẫn là nhỏ, ta có thể tự tin rằng đạo hàm mà\\nta tính được là chính xác.\\nBạn đọc có thể tự kiểm tra lại các công thức trong Bảng 2.1 theo phương pháp này.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 51, 'page_label': '40'}, page_content='Chương 3\\nÔn tập Xác Suất\\nChương này được viết dựa trên Chương 2 và 3 của cuốn Computer Vision: Models, Learning,\\nand Inference–Simon J.D. Prince (http://www.computervisionmodels.com).\\n3.1 Xác Suất\\n3.1.1 Random variables\\nMột biến ngẫu nhiên (random variable) x là một đại lượng dùng để đo những đại lượng\\nkhông xác định. Biến này có thể được dùng để ký hiệu kết quả/đầu ra (outcome) của một\\nthí nghiệm, ví dụ như tung đồng xu, hoặc một đại lượng biến đổi trong tự nhiên, ví dụ như\\nnhiệt độ trong ngày. Nếu chúng ta quan sát rất nhiều đầu ra{xi}I\\ni=1 của các thí nghiệm này,\\nta có thể nhận được những giá trị khác nhau ở mỗi thí nghiệm. Tuy nhiên, sẽ có những giá\\ntrị xảy ra nhiều lần hơn những giá trị khác, hoặc xảy ra gần một giá trị này hơn những giá trị\\nkhác. Thông tin về đầu ra này được đo bởi mộtphân phối xác suất(probaility distribution)\\nđược biểu diễn bằng một hàmp(x). Một biến ngẫu nhiên có thể làrời rạc(discrete) hoặc\\nliên tục(continuous).\\nMột biến ngẫu nhiên rời rạc sẽ lấy giá trị trong một tập hợp các điểm rời rạc cho trước. Ví\\ndụ tung đồng xu thì có hai khả năng làhead và tail1.Tập các giá trị này có thể làcó thứ tự\\nnhư khi tung xúc xắc hoặckhông có thứ tự, ví dụ khi đầu ra là các giá trịnắng, mưa, bão.\\nMỗi đầu ra có một giá trị xác suất tương ứng với nó. Các giá trị xác suất này không âm và\\ncó tổng bằng một.\\nNếu x là biến ngẫu nhiên rời rạc thì\\n∑\\nx\\np(x) = 1 (3.1)\\nBiến ngẫu nhiên liên tục lấy các giá trị là các số thực. Những giá trị này có thể là hữu hạn,\\nví dụ thời gian làm bài của mỗi thí sinh trong một bài thi 180 phút, hoặc vô hạn, ví dụ thời\\n1 đồng xu thường có một mặt có hình đầu người, được gọi làhead, trái ngược với mặt này được gọi là mặttail'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 52, 'page_label': '41'}, page_content='41 CHƯƠNG 3. ÔN TẬP XÁC SUẤT\\ngian phải chờ tới khách hàng tiếp theo. Không như biến ngẫu nhiên rời rạc, xác suất để đầu\\nra bằngchính xácmột giá trị nào đó, theo lý thuyết, là bằng không. Thay vào đó, xác suất\\nđể đầu ra rời vào một khoảng giá trị nào đó là khác không. Việc này được mô tả bởihàm\\nmật độ xác suất(probability density function - pdf). Hàm mật độ xác suất luôn cho giá trị\\ndương, và tích phân của nó trên toàn miền giá trị đầu rapossible outcomephải bằng một.\\nNếu x là biến ngẫu nhiên liên tục thì\\n∫\\np(x)dx= 1 (3.2)\\nNếu x là biến ngẫu nhiên rời rạc, thìp(x) ≤1, ∀x. Trong khi đó, nếux là biến ngẫu\\nnhiên liên tục,p(x) có thể nhận giá trị không âm bất kỳ, điều này vẫn đảm bảo là tích\\nphân của hàm mật độ xác suất theo toàn bộ giá trị có thể có củax bằng một.\\n3.1.2 Xác suất đồng thời\\nXét hai biến ngẫu nhiênx và y. Nếu ta quan sát rất nhiều cặp đầu ra củax và y, thì có\\nnhững tổ hợp hai đầu ra xảy ra thường xuyên hơn những tổ hợp khác. Thông tin này được\\nbiểu diễn bằng một phân phối được gọi làxác suất đồng thời(joint probability) củax và y,\\nđược ký hiệu làp(x,y), đọc là xác suất củax và y. Hai biến ngẫu nhiênx và y có thể đồng\\nthời là biến ngẫu nhiên rời rạc, liên tục, hoặc một rời rạc, một liên tục. Luôn nhớ rằng tổng\\ncác xác suất trên mọi cặp giá trị có thể xảy ra(x,y) bằng một.\\nCả x và y là rời rạc:\\n∑\\nx,y\\np(x,y) = 1 (3.3)\\nCả x và y là liên tục:\\n∫\\np(x,y)dxdy= 1 (3.4)\\nx rời rạc, yliên tục:\\n∑\\nx\\n∫\\np(x,y)dy=\\n∫ (∑\\nx\\np(x,y)\\n)\\ndy= 1 (3.5)\\nXét ví dụ trong Hình 3.1, phần có nền màu lục nhạt. Biến ngẫu nhiênx thể hiện điểm thi\\nmôn Toán của học sinh ở một trường THPT trong một kỳ thi Quốc gia, biến ngẫu nhiêny\\nthể hiện điểm thi môn Vật Lý cũng trong kỳ thi đó. Đại lượngp(x= x∗,y = y∗) là tỉ lệ giữa\\ntần suất số học sinh đượcđồng thời x∗ điểm trong môn Toán vày∗ điểm trong môn Vật Lý\\nvà toàn bộ số học sinh của trường đó. Tỉ lệ này có thể coi là xác suất khi số học sinh trong\\ntrường là lớn. Ở đâyx∗ và y∗ là các số xác định. Thông thường, xác suất này được viết gọn'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 52, 'page_label': '41'}, page_content='và toàn bộ số học sinh của trường đó. Tỉ lệ này có thể coi là xác suất khi số học sinh trong\\ntrường là lớn. Ở đâyx∗ và y∗ là các số xác định. Thông thường, xác suất này được viết gọn\\nlại thànhp(x∗,y∗), vàp(x,y) được dùng như một hàm tổng quát để mô tả các xác suất. Giả\\nsử thêm rằng điểm các môn là các số tự nhiên từ 1 đến 10.\\nCác ô vuông màu lam thể hiện xác suấtp(x,y), với diện tích ô vuông càng to thể hiện xác\\nsuất đó càng lớn. Chú ý rằng tổng các xác suất này bằng một.\\nCác bạn có thể thấy rằng xác suất để một học sinh được 10 điểm một Toán và 1 điểm môn\\nLý rất thấp, điều tương tự xảy ra với 10 điểm môn Lý và 1 điểm môn Toán. Ngược lại, xác\\nsuất để một học sinh được khoảng 7 điểm cả hai môn là cao nhất.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 53, 'page_label': '42'}, page_content='CHƯƠNG 3. ÔN TẬP XÁC SUẤT 42\\nJoint probability\\nConditional\\nProbabilities\\nMarginalization\\n1\\n1\\n2\\n2\\n3\\n3\\n4\\n4\\n5\\n5\\n6\\n6\\n7\\n7\\n8\\n8\\n9\\n9\\n10\\n10\\nx : Math score\\n( x, y )\\ny : Physics score\\n1 2 3 4 5 6 7 8 9 10\\n( x | y = 9)\\n1 2 3 4 5 6 7 8 9 10\\n( x | y = 3)\\n1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n9\\n10\\n(y|x= 10)\\n1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n9\\n10\\n(y|x= 2)\\n1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n9\\n10\\n(y) =\\n∑\\nx\\n(x, y)\\n1 2 3 4 5 6 7 8 9 10\\n( x ) =\\n∑\\ny\\n( x, y )\\nHình 3.1: Xác suất đồng thời (phần trung tâm có nền màu lục nhạt), Xác suất biên (phía trên\\nvà bên trái) và Xác suất có điền kiện (phía dưới và bên phải).\\nThông thường, chúng ta sẽ làm việc với các bài toán ở đó xác suất có điều kiện được xác\\nđịnh trên nhiều hơn hai biến ngẫu nhiên. Chẳng hạn,p(x,y,z ) thể hiện joint probability của\\nba biến ngẫu nhiênx,y và z. Khi có nhiều biến ngẫu nhiên, ta có thể viết chúng dưới dạng\\nvector. Cụ thể, ta có thể viếtp(x) để thể hiện xác suất có điều kiện của biến ngẫu nhiên\\nnhiều chiềux = [x1,x2,...,x n]T. Khi có nhiều tập các biến ngẫu nhiên, ví dụx và y, ta có\\nthể biếtp(x,y) để thể hiện xác suất có điều kiện của tất cả các thành phần trong hai biến\\nngẫu nhiên nhiều chiều này.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 54, 'page_label': '43'}, page_content='43 CHƯƠNG 3. ÔN TẬP XÁC SUẤT\\n3.1.3 Xác suất biên\\nNếu biết xác suất đồng thời của nhiều biến ngẫu nhiên, ta cũng có thể xác định được phân\\nphối xác suất của từng biến bằng cách lấy tổng với biến ngẫu nhiên rời rạc hoặc tích phân\\nvới biến ngẫu nhiên liên tục theo tất cả các biến còn lại:\\nNếu x,y rời rạc: p(x) =\\n∑\\ny\\np(x,y) (3.6)\\np(y) =\\n∑\\nx\\np(x,y) (3.7)\\nNếu x,y liên tục: p(x) =\\n∫\\np(x,y)dy (3.8)\\np(y) =\\n∫\\np(x,y)dx (3.9)\\nVới nhiều biến hơn, chẳng hạn bốn biến rời rạcx,y,z,w , cách tính được thực hiện tương tự:\\np(x) =\\n∑\\ny,z,w\\np(x,y,z,w ) (3.10)\\np(x,y) =\\n∑\\nz,w\\np(x,y,z,w ) (3.11)\\nCách xác định xác suất của một biến dựa trên xác suất đồng thời của nó với các biến khác\\nđược gọi làmarginalization. Phân phối đó được gọi làxác suất biên(marginal probability).\\nTừ đây trở đi, nếu không đề cập gì thêm, chúng ta sẽ dùng ký hiệu∑ để chỉ chung cho\\ncả hai loại biến. Nếu biến ngẫu nhiên là liên tục, bạn đọc ngầm hiểu rằng dấu∑cần được\\nthay bằng dấu tích phân\\n∫\\n, biến lấy vi phân chính là biến được viết dưới dấu∑. Chẳng\\nhạn, trong (3.11), nếuz là liên tục,w là rời rạc, công thức đúng sẽ là\\np(x,y) =\\n∑\\nw\\n(∫\\np(x,y,z,w )dz\\n)\\n=\\n∫ (∑\\nw\\np(x,y,z,w )\\n)\\ndz (3.12)\\nQuay lại ví dụ trong Hình 3.1 với hai biến ngẫu nhiên rời rạcx,y. Lúc này,p(x) được hiểu\\nlà xác suất để một học sinh đạt đượcx điểm môn Toán. Xác suất này được thể hiện ở khu\\nvực có nền màu tím nhạt, phía trên. Nhắc lại rằng xác suất ở đây thực ra là tỉ lệ giữa số\\nhọc sinh đạtxđiểm môn Toán và toàn bộ số học sinh. Có hai cách tính xác suất này. Cách\\nthứ nhất, dựa trên cách vừa định nghĩa, là đếm số học sinh đượcx điểm môn toán rồi chia\\ncho tổng số học sinh. Cách tính thứ hai dựa trên xác suất đồng thời đã biết về xác suất để\\nmột học sinh đượcxđiểm môn Toán vày điểm môn Lý. Số lượng học sinh đạtx= x∗ điểm\\nmôn Toán sẽ bằng tổng số lượng học sinh đạtx = x∗ điểm môn Toánvà y điểm môn Lý,\\nvới y là một giá trị bất kỳ từ 1 đến 10. vì vậy, để tính xác suấtp(x), ta chỉ cần tính tổng'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 54, 'page_label': '43'}, page_content='môn Toán sẽ bằng tổng số lượng học sinh đạtx = x∗ điểm môn Toánvà y điểm môn Lý,\\nvới y là một giá trị bất kỳ từ 1 đến 10. vì vậy, để tính xác suấtp(x), ta chỉ cần tính tổng\\ncủa toàn bộp(x,y) với y chạy từ 1 đến 10. Tương tự nếu ta muốn tínhp(y) (xem phần bên\\ntrái của khu vực nền tím nhạt).\\nDựa trên nhận xét này, mỗi giá trị củap(x) chính bằng tổng các giá trị trong cột thứxcủa\\nhình vuông trung tâm nền xanh lục. Mỗi giá trị củap(y) sẽ bằng tổng các giá trị trong hàng\\nthứ y tính từ đưới lên. Chú ý rằng tổng các xác suất luôn bằng một.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 55, 'page_label': '44'}, page_content='CHƯƠNG 3. ÔN TẬP XÁC SUẤT 44\\n3.1.4 Xác suất có điều kiện.\\nDựa vào phân phối điểm của các học sinh, liệu ta có thể tính được xác suất để một học sinh\\nđược điểm 10 môn Lý, biết rằng học sinh đó được điểm 1 môn Toán?\\nXác suất để một biến ngẫu nhiênx nhận một giá trị nào đó biết rằng biến ngẫu nhiên\\ny có giá trịy∗ được gọi làxác suất có điều kiện(conditional probability), được ký hiệu là\\np(x|y= y∗).\\nXác suất có điều kiệnp(x|y= y∗) có thể được tính dựa trên xác suất đồng thờip(x,y). Quay\\nlại Hình 3.1 với vùng có nền màu nâu nhạt. Nếu biết rằngy= 9, xác suấtp(x|y= 9) có thể\\ntính được dựa trên hàng thứ chín của hình vuông trung tâm, tức hàngp(x,y = 9). Trong\\nhàng này, những ô vuông lớn hơn thể hiện xác suất lớn hơn. Tương ứng như thế,p(x|y= 9)\\ncũng lớn nếup(x,y = 9) lớn. Chú ý rằng tổng các xác suất∑\\nxp(x,y = 9) nhỏ hơn một, và\\nbằng tổng các xác suất trên hàng thứ chín này. Để thoả mãn điều kiện tổng các xác suất\\nbằng một, ta cần chia mỗi đại lượngp(x,y = 9) cho tổng của toàn hàng này. Tức là\\np(x|y= 9) = p(x,y = 9)∑\\nx\\np(x,y = 9) = p(x,y = 9)\\np(y= 9) (3.13)\\nTổng quát,\\np(x|y= y∗) = p(x,y = y∗)∑\\nx\\np(x,y = y∗) = p(x,y = y∗)\\np(y= y∗) (3.14)\\nở đây ta đã sử dụng công thức tính xác suất biên trong (3.7) cho mẫu số. Thông thường, ta\\ncó thể viết xác suất có điều kiện mà không cần chỉ rõ giá trịy= y∗và có công thức gọn hơn:\\np(x|y) = p(x,y)\\np(y) , và tương tự, p(y|x) = p(y,x)\\np(x) (3.15)\\nTừ đó ta có quan hệ\\np(x,y) = p(x|y)p(y) = p(y|x)p(x) (3.16)\\nKhi có nhiều hơn hai biến ngẫu nhiên, ta có các công thức\\np(x,y,z,w ) = p(x,y,z |w)p(w) (3.17)\\n= p(x,y|z,w)p(z,w) = p(x,y|z,w)p(z|w)p(w) (3.18)\\n= p(x|y,z,w )p(y|z,w)p(z|w)p(w) (3.19)\\nCông thức (3.19) có dạngchuỗi (chain) và được sử dụng nhiều sau này.\\n3.1.5 Quy tắc Bayes\\nCông thức (3.16) biểu diễn xác suất đồng thời theo hai cách. Từ đó ta có thể suy ra:\\np(y|x)p(x) = p(x|y)p(y) (3.20)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 56, 'page_label': '45'}, page_content='45 CHƯƠNG 3. ÔN TẬP XÁC SUẤT\\nBiến đối một chút:\\np(y|x) = p(x|y)p(y)\\np(x) (3.21)\\n= p(x|y)p(y)∑\\ny\\np(x,y) (3.22)\\n= p(x|y)p(y)∑\\ny\\np(x|y)p(y) (3.23)\\nở đó dòng thứ hai và thứ ba các công thức về xác suất biên và xác suất đồng thời ở mẫu số\\nđã được sử dụng. Từ (3.23) ta có thể thấy rằngp(y|x) hoàn toàn có thể tính được nếu ta\\nbiết mọip(x|y) và p(y). Tuy nhiên, việc tính trực tiếp xác suất này thường là phức tạp.\\nBa công thức(3.21)-(3.23) thường được gọi làQuy tắc Bayes(Bayes’ rule). Chúng\\nđược sử dụng rộng rãi trong Machine Learning\\n3.1.6 Biến ngẫu nhiên độc lập\\nNếu biết giá trị của một biến ngẫu nhiênx không mang lại thông tin về việc suy ra giá\\ntrị của biến ngẫu nhiêny (và ngược lại), thì ta nói rằng hai biến ngẫu nhiên làđộc lập\\n(independent). Chẳng hạn, chiều cao của một học sinh và điểm thi môn Toán của học sinh\\nđó có thể coi là hai biến ngẫu nhiênđộc lập.\\nKhi hai biến ngẫu nhiênx và y là độc lập, ta sẽ có:\\np(x|y) = p(x) (3.24)\\np(y|x) = p(y) (3.25)\\nThay vào biểu thức xác suất đồng thời trong (3.16), ta có:\\np(x,y) = p(x|y)p(y) = p(x)p(y) (3.26)\\n3.1.7 Kỳ vọng và ma trận hiệp phương sai\\nKỳ vọng (expectation) của một biến ngẫu nhiên được định nghĩa là\\nE[x] =\\n∑\\nx\\nxp(x) nếu x là rời rạc (3.27)\\nE[x] =\\n∫\\nxp(x)dx nếu x là liên tục (3.28)\\nGiả sửf(.) là một hàm số trả về một số với mỗi giá trịx∗ của biến ngẫu nhiênx. Khi đó,\\nnếu x là biến ngẫu nhiên rời rạc, ta sẽ có\\nE[f(x)] =\\n∑\\nx\\nf(x)p(x) (3.29)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 57, 'page_label': '46'}, page_content='CHƯƠNG 3. ÔN TẬP XÁC SUẤT 46\\nCông thức cho biến ngẫu nhiên liên tục cũng được viết tương tự.\\nVới xác suất đồng thời\\nE[f(x,y)] =\\n∑\\nx,y\\nf(x,y)p(x,y)dxdy (3.30)\\nCó ba tính chất cần nhớ về kỳ vọng:\\n1. Kỳ vọng của một hằng số theo một biến ngẫu nhiênx bất kỳ bằng chính hằng số đó:\\nE[α] = α (3.31)\\n2. Kỳ vọng có tính chất tuyến tính:\\nE[αx] = αE[x] (3.32)\\nE[f(x) + g(x)] = E[f(x)] + E[g(x)] (3.33)\\n3. Kỳ vọng của tích hai biến ngẫu nhiên bằng tích kỳ vọng của hai biến đónếu hai biến\\nngẫu nhiên đó là độc lập.\\nE[f(x)g(y)] = E[f(x)]E[g(y)] (3.34)\\nKhái niệm kỳ vọng thường đi kèm với khái niệmphương sai(variance) trong không gian một\\nchiều, vàma trận hiệp phương sai(covariance matrix) trong không gian nhiều chiều.\\nVới dữ liệu một chiều\\nCho N giá trịx1,x2,...,x N. Kỳ vọngvàphương saicủa bộ dữ liệu này được tính theo công\\nthức:\\n¯x= 1\\nN\\nN∑\\nn=1\\nxn = 1\\nNx1 (3.35)\\nσ2 = 1\\nN\\nN∑\\nn=1\\n(xn −¯x)2 (3.36)\\nvới x =\\n[\\nx1,x2,...,x N\\n]\\n, và1 ∈RN là vector cột chứa toàn phần tử 1. Kỳ vọng đơn giản\\nlà trung bình cộng của toàn bộ các giá trị. Phương sai là trung bình cộng của bình phương\\nkhoảng cách từ mỗi điểm tới kỳ vọng. Phương sai càng nhỏ thì các điểm dữ liệu càng gần\\nvới kỳ vọng, tức các điểm dữ liệu càng giống nhau. Phương sai càng lớn thì ta nói dữ liệu\\ncàng có tính phân tán. Ví dụ về kỳ vọng và phương sai của dữ liệu một chiều có thể được\\nthấy trong Hình 3.2a. Căn bậc hai của phương sai,σcòn được gọi làđộ lệch chuẩn(standard\\ndeviation) của dữ liệu.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 58, 'page_label': '47'}, page_content='47 CHƯƠNG 3. ÔN TẬP XÁC SUẤT\\nVới dữ liệu nhiều chiều\\nCho N điểm dữ liệu được biểu diễn bởi các vector cộtx1,..., xN, khi đó,vector kỳ vọngvà\\nma trận hiệp phương saicủa toàn bộ dữ liệu được định nghĩa là:\\n¯x = 1\\nN\\nN∑\\nn=1\\nxn (3.37)\\nS = 1\\nN\\nN∑\\nn=1\\n(xn −¯x)(xn −¯x)T = 1\\nN\\nˆX ˆXT (3.38)\\nTrong đó ˆX được tạo bằng cách trừ mỗi cột củaX đi ¯x:\\nˆxn = xn −¯x (3.39)\\nMột vài tính chất của ma trận hiệp phương sai:\\n• Ma trận hiệp phương sai là một ma trận đối xứng, hơn nữa, nó là một ma trận nửa xác\\nđịnh dương.\\n• Mọi phần tử trên đường chéo của ma trận hiệp phương sai là các số không âm. Chúng\\ncũng chính là phương sai của từng chiều của dữ liệu.\\n• Các phần tử ngoài đường chéosij,i ̸= j thể hiện sự tương quan giữa thành phần thứi\\nvà thứj của dữ liệu, còn được gọi là hiệp phương sai. Giá trị này có thể dương, âm hoặc\\nbằng không. Khi nó bằng không, ta nói rằng hai thành phầni,j trong dữ liệu làkhông\\ntương quan (uncorrelated).\\n• Nếu ma trận hiệp phương sai là ma trận đường chéo, ta có dữ liệu hoàn toàn không tương\\nquan giữa các chiều.\\nVí dụ về dữ liệu không tương quan và tương quan được cho trong Hình 3.2b và 3.2c.\\n3.2 Một vài phân phối thường gặp\\n3.2.1 Phân phối Bernoulli\\nPhân phối Bernoulli là một phân phối rời rạc mô tả các biến ngẫu nhiên nhị phân: trường\\nhợp đầu ra chỉ nhận một trong hai giá trịx∈{0,1}. Hai giá trị này có thể làhead và tail\\nkhi tung đồng xu; có thể làgiao dịch lừa đảovà giao dịch thông thườngtrong bài toán xác\\nđịnh giao dịch lừa đảo trong tín dụng; có thể làngười và không phải ngườitrong bài toán\\ntìm xem trong một bức ảnh có người hay không.\\nBernoulli distribution được mô tả bằng một tham sốλ∈[0,1] và là xác suất để biến ngẫu\\nnhiên x= 1. Xác suất của mỗi đầu ra sẽ là\\np(x= 1) = λ, p (x= 0) = 1 −p(x= 1) = 1 −λ (3.40)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 59, 'page_label': '48'}, page_content='CHƯƠNG 3. ÔN TẬP XÁC SUẤT 48\\nx\\nσ ¯x\\n(a)\\nσ1\\nσ2 e1\\ne2 (b)\\ne1\\ne2\\nσ1\\nσ2\\n(c)\\nHình 3.2: Ví dụ về kỳ vọng và phương sai. (a) Trong không gian một chiều. (b) Trong không\\ngian hai chiều mà hai chiều không tương quan. Trong trường hợp này, ma trận hiệp phương sai\\nlà ma trận đường chéo với hai phần tử trên đường chéo làσ1,σ2, đây cũng chính là hai trị riêng\\ncủa ma trận hiệp phương sai và là phương sai của mỗi chiều dữ liệu. (c) Dữ liệu trong không gian\\nhai chiều có tương quan. Theo mỗi chiều, ta có thể tính được kỳ vọng và phương sai. Phương\\nsai càng lớn thì dữ liệu trong chiều đó càng phân tán. Trong ví dụ này, dữ liệu theo chiều thứ hai\\nphân tán nhiều hơn so so với chiều thứ nhất.\\nHai đẳng thức này thường được viết gọn lại:\\np(x) =λx(1−λ)1−x (3.41)\\nvới giả định rằng00 = 1. Thật vậy,p(0) =λ0(1−λ)1 = 1 −λ, vàp(1) =λ1(1−λ)0 = λ.\\nPhân phối Bernoulli thường được ký hiệu ngắn gọn dưới dạng\\np(x) =Bernx[λ] (3.42)\\n3.2.2 Phân phối Categorical\\nTrong nhiều trường hợp, đầu ra của biến ngẫu nhiên rời rạc có thể là một trong nhiều hơn\\nhai giá trị khác nhau. Ví dụ, một bức ảnh có thể chứa một chiếc xe, một người, hoặc một\\ncon mèo. Khi đó, ta dùng một phân phối tổng quát của phân phối Bernoulli, được gọi là\\nphân phối Categorical. Các đầu ra được mô tả bởi một phần tử trong tập hợp{1,2,...,K }.\\nNếu cóK đầu ra, phân phối Categorical sẽ được mô tả bởiK tham số, viết dưới dạng vector:\\nλ = [λ1,λ2,...,λ K]với cácλk không âm và có tổng bằng một. Mỗi giá trịλk thể hiện xác\\nsuất để đầu ra nhận giá trịk: p(x= k) =λk.\\nPhân phối Categorical thường được ký hiệu dưới dạng:\\np(x) =Catx[λ] (3.43)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 60, 'page_label': '49'}, page_content='49 CHƯƠNG 3. ÔN TẬP XÁC SUẤT\\n−7.5 −5.0 −2.5 0.0 2.5 5.0 7.5\\nx\\n0.0\\n0.1\\n0.2\\n0.3\\n0.4\\n0.5\\np(x) µ = 0, σ2 = 1\\nµ = .5, σ2 = .5\\nµ = −1, σ2 = 2\\n(a)\\n(b)\\nHình 3.3:Ví dụ về hàm mật độ xác suất của (a) phân phối chuẩn một chiều, và (b) phân phối\\nchuẩn hai chiều.\\nNếu thay vì biểu diễn đầu ra là một sốk trong tập hợp{1,2,...,K }, ta biểu diễn đầu ra là\\nmột vector ở dạngone-hot, tức một vectorK phần tử với chỉ phần tử thứk bằng một, các\\nphần tử còn lại bằng không. Nói cách khác, tập hợp các đầu ra là tập hợp các vector đơn vị\\nbậc K: x ∈{e1,e2,..., eK}với ek là vector đơn vị thứk. Khi đó, ta sẽ có\\np(x = ek) =\\nK∏\\nj=1\\nλ\\nxj\\nj = λk (3.44)\\nKhi x = ek,xk = 1,xj = 0, ∀j ̸= k. Thay vào (3.44) ta sẽ đượcp(x = ek) = λk = p(x= k).\\n3.2.3 Phân phối chuẩn một chiều\\nPhân phối chuẩn một chiều(univariate normalhoặc Gaussian distribution) được định nghĩa\\ntrên các biến liên tục nhận giá trịx∈(−∞,∞). Đây là một phân phối được sử dụng nhiều\\nnhất với các biến ngẫu nhiên liên tục. Phân phối này được mô tả bởi hai tham số:kỳ vọng\\nµvà phương sai(variance) σ2. Giá trịµcó thể là bất kỳ số thực nào, thể hiện vị trí của giá\\ntrị mà tại đó mà hàm mật độ xác suất đạt giá trị cao nhất. Giá trịσ2 là một giá trị dương,\\nvới σ thể hiệnđộ rộng của phân phối này.σ lớn chứng tỏ khoảng giá trị đầu ra có khoảng\\nbiến đổi mạnh, và ngược lại.\\nHàm mật độ xác suất của phân phối này được định nghĩa là\\np(x) = 1√\\n2πσ2\\nexp\\n(\\n−(x−µ)2\\n2σ2\\n)\\n(3.45)\\nHoặc được viết gọn hơn dưới dạngp(x) = Normx[µ,σ2], hoặcN(µ,σ2).\\nVí dụ về đồ thị hàm mật độ xác suất của phân phối chuẩn một chiều được cho trên Hình 3.3a.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 61, 'page_label': '50'}, page_content='CHƯƠNG 3. ÔN TẬP XÁC SUẤT 50\\n3.2.4 Phân phối chuẩn nhiều chiều\\nPhân phối này là trường hợp tổng quát của phân phối chuẩn khi biến ngẫu nhiên là nhiều\\nchiều, giả sử làD chiều. Có hai tham số mô tả phân phối này:vector kỳ vọngµ∈RD và\\nma trận hiệp phương saiΣ ∈SD là một ma trậnđối xứng xác định dương.\\nHàm mật độ xác suất có dạng\\np(x) = 1\\n(2π)D/2|Σ|1/2 exp\\n(1\\n2(x −µ)TΣ−1(x −µ)\\n)\\n(3.46)\\nvới |Σ|là định thức của ma trận hiệp phương saiΣ.\\nPhân phối này thường được viết gọn lại dưới dạngp(x) = Normx[µ,Σ], hoặcN(µ,Σ).\\nVí dụ về hàm mật độ xác suất của một phân phối chuẩn hai chiều (bivariate normal distri-\\nbution) được mô tả bởi một mặt cong cho trên Hình 3.3b. Nếu cắt mặt này theo các mặt\\nphẳng song song với mặt đáy, ta sẽ thu được các hình ellipse đồng tâm.\\n3.2.5 Phân phối Beta\\nPhân phối Beta (Beta distribution) là một phân phối liên tục được định nghĩa trên một biến\\nngẫu nhiên λ ∈[0,1] Phân phối Beta distribution được dùng để mô tảtham số cho một\\ndistribution khác. Cụ thể, phân phối này phù hợp với việc mô tả sựbiến động của tham số\\nλ trong phân phối Bernoulli.\\nPhân phối Beta được mô tả bởi hai tham sốdương α,β. Hàm mật độ xác suất của nó là\\np(λ) = Γ(α+ β)\\nΓ(α)Γ(β)λα−1(1 −λ)β−1 (3.47)\\nvới Γ(.) là hàm số gamma, được định nghĩa là\\nΓ(z) =\\n∫ ∞\\n0\\ntz−1 exp(−t)dt (3.48)\\nTrên thực tế, việc tính giá trị của hàm số gamma không thực sự quan trọng vì nó chỉ mang\\ntính chuẩn hoá để tổng xác suất bằng một.\\nDạng gọn của phân phối Beta:p(λ) = Betaλ[α,β]\\nHình 3.4 minh hoạ các hàm mật độ xác suất của phân phối Beta với các cặp giá trị(α,β)\\nkhác nhau.\\n• Trong Hình 3.4a, khiα = β. Đồ thị của các hàm mật độ xác suất đối xứng qua đường\\nthẳng λ= 0.5. Khiα= β = 1, thay vào (3.47) ta thấyp(λ) = 1 với mọiλ. Trong trường\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 62, 'page_label': '51'}, page_content='51 CHƯƠNG 3. ÔN TẬP XÁC SUẤT\\n(a)\\n (b)\\n (c)\\nHình 3.4: Ví dụ về hàm mật độ xác suất của phân phối Beta. (a)α= β, đồ thị hàm số là đối\\nxứng. (b)α<β , đồ thị hàm số lệch sang trái, chứng tỏ xác suấtλnhỏ là lớn. (c)α>β , đồ thị\\nhàm số lệch sang phải, chứng tỏ xác suấtλ lớn là lớn.\\nhợp này, phân phối Beta trở thànhphân phối đều(uniform distribution). Khiα= β >1,\\ncác hàm số đạt giá trị cao tại gần trung tâm, tức là khả năng cao làλ sẽ nhận giá trị\\nxung quanh điểm 0.5. Khiα= β <1, hàm số đạt giá trị cao tại các điểm gần 0 và 1.\\n• Trong Hình 3.4b, khiα<β , ta thấy rằng đồ thị có xu hướng lệch sang bên trái. Các giá\\ntrị (α,β) này nên được sử dụng nếu ta dự đoán rằngλ là một số nhỏ hơn0.5.\\n• Trong Hình 3.4c, khiα >β, điều ngược lại xảy ra với các hàm sồ đạt giá trị cao tại các\\nđiểm gần 1.\\n3.2.6 Phân phối Dirichlet\\nPhân phối Dirichlet chính là trưởng hợp tổng quát của phân phối Beta khi được dùng để mô\\ntả tham số của phân phối Categorical. Nhắc lại rằng phân phối Categorical là trường hợp\\ntổng quát của phân phối Bernoulli.\\nPhân phối Dirichlet được định nghĩa trênK biến liên tụcλ1,...,λ K trong đó cácλk không\\nâm và có tổng bằng một. Bởi vậy, nó phù hợp để mô tả tham số của phân phối Categorical.\\nCó K tham sốdương để mô tả một phân phối Dirichlet:α1,...,α K.\\nHàm mật độ xác suất của phân phối Dirichlet là\\np(λ1,...,λ K) = Γ(∑K\\nk=1 αk)∏K\\nk=1 Γ(αk)\\nK∏\\nk=1\\nλαk−1\\nk (3.49)\\nCách biểu diễn ngắn gọn:p(λ1,...,λ K) = Dirλ1,...,λK [α1,...,α K]\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 63, 'page_label': '52'}, page_content='Chương 4\\nMaximum Likelihood và Maximum A\\nPosteriori\\n4.1 Giới thiệu\\nCó rất nhiều mô hình machine learning được xây dựng dựa trên các mô hình thống kê\\n(statistical models). Các mô hình thống kê thường dựa trên các phân phối xác suất đã được\\nđề cập trong Chương 3. Với phân phối Bernoulli, tham số là biếnλ. Với phân phối chuẩn\\nnhiều chiều, các tham số là mean vectorµvà ma trận hiệp phương saiΣ. Với một mô hình\\nthông kê bất kỳ, ký hiệuθ là tập hợp tất cả các tham số của mô hình đó. Learning chính là\\nquá trìnhước lượng(estimate) bộ tham sốθ sao cho mô hình tìm được khớp với phân phối\\ncủa dữ liệu nhất. Quá trình này còn được gọi làước lượng tham số(parameter estimation).\\nCó hai cách ước lượng tham số thường được dùng trong các mô hình machine learning thống\\nkê. Cách thứ nhất chỉ dựa trên dữ liệu đã biết trong tập huấn luyện, được gọi làmaximum\\nlikelihood estimationhay ML estimationhoặc MLE. Cách thứ hai không những dựa trên tập\\nhuấn luyện mà còn dựa trên những thông tin biết trước của các tham số. Những thông tin\\nnày có thể có được bằngcảm quan của người xây dựng mô hình.Cảm quan càng rõ ràng,\\ncàng hợp lý thì khả năng thu được bộ tham số tốt là càng cao. Chẳng hạn, thông tin biết\\ntrước củaλ trong Bernoulli distribution là việc nó là một số trong đoạn[0,1]. Với bài toán\\ntung đồng xu, vớiλ là xác suất có được mặthead, ta dự đoán được rằng giá trị này nên là\\nmột số gần với0.5. Cách ước lượng tham số thứ hai này được gọi làmaximum a posteriori\\nestimation hay MAP estimation. Trong chương này, chúng ta cùng tìm hiểu ý tưởng và cách\\ngiải quyết bài toán ước lượng tham số mô hình theoMLE hoặc MAP Estimation.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 64, 'page_label': '53'}, page_content='53 CHƯƠNG 4. MAXIMUM LIKELIHOOD VÀ MAXIMUM A POSTERIORI\\n4.2 Maximum likelihood estimation\\n4.2.1 Ý tưởng\\nGiả sử có các điểm dữ liệux1,x2,..., xN. Giả sử thêm rằng ta đã biết các điểm dữ liệu này\\ntuân theo một phân phối nào đó được mô tả bởi bộ tham sốθ.\\nMaximum likelihood estimation là việc đi tìm bộ tham sốθsao cho xác suất sau đây đạt giá\\ntrị lớn nhất:\\nθ= max\\nθ\\np(x1,..., xN|θ) (4.1)\\nBiểu thức (4.1) có ý nghĩa như thế nào và vì sao việc này có lý?\\nGiả sử rằng ta đã biết dạng của mô hình, và mô hình này được mô tả bởi bộ tham sốθ. Như\\nvậy,p(x1|θ) chính là xác suất xảy rasự kiệnx1 biết rằng mô hình được mô tả bởi bộ tham\\nsố θ (đây là một xác suất có điều kiện). Vàp(x1,..., xN|θ) chính là xác suất để toàn bộ các\\nsự kiệnx1,x2,..., xN đồng thời xảy ra, xác suất đồng thời này còn được gọi làlikelihood. Ở\\nđây,likelihood chính là hàm mục tiêu.\\nBởi vì sự việc đã xảy ra, tức dữ liệu huấn luyện bản thân chúng đã như thế, xác suất đồng\\nthời này cần phải càng cao càng tốt. Việc này cũng giống như việc đã biếtkết quả, và ta cần\\nđi tìmnguyên nhân sao cho xác suất xảy ra kết quả càng cao càng tốt. MLE chính là việc\\nđi tìm bộ tham sốθ sao cho Likelihood là lớn nhất. Trong mô hình này ta cũng có một bài\\ntoán tối ưu với hàm mục tiêu làp(x1,..., xN|θ). Lúc này ta không tối thiểu hàm mục tiêu\\nmà cần tối đa nó, vì ta muốn rằng xác suất xảy ra việc này là lớn nhất.\\n4.2.2 Giả sử về sự độc lập và log-likelihood\\nViệc giải trực tiếp bài toán (4.1) thường là phức tạp vì việc đi tìm mô hình xác suất đồng\\nthời cho toàn bộ dữ liệu là ít khi khả thi. Một cách tiếp cận phổ biến là giả sử đơn giản rằng\\ncác điểm dữ liệuxn là độc lập với nhau. Nói cách khác, ta xấp xỉ likelihood trong (4.1) bởi\\np(x1,..., xN|θ) ≈\\nN∏\\nn=1\\np(xn|θ) (4.2)\\n(Nhắc lại rằng hai sự kiệnx,y là độc lập nếu xác suất đồng thời của chúng bằng tích xác suất\\ncủatừngsựkiện: p(x,y) = p(x)p(y).Vàkhilàxácsuấtcóđiềukiện: p(x,y|z) = p(x|z)p(y|z).)\\nLúc đó, bài toán (4.1) có thể được giải quyết bằng cách giải bài toán tối ưu sau:\\nθ= max\\nθ\\nN∏'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 64, 'page_label': '53'}, page_content='củatừngsựkiện: p(x,y) = p(x)p(y).Vàkhilàxácsuấtcóđiềukiện: p(x,y|z) = p(x|z)p(y|z).)\\nLúc đó, bài toán (4.1) có thể được giải quyết bằng cách giải bài toán tối ưu sau:\\nθ= max\\nθ\\nN∏\\nn=1\\np(xn|θ) (3) (4.3)\\nViệc tối ưu một tích thường phức tạp hơn việc tối ưu một tổng, vì vậy việc tối đa hàm mục\\ntiêu thường được chuyển về việc tối đalog của hàm mục tiêu:\\nθ= max\\nθ\\nN∑\\nn=1\\nlog (p(xn|θ)) (4.4)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 65, 'page_label': '54'}, page_content='CHƯƠNG 4. MAXIMUM LIKELIHOOD VÀ MAXIMUM A POSTERIORI 54\\nÔn lại một chút về hai tính chất của hàm logarit: (i)log của một tích bằng tổng của các\\nlog, và (ii) vìlog là một hàm đồng biến, một biểu thức dương sẽ là lớn nhất nếulog của nó\\nlà lớn nhất, và ngược lại.\\n4.2.3 Ví dụ\\nVí dụ 1: phân phối Bernoulli\\nBài toán: giả sử tung một đồng xuN lần và nhận đượcn mặt head. Ước lượng xác suất\\nkhi tung đồng xu nhận được mặthead.\\nLời giải:\\nMột cách trực quan, ta có thể ước lượng được rằng xác suất đó chính làλ = n\\nN. Chúng ta\\ncùng ước lượng giá trị này sử dụng MLE.\\nGiả sử λ là xác suất để nhận được một mặthead. Đặt x1,x2,...,x N là các đầu ra nhận\\nđược, trong đó cón giá trị bằng 1 tương ứng với mặthead và m = N −n giá trị bằng 0\\ntương ứng với mặttail. Ta có thể suy ra ngay rằng\\nN∑\\ni=1\\nxi = n, N −\\nN∑\\ni=1\\nxi = N −n= m (4.5)\\nVì đây là một xác suất của biến ngẫu nhiên nhị phân rời rạc, ta có thể nhận thấy việc nhận\\nđược mặthead hay tail khi tung đồng xu tuân theo phân phối Bernoulli:\\np(xi|λ) = λxi(1 −λ)1−xi (4.6)\\nKhi đó tham số mô hìnhλcó thể được ước lượng bằng việc giải bài toán tối ưu sau đây, với\\ngiả sử rằng kết quả của các lần tung đồng xu là độc lập với nhau:\\nλ= argmax\\nλ\\n[p(x1,x2,...,x N|λ)] = argmax\\nλ\\n[N∏\\ni=1\\np(xi|λ)\\n]\\n(4.7)\\n= argmax\\nλ\\n[N∏\\ni=1\\nλxi(1 −λ)1−xi\\n]\\n= argmax\\nλ\\n[\\nλ\\n∑N\\ni=1 xi(1 −λ)N−∑N\\ni=1 xi\\n]\\n(4.8)\\n= argmax\\nλ\\n[λn(1 −λ)m] = argmax\\nλ\\n[nlog(λ) + mlog(1 −λ)] (4.9)\\ntrong (4.9), ta đã lấylog của hàm mục tiêu. Tới đây, bài toán tối ưu (4.9) có thể được giải\\nbằng cách lấy đạo hàm của hàm mục tiêu bằng 0. Tứcλ là nghiệm của phương trình\\nn\\nλ − m\\n1 −λ = 0 ⇔n\\nλ = m\\n1 −λ ⇔λ= n\\nn+ m = n\\nN (4.10)\\nVậy kết quả ta ước lượng ban đâu là có cơ sở.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 66, 'page_label': '55'}, page_content='55 CHƯƠNG 4. MAXIMUM LIKELIHOOD VÀ MAXIMUM A POSTERIORI\\nVí dụ 2: Categorical distribution\\nMột ví dụ khác phức tạp hơn một chút.\\nBài toán:giả sử tung một viên xúc xắc sáu mặt có xác suất rơi vào các mặt có thể không\\nđều nhau. Giả sử trongN lần tung, số lượng xuất hiện các mặt thứ nhất, thứ hai,..., thứ\\nsáu lần lượt làn1,n2,...,n 6 lần với\\n6∑\\ni=1\\nni = N. Tính xác suất rơi vào mỗi mặt ở lần tung\\ntiếp theo. Giả sử thêm rằngni >0, ∀i= 1,..., 6.\\nLời giải:\\nBài toán này có vẻ phức tạp hơn bài toán trên một chút, nhưng ta cũng có thể dự đoán được\\nước lượng tốt nhất của xác suất rơi vào mặt thứi là λi = ni\\nN.\\nMã hoá mỗi quan sát đầu ra thứi bởi một vector 6 chiềuxi ∈{0,1}6 trong đó các phần\\ntử của nó bằng 0 trừ phần tử tương ứng với mặt quan sát được là bằng 1. Nhận thấy rằng∑N\\ni=1 xj\\ni = nj, ∀j = 1,2,..., 6, trong đóxj\\ni là thành phần thứj của vectorxi.\\nCó thể thấy rằng xác suất rơi vào mỗi mặt tuân theo phân phối categorical với các tham số\\nλj >0,j = 1,2,..., 6. Ta dùngλđể thể hiện cho cả sáu tham số này.\\nVới các tham sốλ, xác suất để sự kiệnxi xảy ra là\\np(xi|λ) =\\n6∏\\nj=1\\nλ\\nxj\\ni\\nj (4.11)\\nKhi đó, vẫn với giả sử về sự độc lập giữa các lần tung xúc xắc, ước lượng bộ tham sốλdựa\\ntrên việc tối đa log-likelihood ta có:\\nλ= argmax\\nλ\\n[N∏\\ni=1\\np(xi|λ)\\n]\\n= argmax\\nλ\\n[N∏\\ni=1\\n6∏\\nj=1\\nλ\\nxj\\ni\\nj\\n]\\n(4.12)\\n= argmax\\nλ\\n[ 6∏\\nj=1\\nλ\\n∑N\\ni=1 xj\\ni\\nj\\n]\\n= argmax\\nλ\\n[ 6∏\\nj=1\\nλ\\nnj\\nj\\n]\\n(4.13)\\n= argmax\\nλ\\n[ 6∑\\nj=1\\nnj log(λj)\\n]\\n(4.14)\\nKhác với bài toán (4.9) một chút, chúng ta không được quên điều kiện∑6\\nj=1 λj = 1. Ta có\\nbài toán tối ưu có ràng buộc sau đây\\nmax\\nλ\\n6∑\\nj=1\\nnj log(λj) thoả mãn:\\n6∑\\nj=1\\nλj = 1 (4.15)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 67, 'page_label': '56'}, page_content='CHƯƠNG 4. MAXIMUM LIKELIHOOD VÀ MAXIMUM A POSTERIORI 56\\nBài toán tối ưu này có thể được giải bằng phương pháp nhân tử Lagrange (xem Phụ lục A).\\nLagrangian của bài toán này là\\nL(λ,µ) =\\n6∑\\nj=1\\nnj log(λj) + µ(1 −\\n6∑\\nj=1\\nλj) (4.16)\\nNghiệm của bài toán là nghiệm của hệ đạo hàm củaL(.) theo từng biến bằng 0\\n∂L(λ,µ)\\n∂λj\\n= nj\\nλj\\n−µ = 0, ∀j = 1,2,..., 6 (4.17)\\n∂L(λ,µ)\\n∂µ = 1 −\\n6∑\\nj=1\\nλj = 0 (4.18)\\nTừ (4.17) ta cóλj = nj\\nµ . Thay vào (4.18),\\n6∑\\nj=1\\nnj\\nµ = 1 ⇒µ=\\n6∑\\nj=1\\nnj = N (4.19)\\nTừ đó ta có ước lượngλj = nj\\nN , ∀j = 1,2,..., 6.\\nQua hai ví dụ trên ta thấy MLE cho hết quả khá hợp lý.\\nVí dụ 3: Univariate normal distribution\\nBài toán:Khi thực hiện một phép đo, giả sử rằng rất khó để có thể đochính xác độ dài\\ncủa một vật. Thay vào đó, người ta thường đo vật đó nhiều lần rồi suy ra kết quả, với giả\\nthiết rằng các phép đo là độc lập với nhau và kết quả mỗi phép đo là một phân phối chuẩn.\\nƯớc lượng chiều dài của vật đó dựa trên các kết quả đo được.\\nLời giải:Vì biết rằng kết quả phép đo tuân theo phân phối chuẩn, ta sẽ cố gắng đi xây\\ndựng phân phối chuẩn đó. Chiều dài của vật có thể được coi là giá trị mà hàm mật độ xác\\nsuất đạt giá trị cao nhất, tức khả năng rơi vào khoảng giá trị xung quanh nó là lớn nhất.\\nTrong phân phối chuẩn, ta biết rằng hàm mật độ xác suất đạt giá trị lớn nhất tại chính kỳ\\nvọng của phân phối đó. Chú ý rằng kỳ vọng của phân phối và kỳ vọng của dữ liệu quan sát\\nđược có thể không chính xác bằng nhau, nhưng rất gần nhau. Nếu ước lượng kỳ vọng của\\nphân phối như cách làm dưới đây sử dụng MLE, ta sẽ thấy rằng kỳ vọng của dữ liệu chính\\nlà đánh giá tốt nhất cho kỳ vọng của phân phối.\\nThật vậy, giả sử các kích thước quan sát được làx1,x2,...,x N. Ta cần đi tìm một phân\\nphối chuẩn, được mô tả bởi một giá trị kỳ vọngµ và phương saiσ2, sao cho các giá trị\\nx1,x2,...,x N là likely nhất. Ta đã biết rằng, hàm mật độ xác suất tạixi của môt phân phối\\nchuẩn có kỳ vọngµ và phương saiσ2 là\\np(xi|µ,σ2) = 1√\\n2πσ2\\nexp\\n(\\n−(xi −µ)2\\n2σ2\\n)\\n(4.20)'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 67, 'page_label': '56'}, page_content='x1,x2,...,x N là likely nhất. Ta đã biết rằng, hàm mật độ xác suất tạixi của môt phân phối\\nchuẩn có kỳ vọngµ và phương saiσ2 là\\np(xi|µ,σ2) = 1√\\n2πσ2\\nexp\\n(\\n−(xi −µ)2\\n2σ2\\n)\\n(4.20)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 68, 'page_label': '57'}, page_content='57 CHƯƠNG 4. MAXIMUM LIKELIHOOD VÀ MAXIMUM A POSTERIORI\\nVậy, để đánh giáµvà σ, ta sử dụng MLE với giả thiết rằng kết quả các phép đo là độc lập:\\nµ,σ = argmax\\nµ,σ\\n[N∏\\ni=1\\np(xi|µ,σ2)\\n]\\n(4.21)\\n= argmax\\nµ,σ\\n[\\n1\\n(2πσ2)N/2 exp\\n(\\n−\\n∑N\\ni=1(xi −µ)2\\n2σ2\\n)]\\n(4.22)\\n= argmax\\nµ,σ\\n[\\n−Nlog(σ) −\\n∑N\\ni=1(xi −µ)2\\n2σ2 ≜J(µ,σ)\\n]\\n(4.23)\\nTa đã lấylog của hàm bên trong dấu ngoặc vuông của (4.22) để được (4.23), phần hằng số\\ncó chứa2π cũng đã được bỏ đi vì nó không ảnh hưởng tới kết quả.\\nĐể tìmµ và σ, ta giải hệ phương trình đạo hàm củaJ(µ,σ) theo mỗi biến bằng không:\\n∂J\\n∂µ = 1\\nσ2\\nN∑\\ni=1\\n(xi −µ) = 0 (4.24)\\n∂J\\n∂σ = −N\\nσ + 1\\nσ3\\nN∑\\ni=1\\n(xi −µ)2 = 0 (4.25)\\n⇒µ=\\n∑N\\ni=1 xi\\nN , σ 2 =\\n∑N\\ni=1(xi −µ)2\\nN (4.26)\\nKết quả thu được không có gì bất ngờ.\\nVí dụ 4: Multivariate normal distribution\\nBài toán:Giả sử tập dữ liệu ta thu được là các giá trị nhiều chiềux1,..., xN tuân theo\\nphân phối chuẩn. Hãy đánh giá các tham số, vector kỳ vọngµvà ma trận hiệp phương sai\\nΣ của phân phối này dựa trên MLE, giả sử rằng cácx1,..., xN là độc lập.\\nLời giải:Việc chứng minh các công thức\\nµ=\\n∑N\\ni=1 xi\\nN (4.27)\\nΣ = 1\\nN\\nN∑\\ni=1\\n(x −µ)(x −µ)T (4.28)\\nxin được dành lại cho bạn đọc như một bài tập nhỏ. Dưới đây là một vài gợi ý:\\n• Hàm mật độ xác suất của phân phối chuẩn nhiều chiều là\\np(x|µ,Σ) = 1\\n(2π)D/2∥Σ∥1/2 exp\\n(\\n−1\\n2(x −µ)TΣ−1(x −µ)\\n)\\n(4.29)\\nChú ý rằng ma trận hiệp phương saiΣ là xác định dương nên có nghịch đảo.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 69, 'page_label': '58'}, page_content='CHƯƠNG 4. MAXIMUM LIKELIHOOD VÀ MAXIMUM A POSTERIORI 58\\n• Một vài đạo hàm theo ma trận:\\n∇Σ log |Σ|= (Σ−1)T ≜Σ−T (chuyển vị của nghịch đảo) (4.30)\\n∇Σ(xi −µ)TΣ−1(xi −µ) = −Σ−T(xi −µ)(xi −µ)TΣ−T (4.31)\\n(Xem thêm Matrix Calculus, mục D.2.1 và D.2.4 tạihttps://goo.gl/JKg631 .)\\n4.3 Maximum a Posteriori\\n4.3.1 Ý tưởng\\nQuay lại với ví dụ 1 về tung đồng xu. Nếu tung đồng xu 5000 lần và nhận được 1000 lần\\nhead, ta có thể đánh giá xác suất củahead là 1/5 và việc đánh giá này là đáng tin vì số mẫu\\nlà lớn. Nếu tung 5 lần và chỉ nhận được 1 mặthead, theo MLE, xác suất để có một mặthead\\nđược đánh giá là1/5. Tuy nhiên với chỉ 5 kết quả, ước lượng này là không đáng tin, nhiều\\nkhả năng việc đánh giá đã bị overfitting. Khi tập huấn luyện quá nhỏ (low-training) chúng\\nta cần phải quan tâm tới một vài giả thiết của các tham số. Trong ví dụ này, giả thiết của\\nchúng ta là xác suất nhận được mặthead phải gần1/2.\\nMaximum A Posteriori (MAP) ra đời nhằm giải quyết vấn đề này. Trong MAP, chúng ta\\ngiới thiệu một giả thiết biết trước, được gọi làprior, của tham sốθ. Từ giả thiết này, chúng\\nta có thể suy ra các khoảng giá trị và phân bố của tham số.\\nNgược với MLE, trong MAP, chúng ta sẽ đánh giá tham số như là một xác suất có điều kiện\\ncủa dữ liệu:\\nθ= argmax\\nθ\\np(θ|x1,..., xN)\\ued19 \\ued18\\ued17 \\ued1a\\nposterior\\n(4.32)\\nBiểu thức p(θ|x1,..., xN) còn được gọi làxác suất posterior của θ. Chính vì vậy mà việc\\nước lượngθ theo (4.32) được gọi làMaximum A Posteriori.\\nThông thường, hàm tối ưu trong (4.32) khó xác định dạng một cách trực tiếp. Chúng ta\\nthường biết điều ngược lại, tức nếu biết tham số, ta có thể tính được hàm mật độ xác suất\\ncủa dữ liệu. Vì vậy, để giải bải toán MAP, ta thường sử dụng quy tắc Bayes. Bài toán MAP\\nthường được biến đổi thành\\nθ= argmax\\nθ\\np(θ|x1,..., xN) = argmax\\nθ\\n\\uf8ee\\n\\uf8ef\\uf8ef\\uf8f0\\nlikelihood\\n\\ued17 \\ued1a\\ued19 \\ued18\\np(x1,..., xN|θ)\\nprior\\n\\ued17\\ued1a\\ued19\\ued18\\np(θ)\\np(x1,..., xN)\\ued19 \\ued18\\ued17 \\ued1a\\nevidence\\n\\uf8f9\\n\\uf8fa\\uf8fa\\uf8fb (4.33)\\n= argmax\\nθ\\n[p(x1,..., xN|θ)p(θ)] (4.34)\\n= argmax\\nθ\\n[N∏\\ni=1\\np(xi|θ)p(θ)\\n]\\n(4.35)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 70, 'page_label': '59'}, page_content='59 CHƯƠNG 4. MAXIMUM LIKELIHOOD VÀ MAXIMUM A POSTERIORI\\nĐẳng thức (4.33) xảy ra theo quy tắc Bayes. Đẳng thức (4.34) xảy ra vì mẫu số của (4.33)\\nkhông phụ thuộc vào tham sốθ. Đẳng thức (4.35) xảy ra nếu chúng ta giả thiết về sự độc\\nlập giữa cácxi. Chú ý rằng giả thiết độc lập thường xuyên được sử dụng.\\nNhư vậy, điểm khác biệt lớn nhất giữa hai bài toán tối ưu MLE và MAP là việc hàm mục\\ntiêu của MAP có thêmp(θ), tức phân phối củaθ. Phân phối này chính là những thông tin\\nta biết trước vềθ và được gọi làprior. Ta kết luận rằngposterior tỉ lệ thuận với tích\\ncủa likelihood và prior.\\nVậy chọnprior thế nào? chúng ta cùng làm quen với một khái niệm mới:conjugate prior.\\n4.3.2 Conjugate prior\\nNếu phân phối xác suất posteriorp(θ|x1,..., xN) có cùng dạng(same family) với phân phối\\nxác suất p(θ), prior và posterior được gọi làconjugate distributions, và p(θ) được gọi là\\nconjugate prior cho hàm likelihoodp(x1,..., xN|θ). Nghiệm của bài toán MAP và MLE có\\ncấu trúc giống nhau.\\nMột vài cặp cácconjugate distributions1:\\n• Nếu likelihood function là một Gaussian (phân phối chuẩn), và prior cho vector kỳ vọng\\ncũng là một Gaussian, thế thì phân phối posterior cũng là một Gaussian. Ta nói rằng\\nGaussian conjugate với chính nó (hay còn gọi làself-conjugate).\\n• NếulikelihoodfunctionlàmộtGaussianvàpriorchophươngsailàmộtphânphốigamma 2,\\nphân phối posterior cũng là một Gaussian. Ta nói rằng phân phối gamma là conjugate\\nprior cho phương sai của Gassian. Chú ý rằng phương sai có thể được coi là một biến\\ngiúp đođộ chính xáccủa mô hình. Phương sai càng nhỏ thì độ chính xác càng cao.\\n• Phân phối Beta là conjuate của phân phối Bernoulli.\\n• Phân phối Dirichlet là conjugate của phân phối categorical.\\n4.3.3 Hyperparameters\\nXét một ví dụ nhỏ với phân phối Bernoulli với hàm mật độ xác suất:\\np(x|λ) = λx(1 −λ)1−x (4.36)\\nvà conjugate của nó, phân phối Beta, có hàm phân mật độ xác suất:\\np(λ) = Γ(α+ β)\\nΓ(α)Γ(β)λα−1(1 −λ)β−1 (4.37)'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 70, 'page_label': '59'}, page_content='p(x|λ) = λx(1 −λ)1−x (4.36)\\nvà conjugate của nó, phân phối Beta, có hàm phân mật độ xác suất:\\np(λ) = Γ(α+ β)\\nΓ(α)Γ(β)λα−1(1 −λ)β−1 (4.37)\\nBỏ qua thừa số hằng số chỉ mang mục đích chuẩn hoá cho tích phân của hàm mật độ xác suất\\nbằng một, ta có thể nhận thấy rằng phần còn lại của phân phối Beta có cùnghọ (family)\\n1 Đọc thêm:Conjugate prior–Wikipedia(https://goo.gl/E2SHbD ).\\n2 Gamma distribution–Wikipedia, (https://goo.gl/kdWd2R .)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 71, 'page_label': '60'}, page_content='CHƯƠNG 4. MAXIMUM LIKELIHOOD VÀ MAXIMUM A POSTERIORI 60\\nvới phân phối Bernoulli. Cụ thể, nếu sử dụng phân phối Beta làmprior cho tham sốλ, và\\nbỏ qua phần thừa số hằng số, posterior sẽ có dạng\\np(λ|x) ∝p(x|λ)p(λ)\\n∝λx+α−1(1 −λ)1−x+β−1 (4.38)\\ntrong đó,∝là ký hiệu củatỉ lệ với.\\nNhận thấy rằng (4.38)vẫn có dạng của một phân phối Bernoulli.Chính vì vậy mà phân\\nphối Beta được gọi là mộtconjugate priorcho phân phối Bernoulli.\\nTrong ví dụ này, tham sốλ phụ thuộc vào hai tham số khác làα và β. Để tránh nhầm lẫn,\\nhai tham số(α,β) được gọi làsiêu tham số (hyperparameters).\\nQuay trở lại ví dụ về bài toán tung đồng xuN lần cónlần nhận được mặthead vàm= N−n\\nlần nhận được mặttail. Nếu sử dụng MLE, ta nhận được ước lượngλ= n/M. Nếu sử dụng\\nMAP với prior là một Beta[α,β] thì kết quả sẽ thay đổi thế nào?\\nBài toán tối ưu MAP:\\nλ= argmax\\nλ\\n[p(x1,...,x N|λ)p(λ)]\\n= argmax\\nλ\\n[(N∏\\ni=1\\nλxi(1 −λ)1−xi\\n)\\nλα−1(1 −λ)β−1\\n]\\n= argmax\\nλ\\n[\\nλ\\n∑N\\ni=1 xi+α−1(1 −λ)N−∑N\\ni=1 xi+β−1\\n]\\n= argmax\\nλ\\n[\\nλn+α−1(1 −λ)m+β−1]\\n(4.39)\\nBài toán tối ưu (4.39) chính là bài toán tối ưu (4.38) với tham số thay đổi một chút. Tương\\ntự như (4.38), nghiệm của (4.39) có thể được suy ra là\\nλ= n+ α−1\\nN + α+ β−2 (4.40)\\nNhờ việc chọn prior phù hợp, ở đây là conjugate prior, posterior và likelihood có dạng giống\\nnhau, khiến cho việc tối ưu bài toán MAP được thuận lợi.\\nViệc còn lại là chọn cặphyperparameters α và β.\\nChúng ta cùng xem lại hình dạng của phân phối Beta và nhận thấy rằng khiα = β >1,\\nhàm mật độ xác suất của phân phối Beta đối xứng qua điểm 0.5 và đạt giá trị cao nhất tại\\n0.5. Xét Hình 4.1, ta nhận thấy rằng khiα= β >1, mật độ xác suất xung quanh điểm 0.5\\nnhận giá trị cao, điều này chứng tỏλ có xu hướng gần với 0.5.\\nNếu ta chọnα= β = 1, ta nhận được phân phối đều vì đồ thị hàm mật độ xác suất là một\\nđường thẳng. Lúc này, xác suất củaλ tại mọi vị trí trong khoảng[0,1] là như nhau. Thực\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 72, 'page_label': '61'}, page_content='61 CHƯƠNG 4. MAXIMUM LIKELIHOOD VÀ MAXIMUM A POSTERIORI\\nHình 4.1: Đồ thị hàm mật độ xác\\nsuất của phân phối Beta khiα= β\\nvà nhận các giá trị khác nhau. Khi\\ncả hai giá trị này lớn, xác suất đểλ\\ngần 0.5 sẽ cao hơn.\\nchất, nếu ta thayα= β = 1 vào (4.40) ta sẽ thu đượcλ= n/N, đây chính là ước lượng thu\\nđược bằng MLE. MLE là một trường hợp đặc biệt của MAP khi prior là một phân phối đều.\\nNếu ta chọnα= β = 2, ta sẽ thu được:λ= n+ 1\\nN + 2. Chẳng hạn khiN = 5,n = 1 như trong\\nví dụ. MLE cho kết quảλ= 1/5, MAP sẽ cho kết quảλ= 2/7, gần với1/2 hơn.\\nNếu chọnα = β = 10 ta sẽ cóλ = (1 + 9)/(5 + 18) = 10 /23. Ta thấy rằng khiα = β và\\ncàng lớn thì ta sẽ thu đượcλ càng gần1/2. Điều này có thể dễ nhận thấy vì prior nhận giá\\ntrị rất cao tại 0.5 khi các siêu tham sốα= β lớn.\\n4.3.4 MAP giúp tránh overfitting\\nViệc chọn các hyperparameter thường được dựa trên thực nghiệm, chẳng hạn bằng cross-\\nvalidation. Việc thử nhiều bộ tham số rồi chọn ra bộ tốt nhất là việc mà các kỹ sư machine\\nlearning thường xuyên phải đối mặt. Cũng giống như việc chọn regularization parameter để\\ntránh overfitting vậy.\\nNếu viết lại bài toán MAP dưới dạng:\\nθ= argmax\\nθ\\np(X|θ)p(θ) (4.41)\\n= argmax\\nλ\\n\\uf8ee\\n\\uf8f0log p(X|θ)\\ued19 \\ued18\\ued17 \\ued1a\\nlikelihood\\n+ logp(θ)\\ued19\\ued18\\ued17\\ued1a\\nprior\\n\\uf8f9\\n\\uf8fb (4.42)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 73, 'page_label': '62'}, page_content='CHƯƠNG 4. MAXIMUM LIKELIHOOD VÀ MAXIMUM A POSTERIORI 62\\nta có thể thấy rằng hàm mục tiêu có dạngL(θ) +λR(θ) giống như trong regularization, với\\nhàm log-likelihood đóng vai trò như hàm mất mátL(θ), và log của prior đóng vai trò như\\nhàm R(θ). Ta có thể nói rằng, MAP chính là một phương pháp giúp tránh overfitting trong\\ncác mô hình machine learning thống kê. MAP đặc biệt hữu ích khi tập huấn luyện là nhỏ.\\n4.4 Tóm tắt\\n• Khi sử dụng các mô hình thống kê machine learning, chúng ta thường xuyên phải ước\\nlượng các tham số của mô hìnhθ, đại diện cho các tham số của các phân phối xác suất.\\nCó hai phương pháp phổ biến được sử dụng để ước lượngθ là Maximum Likelihood\\nEstimation (MLE) và Maximum A Posterior Estimation (MAP).\\n• Với MLE, việc xác định tham sốθ được thực hiện bằng cách đi tìm các tham số sao cho\\nxác suất của tập huấn luyện, hay còn gọi làlikelihood, là lớn nhất:\\nθ= argmax\\nθ\\np(x1,..., xN|θ) (4.43)\\n• Để giải bài toán tối ưu này, giả thiết các dữ liệuxi độc lập thường được sử dụng. Và bài\\ntoán MLP trở thành:\\nθ= argmax\\nθ\\nN∏\\ni=1\\np(xi|θ) (4.44)\\n• Với MAP, các tham số được đánh giá bằng cách tối đaposterior:\\nθ= argmax\\nθ\\np(θ|x1,..., xN) (4.45)\\n• Quy tắc Bayes và giả thiết về sự độc lập của dữ liệu thường được sử dụng:\\nθ= argmax\\nθ\\n[N∏\\ni=1\\np(xi|θ)p(θ)\\n]\\n(4.46)\\nHàm mục tiêu ở đây chính là tích củalikelihood và prior.\\n• Prior thường được chọn dựa trên các thông tin biết trước của tham số, và phân phối\\nđược chọn thường là cácconjugate distribution với likelihood, tức các phân phối khiến\\nviệc nhân thêmprior vẫn giữ được cấu trúc giống nhưlikelihood.\\n• MAP có thể được coi là một phương pháp giúp tránh overfitting. MAP thường mang lại\\nhiệu quả cao hơn MLE với trường hợp có ít dữ liệu huấn luyện.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 74, 'page_label': '63'}, page_content='Phần II\\nTổng quan về machine learning'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 75, 'page_label': '64'}, page_content='Chương 5\\nCác khái niệm cơ bản\\nNội dung của chương này được tham khảo chủ yếu từ Mục 5.1 trong cuốn sáchDeep learning\\n(Goodfellow, 2016).\\nMột thuật toán machine learning là một thuật toán có khả nănghọc tậptừ dữ liệu. Vậy thực\\nsự học tậpở đây có nghĩa như thế nào? Theo Mitchell trong cuốnMachine Learning[M+97],\\nMục 1.1, thì “A computer program is said tolearn from experience E with respect to some\\ntasks T and performance measureP, if its performance at tasks inT, as measured byP,\\nimproves with experienceE. ”\\nTạm dịch:\\nĐịnh nghĩa 5.1: Học (chương trình máy tính)\\nMột chương trình máy tính được gọi làhọc từ kinh nghiệm E để hoàn thànhnhiệm\\nvụ T, với hiệu quả được đo bằngphép đánh giáP, nếu hiệu quả của nó khi thực hiện\\nnhiệm vụT, khi được đánh giá bởiP, cải thiện theo kinh nghiệmE.\\nTrongchươngnày,chúngtasẽđivàotừngkháiniệm task,performance measure,và experience\\nthông qua các ví dụ.\\n5.1 Nhiệm vụ,T\\nCác nhiệm vụ trong machine learning thường được mô tả thông qua việc một hệ thống\\nmachine learning xử lý mộtđiểm dữ liệu(data point) như thế nào. Trong bài toán phân loại\\nảnh, mỗi ảnh là một điểm dữ liệu. Trong bài toán phân nhóm khách hàng, mỗi khách hàng\\nlà một điểm dữ liệu. Trong bài toán xác định một tin nhắn có là rác hay không, mỗi tin\\nnhắn là một điểm dữ liệu. Mỗi điểm dữ liệu bao gồm nhiềuđặc trưng (feature) khác nhau,\\nmỗi feature thường được biểu diễn dưới dạng một con số. Chúng ta thường biểu diễn một'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 76, 'page_label': '65'}, page_content='65 CHƯƠNG 5. CÁC KHÁI NIỆM CƠ BẢN\\nđiểm dữ liệu như một vector1 x ∈Rd trong đó mỗi phần tửxi là một đặc trưng, vector này\\nthường được gọi làvector đặc trưng(feature vector). Ví dụ, trong một bức ảnh, mỗi giá trị\\ncủa một điểm ảnh có thể coi là một đặc trưng, vector chứa toàn bộ giá trị các pixel của ảnh\\ncó thể coi là một vector đặc trưng. Chương 6 sẽ bàn sâu thêm về vector đặc trưng của dữ\\nliệu.\\nRất nhiều nhiệm vụ phức tạp có thể được giải quyết bằng machine learning. Dưới đây là\\nmột trong những bài toán phổ biến nhất của machine learning.\\n5.1.1 Classification\\nClassification, hayphân loại, phân lớp. Đây là một trong những bài toán được nghiên cứu\\nnhiều nhất trong machine learning. Trong bài toán này, chương trình sẽ được yêu cầu chỉ ra\\nnhãn, haylớp (label) của một điểm dữ liệu. Nhãn này thường là một phần tử trong một tập\\nhợp cóC phần tử khác nhau. Mỗi phần tử trong tập hợp này được gọi là mộtlớp (class), và\\nthường được đánh số từ1 đến C. Để giải bài toán này, ta thường phải xây dựng một hàm\\nsố f : Rd →{1,2,...,C }. Khiy= f(x), mô hình gán cho một điểm dữ liệu được mô tả bởi\\nvector đặc trưngx một nhãn được xác định bởi sốy.\\nVí dụ:trong nhận dạng chữ số viết tay, ta có ảnh của hàng nghìn ví dụ của mỗi chữ số\\nđược viết bởi nhiều người khác nhau. Các bức ảnh này cùng với nhãn của chúng được đưa\\nvào một thuật toán machine learning. Sau khi thuật toán nàyhọc được một mô hình, tức\\nmột hàm số mà đầu vào là một bức ảnh và đầu ra là một chữ số, khi nhận được một bức\\nảnh mới mà mô hìnhchưa nhìn thấy bao giờ, nó sẽ dự đoán bức ảnh đó chứa chữ số nào.\\nVí dụ này khá giống với cách học của con người khi còn nhỏ. Ta đưa bảng chữ cái cho một\\nđứa trẻ và chỉ cho chúng đây là chữ A, đây là chữ B. Sau một vài lần được dạy thì trẻ có\\nthể nhận biết được đâu là chữ A, đâu là chữ B mà chúng chưa nhìn thấy bao giờ.\\nCó một biến thể nhỏ ở đầu ra của hàm sốf(x) khi đầu ra không phải là một số mà là một\\nvector y ∈RC trong đó yc chỉ ra xác suất để điểm dữ liệux rơi vào lớp thức. Lớp được'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 76, 'page_label': '65'}, page_content='Có một biến thể nhỏ ở đầu ra của hàm sốf(x) khi đầu ra không phải là một số mà là một\\nvector y ∈RC trong đó yc chỉ ra xác suất để điểm dữ liệux rơi vào lớp thức. Lớp được\\nchọn cuối cùng là lớp có xác suất rơi vào là cao nhất. Việc sử dụng xác suất này đôi khi rất\\nquan trọng, nó giúp chỉ rađộ chắc chắn(confidence) của mô hình. Nếu xác suất cao nhất\\nlà cao hơn nhiều so với các xác suất còn lại, ta nói mô hình có độ chắn chắn là cao khi phân\\nlớp điểm dữ liệux. Ngược lại, nếu độ chênh lệch giữa xác suất cao nhất và các xác suất tiếp\\ntheo là nhỏ, thì khả năng mô hình đã phân loại nhầm là cao hơn.\\n5.1.2 Regression\\nNếu nhãn không được chia thành các nhóm mà là các giá trị thực (có thể vô hạn) thì bài\\ntoán được gọi làhồi quy, một số tài liệu gọi làtiên lượng (regression). Trong bài toán này,\\nta cần xây dựng một hàm sốf : Rd →R.\\n1 Có những loại dữ liệu không được biểu diễn dưới dạng một vector mà có thể là một ma trận–khi giữ nguyên một\\nbức ảnh trong không gian hai chiều, hoặc mộttensor–mảng nhiều chiều–khi xem các bức ảnh với nhiều channel\\nkhác nhau. Trong cuốn sách này, chúng ta chỉ xét các điểm dữ liệu dưới dạng vector, hoặcvector hoá(vectorization)\\ncác điểm dữ liệu nhiều chiều.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 77, 'page_label': '66'}, page_content='CHƯƠNG 5. CÁC KHÁI NIỆM CƠ BẢN 66\\nVí dụ 1:Ước lượng một căn nhà rộngx m2, cóy phòng ngủ và cách trung tâm thành phố\\nz km sẽ có giá khoảng bao nhiêu?\\nVí dụ 2:Microsoft có một ứng dụng dự đoán giới tính và tuổi dựa trên khuôn mặt (http:\\n//how-old.net/ ). Phần dự đoán giới tính có thể được coi là một thuật toán classification,\\nphần dự đoán tuổi có thể coi là một thuật toán regression. Chú ý rằng phần dự đoán tuổi\\ncũng có thể coi là classification nếu ta coi tuổi là một số nguyên dương không lớn hơn 150,\\nchúng ta sẽ có 150 class (lớp) khác nhau.\\nBài toán regression có thể mở rộng ra việc dự đoán nhiều đầu ra cùng một lúc, khi đó, hàm\\ncần tìm sẽ làf : Rd →Rm. Một ví dụ là bài toánsingle image super resolution, ở đó, hệ\\nthống cần tạo ra một bức ảnh có độ phân giải cao dựa trên một ảnh có độ phân giải thấp\\nhơn. Khi đó, việc dự đoán giá trị của các pixel trong ảnh đầu ra là một bài toán regression\\nvới nhiều đầu ra.\\n5.1.3 Machine translation\\nTrong bài toán này, đầu vào là một câu, đoạn, hay bài văn trong một ngôn ngữ, và chương\\ntrình máy tính được yêu cầu chuyển đổi nó sang một ngôn ngữ khác. Lời giải cho bài toán\\nnày gần đây đã có nhiều bước phát triển vượt bậc dựa trên các thuật toán deep learning.\\n5.1.4 Clustering\\nClustering là bài toánphân nhóm toàn bộ dữ liệuXthành các nhóm nhỏ dựa trên sự liên\\nquan giữa các dữ liệu trong mỗi nhóm.\\nVí dụ:phân nhóm khách hàng dựa trên hành vi mua hàng. Điều này cũng giống như việc\\nta đưa cho một đứa trẻ rất nhiều mảnh ghép với các hình thù và màu sắc khác nhau, ví dụ\\ntam giác, vuông, tròn với màu xanh và đỏ, sau đó yêu cầu trẻ phân chúng thành từng nhóm.\\nMặc dù không cho trẻ biết mảnh nào tương ứng với hình nào hoặc màu nào, nhiều khả năng\\nchúng vẫn có thể phân loại các mảnh ghép theo màu hoặc hình dạng.\\n5.1.5 Completion\\nCompletion là bài toánđiền những giá trị còn thiếu của một điểm dữ liệu. Trong nhiều bài\\ntoán thực tế, việc thu thập toàn bộ thông tin của một điểm dữ liệu, ví dụ khách hàng, là'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 77, 'page_label': '66'}, page_content='5.1.5 Completion\\nCompletion là bài toánđiền những giá trị còn thiếu của một điểm dữ liệu. Trong nhiều bài\\ntoán thực tế, việc thu thập toàn bộ thông tin của một điểm dữ liệu, ví dụ khách hàng, là\\nkhông khả thi. Nhiệm vụ của bài toán này là dựa trên mối tương quan giữa các điểm dữ liệu\\nđể dự đoán những giá trị còn thiếu.Các hệ thống khuyến nghị(recommendation system) là\\nmột ví dụ điển hình của loại này.\\nBạn đọc có thể đọc thêm về các bài toánxếp hạng(ranking), thu thập thông tin(information\\nretrieval), giảm nhiễu (denoising), v.v..\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 78, 'page_label': '67'}, page_content='67 CHƯƠNG 5. CÁC KHÁI NIỆM CƠ BẢN\\n5.2 Phép đánh giá,P\\nĐể kiểm tra năng lực của một thuật toán machine learning, chúng ta cần phải thiết kế các\\nphép đánh giá có thể đo đạc được kết quả.\\nThông thường, khi thực hiện một thuật toán machine learning, dữ liệu sẽ được chia thành\\nhai phần riêng biệt:tập huấn luyện(training set) vàtập kiểm thử(test set). Tập huấn luyện\\nsẽ được dùng để tìm các tham số mô hình. Tập kiểm thử được dùng để đánh giá năng lực\\ncủa mô hình tìm được. Có một điểm cần lưu ý rằng khi tìm các tham số mô hình, ta chỉ\\nđược dùng các thông tin trong tập huấn luyện. Việc đánh giá có thể được áp dụng lên cả\\nhai tập hợp. Muốn mô hình thực hiện tốt trên tập kiểm thử thì nó trước hết phải hoạt động\\ntốt trên tập huấn luyện.\\nLưu ý:Ranh giới giữa tập huấn luyện và tập kiểm thử đôi khi không rõ ràng. Các thuật\\ntoán thực tế liên tục được cập nhật dựa trên dữ liệu mới thêm vào, các thuật toán này được\\ngọi là online learning hoặc online training. Phần dữ liệu mới này ban đầu không được hệ\\nthống sử dụng để xây dựng mô hình, nhưng về sau có thể được mô hình sử dụng để cải\\ntiến. Ngược vớionline learninglà offline learning, ở đó hệ thống xây dựng mô hìnhmột lần\\ndựa trên một tập chính là tập huấn luyện. Các điểm dữ liệu không được dùng trong quá\\ntrình xây dựng hệ thống được coi là tập kiểm thử. Trong cuốn sách này, khi không đề cập\\ngì thêm, các thuật toán được ngầm hiểu làoffline learning, trong đótraining setlà tập hợp\\nđược dùng để xây dựng mô hình ban đầu,test set là tập hợp được dùng để đánh giá hiệu\\nquả của mô hình được xây dựng đó.\\n5.3 Kinh nghiệm,E\\nViệc huấn luyện các mô hình machine learning có thể coi là việc cho chúngtrải nghiệmtrên\\ncác tập dữ liệu (dataset)–chính là training set. Các tập dữ liệu khác nhau sẽ cho các mô\\nhình các trải nghiệm khác nhau. Chất lượng của các tập dữ liệu này cũng ảnh hưởng tới\\nhiệu năng của mô hình.\\nDựa trên tính chất của các tập dữ liệu, các thuật toán machine learning có thể phân loại'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 78, 'page_label': '67'}, page_content='hình các trải nghiệm khác nhau. Chất lượng của các tập dữ liệu này cũng ảnh hưởng tới\\nhiệu năng của mô hình.\\nDựa trên tính chất của các tập dữ liệu, các thuật toán machine learning có thể phân loại\\nthành hai nhóm chính làhọc không giám sát (unsupervised learning) và học có giám sát\\n(supervised learning).\\nSupervised learning là thuật toán dự đoán đầu ra của một hoặc nhiều dữ liệu mới dựa\\ntrên các cặp (đầu vào, đầu ra) đã biết từ trước. Supervised learning là nhóm phổ biến nhất\\ntrong các thuật toán machine learning.\\nMột cách toán học, supervised learning là khi chúng ra có một tập hợp biến đầu vàoX=\\n{x1,x2,..., xN}và một tập hợp đầu ra tương ứngY= {y1,y2,..., yN}, trong đóxi,yi là\\ncác vector. Các cặp dữ liệu biết trước(xi,yi) ∈X×Y tạo nên tập huấn luyện. Từ tập huấn\\nluyện này, chúng ta cần tạo ra một hàm số ánh xạ mỗi phần tử từ tậpXsang một phần tử\\n(xấp xỉ) tương ứng của tậpY:\\nyi ≈f(xi), ∀i= 1,2,...,N\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 79, 'page_label': '68'}, page_content='CHƯƠNG 5. CÁC KHÁI NIỆM CƠ BẢN 68\\nMục đích là xấp xỉ hàm sốf thật tốt để khi có một dữ liệux mới, chúng ta có thể tính được\\nnhãn tương ứng của nóy = f(x).\\nNgược lại, trongunsupervised learning, chúng ta không biết được kết quả đầu ra mà chỉ\\nbiết các vector đặc trưng của dữ liệu đầu vào. Các thuật toán unsupervised learning sẽ dựa\\nvào cấu trúc của dữ liệu để thực hiện một công việc nào đó, ví dụ như phân nhóm hoặcgiảm\\nsố chiều của dữ liệu(dimentionality reduction). Một cách toán học, unsupervised learning\\nlà khi chúng ta chỉ có dữ liệu đầu vàoXmà không biết đầu raYtương ứng.\\nKhông giống như trong supervised learning, chúng ta không biết câu trả lời chính xác cho\\nmỗi dữ liệu đầu vào trong unsupervised learning. Giống như khi ta học, ta chỉ được đưa cho\\nmột chữ cái mà không nói đó là chữ A hay chữ B. Cụm từkhông giám sát, haykhông ai chỉ\\nbảo (unsupervised) được đặt tên theo nghĩa này.\\nTừ góc độ xác suất thống kê, unsupervised learning trải nghiệm qua rất nhiều ví dụ (các\\nđiểm dữ liệu)x và cố gắng học phân phối xác suấtp(x), hoặc các tính chất của phân phối\\ncủa dữ liệu một cách trực tiếp hoặc gián tiếp. Trong khi đó, supervised learning quan sát các\\nví dụx và các kết quả tương ứngy, sau đó cố gắng học cách dự đoány từ x thông qua việc\\nđánh giá xác suất có điều kiệnp(y|x). Xác suất này có thể diễn đạt bằng lời là biết rằng\\nmột điểm dữ liệu có vector đặc trưng làx, xác suất để đầu ra của nó bằngy là bao nhiêu.\\nRanh giới giữa unsupervised learning và supervised learning đôi khi là không rõ ràng. Thông\\nthường, người ta thường coi các bài classification, regression là supervised learning, các bài\\nclustering haydensity estimation (ước lượng một phân phối) là unsupervised learning.\\nCó những bài toán mà dữ liệu được dùng để huấn luyện bao gồm cả những dữ liệu có nhãn\\nvà chưa được gán nhãn. Các bài toán khi chúng ta có một lượng lớn dữ liệuX nhưng chỉ\\nmột phần trong chúng được gán nhãn được gọi làhọc bán giám sát, haysemi-supervised'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 79, 'page_label': '68'}, page_content='và chưa được gán nhãn. Các bài toán khi chúng ta có một lượng lớn dữ liệuX nhưng chỉ\\nmột phần trong chúng được gán nhãn được gọi làhọc bán giám sát, haysemi-supervised\\nlearning. Những bài toán thuộc nhóm này nằm giữa hai nhóm được nêu bên trên.\\nMột ví dụ điển hình của nhóm này là chỉ có một phần ảnh hoặc văn bản được gán nhãn\\n(ví dụ bức ảnh về người, động vật hoặc các văn bản khoa học, chính trị) và phần lớn các\\nbức ảnh/văn bản khác chưa được gán nhãn được thu thập từ internet. Thực tế cho thấy rất\\nnhiều các bài toán machine learning thuộc vào nhóm này vì việc thu thập dữ liệu có nhãn\\ntốn rất nhiều thời gian và có chi phí cao. Rất nhiều loại dữ liệu, ví dụ như ảnh y học, thậm\\nchí cần phải có chuyên gia mới gán nhãn được. Ngược lại, dữ liệu chưa có nhãn có thể được\\nthu thập với chi phí thấp từ internet.\\nCó những thuật toán machine learning không luôn trải nghiệm trên một tập dữ liệu cố định.\\nVí dụ, học củng cố (reinforcement learning) trải nghiệm trực tiếp với môi trường xun\\nquanh, liên tục nhận phản hồi từ môi trường để tự cải thiện hành vi của hệ thống trong các\\nmôi trường mới. Các ví dụ điển hình của reinforcement learning là việc huấn luyện cho xe tự\\nlái dựa vào ảnh nhận từ camera và điều khiển tay lái cũng như tốc độc của xe. Reinforcement\\nlearning hiện nay chủ yếu được áp dụng vào các trò chơi, khi mà máy tính có thể mô phỏng\\nđược các trạng thái của môi trường và huấn luyện thuật toán thông qua rất nhiều vòng lặp.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 80, 'page_label': '69'}, page_content='69 CHƯƠNG 5. CÁC KHÁI NIỆM CƠ BẢN\\nVí dụ 1:AlphaGo gần đây nổi tiếng với việc chơi cờ vây thắng cả con người (https://goo.\\ngl/PzKcvP ). Cờ vây được xem là có độ phức tạp cực kỳ cao2 với tổng số nước đi là xấp\\nxỉ 10761, so với cờ vua là10120 và tổng số nguyên tử trong toàn vũ trụ là khoảng1080!! Hệ\\nthống phải chọn ra mộtđường đi nước bướctối ưu trong số hàng nhiều tỉ tỉ lựa chọn, và\\ntất nhiên, việc thử tất cả các lựa chọn là không khả thi. Về cơ bản, AlphaGo bao gồm các\\nthuật toán thuộc cả supervised learning và reinforcement learning. Trong phần supervised\\nlearning, dữ liệu từ các ván cờ do con người chơi với nhau được đưa vào để huấn luyện. Tuy\\nnhiên, mục đích cuối cùng của AlphaGo không phải là chơi như con người mà phải thậm\\nchí thắng cả con người. Vì vậy, sau khihọc xong các ván cờ của con người, AlphaGo tự chơi\\nvới chính nó với hàng triệu ván chơi để tìm ra các nước đi mới tối ưu hơn. Thuật toán trong\\nphần tự chơi này được xếp vào loại reinforcement learning.\\nGần đây, Google DeepMind đã tiến thêm một bước đáng kể với AlphaGo Zero. Hệ thống\\nnày thậm chí không cần học từ các ván cờ của con người. Nó có thể tự chơi với chính mình\\nđể tìm ra các chiến thuật tối ưu. Sau 40 ngày được huấn luyện, nó đã thắng tất cả các con\\nngười và hệ thống khác, bao gồm AlphaGo3.\\nVí dụ 2:Huấn luyện cho máy tính chơi game Mario4. Đây là một chương trình thú vị dạy\\nmáy tính chơi game Mario. Game này đơn giản hơn cờ vây vì tại một thời điểm, người chơi\\nchỉ phải bấm một số lượng nhỏ các nút (di chuyển, nhảy, bắn đạn) hoặc không cần bấm nút\\nnào. Đồng thời, phản ứng của máy cũng đơn giản hơn và lặp lại ở mỗi lần chơi (tại thời\\nđiểm cụ thể sẽ xuất hiện một chướng ngại vật cố định ở một vị trí cố định). Đầu vào của\\nthuật toán là sơ đồ của màn hình tại thời điểm hiện tại, nhiệm vụ của thuật toán là với đầu\\nvào đó, tổ hợp phím nào nên được bấm. Việc huấn luyện này được dựa trên điểm số cho\\nviệc di chuyển được bao xa trong thời gian bao lâu trong game, càng xa và càng nhanh thì'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 80, 'page_label': '69'}, page_content='vào đó, tổ hợp phím nào nên được bấm. Việc huấn luyện này được dựa trên điểm số cho\\nviệc di chuyển được bao xa trong thời gian bao lâu trong game, càng xa và càng nhanh thì\\nđược điểm thưởng càng cao (điểm thưởng này không phải là điểm của trò chơi mà là điểm\\ndo chính người lập trình tạo ra). Thông qua huấn luyện, thuật toán sẽ tìm ra một cách tối\\nđa số điểm trên, qua đó đạt được mục đích cuối cùng là cứu công chúa.\\nReinforcement learning là một lĩnh vực thú vị trong machine learning. Rất tiếc, reinforcement\\nlearning nằm ngoài phạm vi của cuốn sách này.\\n5.4 Hàm mất mát và tham số mô hình\\nMỗi mô hình machine learning được mô tả bởicác tham số mô hình(model parameters).\\nCông việc của một thuật toán machine learning là đi tìm các tham số mô hình phù hợp với\\nmỗi bài toán. Việc đi tìm các tham số mô hình có liên quan mật thiết đến các phép đánh\\ngiá. Mục đích của chúng ta là đi tìm các tham số mô hình sao cho các phép đánh giá cho\\nkết quả tốt nhất. Trong bài toán classification, kết quả tốt có thể được hiểu là ít điểm dữ\\nliệu bị phân lớp sai nhất. Trong bài toán regression, kết quả tốt là khi sự sai lệch giữa đầu\\nra dự đoán và đầu ra thực sự là ít nhất.\\n2 Google DeepMind’s AlphaGo: How it works(https://goo.gl/nDNcCy ).\\n3 AlphaGo Zero: Learning from scratch(https://goo.gl/xtDjoF ).\\n4 MarI/O - Machine Learning for Video Games(https://goo.gl/QekkRz )\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 81, 'page_label': '70'}, page_content='CHƯƠNG 5. CÁC KHÁI NIỆM CƠ BẢN 70\\nQuan hệ giữa một phép đánh giá và các tham số mô hình thường được mô tả thông qua\\nmột hàm số được gọi làhàm mất mát(loss function, haycost function). Hàm mất mát này\\nthường có giá trị nhỏ khi phép đánh giá cho kết quả tốt và ngược lại. Việc đi tìm các tham\\nsố mô hình sao cho phép đánh giá trả về kết quả tốt tương đương với việc tối thiểu hàm\\nmất mát. Như vậy, việc xây dựng một mô hình machine learning chính là việc đi giải một\\nbài toán tối ưu. Quá trình đó có thể được coi là quá trìnhlearning của machine.\\nTập hợp các tham số mô hình thường được ký hiệu bằngθ, hàm mất mát của mô hình\\nthường được ký hiệu làL(θ) hoặc J(θ). Bài toán tối thiểu hàm mất mát để tìm tham số mô\\nhình thường được viết dưới dạng:\\nθ∗= argmin\\nθ\\nL(θ) (5.1)\\nký hiệuargmin\\nθ\\nL(θ) được hiểu là giá trị củaθ để hàm sốL(θ) đạt giá trị nhỏ nhất. Khi sử\\ndụng argmin, chúng ta phải chỉ rõ nó được thực hiện theo các biến số nào bằng cách ghi các\\nbiến số ở dướimin (ở đây làθ). Nếu hàm số chỉ có một biến số, ta có thể bỏ qua biến số đó\\ndưới min. Tuy nhiên, biến số nên được ghi rõ ràng để giảm thiểu sự nhầm lẫn.argmax cũng\\nđược sử dụng một cách tương tự khi ta cần tìm giá trị của các biến số để một hàm số đạt\\ngiá trị lớn nhất.\\nMột hàm sốL(θ) bất kỳ có thể có rất nhiều giá trị củaθ để nó đạt giá trị nhỏ nhất, hoặc\\ncũng có thể nó không chặn dưới. Thậm chí, việc tìm giá trị nhỏ nhất của một hàm số đôi\\nkhi là không khả thi. Trong machine learning cũng như nhiều bài toán tối ưu thực tế, việc\\nchỉ cần tìm ra một bộ tham sốθ làm cho hàm mất mát đạt giá trị nhỏ nhất, hoặc thậm chí\\nđạt một giá trị cực tiểu5, thường mang lại các kết quả khả quan.\\nĐể hiểu rõ bản chất của các thuật toán machine learning, việc nắm vững các kỹ thuật tối\\nưu cơ bản là rất quan trọng. Cuốn sách này có nhiều chương cung cấp các kiến thức cần\\nthiết cho tối ưu, bao gồm tối ưu không ràng buộc (Chương 12) và tối ưu có ràng buộc (xem\\nPhần VII).'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 81, 'page_label': '70'}, page_content='ưu cơ bản là rất quan trọng. Cuốn sách này có nhiều chương cung cấp các kiến thức cần\\nthiết cho tối ưu, bao gồm tối ưu không ràng buộc (Chương 12) và tối ưu có ràng buộc (xem\\nPhần VII).\\nTrong các chương tiếp theo của cuốn sách này, chúng ta sẽ dần làm quen với các thành phần\\ncơ bản của một hệ thống machine learning.\\n5 Lưu ý rằng cực tiểu trong toán học không có nghĩa là nhỏ nhất.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 82, 'page_label': '71'}, page_content='Chương 6\\nGiới thiệu về feature engineering\\n6.1 Giới thiệu\\nMỗi điểm dữ liệu trong các bài toán machine learning thường được biểu diễn bằng một vector\\nđược gọi làvector đặc trưng(feature vector)1. Hơn nữa, trong cùng một bài toán, các feature\\nvector của tất cả các điểm thường có kích thước như nhau. Điều này là cần thiết vì các phép\\ntoán trong mô hình (cộng, nhân ma trận, vector) yêu cầu đầu vào có cùng kích thước. Khi\\nđó, toàn bộdữ liệu có thể được lưu trong một ma trận mà mỗi hàng hoặc mỗi cột là feature\\nvector của một điểm dữ liệu. Tuy nhiên, trên thực tế, dữ liệu thường ở dạngthô (raw data)\\nvới kích thước khác nhau. Hoặc thậm chí khi kích thước của các điểm là như nhau, việc lựa\\nchọn, tính toán đặc trưng nào phù hợp cho mỗi bài toán là nhiệm vụ quan trọng trước tiên\\ncần được giải quyết.\\nVới các bài toánthị giác máy tính(computer vision), các bức ảnh thường là các ma trận\\nhoặc tensor với kích thước khác nhau. Trong bài toán nhận dạng vật thể trong ảnh, đôi khi\\nta cần làm thêm một bước nữa làxác định vị trí vật thể(object detection), tức là tìm các\\nkhung chứa vật thể cần dự đoán. Ví dụ, trong bài toán nhận dạng khuôn mặt, ta cần tìm\\nđược vị trí các khuôn mặt trong ảnh và cắt ra các khuôn mặt đó trước khi làm các bước\\ntiếp theo. Ngay cả khi đã xác định được các khung chứa các khuôn mặt, ta vẫn phải làm\\nrất nhiều việc vì hình ảnh của khuôn mặt còn phụ thuộc vào góc chụp, ánh sáng, v.v. và rất\\nnhiều yếu tố khác nữa.\\nCác bài toánxử lý ngôn ngữ tự nhiên(natural language processing–NLP) cũng có khó khăn\\ntương tự khi độ dài của các văn bản là khác nhau, thậm chí có những từ rất hiếm gặp hoặc\\nkhông có trong từ điển. Cũng có khi thêm một vài từ vào văn bản mà nội dung của văn bản\\nkhông đổi hoặc hoàn toàn mang nghĩa ngược lại. Hoặc cùng là một câu nói nhưng tốc độ,\\nâm giọng của mỗi người là khác nhau, tại các thời điểm khác nhau là khác nhau.\\n1 Trong các hệ thống deep learning, một bức ảnh hai chiều có thể được trực tiếp đưa vào hệ thống mà không cần'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 82, 'page_label': '71'}, page_content='âm giọng của mỗi người là khác nhau, tại các thời điểm khác nhau là khác nhau.\\n1 Trong các hệ thống deep learning, một bức ảnh hai chiều có thể được trực tiếp đưa vào hệ thống mà không cần\\nqua nhiều bước feature engineering. Cuốn sách này chỉ làm việc với các đặc trưng ở dạng vector cột.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 83, 'page_label': '72'}, page_content='CHƯƠNG 6. GIỚI THIỆU VỀ FEATURE ENGINEERING 72\\nKhi làm việc với các bài toán machine learning thực tế, nhìn chung chúng ta chỉ có được\\ndữ liệu thô chưa qua chỉnh sửa, chọn lọc. Ngoài ra, chúng ta có thể phải tìm cách loại ra\\nnhững dữ liệu nhiễu, và để đưa dữ liệu thô với kích thước, hay số chiều khác nhau về cùng\\nmột chuẩn (cùng là các vector hoặc ma trận). Dữ liệu chuẩn mới này phải đảm bảo giữ được\\nnhững thông tin đặc trưng cho dữ liệu thô ban đầu. Không những thế, tùy vào từng bài\\ntoán, ta cần thiết kế những phép biến đổi để có những đặc trưng phù hợp. Quá trình quan\\ntrọng này được gọi làtrích chọn đặc trưng(feature engineeringhay feature extraction).\\nXin trích một câu nói (xin không dịch) của Andrew Ng2:\\nComing up with features is difficult, time-consuming, requires expert knowledge. “Applied\\nmachine learning” is basically feature engineering.\\nĐể có cái nhìn tổng quan, trong mục tiếp theo, bước feature engineering này sẽ được đặt\\ntrong một bức tranh lớn hơn.\\n6.2 Mô hình chung cho các bài toán Machine Learning\\nPhần lớn các mô hình machine learning có thể được minh hoạ trong Hình 6.1. Có hai bước\\n(phase) lớn trong mỗi bài toán machine learning là bước huấn luyện (training phase) và bước\\nkiểm thử (test phase). Bước huấn luyện sẽ chỉ dùng dữ liệu huấn luyện, bước kiểm thử sẽ\\nchỉ dùng dữ liệu trong tập kiểm thử3.\\n6.2.1 Training phase\\nCó hai khối có nền màu lục cần được thiết kế:\\nKhối thứ nhất,Feature Extraction, có nhiệm vụ tạo ra một vector đặc trưng cho mỗi\\nđiểm dữ liệu đầu vào. Vector đặc trưng này thường có kích thước như nhau, bất kể dữ liệu\\nđầu vào có kích thước như thế nào.\\nĐầu vào của khối Feature Extraction có thể là các yếu tố sau:\\n• Dữ liệu thô ban đầu(raw training input). Dữ liệu thô bao gồm tất cả các thông tin ta\\nbiết về dữ liệu. Ví dụ: dữ liệu thô của một ảnh là giá trị của từng pixel; của một văn\\nbản là từng từ, từng câu; của một file âm thanh là một đoạn tín hiệu; với bài toán dự'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 83, 'page_label': '72'}, page_content='biết về dữ liệu. Ví dụ: dữ liệu thô của một ảnh là giá trị của từng pixel; của một văn\\nbản là từng từ, từng câu; của một file âm thanh là một đoạn tín hiệu; với bài toán dự\\nbáo thời tiết, dữ liệu thô là thông tin về hướng gió, nhiệt độ, độ ẩm,v.v.. Dữ liệu thô này\\nthường không ở dạng vector và không có số chiều như nhau. Thậm chí có thể có số chiều\\nnhư nhau nhưng số chiều quá lớn, chẳng hạn một bức ảnh màu1000 ×1000 pixel sẽ có\\nsố pixel là đã là3 ×106 (ảnh màu thường có ba channel: red, green, blue–RGB). Đây là\\nmột con số quá lớn, không lợi cho lưu trữ và tính toán.\\n2 Feature Engineering– Wikipedia(https://goo.gl/v4e21T )\\n3 Trước khi đánh giá một mô hình trên tập kiểm thử, ta cần đảm bảo rằng mô hình đó đã làm việc tốt trên tập\\nhuấn luyện.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 84, 'page_label': '73'}, page_content='73 CHƯƠNG 6. GIỚI THIỆU VỀ FEATURE ENGINEERING\\nTRAINING PHASE\\nRaw training\\ndata (input)\\nTraining output\\n(ytrain)\\nPrior knowledge\\nabout data\\nFeature\\nExtraction\\n(Feature\\nEngineering)\\nExtracted\\nfeatures\\n(Xtrain)\\n Classiﬁcation,\\nRegression,\\nClustering,...\\nAlgorithms\\nTEST PHASE\\nRaw test\\ndata (input)\\n Feature\\nExtraction\\n(Feature\\nEngineering)\\nExtracted\\nfeatures\\n(Xtest)\\n Classiﬁcation,\\nRegression,\\nClustering,...\\nAlgorithms\\nTest output\\n(ytest)\\nHình 6.1: Mô hình thường gặp trong các bài toán machine learning.\\n• output của training set. Trong các bài toán unsupervised learning, ta không biết\\noutput nên hiển nhiên sẽ không có giá trị này. Trong các bài toán supervised learning, có\\nkhi dữ liệu này cũng không được sử dụng. Ví dụ, nếuraw input đã có cùng số chiều rồi\\nnhưng số chiều quá lớn, ta muốn giảm số chiều của nó thì cách đơn giản nhất làchiếu\\nvector đó xuống một không gian có số chiều nhỏ hơn bằng cách lấy một ma trận ngẫu\\nnhiên nhân với nó vào bên trái. Ma trận này thường là ma trậnbéo, tức có số hàng ít\\nhơn số cột, để đảm bảo số chiều thu được nhỏ hơn số chiều ban đầu. Việc làm này mặc\\ndù làm mất đi thông tin, trong nhiều trường hợp vẫn mang lại hiệu quả vì đã giảm được\\nlượng tính toán ở phần sau. Đôi khima trận chiếukhông phải là ngẫu nhiên mà có thể\\nđược học dựa trên toàn bộ dữ liệu thô ban đầu. Trong nhiều trường hợp khác, dữ liệu\\noutput của tập huấn luyện cũng được sử dụng để tạo ra bộ trích chọn đặc trưng. Trong\\nbài toán classification, việc giữ lại nhiều thông tin không quan trọng bằng việc giữ lại các\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 85, 'page_label': '74'}, page_content='CHƯƠNG 6. GIỚI THIỆU VỀ FEATURE ENGINEERING 74\\nthông tin có ích cho bài toán. Ví dụ, giả sử dữ liệu thô là các hình vuông và hình tam\\ngiác có màu đỏ và xanh. Trong bài toán phân loại đa giác, nếu các nhãn làtam giác và\\nvuông, ta không quan tâm tới màu sắc mà chỉ quan tâm tới số cạnh của đa giác. Ngược\\nlại, trong bài toán phân loại màu, các nhãn làxanh vàđỏ, ta không quan tâm tới số cạnh\\nmà chỉ quan tâm đến màu sắc.\\n• Prior knowledge about data: Các thông tin khác đã biết về loại dữ liệu (ngoài những\\nthông tin về raw input và output).\\nSau khi các tham số mô hình của bộ feature extraction được thiết kế, dữ liệu thô ban đầu\\nđược đưa qua và tạo ra các vector đặc trưng tương ứng được gọi làextracted feature. Những\\nextracted feature này sẽ được đưa vào huấn luyện các thuật toán chính như classification,\\nregression, clustering, v.v. trong khối màu lục phía sau.\\nTrong một số thuật toán cao cấp hơn, việc xây dựng bộ trích chọn đặc trưng và các\\nthuật toán chính (classification, clustering, v.v.) có thể được thực hiện cùng lúc với\\nnhau thay vì từng bước như trên. Các mô hình đó có tên gọi chung là end-to-end. Với\\nsự phát triển của deep learning trong những năm gần đây, người ta cho rằng các hệ\\nthống end-to-end (từ đầu đến cuối) mang lại kết quả tốt hơn nhờ vào việc hai khối\\nphía trên được huấn luyện cùng nhau, bổ trợ lẫn nhau cùng hướng tới mục đích cuối\\ncùng. Thực tế cho thấy, các phương pháp state-of-the-art (các phương pháp hiệu quả\\nnhất) thường là các mô hình end-to-end.\\n6.2.2 Testing phase\\nKhi có dữ liệu thô mới, ta sử dụng bộ trích chọn đặc trưng đã tìm được ở trên để tạo ra\\nvector đặc trưng ứng với dữ liệu thô đó. Vector đặc trưng này được đưa vào thuật toán chính\\nđã tìm được để đưa ra quyết định.\\n6.3 Một số ví dụ về Feature Engineering\\n6.3.1 Trực tiếp lấy dữ liệu thô\\nXét một bài toán phân loại các bức ảnh xám mà mỗi bức ảnh đã có kích thước cố định là\\nm×n pixel. Cách đơn giản nhất để tạo ra vector đặc trưng cho bức ảnh này làkéo dàima'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 85, 'page_label': '74'}, page_content='Xét một bài toán phân loại các bức ảnh xám mà mỗi bức ảnh đã có kích thước cố định là\\nm×n pixel. Cách đơn giản nhất để tạo ra vector đặc trưng cho bức ảnh này làkéo dàima\\ntrận các pixel thành một vector cómnphần tử, hay đặc trưng. Khi đó, giá trị mỗi đặc trưng\\nsẽ là một giá trị của một pixel trong bức ảnh ban đầu, thứ tự không quan trọng. Kỹ thuật\\nnày còn được gọi làvector hoá (vectorization).\\nViệc làm đơn giản này đã làm mấtthông tin về không gian(spatial information) giữa các\\nđiểm ảnh vì các pixel gần nhau theo phương ngang trong bức ảnh ban đầu có thể không còn\\ngần nhau trong vector đặc trưng mới nữa. Tuy nhiên, trong nhiều trường hợp, kỹ thuật này\\nvẫn mang lại kết quả khả quan.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 86, 'page_label': '75'}, page_content='75 CHƯƠNG 6. GIỚI THIỆU VỀ FEATURE ENGINEERING\\n6.3.2 Lựa chọn đặc trưng\\nGiả sử rằng các điểm dữ liệu có số đặc trưng khác nhau (do kích thước dữ liệu khác nhau\\nhay do một số đặc trưng mà điểm dữ liệu này có nhưng điểm dữ liệu kia lại không thu thập\\nđược), và số lượng đặc trưng là cực lớn. Chúng ta cầnchọn ra một số lượng nhỏ hơn các đặc\\ntrưng phù hợp với bài toán.\\n6.3.3 Giảm chiều dữ liệu\\nMột phương pháp khác thường được dùng làlàm giảm số chiều dữ liệu (dimensionality\\nreduction) để giảm bộ nhớ và khối lượng tính toán. Việc giảm số chiều này có thể được\\nthực hiện bằng nhiều cách, trong đóchiếu ngẫu nhiên(random projection) là cách đơn giản\\nnhất. Trong phương pháp này, mộtma trận chiếu(projection matrix) ngẫu nhiên được chọn,\\nthường là một ma trận béo–số cột nhiều hơn số hàng, để nhân vào bên trái của từng vector\\nđặc trưng ban đầu để được các vector đặc trưng có số chiều thấp hơn. Cụ thể, giả sử vector\\nđặc trưng ban đầu làx0 ∈RD, nếu ta chọn một ma trận chiếuP ∈Rd×D với d≪D, vector\\nmới x1 = Px0 ∈Rd có số chiều nhỏ hơn số chiều của vectorx0 ban đầu.\\nViệc chọn một ma trận chiếu ngẫu nhiên đôi khi mang lại kết quả tệ không mong muốn vì\\nthông tin có thể bị mất đi quá nhiều. Một phương pháp được sử dụng nhiều để tối thiểu lượng\\nthông tin mất đi có tên là principal component analysis sẽ được trình bày trong Chương 21.\\nLưu ý:Feature engineering không nhất thiết phải làm giảm số chiều dữ liệu, đôi khi vector\\nđặc trưng có thể có có kích thước lớn hơn dữ liệu thô ban đầu.\\n6.3.4 Bag of words\\nChúng ta hẳn đã tự đặt ra các câu hỏi: với một văn bản, vector đặc trưng sẽ có dạng như\\nthế nào? Làm sao đưa các từ, các câu, đoạn văn ở dạngtext trong các văn bản về một vector\\nmà mỗi phần tử là một số?\\nCó một kỹ thuật rất phổ biến trong xử lý văn bản có tên làtúi đựng từ(bag of words–BoW).\\nBắt đầu bằng ví dụ phân loại tin nhắn rác. Ta thấy rằng nếu một tin có chứa các từkhuyến\\nmại, giảm giá, trúng thưởng, miễn phí, quà tặng, tri ân, v.v., nhiều khả năng đó là một tin'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 86, 'page_label': '75'}, page_content='Bắt đầu bằng ví dụ phân loại tin nhắn rác. Ta thấy rằng nếu một tin có chứa các từkhuyến\\nmại, giảm giá, trúng thưởng, miễn phí, quà tặng, tri ân, v.v., nhiều khả năng đó là một tin\\nnhắn rác. Từ đó, phương pháp đầu tiên có thể nghĩ tới làđếm xem trong tin đó có bao nhiêu\\ntừ thuộc vào các từ trên, nếu số lượng này nhiều hơn một ngưỡng nào đó thì ta quyết định\\nđó là tin rác. (Tất nhiên bài toán thực tế phức tạp hơn nhiều khi các từ có thể được viết\\ndưới dạng không dấu, hoặc bị cố tình viết sai chính tả, hoặc dùng ngôn ngữ teen). Với các\\nloại văn bản khác nhau, lượng từ liên quan tới từng chủ đề cũng khác nhau. Từ đó có thể\\ndựa vào số lượng các từ trong từng loại để tạo các vector đặc trưng cho từng văn bản.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 87, 'page_label': '76'}, page_content='CHƯƠNG 6. GIỚI THIỆU VỀ FEATURE ENGINEERING 76\\nXin lấy một ví dụ về hai văn bản đơn giản sau đây4:\\n(1) \"John likes to watch movies. Mary likes movies too.\"\\nvà\\n(2) \"John also likes to watch football games.\"\\nDựatrên haivăn bảnnày,ta códanhsáchcác từđượcsử dụng,được gọi là từ điển(dictionary\\nhoặc codebook) với mườitừ như sau:\\n[\"John\", \"likes\", \"to\", \"watch\", \"movies\", \"also\", \"football\", \"games\", \"Mary\", \"too\"]\\nVới mỗi văn bản, ta sẽ tạo ra một vector đặc trưng có số chiều bằng 10, mỗi phần tử đại\\ndiện cho số từ tương ứng xuất hiện trong văn bản đó. Với hai văn bản trên, ta sẽ có hai\\nvector đặc trưng\\n(1) [1, 2, 1, 1, 2, 0, 0, 0, 1, 1]\\n(2) [1, 1, 1, 1, 0, 1, 1, 1, 0, 0]\\nVăn bản (1) có 1 từ\"John\", 2 từ\"likes\", 0 từ\"also\", 0 từ\"football\", v.v. nên ta thu được\\nvector tương ứng như trên.\\nCó một vài điều cần lưu ý trong BoW:\\n• Với những ứng dụng thực tế,từ điểncó nhiều hơn mười từ rất nhiều, có thể đến cả triệu,\\nnhư vậy vector đặc trưng thu được sẽ rất dài. Một văn bản chỉ có một câu, và một tiểu\\nthuyết nghìn trang đều được biểu diễn bằng các vector có kích thước như nhau.\\n• Có rất nhiều từ trong từ điển không xuất hiện trong một văn bản. Như vậy các vector\\nđặc trưng thu được thường có rất nhiều phần tử bằng không. Các vector có nhiều phần\\ntử bằng không được gọi làvector thưa(sparse vector). Để việc lưu trữ được hiệu quả hơn,\\nta không lưu cả vector đó mà chỉ lưuvị trí của các phần tử khác 0 vàgiá trịtương ứng.\\nChú ý rằng nếu có hơn một nửa số phần tử khác không, việc làm này lại phản tác dụng.\\nTuy nhiên, trường hợp này ít xảy ra vì hiếm có văn bản nào lại chứa tới một nửa từ điển.\\n• Ta xử lý các từ hiếm gặp không nằm trong từ điển như thế nào? Một kỹ thuật thường\\nđược dùng là thêm phần tử<Unknown> vào trong từ điển. Mọi từ không có trong từ điển\\nđều được coi là<Unknown>. Lúc này, kích thước của vector đặc trưng sẽ tăng lên một.\\n• Tuy nhiên, những từ hiếm đôi khi lại mang những thông tin quan trọng nhất mà chỉ loại'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 87, 'page_label': '76'}, page_content='đều được coi là<Unknown>. Lúc này, kích thước của vector đặc trưng sẽ tăng lên một.\\n• Tuy nhiên, những từ hiếm đôi khi lại mang những thông tin quan trọng nhất mà chỉ loại\\nvăn bản đó có. Đây là một nhược điểm của BoW. Có một phương pháp cải tiến giúp\\n4 Bag of words–Wikipedia(https://goo.gl/rBtZqx )\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 88, 'page_label': '77'}, page_content='77 CHƯƠNG 6. GIỚI THIỆU VỀ FEATURE ENGINEERING\\nkhắc phục nhược điểm này có tên làterm frequency-inverse document frequency(TF-\\nIDF) [SWY75] dùng để xác định tầm quan trọng của một từ trong một văn bản dựa trên\\ntoàn bộ văn bản trong cơ sở dữ liệu5.\\n• Nhược điểm lớn nhất của BoW là nó không mang thông tin về thứ tự của các từ, cũng\\nnhư sự liên kết giữa các câu, các đoạn văn trong văn bản. Thứ tự của các từ trong văn\\nbản thường mang thông tin quan trọng. Ví dụ, ba câu sau đây: “Em yêu anh không?”,\\n“Em không yêu anh”, và “Không, (nhưng) anh yêu em” khi được trích chọn đặc trưng\\nbằng BoW sẽ cho ra ba vector giống hệt nhau, mặc dù ý nghĩa khác hẳn nhau.\\n6.3.5 Bag of words trong computer vision\\nBag of words cũng được áp dụng trong computer vision cho các bức ảnh với cách định nghĩa\\ntừ và từ điển khác. Xét các ví dụ sau:\\nVí dụ 1:Có hai class ảnh, một class là ảnh các khu rừng, một class là ảnh các sa mạc. Giả\\nsử ta biết rằng một bức ảnh chỉ thuộc một trong hai loại này, việc phân loại một bức ảnh\\nlà rừng hay sa mạc một cách trực quan nhất là dựa vào màu sắc. Màu xanh lục nhiều thì\\nlà rừng, màu đỏ và vàng nhiều thì là sa mạc. Vậy chúng ta có thể có một mô hình đơn giản\\nđể trích chọn đặc trưng như sau:\\n• Với một bức ảnh, chuẩn bị một vectorx có số chiều bằng 3, đại diện cho ba màu xanh\\nlục (x1), đỏ (x2), và vàng (x3).\\n• Với mỗi điểm ảnh trong bức ảnh đó, xem nó gần với màu xanh, đỏ hay vàng nhất dựa\\ntrên giá trị của pixel đó. Nếu nó gần điểm xanh nhất, tăngx1 lên một; gần đỏ nhất, tăng\\nx2 lên một; gần vàng nhất, tăngx3 lên một.\\n• Sau khi xem xét tất cả các điểm ảnh, dù cho bức ảnh có kích thước thế nào, ta vẫn thu\\nđược một vector có kích thước bằng ba, mỗi phần tử thể hiện việc có bao nhiêu pixel\\ntrong bức ảnh có màu tương ứng. Vector cuối này còn được gọi làhistogram vectorcủa\\nbức ảnh tương ứng với ba màu xanh, đỏ, vàng. Vector này có thể coi là một đặc trưng\\ntốt trong bài toán phân lớp ảnh rừng hay say mạc.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 88, 'page_label': '77'}, page_content='bức ảnh tương ứng với ba màu xanh, đỏ, vàng. Vector này có thể coi là một đặc trưng\\ntốt trong bài toán phân lớp ảnh rừng hay say mạc.\\nVí dụ 2:Trên thực tế, các bài toán xử lý ảnh không đơn giản như Ví dụ 1 trên đây. Mắt\\nngười thực ra nhạy với các đường nét, hình dáng hơn là màu sắc. Chúng ta có thể nhận biết\\nđược một bức ảnh có cây hay không ngay cả khi bức ảnh đó không có màu. Vì vậy, xem xét\\ngiá trị từng điểm ảnh một không mang lại kết quả khả quan vì lượng thông tin về đường\\nnét bị mất quá nhiều.\\nCó một giải pháp là thay vì xem xét một điểm ảnh, ta xem xét một vùng hình chữ nhật nhỏ\\ntrong ảnh, vùng này còn được gọi làpatch. Các patch này nên đủ lớn để có thể chứa được\\ncác bộ phận có thể mô tả được vật thể trong ảnh. Ví dụ với mặt người, các patch nên đủ\\nlớn để chứa được các phần của khuôn mặt như mắt, mũi, miệng như trong Hình 6.2. Tương\\n5 5 Algorithms Every Web Developer Can Use and Understand, section 5(https://goo.gl/LJW3H1 ).\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 89, 'page_label': '78'}, page_content='CHƯƠNG 6. GIỚI THIỆU VỀ FEATURE ENGINEERING 78\\nHình 6.2:Bag of words cho ảnh chứa mặt người (Nguồn:Bag of visual words model: recognizing\\nobject categories(https://goo.gl/EN2oSM ).\\ntự thế, với ảnh là ô tô, các patch thu được có thể là bánh xe, khung xe, cửa xe, v.v. trên\\nHình 6.3, hàng trên bên phải.\\nMột câu hỏi được đặt ra là, trong xử lý văn bản, hai từ được coi là như nhau nếu nó được\\nbiểu diễn bởi các ký tự giống nhau. Vậy trong xử lý ảnh, hai patch được coi là như nhau khi\\nnào? Khi mọi pixel trong hai patch có giá trị bằng nhau sao?\\nCâu trả lời là không. Xác suất để hai patch giống hệt nhau từng pixel là rất thấp vì có thể\\nmột phần của vật thể trong một patch bị lệch đi vài pixel so với phần đó trong patch kia;\\nhoặc phần vật thể trong patch bị méo, hoặc có độ sáng khác nhau, mặc dù mắt người vẫn\\nnhìn thấy hai patch đórất giống nhau. Vậy thì hai patch được coi là như nhau khi nào? Và\\ntừ điển ở đây được định nghĩa như thế nào?\\nCâu trả lời ngắn cho câu hỏi này là hai patch được coi là gần giống nhau nếu khoảng cách\\nEuclid giữa hai vector tạo bởi hai patch đó là nhỏ. Từ điển sẽ có số từ do ta tự chọn. Số từ\\ntrong từ điển càng cao thì độ sai lệch càng ít, nhưng sẽ nặng về tính toán hơn.\\nCụ thể hơn chúng ta có thể áp dụng một phương pháp phân nhóm đơn giản làK-means\\nclustering (xem Chương 10). Với rất nhiều patch thu được, giả sử ta muốn xây dựng một từ\\nđiển với chỉ khoảng 1000từ. Ta có thể dùngK-means clustering để phân toàn bộ các patch\\nthành 1000 nhóm (bag) khác nhau. Mỗi nhóm gồm các patch gần giống nhau và được mô\\ntả bằng trung bình cộng của tất cả các patch trong nhóm đó (xem Hình 6.3 hàng dưới). Với\\nmột ảnh bất kỳ, ta trích ra các patch từ ảnh đó, tìm xem mỗi patch gần với nhóm nào nhất\\ntrong 1000 nhóm tìm được ở trên và quyết định patch này thuộc nhóm đó. Cuối cùng, ta\\nsẽ thu được một vector đặc trưng có kích thước bằng 1000 mà mỗi phần tử là số lượng các\\npatch trong ảnh rơi vào nhóm tương ứng.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 90, 'page_label': '79'}, page_content='79 CHƯƠNG 6. GIỚI THIỆU VỀ FEATURE ENGINEERING\\nHình 6.3: Bag of Words cho ảnh xe hơi (Nguồn: B. Leibe).\\n6.4 Transfer Learning cho bài toán phân loại ảnh\\n(Giả sử rằng bạn đọc đã có kiến thức nhất định về deep neural network.)\\nNgoài BoW, các phương pháp thường được sử dụng để xây dựng feature vector cho ảnh là\\nscale invariant feature transform–SIFT[Low99],speeded-up robust features–SURF[BTVG06],\\nhistogram of oriented gradients–HOG[DT05], local binary pattern–LBP[Low99], v.v.. Các\\nbộ phân lớp thường được sử dụng là multi-class SVM (Chương 29), softmax regression\\n(Chương 15), sparse coding và discriminative dictionary learning [WYG+09, VMM+16,\\nVM17], random forest[LW+02], v.v..\\nCác feature được tạo bởi các phương pháp nêu trên thường được gọi là cácfeature được tạo\\nthủ công(hand-crafted feature) vì chúng chủ yếu dựa trên các quan sát về đặc tính riêng của\\nảnh. Các phương pháp này cho kết quả khá ấn tượng trong một số trường hợp. Tuy nhiên,\\nchúng vẫn còn nhiều hạn chế vì quá trình tìm ra các feature và các classifier phù hợp vẫn là\\nriêng biệt.\\nNhững năm gần đây, deep learning phát triển cực nhanh dựa trên lượng dữ liệu huấn luyện\\nkhổng lồ và khả năng tính toán ngày càng được cải tiến của các máy tính. Các kết quả cho\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 91, 'page_label': '80'}, page_content='CHƯƠNG 6. GIỚI THIỆU VỀ FEATURE ENGINEERING 80\\nInput Hidden 1 ...\\nFully connected layer\\nsoftmax or multi-class\\nSVM\\nFeature vector\\nSecond to last Output\\nHình 6.4:Mô hình chung cho các bài toán classification sử dụng Deep Learning. Layer cuối cùng\\nthường là một Fully Connected Layer và thường là một Softmax Regression.\\nbài toán phân loại ảnh ngày càng được nâng cao. Bộ cơ sở dữ liệu thường được dùng nhất là\\nImageNet (https://www.image-net.org ) 1.2 triệu ảnh cho 1000 class khác nhau. Rất nhiều\\ncác mô hình deep learning đã giành chiến thắng trong các cuộc thiImageNet large scale vi-\\nsual recognition challenge–ILSVRC: AlexNet [KSH12], ZFNet [ZF14], GoogLeNet [SLJ+15],\\nResNet [HZRS16], VGG [SZ14]. Nhìn chung, các mô hình này là các neural network với rất\\nnhiều layer (xem Chương 16). Các layer phía trước thường là các convolutional layer. Layer\\ncuối cùng là một fully connected layer và thường là một softmax regression (xem Hình 6.4).\\nSố lượng unit ở layer cuối cùng bằng với số lượng class (với ImageNet là 1000). Vì vậy out-\\nput ở layer gần cuối cùng (second to last layer) có thể được coi là feature vector và softmax\\nregression chính là classifier được sử dụng.\\nChính nhờ việc các feature và classifier được huấn luyện cùng nhau thông qua việc tối ưu\\ncác hệ số trong deep network khiến cho các mô hình này đạt kết quả tốt. Tuy nhiên, những\\nmô hình này đều bao gồm rất nhiều layer và các trọng số. Việc huấn luyện dựa trên 1.2M\\nbức ảnh của ImageNet cũng tốn rất nhiều thời gian (2-3 tuần).\\nVới các bài toán dựa trên tập dữ liệu khác với ít dữ liệu hơn, ta có thể không cần xây dựng\\nlại network và huấn luyện nó từ đầu. Thay vào đó, ta có thể sử dụng các mô hình đã được\\nhuấn luyện nêu trên, và sử dụng một vài kỹ thuật khác để giải quyết bài toán. Phương pháp\\nsử dụng các mô hình có sẵn như thế này được gọi làtransfer learning.\\nNhư đã đề cập, toàn bộ các layer trừ output layer có thể được coi là một feature extractor.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 91, 'page_label': '80'}, page_content='sử dụng các mô hình có sẵn như thế này được gọi làtransfer learning.\\nNhư đã đề cập, toàn bộ các layer trừ output layer có thể được coi là một feature extractor.\\nDựa trên nhận xét rằng các bức ảnh đều có những đặc tính giống nhau nào đó, với cơ sở dữ\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 92, 'page_label': '81'}, page_content='81 CHƯƠNG 6. GIỚI THIỆU VỀ FEATURE ENGINEERING\\nliệu khác, ta cũng có thể sử dụng phần feature extractor này để tạo ra các feature vector.\\nSau đó, ta thay output layer cũng bằng một softmax regression, multi-class SVM (với số\\nlượng unit phù hợp) hoặc các classifier phổ biến khác. Cách làm này có thể tăng độ chính\\nxác phân lớp lên đáng kể so với việc sử dụng cáchand-crafted features.\\nHướng tiếp cận thứ hai là sử dụng các mô hình đã được huấn luyện và cho cập nhật một vài\\nlayer cuối dựa trên dữ liệu mới thêm một vài vòng lặp. Kỹ thuật này được gọi làtinh chỉnh\\n(fine-tuning). Việc này được dựa trên quan sát rằng những layer đầu trong deep network\\nthường giúp trích xuất những đặc tính chung của ảnh (các cạnh, còn được gọi làlow-level\\nfeature), các layer cuối thường mang những đặc trưng riêng của cơ sở dữ liệu (CSDL) (và\\nđược gọi làhigh-level feature). Vì vậy, việc huấn luyện các layer cuối mang nhiều giá trị hơn.\\nDựa trên kích thước và độ tương quan giữa CSDL mới và CSDL gốc (chủ yếu là ImageNet),\\ncó một vài quy tắc để huấn luyện network mới như sau6:\\n• CSDL mới là nhỏ và tương tự như CSDL gốc.Vì CSDL mới nhỏ, việc tiếp tục huấn luyện\\nmô hình có thể dễ dẫn đến hiện tượng overfitting (Chương 8). Cũng vì hai CSDL là tương\\ntự nhau, ta dự đoán rằng các high-level feature của chúng là tương tự nhau. Vì vậy, ta\\nkhông cần huấn luyện lại network mà chỉ cần huấn luyện một classifer dựa trên feature\\nvector ở đầu ra ở layer gần cuối.\\n• CSDL mới là lớn và tương tự như CSDL gốc.Vì CSDL này lớn, overfitting ít có khả năng\\nxảy ra hơn, ta có thể huấn luyện mô hình thêm một một vài vòng lặp. Việc huấn luyện\\ncó thể được thực hiện trên toàn bộ hoặc chỉ một vài layer cuối.\\n• CSDL mới là nhỏ và rất khác với CSDL gốc.Vì CSDL này nhỏ, tốt hơn hết là dùng các\\nclassifier đơn giản để tránh overfitting. Nếu muốn huấn luyện thêm, ta cũng chỉ nên thực\\nhiện trên các layer cuối. Hoặc sử dụng một kỹ thuật khác là coi đầu ra của một layerxa\\nlayer cuối hơn (xa hơn layer gần cuối) làm các feature vector.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 92, 'page_label': '81'}, page_content='hiện trên các layer cuối. Hoặc sử dụng một kỹ thuật khác là coi đầu ra của một layerxa\\nlayer cuối hơn (xa hơn layer gần cuối) làm các feature vector.\\n• CSDL mới là lớn và rất khác CSDL gốc.Thực tế cho thấy, sử dụng các network sẵn có\\ntrên CSDL mới vẫn hữu ích. Trong trường hợp này, ta vẫn có thể sử dụng các network\\nsẵn có như là điểm khởi tạo của network mới, không nên huấn luyện network mới từ đầu.\\nCó một điểm đáng chú ý nữa là khi tiếp tục huấn luyện các network này, ta chỉ nên chọn\\nlearning ratenhỏ để các hệ số mới không đi quá xa so với các hệ số đã được huấn luyện ở\\ncác mô hình trước.\\n6.5 Chuẩn hoá vector đặc trưng\\nCác điểm dữ liệu đôi khi được đo đạc với những đơn vị khác nhau, mét và feet chẳng hạn.\\nHoặc có hai thành phần (của vector dữ liệu) chênh lệch nhau quá lớn, một thành phần có\\nkhoảng giá trị từ 0 đến 1000, thành phần kia chỉ có khoảng giá trị từ 0 đến 1 chẳng hạn.\\nLúc này, chúng ta cần chuẩn hóa dữ liệu trước khi thực hiện các bước tiếp theo.\\n6 Transfer Learning, CS231n(https://goo.gl/VN1g7F )\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 93, 'page_label': '82'}, page_content='CHƯƠNG 6. GIỚI THIỆU VỀ FEATURE ENGINEERING 82\\nChú ý:việc chuẩn hóa này chỉ được thực hiện khi vector dữ liệu đã có cùng chiều.\\nMột vài phương pháp chuẩn hóa thường dùng:\\n6.5.1 Rescaling\\nPhương pháp đơn giản nhất là đưa tất cả các đặc trưng về cùng một khoảng, chẳng hạn\\n[0,1] hoặc [−1,1] tùy thuộc vào ứng dụng. Nếu muốn đưa đặc trưng thứi của một vector\\nđặc trưngx về khoảng[0,1], công thức sẽ là:\\nx′\\ni = xi −min(xi)\\nmax(xi) −min(xi)\\ntrong đó xi và x′\\ni lần lượt là giá trị đặc trưng ban đầu và giá trị đặc trưng sau khi được\\nchuẩn hóa. min(xi),max(xi) là giá trị nhỏ nhất và lớn nhất của đặc trưng thứi xét trên\\ntoàn bộ các điểm dữ liệu của tập huấn luyện.\\n6.5.2 Standardization\\nMột phương pháp khác cũng thường được sử dụng là giả sử mỗi đặc trưng đều có phân phối\\nchuẩn với kỳ vọng là 0 và phương sai là 1. Khi đó, công thức chuẩn hóa sẽ là\\nx′\\ni = xi −¯xi\\nσi\\nvới ¯xi,σi lần lượt là kỳ vọng và độ lệch chuẩn (standard deviation) của đặc trưng đó xét trên\\ntoàn bộ dữ liệu huấn luyện.\\n6.5.3 Scaling to unit length\\nMột lựa chọn khác cũng được sử dụng rộng rãi là chuẩn hóa các thành phần của mỗi vector\\ndữ liệu sao cho toàn bộ vector có độ dài Euclid bằng một. Việc này có thể được thực hiện\\nbằng cách chia mỗi vector đặc trưng choℓ2 norm của nó:\\nx′= x\\n∥x∥2\\n6.6 Đọc thêm\\n1. G. Csurkaet al., Visual categorization with bags of keypoints. Workshop on statistical\\nlearning in computer vision, ECCV. Vol. 1. No. 1-22. 2004 [CDF+04].\\n2. S. Lazebnik et al., Beyond bags of features: Spatial pyramid matching for recognizing\\nnatural scene categories., CVPR 2006 [LSP06]\\n3. Preprocessing data, scikit learn(https://goo.gl/gkCuUp ).\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 94, 'page_label': '83'}, page_content='Chương 7\\nLinear regression\\nTrong chương này, chúng ta cùng làm quen với một trong những thuật toán machine learning\\ncơ bản nhất–linear regression (hồi quy tuyến tính). Qua chương này, bạn đọc sẽ có cái nhìn\\nban đầu về việc xây dựng một hệ thống machine learning. Linear regression là một thuật\\ntoán supervised, ở đó quan hệ giữa đầu vào và đầu ra được mô tả bởi một hàm tuyến tính.\\nThuật toán này còn được gọi làlinear fittinghoặc linear least square.\\n7.1 Giới thiệu\\nXét bài toán ước lượng giá của một căn nhà rộngx1 m2, cóx2 phòng ngủ và cách trung tâm\\nthành phốx3 km. Giả sử ta đã thu thập được số liệu từ 1000 căn nhà trong thành phố đó,\\nliệu rằng khi có một căn nhà mới với các thông số về diện tíchx1, số phòng ngủx2 và khoảng\\ncách tới trung tâmx3, chúng ta có thể dự đoán được giáy của căn nhà đó không? Nếu có\\nthì hàm dự đoány= f(x) sẽ có dạng như thế nào. Ở đây, vector đặc trưngx = [x1,x2,x3]T\\nlà một vector cột chứa thông tin đầu vào, đầu ray là một số vô hướng.\\nMột cách trực quan, ta có thể thấy rằng: (i) diện tích nhà càng lớn thì giá nhà càng cao; (ii)\\nsố lượng phòng ngủ càng lớn thì giá nhà càng cao; (iii) càng xa trung tâm thì giá nhà càng\\ngiảm. Dựa trên quan sát này, ta có thể mô hình quan hệ giữa đầu ra và đầu vào bằng một\\nhàm tuyến tính đơn giản:\\ny≈ˆy= f(x) = w1x1 + w2x2 + w3x3 = xTw (7.1)\\ntrong đów = [w1,w2,w3]T là vector hệ số (hoặc trọng số–weight vector) ta cần đi tìm. Đây\\ncũng chính là tham số mô hình của bài toán. Mối quan hệy≈f(x) như trong (7.1) là một\\nmối quan hệ tuyến tính.\\nBài toán trên đây là bài toán dự đoán giá trị của đầu ra dựa trên vector đặc trưng đầu vào.\\nNgoài ra, giá trị của đầu ra có thể nhận rất nhiều giá trị thực dương khác nhau. Vì vậy,\\nđây là một bài toán regression. Mối quan hệˆy = xTw là một mối quan hệ tuyến tính. Tên\\ngọilinear regressionxuất phát từ đây.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 95, 'page_label': '84'}, page_content='CHƯƠNG 7. LINEAR REGRESSION 84\\nChú ý:\\n1. ylà giá trị thực của đầu ra(ground truth), trong khiˆylà giá trịđầu ra dự đoán(predicted\\noutput) của mô hình linear regression. Nhìn chung,y và ˆy là hai giá trị khác nhau do có\\nsai số mô hình, tuy nhiên, chúng ta mong muốn rằng sự khác nhau này rất nhỏ.\\n2. Linear hay tuyến tính hiểu một cách đơn giản làthẳng, phẳng. Trong không gian hai\\nchiều, một hàm số được gọi làtuyến tính nếu đồ thị của nó có dạng mộtđường thẳng.\\nTrong không gian ba chiều, một hàm số được goi làtuyến tính nếu đồ thị của nó có\\ndạng mộtmặt phẳng. Trong không gian nhiều hơn ba chiều, khái niệmmặt phẳngkhông\\ncòn phù hợp nữa, thay vào đó, một khái niệm khác ra đời được gọi làsiêu mặt phẳng\\n(hyperplane). Các hàm số tuyến tính là các hàm đơn giản nhất, vì chúng thuận tiện trong\\nviệc hình dung và tính toán.\\n7.2 Xây dựng và tối ưu hàm mất mát\\n7.2.1 Sai số dự đoán\\nSau khi đã xây dựng được mô hình dự đoán đầu ra như (7.1), ta cần tìm một phép đánh giá\\nphù hợp với bài toán. Với bài toán regression nói chung, ta mong muốn rằng sự sai kháce\\ngiữa giá trị thựcy và giá trị dự đoánˆy là nhỏ nhất. Nói cách khác, chúng ta muốn giá trị\\nsau đây càng nhỏ càng tốt:\\n1\\n2e2 = 1\\n2(y−ˆy)2 = 1\\n2(y−xTw)2 (7.2)\\nở đây ta lấy bình phương vìe = y−ˆy có thể là một số âm. Việc sai số là nhỏ nhất có thể\\nđược mô tả bằng cách lấy trị tuyệt đối|e|= |y−ˆy|, tuy nhiên, cách làm này ít được sử dụng\\nvì hàm trị tuyệt đối không khả vi tại mọi điểm, không thuật tiện cho việc tối ưu sau này.\\nHệ số 1\\n2 sẽ bị triệt tiêu sau này khi lấy đạo hàm củae theo tham số mô hìnhw.\\n7.2.2 Hàm mất mát\\nĐiều tương tự xảy ra với tất cả các cặp(input, output) (xi,yi),i = 1,2,...,N , vớiN là số\\nlượng dữ liệu quan sát được. Điều chúng ta mong muốn–trung bình sai số là nhỏ nhất–tương\\nđương với việc tìmw để hàm số sau đạt giá trị nhỏ nhất:\\nL(w) = 1\\n2N\\nN∑\\ni=1\\n(yi −xT\\ni w)2 (7.3)\\nHàm số L(w) chính là hàm mất mát của linear regression với tham số mô hìnhθ = w.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 95, 'page_label': '84'}, page_content='đương với việc tìmw để hàm số sau đạt giá trị nhỏ nhất:\\nL(w) = 1\\n2N\\nN∑\\ni=1\\n(yi −xT\\ni w)2 (7.3)\\nHàm số L(w) chính là hàm mất mát của linear regression với tham số mô hìnhθ = w.\\nChúng ta luôn mong muốn rằng sự mất mát là nhỏ nhất, điều này có thể đạt được bằng\\ncách tối thiểu hàm mất mát theow:\\nw∗= argmin\\nw\\nL(w) (7.4)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 96, 'page_label': '85'}, page_content='85 CHƯƠNG 7. LINEAR REGRESSION\\nw∗ là nghiệm cần tìm, đôi khi dấu∗ được bỏ đi và nghiệm có thể được viết gọn lại thành\\nw = argmin\\nw\\nL(w).\\nTrung bình sai số\\nViệc lấy trung bình (hệ số 1\\nN) hay lấy tổng trong hàm mất mát, về mặt toán học,\\nkhông ảnh hưởng tới nghiệm của bài toán. Trong machine learning, các hàm mất mát\\nthường có chứa hệ số tính trung bình theo từng điểm dữ liệu trong tập huấn luyện. Khi\\ntính giá trị của hàm mất mát trên tập kiểm thử, ta cũng tính trung bình lỗi của mỗi\\nđiểm. Việc lấy trung bình này quan trọng vì số lượng điểm dữ liệu trong mỗi tập dữ\\nliệu có thể thay đổi. Việc tính toán mất mát trên từng điểm dữ liệu sẽ hữu ích hơn\\ntrong việc đánh giá chất lượng mô hình sau này. Ngoài ra, việc lấy trung bình cũng\\ngiúp tránh hiện tượng tràn số khi số lượng điểm dữ liệu quá nhiều.\\nTrước khi đi xây dựng nghiệm cho bài toán tối ưu hàm mất mát, ta thấy rằng hàm số này\\ncó thể được viết gọn lại dưới dạng ma trận, vector, và norm như dưới đây:\\nL(w) = 1\\n2N\\nN∑\\ni=1\\n(yi −xT\\ni w)2 = 1\\n2N\\n\\ued79\\ued79\\ued79\\ued79\\ued79\\ued79\\ued79\\ued79\\ued79\\n\\uf8ee\\n\\uf8ef\\uf8ef\\uf8ef\\uf8f0\\ny1\\ny2\\n...\\nyN\\n\\uf8f9\\n\\uf8fa\\uf8fa\\uf8fa\\uf8fb−\\n\\uf8ee\\n\\uf8ef\\uf8ef\\uf8ef\\uf8f0\\nxT\\n1\\nxT\\n2\\n...\\nxT\\nN\\n\\uf8f9\\n\\uf8fa\\uf8fa\\uf8fa\\uf8fbw\\n\\ued79\\ued79\\ued79\\ued79\\ued79\\ued79\\ued79\\ued79\\ued79\\n2\\n2\\n= 1\\n2N∥y −XTw∥2\\n2 (7.5)\\nvới y = [y1,y2,...,y N]T, X = [x1,x2,..., xN]. Như vậyL(w) là một hàm số liên quan tới\\nbình phương củaℓ2 norm.\\n7.2.3 Nghiệm cho bài toán Linear Regression\\nNhận thấy rằng hàm mất mátL(w) có đạo hàm tại mọiw (xem Bảng 2.1). Vậy việc tìm\\ngiá trị tối ưu củaw có thể được thực hiện thông qua việc giải phương trình đạo hàm của\\nL(w) theo w bằng không. Thật may mắn, đạo hàm của hàm mất mát của linear regression\\nrất đơn giản:\\n∇L(w)\\n∇w = 1\\nNX(XTw −y) (7.6)\\nGiải phương trình đạo hàm bằng không:\\n∇L(w)\\n∇w = 0 ⇔XXTw = Xy (7.7)\\nNếu ma trậnXXT khả nghịch, phương trình (7.7) có nghiệm duy nhấtw = (XXT)−1Xy.\\nNếu ma trậnXXT không khả nghịch, phương trình (7.7) sẽ vô nghiệm hoặc có vô số nghiệm.\\nLúc này, một nghiệm đặc biệt của phương trình có thể được xác định dựa vàogiả nghịch đảo\\n(pseudo inverse). Người ta chứng minh được rằng1 với mọi ma trậnX, luôn tồn tại duy nhất'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 96, 'page_label': '85'}, page_content='Lúc này, một nghiệm đặc biệt của phương trình có thể được xác định dựa vàogiả nghịch đảo\\n(pseudo inverse). Người ta chứng minh được rằng1 với mọi ma trậnX, luôn tồn tại duy nhất\\n1 Least Squares, Pseudo-Inverse, PCA & SVD(https://goo.gl/RoQ6mS )\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 97, 'page_label': '86'}, page_content='CHƯƠNG 7. LINEAR REGRESSION 86\\nmột giá trịw có ℓ2 norm nhỏ nhất giúp tối thiểu∥XTw −y∥2\\nF. Cụ thể,w = (XXT)†Xy,\\ntrong đó(XXT)†là giả nghịch đảo củaXXT. Giả nghịch đảo của một ma trậnA luôn luôn\\ntồn tại, thậm chí cả khi ma trận đó không vuông. KhiA là vuông và khả nghịch thì giả\\nnghịch đảo chính là nghịch đảo. Nghiệm của bài toán tối ưu (7.4) là\\nw = (XXT)†Xy (7.8)\\nHàm số tính giả nghịch đảo của một ma trận bất kỳ có sẵn trong thư viện numpy.\\n7.2.4 Bias trick\\nChú ý rằng quan hệy = xTw là một quan hệ tuyến tính. Linear regression thường để nói\\ntới một quan hệ hơi phức tạp hơn một chút khi có sự xuất hiện của một số hạng tự dob:\\ny= xTw + b (7.9)\\nMối quan hệ này còn được gọi làaffine. Nếub= 0, đường thẳngy = xTw + b luôn đi qua\\ngốc toạ độ. Việc thêm hệ sốb vào sẽ khiến cho mô hình linh hoạt hơn một chút bằng cách\\nbỏ ràng buộc đường thẳng quan hệ giữa đầu ra và đầu vào luôn đi qua gốc toạ độ. Đại lượng\\nb còn được gọi làbias. Đại lượng này cũng có thểhọc đượcnhư vector hệ sốw.\\nĐể ý thấy rằng, nếu coix0 = 1, ta sẽ có:\\ny= xTw + b= w1x1 + w2x2 + ··· + wdxd + bx0 = ¯xT ¯w (7.10)\\ntrong đó ¯x = [x0,x1,x2,...,x N]T và ¯w = [b,w1,w2,...,w N]. Nếu đặt ¯X = [¯x1,¯x2,..., ¯xN]\\nta sẽ có nghiệm của bài toán tối thiểu hàm mất mát:\\n¯w = argmin\\nw\\n1\\n2N∥y −¯XT ¯w∥2\\n2 = ( ¯X ¯XT)†¯Xy (7.11)\\nKỹ thuật thêm một đặc trưng bằng 1 vào vector đặc trưng và ghép biasb vào vector hệ số\\nw như trên còn được gọi làbias trick. Chúng ta sẽ còn gặp lại kỹ thuật này nhiều lần trong\\ncuốn sách này.\\n7.3 Ví dụ trên Python\\n7.3.1 Bài toán\\nXét một ví dụ đơn giản có thể áp dụng linear regression. Chúng ta cũng sẽ so sánh nghiệm của\\nbài toán khi giải theo phương trình (7.11) và nghiệm tìm được khi dùng thư viện scikit-learn\\ncủa Python.\\nXét ví dụ về dự đoán cân nặng dựa theo chiều cao. Xét bảng cân nặng và chiều cao của 15\\nngười trong Bảng 7.1. Dữ liệu của hai người có chiều cao 155 cm và 160 cm được tách ra\\nlàm test set, phần còn lại tạo thành training set.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 97, 'page_label': '86'}, page_content='người trong Bảng 7.1. Dữ liệu của hai người có chiều cao 155 cm và 160 cm được tách ra\\nlàm test set, phần còn lại tạo thành training set.\\nBài toán đặt ra là: liệu có thể dự đoán cân nặng của một người dựa vào chiều cao của họ\\nkhông? (Trên thực tế, tất nhiên là không, vì cân nặng còn phụ thuộc vào nhiều yếu tố khác\\nnữa, thể tích chẳng hạn). Có thể thấy là cân nặng thường tỉ lệ thuận với chiều cao (càng\\ncao càng nặng), nên có thể sử dụng linear regression cho việc dự đoán này.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 98, 'page_label': '87'}, page_content='87 CHƯƠNG 7. LINEAR REGRESSION\\nBảng 7.1: Bảng dữ liệu về chiều cao và cân nặng của 15 người\\nChiều cao (cm)Cân nặng (kg)Chiều cao (cm)Cân nặng (kg)\\n147 49 168 60\\n150 50 170 72\\n153 51 173 63\\n155 52 175 64\\n158 54 178 66\\n160 56 180 67\\n163 58 183 68\\n165 59\\n7.3.2 Hiển thị dữ liệu trên đồ thị\\nTrước tiên, chúng ta khai báo training data:\\nfrom __future__ import print_function\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\n# height (cm), input data, each row is a data point\\nX = np.array([[147, 150, 153, 158, 163, 165, 168, 170, 173, 175, 178, 180, 183]]).T\\n# weight (kg)\\ny = np.array([ 49, 50, 51, 54, 58, 59, 60, 62, 63, 64, 66, 67, 68])\\nCác điểm dữ liệu được minh hoạ bởi các điểm màu đỏ trong Hình 7.1 Ta thấy rằng dữ liệu\\nđược sắp xếp gần như theo một đường thẳng, vậy mô hình linear regression sau đây có khả\\nnăng cho kết quả tốt:\\n(cân nặng) =w_1*(chiều cao) +w_0\\nở đâyw_0 chính là biasb.\\n7.3.3 Nghiệm theo công thức\\nTiếp theo, chúng ta sẽ tính toán các hệ sốw_1 và w_0 dựa vào công thức (7.11). Chú ý: giả\\nnghịch đảo của một ma trậnA trong Python sẽ được tính bằngnumpy.linalg.pinv(A).\\n# Building Xbar\\none = np.ones((X.shape[0], 1))\\nXbar = np.concatenate((one, X), axis = 1) # each point is one row\\n# Calculating weights of the fitting line\\nA = np.dot(Xbar.T, Xbar)\\nb = np.dot(Xbar.T, y)\\nw = np.dot(np.linalg.pinv(A), b)\\n# weights\\nw_0, w_1 = w[0], w[1]\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 99, 'page_label': '88'}, page_content='CHƯƠNG 7. LINEAR REGRESSION 88\\n140 150 160 170 180 190\\nHeight (cm)\\n45\\n50\\n55\\n60\\n65\\n70\\n75Weight (kg)\\nHình 7.1: Phân bố của các\\nđiểm dữ liệu (màu đỏ) và đường\\nthẳng xấp xỉ tìm được bởi linear\\nregression.\\nĐường thẳng mô tả mối quan hệ giữa đầu vào và đầu ra được cho trên Hình 7.1. Ta thấy\\nrằng các điểm dữ liệu màu đỏ nằm khá gần đường thẳng dự đoán màu xanh. Vậy mô hình\\nlinear regression hoạt động tốt với tập dữ liệu huấn luyện. Bây giờ, chúng ta sử dụng mô\\nhình này để dự đoán dữ liệu trong test set:\\ny1 = w_1*155 + w_0\\ny2 = w_1*160 + w_0\\nprint(’Input 155cm, true output 52kg, predicted output %.2fkg’ %(y1) )\\nprint(’Input 160cm, true output 56kg, predicted output %.2fkg’ %(y2) )\\nKết quả:\\nInput 155cm, true output 52kg, predicted output 52.94kg\\nInput 160cm, true output 56kg, predicted output 55.74kg\\nChúng ta thấy rằng kết quả dự đoán khá gần với số liệu thực tế.\\n7.3.4 Nghiệm theo thư viện scikit-learn\\nTiếp theo, chúng ta sẽ sử dụng thư viện scikit-learn để tìm nghiệm.\\nfrom sklearn import datasets, linear_model\\n# fit the model by Linear Regression\\nregr = linear_model.LinearRegression()\\nregr.fit(X, y) # in scikit-learn, each sample is one row\\n# Compare two results\\nprint(\"scikit-learn’s solution : w_1 = \", regr.coef_[0], \"w_0 = \", regr.intercept_)\\nprint(\"our solution : w_1 = \", w[1], \"w_0 = \", w[0])\\nKết quả dưới đây cho thấy rằng hai cách tính cho kết quả như nhau.\\nscikit-learn solution : w_1 = [ 0.55920496] w_0 = [-33.73541021]\\nour solution : w_1 = [ 0.55920496] w_0 = [-33.73541021]\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 100, 'page_label': '89'}, page_content='89 CHƯƠNG 7. LINEAR REGRESSION\\nx\\ny\\nPolynomial regression\\nTrained model\\n(a)\\n140 150 160 170 180 190\\nHeight (cm)\\n50\\n60\\n70\\n80\\n90Weight (kg)\\n (b)\\nHình 7.2: (a) Polynomial regression bậc ba. (b) Linear regression nhạy cảm với nhiễu nhỏ.\\n7.4 Thảo luận\\n7.4.1 Các bài toán có thể giải bằng linear regression\\nHàm số y ≈f(x) = xTw là một hàm tuyến tính theo cảw và x. Trên thực tế, linear\\nregression có thể áp dụng cho các mô hình chỉ cần tuyến tính theow. Ví dụ,\\ny≈w1x1 + w2x2 + w3x2\\n1 + w4 sin(x2) + w5x1x2 + w0 (7.12)\\nlà một hàm tuyến tính theo w và vì vậy cũng có thể được giải bằng linear regression.\\nVới mỗi vector đặc trưng x = [ x1,x2]T, chúng ta tính toán vector đặc trưng mới mới\\n˜x = [x1,x2,x2\\n1,sin(x2),x1x2]T rồi áp dụng linear regression với dữ liệu mới này. Tuy nhiên,\\nviệc tìm ra các hàm sốsin(x2) hay x1x2 là tương đốikhông tự nhiên. Hồi quy đa thức(poly-\\nnomial regression) thường được sử dụng nhiều hơn với các vector đặc trưng mới có dạng\\n[1,x1,x2\\n1,... ]T. Một ví dụ về hồi quy đa thức bậc 3 được thể hiện trong Hình 7.2a.\\n7.4.2 Hạn chế của linear regression\\nHạn chế đầu tiên của linear regression là nó rấtnhạy cảm với nhiễu(sensitive to noise).\\nTrong ví dụ về mối quan hệ giữa chiều cao và cân nặng bên trên, nếu có chỉ một cặp dữ liệu\\nnhiễu (150 cm, 90kg) thì kết quả sẽ sai khác đi rất nhiều (xem Hình 7.2b).\\nVì vậy, trước khi thực hiện linear regression, các nhiễu cần phải được loại bỏ. Bước này được\\ngọi làtiền xử lý(pre-processing). Hoặc hàm mất mát có thể thay đổi một chút để tránh việc\\ntối ưu các nhiễu bằng cách sử dụngHuber loss(https://goo.gl/TBUWzg ). Linear regression\\nvới Huber loss được gọi làHuber regression, được khẳng định làrobust to noise(ít bị ảnh\\nhưởng hơn bởi nhiễu). Xem thêmHuber Regressor, scikit learn(https://goo.gl/h2rKu5 ).\\nHạn chế thứ hai của linear regression là nókhông biễu diễn được các mô hình phức\\ntạp. Mặc dù trong phần trên, chúng ta thấy rằng phương pháp này có thể được áp dụng'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 100, 'page_label': '89'}, page_content='Hạn chế thứ hai của linear regression là nókhông biễu diễn được các mô hình phức\\ntạp. Mặc dù trong phần trên, chúng ta thấy rằng phương pháp này có thể được áp dụng\\nnếu quan hệ giữaoutcome và input không nhất thiết phải là tuyến tính, nhưng mối quan\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 101, 'page_label': '90'}, page_content='CHƯƠNG 7. LINEAR REGRESSION 90\\nhệ này vẫn đơn giản nhiều so với các mô hình thực tế. Hơn nữa, việc tìm ra các đặc trưng\\nx2\\n1,sin(x2),x1x2 như ở trên là ít khả thi.\\n7.4.3 Ridge regression\\nTrong trường hợpma trậnXXT không khả nghịch, có một kỹ thuật nhỏ để tránh hiện tượng\\nnày là biến đổiXXT một chút để biến nó trở thànhA = XXT + λI với λ là một số dương\\nrất nhỏ vàI là ma trận đơn vị với bậc phù hợp.\\nMa trậnA là khả nghịch vì nó là một ma trận xác định dương. Thật vậy, với mọiw ̸= 0,\\nwTAw = wT(XXT + λI)w = wTXXTw + λwTw = ∥XTw∥2\\n2 + λ∥w∥2\\n2 >0 (7.13)\\nLúc này, nghiệm của bài toán lày = (XXT + λI)−1Xy. Nếu xét hàm mất mát\\nL2(w) = 1\\n2N(∥y −XTw∥2\\n2 + λ∥w∥2\\n2) (7.14)\\nvới phương trình đạo hàm theow bằng không:\\n∇L2(w)\\n∇w = 0 ⇔ 1\\nN(X(XTw −y) + λw) = 0 ⇔(XXT + λI)w = Xy (7.15)\\nTa thấyw = (XXT+λI)−1Xy chính là nghiệm của bài toán tối thiểuL2(w) trong (7.14). Mô\\nhình machine learning với hàm mất mát (7.14) còn được gọi làridge regression. Ngoài việc\\ngiúp cho phương trình đạo hàm theo hệ số bằng không có nghiệm duy nhất, ridge regression\\ncòn giúp cho mô hình tránh được overfitting như chúng ta sẽ thấy ở Chương 8.\\n7.4.4 Phương pháp tối ưu khác\\nLinear regression là một mô hình đơn giản, lời giải cho phương trình đạo hàm bằng không\\ncũng khá đơn giản.Trong hầu hết các trường hợp, chúng ta không thể giải được phương trình\\nđạo hàm bằng không.Tuy nhiên, nếu một hàm mất mát có đạo hàm không quá phức tạp,\\nnó có thể được giải bằng một phương pháp rất hữu dụng có tên là gradient descent. Trên\\nthực tế, một vector đặc trưng có thể có kích thước rất lớn, dẫn đến ma trậnXXT cũng có\\nkích thước lớn và việc tính ma trận nghịch đảo có thể không lợi về mặt tính toán. Gradient\\ndescent sẽ giúp tránh được việc tính ma trận nghịch đảo. Chúng ta sẽ hiểu kỹ hơn về phương\\npháp này trong Chương 12.\\n7.4.5 Đọc thêm\\n1. Simple Linear Regression Tutorial for Machine Learning(https://goo.gl/WRVda8 ).\\n2. Regularization: Ridge Regression and the LASSO(https://goo.gl/uRzN1K ).'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 101, 'page_label': '90'}, page_content='pháp này trong Chương 12.\\n7.4.5 Đọc thêm\\n1. Simple Linear Regression Tutorial for Machine Learning(https://goo.gl/WRVda8 ).\\n2. Regularization: Ridge Regression and the LASSO(https://goo.gl/uRzN1K ).\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 102, 'page_label': '91'}, page_content='Chương 8\\nOverfitting\\nOverfitting là một hiện tượng không mong muốn thường gặp, người xây dựng mô hình\\nmachine learning cần nắm được các kỹ thuật để tránh hiện tượng này.\\n8.1 Giới thiệu\\nTrong các bài toán supervised learning, chúng ta thường phải đi tìm một mô hình ánh xạ\\ncác vector đặc trưng thành các kết quả tương ứng trong training set. Tức là đi tìm hàm số\\nf sao choyi ≈f(xi), ∀i= 1,2,...,N . Một cách tự nhiên, ta sẽ đi tìm các tham số mô hình\\ncủa f sao cho việc xấp xỉ có sai số càng nhỏ càng tốt. Nói cách khác, mô hình càngkhớp\\n(fit) với dữ liệu càng tốt. Tuy nhiên, sự thật là nếu một mô hìnhquá fit với dữ liệu thì nó\\nsẽ gây phản tác dụng. Hiện tượngquá fitnày trong machine learning được gọi làoverfitting.\\nĐây là một hiện tượng xấu cần tránh. Vì có thể mô hình rấtfit với training set nhưng lại\\nkhông biểu diễn tốt dữ liệu không được nhìn thấy khi huấn luyện. Một mô hình chỉ mô tả\\ntốt training set là mô hình không cótính tổng quát(generalization). Một mô hình tốt là mô\\nhình có tính tổng quát.\\nĐể có cái nhìn đầu tiên về overfitting, chúng ta cùng xem Hình 8.1. Có 50 điểm dữ liệu, ở\\nđó đầu ra bằng một đa thức bậc ba của đầu vào cộng thêm nhiễu. Tập dữ liệu này được\\nchia làm hai phần: 30 điểm dữ liệu màu đỏ là training set, 20 điểm dữ liệu màu vàng là dữ\\nliệu kiểm thử. Đồ thị của đa thức bậc ba này được cho bởi đường nét đứt màu xanh lục. Bài\\ntoán đặt ra là giả sử ta không biết mô hình ban đầu mà chỉ biết các điểm dữ liệu, hãy tìm\\nmột mô hình tốt để mô tả quan hệ giữa đầu vào và đầu ra của dữ liệu đã cho. Giả sử biết\\nthêm rằng mô hình được mô tả bởi một đa thức.\\nNhắc lại đa thức nội suy Lagrange. ChoN cặp điểm dữ liệu(x1,y1),(x2,y2),..., (xN,yN)\\nvới cácxi khác nhau đôi một, luôn tìm được một đa thứcP(.) bậc không vượt quáN −1\\nsao choP(xi) = yi, ∀i= 1,2,...,N .'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 103, 'page_label': '92'}, page_content='CHƯƠNG 8. OVERFITTING 92\\nx\\ny\\nDegree = 2: Underﬁtting\\nTraining samples\\nTest samples\\nPredicted model\\nTrue model\\n(a)\\nx\\ny\\nDegree = 4: Good ﬁt\\nTraining samples\\nTest samples\\nPredicted model\\nTrue model (b)\\nx\\ny\\nDegree = 8: Overﬁtting\\nTraining samples\\nTest samples\\nPredicted model\\nTrue model\\n(c)\\nx\\ny\\nDegree = 16: Overﬁtting\\nTraining samples\\nTest samples\\nPredicted model\\nTrue model (d)\\nHình 8.1: Underfitting và overfitting với polynomial regression.\\nNhư đã đề cập trong Chương 7, với loại dữ liệu này, chúng ta có thể áp dụng polynomial\\nregression với vector đặc trưng làx = [1,x,x 2,x3,...,x d]T cho đa thức bậcd. Điều quan\\ntrọng là cần xác định bậcd của đa thức.\\nRõ ràng là một đa thức bậc không vượt quá 29 có thểfit được hoàn toàn với 30 điểm trong\\ntập training set. Xét một vài giá trịd= 2,4,8,16. Vớid= 2, mô hình không thực sự tốt vì\\nmô hình dự đoán(predicted model) quá khác so vớimô hình thực(true model); thậm chí nó\\ncó xu hướng đi xuống khi mà dữ liệu đang có hướng đi lên. Trong trường hợp này, ta nói mô\\nhình bịunderfitting. Vớid= 8, với các điểm dữ liệu trong training set, mô hình dự đoán và\\nmô hình thực là khá giống nhau. Tuy nhiên, về phía phải, đa thức bậc 8 cho kết quả hoàn\\ntoàn ngược với xu hướng của dữ liệu. Điều tương tự xảy ra trong trường hợpd = 16. Đa\\nthức bậc 16 nàyquá fit training set. Việcquá fit trong trường hợp bậc 16 là không tốt vì\\nmô hình có thể đang cố gắng mô tảnhiễu hơn là dữ liệu. Hiện tượng xảy ra ở hai trường\\nhợp đa thức bậc cao này được gọi làoverfitting. Độ phức tạp của đồ thị trong hai trường\\nhợp này cũng khá lớn, dẫn đến các đường dự đoán không được tự nhiên.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 104, 'page_label': '93'}, page_content='93 CHƯƠNG 8. OVERFITTING\\nVới d= 4, mô hình dự đoán khá giống với mô hình thực. Hệ số bậc cao nhất tìm được rất\\ngần với 01, vì vậy đa thưc bậc bốn này khá gần với đa thức bậc ba ban đầu. Đây chính là\\nmột mô hình tốt.\\nOverfitting là hiện tượng mô hình tìm đượcquá khớp với dữ liệu huấn luyện. Việc này sẽ\\ngây ra hậu quả lớn nếu trong training set có nhiễu. Khi đó, mô hình quá chú trọng vào việc\\nxấp xỉ training set mà quên đi việc quan trọng hơn là tính tổng quát, khiến cho mô hình\\nkhông thực sự mô tả tốt dữ liệu ngoài training set. Overfitting đặc biệt xảy ra khi lượng dữ\\nliệu huấn luyện quá nhỏ hoặc độ phức tạp của mô hình quá cao. Trong ví dụ trên đây, độ\\nphức tạp của mô hình có thể được coi là bậc của đa thức cần tìm.\\nVậy, có những kỹ thuật nào giúp tránh overfitting?\\nTrước hết, chúng ta cần một vài đại lượng để đánh giá chất lượng của mô hình trên training\\nset và test set. Dưới đây là hai đại lượng đơn giản, với giả sửy là đầu ra thực sự (có thể là\\nvector), vàˆ ylà đầu ra dự đoán bởi mô hình.\\nTraining error:Đại lượng này là mức độ sai khác giữa đầu ra thực và đầu ra dự đoán của\\nmô hình, thường là giá trị của hàm mất mát áp dụng lên training data. Hàm mất mát này\\ncần có một thừa số 1\\nNtrain\\nđể tính giá trị trung bình, tức mất mát trung bình trên mỗi điểm\\ndữ liệu. Với các bài toán regression, đại lượng này thường được xác định bởimean squared\\nerror (MSE).\\ntraining error= 1\\n2Ntrain\\n∑\\ntraining set\\n∥y −ˆ y∥2\\n2\\nVới classification, trung bình cộng của cross entropy loss (với softmax regression) hoặc hinge\\nloss (với multi-class SVM) thường được sử dụng.\\nTest error:Tương tự như trên, nhưng mô hình tìm được được áp dụng vào test data. Chú\\ný rằng, khi xây dựng mô hình, ta không được sử dụng thông tin trong tập dữ liệu này. Với\\nregression, đại lượng này thường được định nghĩa bởi\\ntest error= 1\\n2Ntest\\n∑\\ntest set\\n∥y −ˆ y∥2\\n2\\nViệc lấy trung bình là quan trọng vì lượng dữ liệu trong tập huấn luyện và tập kiểm thử có\\nthể chênh lệch rất nhiều.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 104, 'page_label': '93'}, page_content='test error= 1\\n2Ntest\\n∑\\ntest set\\n∥y −ˆ y∥2\\n2\\nViệc lấy trung bình là quan trọng vì lượng dữ liệu trong tập huấn luyện và tập kiểm thử có\\nthể chênh lệch rất nhiều.\\nMột mô hình được coi là tốt (fit) nếu cảtraining errorvà test errorđều thấp. Nếutraining\\nerror thấp nhưng test error cao, ta nói mô hình bị overfitting. Nếutraining error cao và\\ntest error cao, ta nói mô hình bị underfitting. Xác suất để xảy ra việctraining error cao\\nnhưng test errorthấp là rất nhỏ. Trong chương này, chúng ta sẽ làm quen với hai kỹ thuật\\nphổ biến giúp tránh overfitting làvalidation và regularization.\\n1 Source code tạihttps://goo.gl/uD9hm1 .\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 105, 'page_label': '94'}, page_content='CHƯƠNG 8. OVERFITTING 94\\nHình 8.2: Lựa chọn mô hình dựa\\ntrên validation error.\\n8.2 Validation\\n8.2.1 Validation\\nMột mô hình là tốt nếu cả training error và test error đều nhỏ. Tuy nhiên, khi xây dựng một\\nmô hìnhchỉ dựa trên training set, làm thế nào để biết được chất lượng của nó trên test set?\\nPhương pháp đơn giản nhất làtrích từ training set ra một tập con nhỏ và thực hiện việc\\nđánh giá mô hình trên tập con nhỏ này. Tập con nhỏđược trích ra từ training setnày\\nđược gọi làvalidation set. Lúc này,training set mới là phần còn lại của training set\\nban đầu. Việc này khá giống với việc chúng ta ôn thi. Giả sử các đề thi của các năm trước\\nlà training set, đề thi năm nay là test set mà ta chưa biết. Khi ôn tập, ta thường chia đề các\\nnăm trước ra hai phần: phần thứ nhất có thể xem lời giải và tài liệu để ôn tập, phần còn lại\\nta tự làm mà không sử dụng tài liệu để tự đánh giá kiến thức của mình. Lúc này, phần thứ\\nnhất đóng vai trò là training set mới, trong khi phần thứ hai chính là validation set. Nếu\\nkết quả bài làm trên phần thứ hai là khả quan, ta có thể tự tin hơn khi vào bài thi thật.\\nLúc này, có ba đại lượng cần được quan tâm:training errortrên training set mới,validation\\nerror được định nghĩa tương tự trên validation set, vàtest errortrên test set. Với khái niệm\\nmới này, ta tìm mô hình sao cho cảtrain eror và validation error đều nhỏ, qua đó có thể\\ndự đoán được rằngtest error cũng nhỏ. Để làm được việc này, ta có thể huấn luyện nhiều\\nmô hình khác nhau dựa trên training set, sau đó áp dụng các mô hình tìm được và tính\\nvalidation error. Mô hình chovalidation errornhỏ nhất sẽ là một mô hình tốt.\\nThông thường, ta bắt đầu từ mô hình đơn giản, sau đó tăng dần độ phức tạp của mô hình.\\nKhi độ phức tạp này tăng lên, training error sẽ có xu hướng nhỏ dần, nhưng điều tương tự\\ncó thể không xảy ra ở validation error. Validation error ban đầu thường giảm dần và đến\\nmột lúc sẽ tăng lên do overfitting xảy ra trên training khi độ phức tạp của mô hình tăng'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 105, 'page_label': '94'}, page_content='có thể không xảy ra ở validation error. Validation error ban đầu thường giảm dần và đến\\nmột lúc sẽ tăng lên do overfitting xảy ra trên training khi độ phức tạp của mô hình tăng\\nlên. Để chọn ra một mô hình tốt, ta quan sát validation error. Khivalidation errorcó chiều\\nhướng tăng lên thì ta chọn mô hình trước đó.\\nHình 8.2 mô tả ví dụ phía trên với bậc của đa thức tăng từ một đến tám. Validation set là\\n10 điểm được lấy ra ngẫu nhiên từ training set 30 điểm ban đầu. Chúng ta hãy tạm chỉ xét\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 106, 'page_label': '95'}, page_content='95 CHƯƠNG 8. OVERFITTING\\nhai đường màu lam và đỏ, tương ứng với training error và validation error. Khi bậc của đa\\nthức tăng lên, training error có xu hướng giảm. Điều này dễ hiểu vì đa thức bậc càng cao,\\nviệc xấp xỉ càng chính xác. Quan sát đường màu đỏ, khi bậc của đa thức là ba hoặc bốn thì\\nvalidation error thấp, sau đó nó tăng dần lên. Dựa vào validation error, ta có thể xác định\\nđược bậc cần chọn là ba hoặc bốn. Quan sát tiếp đường màu lục, tương ứng với test error,\\nthật là trùng hợp, với bậc bằng ba hoặc bốn, test error cũng đạt giá trị nhỏ nhất, sau đó\\ntăng dần lên. Vậy cách làm này ở đây đã tỏ ra hiệu quả. Và mô hình phù hợp là mô hình\\ncó bậc bằng ba hoặc bốn. Trong ví dụ này, validation set đóng vai trò tìm ra bậc của đa\\nthức, training set đóng vai trò trong việc tìm các hệ số của đa thức với bậc đã biết. Các hệ\\nsố của đa thức chính là cácmodel parameter, trong khi bậc của đa thức có thể được coi là\\nhyperparameter. Cả training set và validation set đều đóng vai trò xây dựng mô hình. Nhắc\\nlại rằng hai tập hợp này được tách ra từ training set ban đầu.\\nViệc không sử dụng test data khi lựa chọn mô hình ở trên nhưng vẫn có được kết quả khả\\nquan vì ta đã giả sử rằng validation data và test data có chung một đặc điểm nào đó (chung\\nphân phối và đều chưa được mô hình nhìn thấy khi huấn luyện). Và khi cả hai đều là chưa\\nđược nhìn thấy,error trên hai tập này sẽ tương đối giống nhau.\\nĐể ý rằng, khi bậc nhỏ (bằng một hoặc hai), cả ba error đều cao, khi đóunderfitting xảy ra.\\n8.2.2 Cross-validation\\nTrong nhiều trường hợp, chúng ta có rất hạn chế số lượng dữ liệu để xây dựng mô hình. Nếu\\nlấy quá nhiều dữ liệu trong training set ra làm dữ liệu validation, phần dữ liệu còn lại của\\ntraining set là không đủ để xây dựng mô hình. Lúc này, validation set phải thật nhỏ để giữ\\nđược lượng dữ liệu cho training đủ lớn. Tuy nhiên, một vấn đề khác nảy sinh. Khi validation\\nset quá nhỏ, hiện tượng overfitting lại có thể xảy ra với training set còn lại. Có giải pháp'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 106, 'page_label': '95'}, page_content='được lượng dữ liệu cho training đủ lớn. Tuy nhiên, một vấn đề khác nảy sinh. Khi validation\\nset quá nhỏ, hiện tượng overfitting lại có thể xảy ra với training set còn lại. Có giải pháp\\nnào cho tình huống này không?\\nCâu trả lời làcross-validation.\\nCross-validation là một cải tiến của validation với lượng dữ liệu trong validation set là nhỏ\\nnhưng chất lượng mô hình được đánh giá trên nhiều tập validation khác nhau. Một cách\\nthường được sử dụng là chia training set rak tập con không giao nhau, có kích thước gần\\nbằng nhau. Tại mỗi lần, được gọi là mộtrun, một trong số k tập con được lấy ra làm\\nvalidation set. Nhiều mô hình khác nhau sẽ được xây dựng dựa vào hợp củak−1 tập con\\ncòn lại. Mô hình cuối được xác định dựa trên trung bình của các training error và validation\\nerror. Cách làm này còn có tên gọi làk-fold cross-validation.\\nKhi k bằng với số lượng phần tử trong training set ban đầu, tức mỗi tập con có đúng một\\nphần tử, ta gọi kỹ thuật này làleave-one-out.\\nThư viện scikit-learn hỗ trợ rất nhiều phương thức cho phân chia dữ liệu và tính toán\\nerror của các mô hình. Bạn đọc có thể xem thêmCross-validation: evaluating estimator\\nperformance (https://goo.gl/Ars2cr ).\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 107, 'page_label': '96'}, page_content='CHƯƠNG 8. OVERFITTING 96\\nHình 8.3: Early stopping. Đường\\nmàu xanh là training error, màu đỏ\\nlà validation error. Trụcx thể hiện\\nsố lượng vòng lặp, trụcy là giá trị\\nerror. Thuật toán huấn luyện dừng\\nlại tại vòng lặp mà validation error\\nđạt giá trị nhỏ nhất (Nguồn: Over-\\nfitting – Wikipedia).\\n8.3 Regularization\\nMột nhược điểm lớn củacross-validation là số lượng mô hình cần huấn luyện tỉ lệ thuận với\\nk. Điều đáng nói là mô hình polynomial regression như trên chỉ có một tham số liên quan\\nđến độ phức tạp của mô hình cần xác định là bậc của đa thức. Trong các nhiều bài toán,\\nlượng tham số cần xác định thường lớn hơn nhiều, và khoảng giá trị của mỗi tham số cũng\\nrộng hơn nhiều, chưa kể đến việc có những tham số có thể là số thực. Điều này dẫn đến việc\\nhuấn luyện nhiều mô hình là khó khả thi. Có một kỹ thuật giúp số mô hình cần huấn luyện\\ngiảm đi nhiều, thậm chí chỉ một mô hình. Kỹ thuật này có tên gọi làregularization.\\nRegularization, một cách dễ hiểu, là thay đổi mô hình một chút, chấp nhận hy sinh độ chính\\nxác trong training set, nhưng giảm độ phức tạp của mô hình, giúp tránh overfitting trong\\nkhi vẫn giữ được tính tổng quát của nó. Dưới đây là một vài kỹ thuật regularization.\\n8.3.1 Early stopping\\nRất nhiều các mô hình machine learning được xây dựng bằng cách sử dụng các thuật toán\\nlặp cho tới khi hàm mất mát hội tụ để tìm ra nghiệm. Nhìn chung, giá trị hàm mất mát\\ngiảm dần khi số vòng lặp tăng lên. Một giải pháp giúp giảm overfitting là dừng thuật toán\\ntrước khi nó hội tụ. Giải pháp này có tên làearly stopping.\\nVậy dừng khi nào là phù hợp? Một kỹ thuật thường được sử dụng là tách từ training set ra\\nmột validation set như trên. Trong khi huấn luyện, ta tính toán cả training error và validation\\nerror, nếu training error vẫn có xu hướng giảm nhưng validation error có xu hướng tăng lên\\nthì ta dừng thuật toán.\\nHình 8.3 mô tả cách tìm điểmstopping. Chúng ta thấy rằng phương pháp này khá giống với'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 107, 'page_label': '96'}, page_content='thì ta dừng thuật toán.\\nHình 8.3 mô tả cách tìm điểmstopping. Chúng ta thấy rằng phương pháp này khá giống với\\nphương pháp tìm bậc của đa thức ở phần trên của bài viết, với độ phức tạp của mô hình có\\nthể được coi là số vòng lặp cần chạy. Số vòng lặp càng cao thì hàm mất mát càng nhỏ, tức\\nmô hình có khả năngquá fit với training set.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 108, 'page_label': '97'}, page_content='97 CHƯƠNG 8. OVERFITTING\\n8.3.2 Thêm số hạng vào hàm mất mát\\nKỹ thuật regularization phổ biến hơn là thêm vào hàm mất mát một số hạng nữa. Số hạng\\nnày thường dùng để đánh giá độ phức tạp của mô hình với giá trị lớn thể hiện mô hình\\nphức tạp.Hàm mất mát mớinày được gọi làregularized loss function, thường được định\\nnghĩa như sau:\\nLreg(θ) = L(θ) + λR(θ)\\nNhắc lại rằngθ được dùng để ký hiệu các tham số trong mô hình.L(θ) là hàm mất mát\\nphụ thuộc vào training set vàθ, R(θ) là số hạngregularization chỉ phụ thuộc vàoθ. Số vô\\nhướng λthường là một số dương nhỏ, còn được gọi làtham số regularization(regularization\\nparameter). Tham số regularization thường được chọn là các giá trị nhỏ để đảm bảo nghiệm\\ncủa bài toán tối ưuLreg(θ) không quá xa nghiệm của bài toán tối ưuL(θ).\\nHai hàm regularization phổ biến làℓ1 norm vàℓ2 norm regularization (viết gọn làℓ1 regu-\\nlarization vàℓ2 regularization). Ví dụ, khi chọnR(w) = ∥w∥2\\n2 cho hàm mất mát của linear\\nregression, chúng ta sẽ đạt được ridge regression. Hàm regularization này khiến các hệ số\\ntrong w không quá lớn, giúp tránh việc đầu ra phụ thuộc quá nhiều vào một đặc trưng\\nnào đó. Trong khi đó, khi chọnR(w) = ∥w∥1, nghiệm w tìm được có xu hướng rất nhiều\\nphần tử bằng không (sparse solution2). Khi thêmℓ1 regularization vào hàm mất mát của\\nlinear regression, chúng ta sẽ thu được LASSO regression. Các thành phần khác không của\\nw tương đương với các đặc trưng quan trọng đóng góp vào việc dự đoán đầu ra. Các đặc\\ntrưng ứng với thành phần bằng không củaw được coi là ít quan trọng. Chính vì vậy, LASSO\\nregression cũng được coi là một phương pháp giúp lựa chọn những đặc trưng hữu ích cho\\nmô hình; nó cũng là một trong các phương phápfeature selection.\\nℓ1 regularization được cho là giúp cho mô hìnhrobust (ít bị ảnh hưởng bởi nhiễu) hơn so với\\nℓ2 regularization. Tuy nhiên, hạn chế củaℓ1 regularization là đạo hàm củaℓ1 norm không\\nxác định tại không (đạo hàm của hàm trị tuyệt đối), dẫn đến việc tìm nghiệm thường tốn'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 108, 'page_label': '97'}, page_content='ℓ2 regularization. Tuy nhiên, hạn chế củaℓ1 regularization là đạo hàm củaℓ1 norm không\\nxác định tại không (đạo hàm của hàm trị tuyệt đối), dẫn đến việc tìm nghiệm thường tốn\\nthời gian hơn. Trong khi đó, đạo hàm củaℓ2 norm xác định mọi nơi, và trong nhiều trường\\nhợp, ta có thể tìm được công thức nghiệm cho phương trình đạo hàm của (regularized) loss\\nfunction bằng không. Các nghiệm có công thức xác định được gọi làclosed-form solution.\\nTrong neural network, việc sử dụngℓ2 regularization còn được gọi làweight decay[KH92].\\nNgoài ra, gần đây một phương pháp regularization rất hiệu quả cho neural network được sử\\ndụng làdropout [SHK+14].\\n8.4 Đọc thêm\\n1. A. Kroghet al., A simple weight decay can improve generalization.NIPS 1991 [KH92].\\n2. N. Srivastavaet al., Dropout: A Simple Way to Prevent Neural Networks from Overfitting,\\nJournal of Machine Learning Research 15.1 (2014): 1929-1958 [SHK+14].\\n3. Understanding the Bias-Variance Tradeoff(https://goo.gl/yvQv3w ).\\n2 L1 Norm Regularization and Sparsity Explained for Dummies(https://goo.gl/VqPTLh ).\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 110, 'page_label': '99'}, page_content='Phần III\\nKhởi động\\nTrong phần này, chúng ta sẽ làm quen với ba thuật toán machine learning chưa cần nhiều\\ntới tối ưu: k-means clustering cho phân nhóm dữ liệu, k-nearest neighbors cho classification\\nvà regression, naive Bayes classifier cho phân loại văn bản.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 111, 'page_label': '100'}, page_content='Chương 9\\nK-nearest neighbors\\nNếu như con người có kiểu học “nước đến chân mới nhảy” thì machine learning cũng có một\\nthuật toán như vậy.\\n9.1 Giới thiệu\\n9.1.1 K-nearest neighbor\\nK-nearest neighbor (KNN) là một trong những thuật toán supervised learning đơn giản. Khi\\nhuấn luyện, thuật toán nàykhông học một điều gì từ dữ liệu huấn luyện mànhớ lại một\\ncách máy móc toàn bộ dữ liệu đó. Đây cũng là lý do thuật toán này được xếp vào loạilazy\\nlearning, mọi tính toán được thực hiện khi nó cần dự đoán đầu ra của dữ liệu mới. KNN có\\nthể áp dụng được vào cả classification và regression. KNN còn được gọi là một thuật toán\\ninstance-based [AKA91] hay memory-based learning.\\nVới KNN, trong bài toán classification, nhãn của một điểm dữ liệu mới được suy ra trực tiếp\\ntừ K điểm dữ liệu gần nhất trong tập huấn luyện. Nhãn đó có thể được quyết định bằng\\nbầu chọn theo đa số(major voting) trong sốK điểm gần nhất, hoặc nó có thể được suy ra\\nbằng cách đánh trọng số khác nhau cho mỗi trong các điểm gần nhất đó rồi suy ra kết quả.\\nChi tiết sẽ được nêu trong phần tiếp theo. Trong bài toán regresssion, đầu ra của một điểm\\ndữ liệu sẽ bằng chính đầu ra của điểm dữ liệu đã biết gần nhất (trong trường hợpK = 1),\\nhoặc là trung bình có trọng số của đầu ra của những điểm gần nhất, hoặc bằng một mối\\nquan hệ dựa trên các điểm gần nhất đó và khoảng cách tới chúng.\\nMột cách ngắn gọn, KNN là thuật toán đi tìm đầu ra của một điểm dữ liệu mới bằng cách\\nchỉ dựa trên thông tin củaK điểm dữ liệu gần nhất trong tập huấn luyện.\\nHình 9.1 mô tả một bài toán phân lớp với ba class: đỏ, lam, lục. Các hình tròn nhỏ với màu\\nkhác nhau thể hiện dữ liệu huấn luyện của các class khác nhau. Các vùng màu nền khác\\nnhau thể hiệnlãnh thổ của mỗi class. Tại một điểm bất kỳ, class của nó được xác định dựa\\ntrên class của điểm gần nó nhất trong trong tập huấn luyện. Trong hình này, có một vài'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 112, 'page_label': '101'}, page_content='101 CHƯƠNG 9. K-NEAREST NEIGHBORS\\nHình 9.1: Ví dụ về 1NN. Các hình tròn\\nlà các điểm dữ liệu huấn luyện. Các hình\\nkhácmàuthểhiệncáclớpkhácnhau.Các\\nvùng nền thể hiện các điểm được phân\\nloại vào lớp có màu tương ứng khi sử\\ndựng 1NN (Nguồn: K-nearest neighbors\\nalgorithm – Wikipedia).\\nvùng nhỏ xem lẫn vào các vùng lớn hơn khác màu. Ví dụ có một điểm màu lục ở gần góc 11\\ngiờ nằm giữa hai vùng lớn với nhiều dữ liệu màu đỏ và lam. Điểm này rất có thể là nhiễu.\\nViệc này nhiều khả năng sẽ dẫn đến việc phân lớp sai cho một điểm dữ liệu kiểm thử rơi\\nvào khu vực này.\\nKNN là một ví dụ rõ nhất của overfitting. Với mô hình này, mọi điểm trong tập huấn luyện\\nđều được mô hình mô tả một cách chính xác, vì vậy, nó rất nhạy cảm với nhiễu.\\nMặc dù có nhiều hạn chế, KNN vẫn là một giải pháp đầu tiên nên nghĩ tới khi giải quyết\\nmột bài toán machine learning.Khi làm các bài toán machine learning nói chung, không có\\nmô hình đúng hay sai, chỉ có mô hình cho kết quả tốt hơn. Chúng ta luôn cần một mô hình\\nđơn giản để giải quyết bài toán, sau đó dần dần tìm cách tăng chất lượng của mô hình.\\n9.2 Phân tích toán học\\nKNN là một thuật toánlazy learning, không có hàm mất mát nào và bài toán tối ưu nào\\nphải thực hiện trong quá trình huấn luyện. Mọi tính toán được thực hiện ở bước kiểm thử.\\nVì KNN ra quyết định dựa trên các điểm gần nhất nên có hai vấn đề ta cần lưu tâm. Thứ\\nnhất, khoảng cách được định nghĩa như thế nào. Thứ hai, cần phải tính toán khoảng cách\\nnhư thế nào cho hiệu quả.\\nVới vấn đề thứ nhất, mỗi điểm dữ liệu được thể hiện bằng một vector đặc trưng, khoảng\\ncách giữa hai điểm chính là khoảng cách giữa hai vector đó. Để đo khoảng cách trong không\\ngian nhiều chiều, norm (xem Mục 1.14) thường được sử dụng, và norm phổ biến nhất làℓ2\\nnorm, chính là khoảng cách Euclid quen thuộc.\\nTa cần lưu ý tới vấn đề thứ hai hơn, đặc biệt vớicác bài toán với tập huấn luyện lớn và\\nvector đặc trưng có kích thước lớn(large-scale problem). Giả sử các vector đặc trưng huấn'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 112, 'page_label': '101'}, page_content='Ta cần lưu ý tới vấn đề thứ hai hơn, đặc biệt vớicác bài toán với tập huấn luyện lớn và\\nvector đặc trưng có kích thước lớn(large-scale problem). Giả sử các vector đặc trưng huấn\\nluyện là các cột của ma trậnX ∈Rd×N với dvà N lớn, KNN sẽ phải tính toán khoảng cách\\ntừ một điểm dữ liệu mớiz ∈Rd đến toàn bộN điểm dữ liệu đã cho và chọn raK khoảng\\ncách nhỏ nhất. Nếu không có một cách tính hiệu quả, khối lượng tính toán ở đây sẽ rất lớn.\\nĐây cũng là cái giá phải trả cho việclazy learning.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 113, 'page_label': '102'}, page_content='CHƯƠNG 9. K-NEAREST NEIGHBORS 102\\nTiếp theo, chúng ta cùng thực hiện một vài phân tích toán học để tìm ra cách tính các\\nkhoảng cách một cách hiệu quả.\\nKhoảng cách từ một điểm tới từng điểm trong một tập hợp\\nKhoảng cách Euclid từ một điểmz tới một điểmxi trong tập huấn luyện được định nghĩa\\nbởi ∥z−xi∥2. Vì trong cách tính này có một bước phải tính căn bậc hai nên người ta thường\\ntính ∥z −xi∥2\\n2. Nếu việc tính khoảng cách chỉ để phục vụ việc sắp xếp thì ta không cần tính\\ncăn bậc hai sau bước này nữa. Để ý rằng\\n∥z −xi∥2\\n2 = (z −xi)T(z −xi) = ∥z∥2\\n2 + ∥xi∥2\\n2 −2xT\\ni z (9.1)\\nTừ đây, nếu nhiệm vụ chỉ là tìm raxi gần vớiz nhất, số hạng đầu tiên có thể được bỏ qua.\\nHơn nữa, nếu có nhiều điểm dữ liệu trong tập kiểm thử, các giá trị∥xi∥2\\n2 có thể được tính\\nvà lưu trước vào bộ nhớ. Khi đó, ta chỉ cần tính các tích vô hướngxT\\ni z.\\nĐể thấy rõ hơn, chúng ta cùng làm một ví dụ trên Python. Trước hết, chọnd và N là các\\ngiá trị lớn và khai báo ngẫu nhiênX và z. Lưu ý rằng vì dữ liệu trong Python thường được\\nlưu ở dạng hàng, khi lập trình ta cần thay đổi một chút.\\nfrom __future__ import print_function\\nimport numpy as np\\nfrom time import time # for comparing runing time\\nd, N = 1000, 10000 # dimension, number of training points\\nX = np.random.randn(N, d) # N d-dimensional points\\nz = np.random.randn(d)\\nTiếp theo, ta viết ba hàm số:\\n1. dist_pp(z, x) tính bình phương khoảng cách Euclid giữa hai vectorz vàx. Hàm này thực\\nhiện cách tính trực tiếp, tức tính hiệu rồi lấy bình phươngℓ2 norm của vector hiệu.\\n2. dist_ps_naive(z, X) tính bình phương khoảng cách giữaz và mỗihàng của X. Trong hàm\\nnày, các khoảng cách được tính dựa trên việc tính từng cặpdist_pp(z, X[i]).\\n3. dist_ps_fast(z, X) tính bình phương khoảng cách giữaz và mỗihàng của X, tuy nhiên,\\nkết quả được tính dựa trên đẳng thức (9.1). Khi có nhiều điểm dữ liệu được lưu trong\\nX, ta cần tính tổng bình phương các phần tử của mỗi điểm dữ liệu và tính tíchXTz.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 113, 'page_label': '102'}, page_content='kết quả được tính dựa trên đẳng thức (9.1). Khi có nhiều điểm dữ liệu được lưu trong\\nX, ta cần tính tổng bình phương các phần tử của mỗi điểm dữ liệu và tính tíchXTz.\\nĐoạn code dưới đây thể hiện cách tính khoảng cách từ một điểmz tới một tập hợp điểmX\\nbằng hai cách. Kết quả và thời gian chạy của mỗi hàm cũng được in ra để so sánh.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 114, 'page_label': '103'}, page_content='103 CHƯƠNG 9. K-NEAREST NEIGHBORS\\n# naively compute square distance between two vector\\ndef dist_pp(z, x):\\nd = z - x.reshape(z.shape) # force x and z to have the same dims\\nreturn np.sum(d*d)\\n# from one point to each point in a set, naive\\ndef dist_ps_naive(z, X):\\nN = X.shape[0]\\nres = np.zeros((1, N))\\nfor i in range(N):\\nres[0][i] = dist_pp(z, X[i])\\nreturn res\\n# from one point to each point in a set, fast\\ndef dist_ps_fast(z, X):\\nX2 = np.sum(X*X, 1) # square of l2 norm of each ROW of X\\nz2 = np.sum(z*z) # square of l2 norm of z\\nreturn X2 + z2 - 2*X.dot(z) # z2 can be ignored\\nt1 = time()\\nD1 = dist_ps_naive(z, X)\\nprint(’naive point2set, running time:’, time() - t1, ’s’)\\nt1 = time()\\nD2 = dist_ps_fast(z, X)\\nprint(’fast point2set , running time:’, time() - t1, ’s’)\\nprint(’Result difference:’, np.linalg.norm(D1 - D2))\\nKết quả:\\nnaive point2set, running time: 0.0932548046112 s\\nfast point2set , running time: 0.0514178276062 s\\nResult difference: 2.11481965531e-11\\nKết quả chỉ ra rằng hàm dist_ps_fast(z, X) chạy nhanh hơn gần gấp đôi so với hàm\\ndist_ps_naive(z, X) (số này còn lớn hơn nữa khi kích thước dữ liệu tăng lên). Quan trọng\\nhơn, sự chênh lệch của kết quả hai phép tính là một số rất nhỏ. Điều này chỉ ra rằng\\ndist_ps_fast(z, X) nên được ưu tiên hơn.\\nKhoảng cách giữa từng cặp điểm trong hai tập hợp\\nThông thường, ta không những phải tính khoảng cách từ một điểmz tới tập hợp các điểm\\nX, mà thường xuyên còn phải tính khoảng cách giữa nhiều điểmZ tới X. Nói đúng hơn, ta\\nphải tính từng cặp khoảng cách giữa mỗi điểm trong tập kiểm thử và một điểm trong tập\\nhuấn luyện. Nếu mỗi tập có 1000 phần tử, ta sẽ phải tính một triệu khoảng cách–là một số\\nrất lớn. Nếu không có một phương pháp tính hiệu quả, thời gian thực hiện sẽ là rất lớn.\\nDưới đây là đoạn code thực hiện cách tính bình phương khoảng cách giữa các cặp điểm trong\\nhai tập điểm sử dụng hai phương pháp khác nhau. Phương pháp thứ nhất sử dụng một vòng'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 114, 'page_label': '103'}, page_content='Dưới đây là đoạn code thực hiện cách tính bình phương khoảng cách giữa các cặp điểm trong\\nhai tập điểm sử dụng hai phương pháp khác nhau. Phương pháp thứ nhất sử dụng một vòng\\nfor tính khoảng cách từ từng điểm trong tập thứ nhất đến tất cả các điểm trong tập thứ\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 115, 'page_label': '104'}, page_content='CHƯƠNG 9. K-NEAREST NEIGHBORS 104\\nhai sử dụng hàmdist_ps_fast(z, X) ở trên. Phương pháp thứ hai tiếp tục sử dụng (9.1) cho\\ntrường hợp tổng quát.\\nM = 100\\nZ = np.random.randn(M, d)\\n# from each point in one set to each point in another set, half fast\\ndef dist_ss_0(Z, X):\\nM = Z.shape[0]\\nN = X.shape[0]\\nres = np.zeros((M, N))\\nfor i in range(M):\\nres[i] = dist_ps_fast(Z[i], X)\\nreturn res\\n# from each point in one set to each point in another set, fast\\ndef dist_ss_fast(Z, X):\\nX2 = np.sum(X*X, 1) # square of l2 norm of each ROW of X\\nZ2 = np.sum(Z*Z, 1) # square of l2 norm of each ROW of Z\\nreturn Z2.reshape(-1, 1) + X2.reshape(1, -1) - 2*Z.dot(X.T)\\nt1 = time()\\nD3 = dist_ss_0(Z, X)\\nprint(’half fast set2set running time:’, time() - t1, ’s’)\\nt1 = time()\\nD4 = dist_ss_fast(Z, X)\\nprint(’fast set2set running time’, time() - t1, ’s’)\\nprint(’Result difference:’, np.linalg.norm(D3 - D4))\\nKết quả:\\nhalf fast set2set running time: 4.33642292023 s\\nfast set2set running time 0.0583250522614 s\\nResult difference: 9.93586539607e-11\\nĐiều này chỉ ra rằng hai cách tính cho kết quả chênh lệch nhau không đáng kể. Trong khi\\nđó dist_ss_fast(Z, X) chạy nhanh hơndist_ss_0(Z, X) nhiều lần.\\nKhi làm việc trên python, chúng ta có thể sử dụng hàmcdist (https://goo.gl/vYMnmM )\\ntrong scipy.spatial.distance, hoặc hàmpairwise_distances (https://goo.gl/QK6Zyi ) trong\\nsklearn.metrics.pairwise. Các hàm này giúp tính khoảng cách từng cặp điểm trong hai tập\\nhợp khá hiệu quả. Phần còn lại của chương này sẽ trực tiếp sử dụng thư viện scikit-learn\\ncho KNN. Việc viết lại thuật toán này không quá phức tạp khi đã có một hàm tính khoảng\\ncách hiệu quả.\\nNếu thực hiện trên GPU, bạn đọc có thể tham khảo thêm bài báo [JDJ17] và source code\\ncủa nó tạihttps://github.com/facebookresearch/faiss .\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 116, 'page_label': '105'}, page_content='105 CHƯƠNG 9. K-NEAREST NEIGHBORS\\nHình 9.2: Ba loại hoa lan trong bộ cơ sở dữ liệu hoa Iris.\\n9.3 Ví dụ trên cơ sở dữ liệu Iris\\n9.3.1 Bộ cơ sở dữ liệu hoa Iris (Iris flower dataset).\\nIris flower dataset (https://goo.gl/eUy83R ) là một bộ dữ liệu nhỏ. Bộ dữ liệu này bao gồm\\nthông tin của ba class hoa Iris (một loài hoa lan) khác nhau: Iris setosa, Iris virginica và Iris\\nversicolor. Mỗi class có 50 bông hoa với dữ liệu là bốn thông tin: chiều dài, chiều rộng đài\\nhoa (sepal), và chiều dài, chiều rộng cánh hoa (petal). Hình 9.2 là ví dụ về hình ảnh của ba\\nloại hoa. Chú ý rằng các điểm dữ liệu không phải là các bức ảnh mà chỉ là một vector đặc\\ntrưng bốn chiếu gồm bốn thông tin ở trên.\\n9.3.2 Thí nghiệm\\nTrong phần này, chúng ta sẽ tách 150 điểm dữ liệu trong Iris flower dataset ra thành hai tập\\nhuấn luyện và kiểm thử. KNN sẽ dựa vào trông tin trong tập huấn luyện để dự đoán xem\\nmỗi dữ liệu trong tập kiểm thử tương ứng với loại hoa nào. Dữ liệu được dự đoán này sẽ\\nđược đối chiếu với dữ liệu thật để đánh giá hiệu quả của KNN.\\nTrước tiên, chúng ta cần khai báo vài thư viện. Iris flower dataset có sẵn trong thư viện\\nscikit-learn.\\nfrom __future__ import print_function\\nimport numpy as np\\nfrom sklearn import neighbors, datasets\\nfrom sklearn.model_selection import train_test_split # for splitting data\\nfrom sklearn.metrics import accuracy_score # for evaluating results\\nTiếp theo, ta sẽ load cơ sở dữ liệu này và chọn ra ngẫu nhiên 130 mẫu làm test set, 20 mẫu\\ncòn lại được dùng làm training set.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 117, 'page_label': '106'}, page_content='CHƯƠNG 9. K-NEAREST NEIGHBORS 106\\nnp.random.seed(7)\\niris = datasets.load_iris()\\niris_X = iris.data\\niris_y = iris.target\\nprint(’Labels:’, np.unique(iris_y))\\n# split train and test\\nX_train, X_test, y_train, y_test = train_test_split(iris_X, iris_y, test_size=130)\\nprint(’Train size:’, X_train.shape[0], ’, test size:’, X_test.shape[0])\\nLabels: [0 1 2]\\nTrain size: 20 , test size: 130\\nDòng np.random.seed(7) để đảm bảo rằng khi các bạn chạy lại các đoạn code này cũng nhận\\nđược kết quả tương tự. Có thể thay 7 bằng một số tự nhiên bất kỳ 32 bit.\\nKết quả với 1NN\\nTới đây, ta trực tiếp sử dụng thư viện scikit-learn cho KNN. Xét ví dụ đầu tiên vớiK = 1.\\nmodel = neighbors.KNeighborsClassifier(n_neighbors = 1, p = 2)\\nmodel.fit(X_train, y_train)\\ny_pred = model.predict(X_test)\\nprint(\"Accuracy of 1NN: %.2f %%\" %(100*accuracy_score(y_test, y_pred)))\\nKết quả:\\nAccuracy of 1NN: 92.31 %\\nKết quả thu được là 92.31% (tỉ lệ các mẫu được phân loại chính xác). Ở đây,n_neighbors = 1\\nchỉ ra rằng ta chỉ lấy một điểm gần nhất, tứcK = 1, p = 2 chính làℓ2 norm ta đã chọn để\\ntính khoảng cách. Bạn đọc có thể thử vớip = 1 tương ứng với khoảng cáchℓ1 norm.\\nKết quả với 7NN\\nNhư đã đề cập, 1NN rất dễ gây ra hiện tượng overfitting. Để giảm thiểu việc này, ta có thể\\ntăng lượng điểm lân cận lên, ví dụ bảy điểm, và xem xét trong bảy điểm gần nhất, đa số\\nchúng thuộc vào class nào.\\nmodel = neighbors.KNeighborsClassifier(n_neighbors = 7, p = 2)\\nmodel.fit(X_train, y_train)\\ny_pred = model.predict(X_test)\\nprint(\"Accuracy of 7NN with major voting: %.2f %%\" %(100*accuracy_score(y_test,\\n% y_pred)))\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 118, 'page_label': '107'}, page_content='107 CHƯƠNG 9. K-NEAREST NEIGHBORS\\nKết quả:\\nAccuracy of 7NN with major voting: 93.85 %\\nTa nhận thấy rằng độ chính xác đã tăng lên khi ta dự đoán dựa trên nhiều lân cận hơn.\\nĐánh trọng số cho các điểm lân cận\\nTrong kỹ thuật major voting bên trên, mỗi trong bảy điểm gần nhất được coi là có vai trò\\nnhư nhau và giá trịlá phiếu của mỗi điểm này là như nhau. Như thế có thể không công\\nbằng, vì những điểm gần hơn cần có trọng số cao hơn. Vì vậy, ta sẽ đánh trọng số khác\\nnhau cho mỗi trong bảy điểm gần nhất này. Cách đánh trọng số phải thoải mãn điều kiện là\\nmột điểm càng gần điểm kiểm thử phải được đánh trọng số càng cao. Cách đơn giản nhất\\nlà lấy nghịch đảo của khoảng cách này.Trong trường hợp test data trùng với một điểm dữ\\nliệu trong training data, tức khoảng cách bằng 0, ta lấy luôn đầu ra của điểm training data.\\nScikit-learn giúp chúng ta đơn giản hóa việc này bằng cách gán thuộc tínhweights = ’\\ndistance’. (Giá trị mặc định củaweights là ’uniform’, tương ứng với việc coi tất cả các điểm\\nlân cận có giá trị như nhau như ở trên).\\nmodel = neighbors.KNeighborsClassifier(n_neighbors = 7, p = 2, weights = ’distance’)\\nmodel.fit(X_train, y_train)\\ny_pred = model.predict(X_test)\\nprint(\"Accuracy of 7NN (1/distance weights): %.2f %%\"(100*accuracy_score(y_test,\\ny_pred)))\\nKết quả:\\nAccuracy of 7NN (1/distance weights): 94.62 %\\nĐộ chính xác tiếp tục được tăng lên.\\nK-nearest neighbors với trọng số tự định nghĩa\\nNgoài 2 phương pháp đánh trọng số weights = ’uniform’ và weights = ’distance’ ở trên,\\nscikit-learn còn cung cấp cho chúng ta một cách để đánh trọng số một cách tùy chọn. Ví dụ,\\nmột cách đánh trọng số phổ biến khác thường được dùng là\\nwi = exp\\n(−∥z −xi∥2\\n2\\nσ2\\n)\\ntrong đó wi là trọng số của điểm gần thứi (xi) của điểm dữ liệu đang xétz, σ là một số\\ndương. Hàm số này cũng thỏa mãn điều kiện điểm càng gầnx thì trọng số càng cao (cao\\nnhất bằng 1). Với hàm số này, chúng ta có thể lập trình như sau:\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 119, 'page_label': '108'}, page_content='CHƯƠNG 9. K-NEAREST NEIGHBORS 108\\ndef myweight(distances):\\nsigma2 = .4 # we can change this number\\nreturn np.exp(-distances**2/sigma2)\\nmodel = neighbors.KNeighborsClassifier(n_neighbors = 7, p = 2, weights = myweight)\\nmodel.fit(X_train, y_train)\\ny_pred = model.predict(X_test)\\nprint(\"Accuracy of 7NN (customized weights): %.2f %%\"\\n(100*accuracy_score(y_test, y_pred)))\\nKết quả:\\nAccuracy of 7NN (customized weights): 95.38 %\\nKết quả tiếp tục tăng lên một chút. Với từng bài toán, chúng ta có thể thay các thuộc tính\\ncủa KNN bằng các giá trị khác nhau và chọn ra giá trị tốt nhất thông qua cross-validation.\\n9.4 Thảo luận\\n9.4.1 KNN cho Regression\\nVới bài toán regression, chúng ta cũng hoàn toàn có thể sử dụng phương pháp tương tự: đầu\\nra của một điểm được xác định dựa trên đầu ra của các điểm lân cận và khoảng cách tới\\nchúng. Giả sửx1,..., xK là K điểm lân cận của một điểm dữ liệuz với đầu ra tương ứng\\nlà y1,...,y K. Giả sử các trọng số ứng với các lân cận này tính được làw1,...,w K. Kết quả\\ndự đoán đầu ra củaz có thể được xác định bởi\\nw1y1 + w2y2 + ··· + wKwK\\nw1 + w2 + ··· + wK\\n(9.2)\\nHình 9.3 là một ví dụ về KNN cho regression vớiK = 5, sử dụng hai cách đánh trọng số\\nkhác nhau. Ta có thể thấy rằngweights = ’distance’ có xu hướng gây ra overfitting.\\n9.4.2 Ưu điểm của KNN\\n1. Độ phức tạp tính toán của quá trình huấn luyện là bằng 0.\\n2. Việc dự đoán kết quả của dữ liệu mới rất đơn giản (sau khi đã xác định được các điểm\\nlân cận).\\n3. Không cần giả sử về phân phối của các class.\\n9.4.3 Nhược điểm của KNN\\n1. KNN rất nhạy cảm với nhiễu khi K nhỏ.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 120, 'page_label': '109'}, page_content='109 CHƯƠNG 9. K-NEAREST NEIGHBORS\\nHình 9.3: KNN cho bài toán Regression (Nguồn: Nearest neighbors regression–scikit-learn–\\nhttps://goo.gl/9VyBF3 ).\\n2. Như đã nói, KNN là một thuật toán mà mọi tính toán đều nằm ở khâu kiểm thử. Trong\\nđó việc tính khoảng cách tớitừng điểm dữ liệu trong tập huấn luyện tốn rất nhiều thời\\ngian, đặc biệt là với các cơ sở dữ liệu có số chiều lớn và có nhiều điểm dữ liệu. Với K\\ncàng lớn thì độ phức tạp cũng sẽ tăng lên. Ngoài ra, việc lưu toàn bộ dữ liệu trong bộ\\nnhớ cũng ảnh hưởng tới hiệu năng của KNN.\\n9.4.4 Đọc thêm\\n1. Tutorial To Implement k-Nearest Neighbors in Python From Scratch(https://goo.gl/\\nJ78Qso).\\n2. Source code cho chương này có thể được tìm thấy tạihttps://goo.gl/asF58Q .\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 121, 'page_label': '110'}, page_content='Chương 10\\nK-means clustering\\n10.1 Giới thiệu\\nChúng ta đã làm quen với linear regression, một mô hình đơn giản trong supervised learning.\\nTrong chương này, một mô hình đơn giản khác trong unsupervised learning sẽ được trình\\nbày. Thuật toán này có tên làphân nhómK-means (K-means clustering).\\nTrong K-means clustering, chúng ta không biết nhãn của từng điểm dữ liệu. Mục đích là\\nlàm thể nào để phân dữ liệu thành các cụm (cluster) khác nhau sao cho dữ liệu trong cùng\\nmột cụm có những tính chất giống nhau.\\nVí dụ:Một công ty muốn tạo ra một chính sách ưu đãi cho những nhóm khách hàng khác\\nnhau dựa trên sự tương tác giữa mỗi khách hàng với công ty đó (số năm là khách hàng; số\\ntiền khách hàng đã chi trả cho công ty; độ tuổi; giới tính; thành phố; nghề nghiệp; v.v.).\\nGiả sử công ty đó có rất nhiều dữ liệu của rất nhiều khách hàng nhưng chưa làm công việc\\nphâm nhóm khách hàng.K-means clustering là một thuật toán có thể giúp thực hiện công\\nviệc này. Sau khi đã phân ra được từng nhóm, nhân viên công ty đó có thể lựa chọn ra một\\nvài khách hàng trong mỗi nhóm để quyết định xem mỗi nhóm tương ứng với nhóm khách\\nhàng nào. Phần việc cuối cùng này cần sự can thiệp của con người, nhưng lượng công việc\\nđã được rút gọn đi rất nhiều.\\nMột định nghĩa đơn giản của nhóm/cụm (cluster) là tập hợp các điểm có các vector đặc\\ntrưng gần nhau. Việc đo khoảng cách giữa các vector thường được thực hiện dựa trên norm,\\ntrong đó khoảng cách Euclid, tứcℓ2 norm, được sử dụng phổ biến hơn cả.\\nHình 10.1 là một ví dụ về dữ liệu được phân vào ba cluster1. Giả sử mỗi cluster có một điểm\\nđại diện (centroid) màu vàng, và nhóm của mỗi điểm được xác định qua việc nó gần với\\ncentroid nào nhất trong ba centroid. Tới đây, chúng ta có một bài toán thú vị:Trên một vùng\\n1 Để cho thống nhất, từcluster sẽ được sử dụng thay thế cho nhóm/cụm. Các thuật ngữ tiếng Anh từ đây cũng\\nđược sử dụng thường xuyên hơn.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 122, 'page_label': '111'}, page_content='111 CHƯƠNG 10. K-MEANS CLUSTERING\\n2\\n 0 2 4 6 8 10\\n2\\n0\\n2\\n4\\n6\\n8\\n10\\nHình 10.1: Ví dụ với ba cụm dữ\\nliệu trong không gian hai chiều.\\nbiển hình vuông lớn có ba đảo hình vuông, tam giác, và tròn màu vàng như tròn Hình 10.1.\\nMột điểm trên biển được gọi là thuộc lãnh hải của một đảo nếu nó nằm gần đảo này hơn so\\nvới hai đảo kia. Hãy xác định ranh giới lãnh hải giữa các đảo.\\nCũng trên Hình 10.1, các vùng với màu nền khác nhau biểu diễn lãnh hải của mỗi đảo.\\nChúng ta thấy rằng đường phân định giữa các lãnh hải là các đường thẳng. Chính xác hơn,\\nchúng là các đường trung trực của các cặp đảo gần nhau. Vì vậy, lãnh hải của một đảo sẽ là\\nmột hình đa giác. Cách phân chia dựa trên khoảng cách tới điểm gần nhất này trong toán\\nhọc được gọi là Voronoi diagram2. Trong không gian ba chiều, lấy ví dụ là các hành tinh,\\nlãnh không của mỗi hành tinh sẽ là một đa diện. Trong không gian nhiều chiều hơn, chúng\\nta sẽ có nhữngsiêu đa diện(hyperpolygon).\\nQuay lại với bài toán phân nhóm và cụ thể là thuật toánK-means clustering, chúng ta cùng\\nthảo luận cơ sở toán học, cách xây dựng và tối ưu hàm mất mát của nó.\\n10.2 Phân tích toán học\\nMục đích cuối cùng của thuật toánK-means clustering là từ dữ liệu đầu vào và số lượng\\nnhóm cần tìm, hãy xác định centroid của mỗi nhóm và phân các điểm dữ liệu vào các nhóm\\ntương ứng. Giả sử thêm rằng mỗi điểm dữ liệu chỉ thuộc vào đúng một nhóm.\\nGiả sửN điểm dữ liệu trong training set được ghép lại thànhX = [x1,x2,..., xN] ∈Rd×N\\nvàK <N là số cluster được xác định trước. Ta cần tìm các centroidm1,m2,..., mK ∈Rd×1\\nvà label của mỗi điểm dữ liệu. Ở đây, mỗi cluster được đại diển bởi một label, thường là một\\nsố tự nhiên từ 1 đếnK. Nhắc lại rằng các điểm dữ liệu trong bài toánK-means clustering\\nban đầu không có label cụ thể, nhiệm vụ của ta là đi tìm label của chúng sao cho các điểm\\ncó cùng label nằm gần nhau, tạo thành một cluster.\\n2 Vonoroi diagram–Wikipedia(https://goo.gl/xReCW8 ).\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 123, 'page_label': '112'}, page_content='CHƯƠNG 10. K-MEANS CLUSTERING 112\\nVới mỗi điểm dữ liệuxi, ta cần tìm labelyi = kcủa nó, ở đâyk∈{1,2,...,K }. Một kỹ thuật\\nkhác khác thường được dùng để biểu diễn label này có tên làone-hot coding. Mỗi labelkđược\\nthay thế bằng mộtvector hàngyi ∈R1×K–được gọi làlabel vector, trong đó tất cả các phần\\ntử củayi bằng 0, ngoại trừ phần tử ở vị trí thứk bằng 1. Cụ thể,yij = 0, ∀j ̸= k,yik = 1.\\nKhi chồng các vectoryi lên nhau, ta được một ma trận labelY ∈RN×K. Nhắc lại rằngyij là\\nphần tử hàng thứi, cột thứj của ma trậnY, và nó cũng chính là phần tử thứj của vector\\nyi. Ví dụ, nếu một điểm dữ liệu có label vector là[1,0,0,..., 0] thì nó thuộc vào cluster thứ\\nnhất, là [0,1,0,..., 0] thì nó thuộc vào cluster thứ hai, v.v. Ràng buộc củayi có thể viết\\ndưới dạng toán học như sau:\\nyij ∈{0,1}, ∀i,j;\\nK∑\\nj=1\\nyij = 1, ∀i (10.1)\\n10.2.1 Hàm mất mát và bài toán tối ưu\\nNếu gọi mk ∈Rd là centroid của mỗi cluster và thay thế tất cả các điểm được phân vào\\ncluster này bởimk, một điểm dữ liệuxi được phân vào clusterk sẽ bị sai số là(xi −mk).\\nChúng ta mong muốn vector sai số này gần với vector không, tứcxi gần vớimk. Một đại\\nlượng đơn giản giúp đo khoảng cách giữa hai điểm là (bình phương) khoảng cách Euclid\\n∥xi −mk∥2\\n2. Hơn nữa, vìxi được phân vào clusterk nên yik = 1,yij = 0, ∀j ̸= k. Khi đó,\\nbiểu thức khoảng cách Euclid có thể được viết lại thành\\n∥xi −mk∥2\\n2 = yik∥xi −mk∥2\\n2 =\\nK∑\\nj=1\\nyij∥xi −mj∥2\\n2 (10.2)\\nNhư vậy, sai số trung bình cho toàn bộ dữ liệu sẽ là:\\nL(Y,M) = 1\\nN\\nN∑\\ni=1\\nK∑\\nj=1\\nyij∥xi −mj∥2\\n2 (10.3)\\nTrong đó M = [ m1,m2,..., mK] ∈Rd×K là ma trận tạo bởiK centroid. Hàm mất mát\\ntrong bài toánK-means clustering làL(Y,M) với ràng buộc như được nêu trong (10.1).\\nTóm lại, bài toán cần tối ưu là\\nY,M = argmin\\nY,M\\n1\\nN\\nN∑\\ni=1\\nK∑\\nj=1\\nyij∥xi −mj∥2\\n2\\nthoả mãn:yij ∈{0,1}, ∀i,j;\\nK∑\\nj=1\\nyij = 1, ∀i\\n(10.4)\\n10.2.2 Thuật toán tối ưu hàm mất mát\\nBài toán (10.4) là một bài toán khó tìmđiểm tối ưuvì nó có thêm các điều kiện ràng buộc.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 123, 'page_label': '112'}, page_content='j=1\\nyij∥xi −mj∥2\\n2\\nthoả mãn:yij ∈{0,1}, ∀i,j;\\nK∑\\nj=1\\nyij = 1, ∀i\\n(10.4)\\n10.2.2 Thuật toán tối ưu hàm mất mát\\nBài toán (10.4) là một bài toán khó tìmđiểm tối ưuvì nó có thêm các điều kiện ràng buộc.\\nBài toán này thuộc loại mix-integer programming (điều kiện biến là số nguyên) - là loại rất\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 124, 'page_label': '113'}, page_content='113 CHƯƠNG 10. K-MEANS CLUSTERING\\nkhó tìm nghiệm tối ưu toàn cục.Tuy nhiên, trong một số trường hợp chúng ta vẫn có thể\\ntìm được phương pháp để tìm được nghiệm gần đúng. Một kỹ thuật đơn giản và phổ biến\\nđể giải bài toán (10.4) là xen kẽ giảiY và M khi biến còn lại được cố định tới khi hàm mất\\nmát hội tụ. Chúng ta sẽ lần lượt giải quyết hai bài toán sau.\\nCố địnhM, tìmY\\nGiả sử đã tìm được các centroid, hãy tìm các label vector để hàm mất mát đạt\\ngiá trị nhỏ nhất.Điều này tương đương với việc tìm cluster cho mỗi điểm dữ liệu. Khi\\ncác centroid là cố định, bài toán tìm label vector cho toàn bộ dữ liệu có thể được chia nhỏ\\nthành bài toán tìm label vector cho từng điểm dữ liệuxi như sau:\\nyi = argmin\\nyi\\n1\\nN\\nK∑\\nj=1\\nyij∥xi −mj∥2\\n2\\nthoả mãn:yij ∈{0,1}, ∀i,j;\\nK∑\\nj=1\\nyij = 1, ∀i\\n(10.5)\\nVì chỉ có một phần tử của label vectoryi bằng 1 nên bài toán (10.5) chính là bài toán đi\\ntìm centroid gần điểmxi nhất: j = argminj ∥xi −mj∥2\\n2.\\nVì ∥xi −mj∥2\\n2 chính là bình phương khoảng cách Euclid từ điểmxi tới centroidmj, ta có\\nthể kết luận rằngmỗi điểmxi thuộc vào cluster có centroid gần nó nhất! Từ đó ta\\ncó thể suy ra label vector của từng điểm dữ liệu.\\nCố địnhY, tìmM\\nGiả sử đã tìm được cluster cho từng điểm, hãy tìm centroid mới cho mỗi cluster\\nđể hàm mất mát đạt giá trị nhỏ nhất.\\nMột khi label vector cho từng điểm dữ liệu đã được xác định, bài toán tìm centroid cho mỗi\\ncluster được rút gọn thành\\nmj = argmin\\nmj\\n1\\nN\\nN∑\\ni=1\\nyij∥xi −mj∥2\\n2. (10.6)\\nTới đây, ta có thể tìm nghiệm bằng phương pháp giải phương trình đạo hàm bằng không, vì\\nhàm cần tối ưu là một hàm liên tục và có đạo hàm xác định tại mọi điểmmj. Đặtl(mj) là\\nhàm bên trong dấuargmin trong 10.6, ta cần giải phương trình\\n∇mj l(mj) = 2\\nN\\nN∑\\ni=1\\nyij(mj −xi) = 0 ⇔mj\\nN∑\\ni=1\\nyij =\\nN∑\\ni=1\\nyijxi ⇔mj =\\n∑N\\ni=1 yijxi\\n∑N\\ni=1 yij\\n(10.7)\\nNếu để ý một chút, chúng ta sẽ thấy rằng mẫu số chính là phép đếmsố lượng các điểm dữ\\nliệu trong clusterj. Còn tử số chính làtổng các điểm dữ liệutrong clusterj. Nói cách khác,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 124, 'page_label': '113'}, page_content='∑N\\ni=1 yij\\n(10.7)\\nNếu để ý một chút, chúng ta sẽ thấy rằng mẫu số chính là phép đếmsố lượng các điểm dữ\\nliệu trong clusterj. Còn tử số chính làtổng các điểm dữ liệutrong clusterj. Nói cách khác,\\nmj là trung bình cộng (mean) của các điểm trong clusterj.\\nTên gọiK-means clusteringcũng xuất phát từ đây.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 125, 'page_label': '114'}, page_content='CHƯƠNG 10. K-MEANS CLUSTERING 114\\n10.2.3 Tóm tắt thuật toán\\nTới đây, ta có thể tóm tắt thuật toán K-means clustering như sau.\\nThuật toán 10.1:K-means clustering\\nĐầu vào:Ma trận dữ liệuX ∈Rd×N và số lượng cluster cần tìmK <N.\\nĐầu ra:Ma trận các centroidM ∈Rd×K và ma trận labelY ∈RN×K.\\n1. Chọn K điểm bất kỳ trong training set làm các centroid ban đầu.\\n2. Phân mỗi điểm dữ liệu vào cluster có centroid gần nó nhất.\\n3. Nếu việc phân nhóm dữ liệu vào từng cluster ở bước 2 không thay đổi so với vòng\\nlặp trước nó thì ta dừng thuật toán.\\n4. Cập nhật centroid cho từng cluster bằng cách lấy trung bình cộng của tất các các\\nđiểm dữ liệu đã được gán vào cluster đó sau bước 2.\\n5. Quay lại bước 2.\\nThuật toán này được đảm bảo sẽ hội tụ sau một số hữu hạn vòng lặp. Thật vậy, vì hàm mất\\nmát là một số dương và sau mỗi bước 2 hoặc 3, giá trị của hàm mất mát bị giảm đi. Vậy,\\ndãy số biểu diễn giá trị của hàm mất mát sau mỗi bước là một đại lượng không tăng và bị\\nchặn dưới, điều này chỉ ra rằng dãy số này phải hội tụ. Để ý thêm nữa, số lượng cách phân\\nnhóm cho toàn bộ dữ liệu là hữu hạn (khi số clusterK là cố định) nên đến một lúc nào đó,\\nhàm mất mát sẽ không thể thay đổi, và chúng ta có thể dừng thuật toán tại đây.\\nNếu tồn tại một cluster không chứa điểm nào, mẫu số trong (10.7) sẽ bằng không, và phép\\nchia sẽ không thực hiện được. Vì vậy,K điểm bất kỳ trong training set được chọn làm các\\ncentroid ban đầu ở Bước 1. để đảm bảo rằng mỗi cluster có ít nhất một điểm. Trong quá\\ntrình huấn luyện, nếu tồn tại một cluster không chứa điểm nào, có hai cách giải quyết. Cách\\nthứ nhất là bỏ đi cluster đó và giảmK đi một. Cách thứ hai là thay centroid của cluster đó\\nbằng một điểm bất kỳ trong training set, chẳng hạn, điểm xa centroid hiện tại của nó nhất.\\n10.3 Ví dụ trên Python\\n10.3.1 Giới thiệu bài toán\\nChúng ta sẽ làm một ví dụ đơn giản. Trước hết, ta tạo centroid và dữ liệu cho từng cluster\\nbằng cách lấy mẫu theo phân phối chuẩn có kỳ vọng là centroid của cluster đó và ma trận'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 125, 'page_label': '114'}, page_content='Chúng ta sẽ làm một ví dụ đơn giản. Trước hết, ta tạo centroid và dữ liệu cho từng cluster\\nbằng cách lấy mẫu theo phân phối chuẩn có kỳ vọng là centroid của cluster đó và ma trận\\nhiệp phương sai là ma trận đơn vị. Ở đây, hàmcdist trong scipy.spatial.distance được dùng\\nđể tính khoảng cách giữa các cặp điểm trong hai tập hợp một cách hiệu quả3.\\nDữ liệu được tạo bằng cách lấy ngẫu nhiên 500 điểm cho mỗi cluster theo phân phối chuẩn\\ncó kỳ vọng lần lượt là(2, 2), (8, 3) và (3, 6), ma trận hiệp phương sai giống nhau và là\\nma trận đơn vị.\\n3 việc xây dựng hàm số này không sử dụng thư viện đã được thảo luận kỹ trong Chương 9\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 126, 'page_label': '115'}, page_content='115 CHƯƠNG 10. K-MEANS CLUSTERING\\nfrom __future__ import print_function\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\nfrom scipy.spatial.distance import cdist\\nimport random\\nnp.random.seed(18)\\nmeans = [[2, 2], [8, 3], [3, 6]]\\ncov = [[1, 0], [0, 1]]\\nN = 500\\nX0 = np.random.multivariate_normal(means[0], cov, N)\\nX1 = np.random.multivariate_normal(means[1], cov, N)\\nX2 = np.random.multivariate_normal(means[2], cov, N)\\nX = np.concatenate((X0, X1, X2), axis = 0)\\nK = 3 # 3 clusters\\noriginal_label = np.asarray([0]*N + [1]*N + [2]*N).T\\n10.3.2 Các hàm số cần thiết choK-means clustering\\nTrước khi viết thuật toán chínhK-means clustering, ta cần viết một số hàm phụ trợ:\\n1. kmeans_init_centroids để khởi tạo các centroids ban đầu.\\n2. kmeans_asign_labels để tìm label mới cho các điểm khi cố định các centroid.\\n3. kmeans_update_centroids để cập nhật các centroid khi biết label của mỗi điểm dữ liệu.\\n4. has_converged để kiểm tra điều kiện dừng của thuật toán.\\ndef kmeans_init_centroids(X, k):\\n# randomly pick k rows of X as initial centroids\\nreturn X[np.random.choice(X.shape[0], k, replace=False)]\\ndef kmeans_assign_labels(X, centroids):\\n# calculate pairwise distances btw data and centroids\\nD = cdist(X, centroids)\\n# return index of the closest centroid\\nreturn np.argmin(D, axis = 1)\\ndef has_converged(centroids, new_centroids):\\n# return True if two sets of centroids are the same\\nreturn (set([tuple(a) for a in centroids]) ==\\nset([tuple(a) for a in new_centroids]))\\ndef kmeans_update_centroids(X, labels, K):\\ncentroids = np.zeros((K, X.shape[1]))\\nfor k in range(K):\\n# collect all points that are assigned to the k-th cluster\\nXk = X[labels == k, :]\\ncentroids[k,:] = np.mean(Xk, axis = 0) # then take average\\nreturn centroids\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 127, 'page_label': '116'}, page_content='CHƯƠNG 10. K-MEANS CLUSTERING 116\\nPhần chính củaK-means clustering:\\ndef kmeans(X, K):\\ncentroids = [kmeans_init_centroids(X, K)]\\nlabels = []\\nit = 0\\nwhile True:\\nlabels.append(kmeans_assign_labels(X, centroids[-1]))\\nnew_centroids = kmeans_update_centroids(X, labels[-1], K)\\nif has_converged(centroids[-1], new_centroids):\\nbreak\\ncentroids.append(new_centroids)\\nit += 1\\nreturn (centroids, labels, it)\\nÁp dụng thuật toán vừa viết vào dữ liệu ban đầu, hiển thị kết quả cuối cùng.\\n(centroids, labels, it) = kmeans(X, K)\\nprint(’Centers found by our algorithm:\\\\n’, centroids[-1])\\nkmeans_display(X, labels[-1])\\nKết quả:\\nCenters found by our algorithm:\\n[[ 1.9834967 1.96588127]\\n[ 3.02702878 5.95686115]\\n[ 8.07476866 3.01494931]]\\nHình 10.2 minh hoạ thuật toánK-means clustering trên tập dữ liệu này sau một số vòng\\nlặp. Ta nhận thấy rằng centroid và các vùnglãnh thổ của chúng thay đổi qua các vòng lặp\\nvà hội tụ sau chỉ sáu vòng lặp. Từ kết quả này chúng ta thấy rằng thuật toánK-means\\nclustering làm việc khá thành công, các centroid tìm được gần với các centroid ban đầu,\\nvà các nhóm dữ liệu được phân ra gần như hoàn hảo (một vài điểm gần ranh giới giữa hai\\ncluster xanh có thể đã lẫn vào nhau).\\n10.3.3 Kết quả tìm được bằng thư viện scikit-learn\\nĐể kiểm tra thêm, chúng ta hãy so sánh kết quả trên với kết quả thu được bằng cách sử\\ndụng thư việnscikit−learn.\\nfrom sklearn.cluster import KMeans\\nmodel = KMeans(n_clusters=3, random_state=0).fit(X)\\nprint(’Centers found by scikit-learn:’)\\nprint(model.cluster_centers_)\\npred_label = model.predict(X)\\nkmeans_display(X, pred_label)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 128, 'page_label': '117'}, page_content='117 CHƯƠNG 10. K-MEANS CLUSTERING\\n2\\n 0 2 4 6 8 10\\n2\\n0\\n2\\n4\\n6\\n8\\n10\\niteration: 1/6\\n(a)\\n2\\n 0 2 4 6 8 10\\n2\\n0\\n2\\n4\\n6\\n8\\n10\\niteration: 2/6 (b)\\n2\\n 0 2 4 6 8 10\\n2\\n0\\n2\\n4\\n6\\n8\\n10\\niteration: 3/6 (c)\\n2\\n 0 2 4 6 8 10\\n2\\n0\\n2\\n4\\n6\\n8\\n10\\niteration: 4/6\\n(d)\\n2\\n 0 2 4 6 8 10\\n2\\n0\\n2\\n4\\n6\\n8\\n10\\niteration: 5/6 (e)\\n2\\n 0 2 4 6 8 10\\n2\\n0\\n2\\n4\\n6\\n8\\n10\\niteration: 6/6 (f)\\nHình 10.2: Thuật toánK-means clustering qua các vòng lặp.\\nKết quả:\\nCentroids found by scikit-learn:\\n[[ 8.0410628 3.02094748]\\n[ 2.99357611 6.03605255]\\n[ 1.97634981 2.01123694]]\\nTa nhận thấy rằng các centroid tìm được cũng rất gần với kết quả kỳ vọng. Từ các centroid\\nnày, cluster của mỗi điểm dữ liệu cũng dễ dàng được suy ra.\\nTiếp theo, chúng ta cùng xem xét ba ứng dụng đơn giản củaK-means clustering.\\n10.4 Phân nhóm chữ số viết tay\\n10.4.1 Bộ cơ sở dữ liệu MNIST\\nMNIST [LCB10] là bộ cơ sở dữ liệu lớn nhất về chữ số viết tay và được sử dụng trong hầu\\nhết các thuật toán phân lớp hình ảnh. MNIST bao gồm hai tập con: training set có tổng\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 129, 'page_label': '118'}, page_content='CHƯƠNG 10. K-MEANS CLUSTERING 118\\nHình 10.3: 200\\nmẫu ngẫu nhiên\\ntrong bộ cơ sở dữ\\nliệu MNIST.\\nHình 10.4:Ví dụ về\\nchữ số 7 và giá trị\\ncác pixel của nó.\\ncộng 60 nghìn mẫu khác nhau về chữ số viết tay từ 0 đến 9, test set có 10 nghìn mẫu khác\\nnhau. Tất cả đều đã được gán nhãn. Hình 10.3 hiển thị 200 mẫu được trích ra từ MNIST.\\nMỗi bức ảnh là một ảnh xám (chỉ có một channel), có kích thước28 ×28 pixel (tổng cộng\\n784 pixel). Mỗi pixel mang một giá trị là một số tự nhiên từ 0 đến 255. Các pixel màu đen\\ncó giá trị bằng không, các pixel càng trắng thì có giá trị càng cao, nhưng không quá 255.\\nHình 10.4 là một ví dụ về chữ số 7 và giá trị các pixel của nó.Vì mục đích hiển thị ma trận\\npixel ở bên phải, bức ảnh kích thước28 ×28 ban đầu đã được resize về kích thước14 ×14.\\n10.4.2 Bài toán phân nhóm giả định\\nBài toán: Giả sử rằng ta không biết nhãn của các chữ số này, hãy phân các bức\\nảnh gần giống nhau về một nhóm.\\nBài toán này có thể được giải quyết bằng K-means clustering.\\nMỗi bức ảnh được coi là một điểm dữ liệu. Vector đặc trưng của một bức ảnh đơn giản là\\nvector cột cỡ784 ×1 thu được bằng cáchchồng các cột của bức ảnh ban đầu lên nhau.\\n10.4.3 Làm việc trên Python\\nĐể tải về MNIST, chúng ta có thể dùng trực tiếp một hàm số trong scikit-learn như sau.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 130, 'page_label': '119'}, page_content='119 CHƯƠNG 10. K-MEANS CLUSTERING\\nfrom __future__ import print_function\\nimport numpy as np\\nfrom sklearn.datasets import fetch_mldata\\ndata_dir = ’../../data’ # path to your data folder\\nmnist = fetch_mldata(’MNIST original’, data_home=data_dir)\\nprint(\"Shape of minst data:\", mnist.data.shape)\\nKết quả:\\nShape of minst data: (70000, 784)\\nshape của ma trận dữ liệumnist.data là (70000, 784) tức có 70000 mẫu, mỗi mẫu có kích\\nthước 784. Chú ý rằng trong scikit-learn, mỗi điểm dữ liệu thường được lưu dưới dạng một\\nvector hàng. Tiếp theo, chúng ta lấy ra ngẫu nhiên 10000 mẫu và thực hiện K-means cluster\\ntrên tập con này.\\nfrom sklearn.cluster import KMeans\\nfrom sklearn.neighbors import NearestNeighbors\\nK = 10 # number of clusters\\nN = 10000\\nX = mnist.data[np.random.choice(mnist.data.shape[0], N)]\\nkmeans = KMeans(n_clusters=K).fit(X)\\npred_label = kmeans.predict(X)\\nSau khi thực hiện đoạn code trên, các centroid được lưu trong biếnkmeans.cluster_centers_,\\nlabel của mỗi điểm dữ liệu được lưu trong biếnpred_label. Hình 10.5 hiển thị các centroid\\ntìm được và 20 mẫu ngẫu nhiên được phân vào mỗi cluster tương ứng. Mỗi hàng tương ứng\\nvới một cluster, cột đầu tiên có nền xanh bên trái là các centroid tìm được (màu đỏ hơn là\\ncác pixel có giá trị cao hơn). Chúng ta thấy rằng các centroid đều hoặc là giống với một chữ\\nsố nào đó, hoặc là kết hợp của hai/ba chữ số nào đó. Ví dụ, centroid ở hàng thứ 4 là sự kết\\nhợp của các số 4, 7, 9; ở hàng thứ 7 là kết hợp của chữ số 7, 8 và 9.\\nQuan sát thấy các bức ảnh lấy ra ngẫu nhiên từ mỗi cluster trông không thực sự giống nhau.\\nLý do có thể là những bức ảnh này ở xa các centroid mặc dù centroid đó đã là gần nhất.\\nNhư vậy K-means clustering làm việc chưa thực sự tốt trong trường hợp này. Tuy nhiên,\\nchúng ta vẫn có thể khai thác một số thông tin hữu ích sau khi thực hiện thuật toán này.\\nThay vì chọn ngẫu nhiên các bức ảnh trong mỗi cluster, ta chọn 20 bức ảnh gần centroid'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 130, 'page_label': '119'}, page_content='chúng ta vẫn có thể khai thác một số thông tin hữu ích sau khi thực hiện thuật toán này.\\nThay vì chọn ngẫu nhiên các bức ảnh trong mỗi cluster, ta chọn 20 bức ảnh gần centroid\\ncủa mỗi cluster nhất, vì càng gần centroid thì độ tin cậy càng cao. Hãy quan sát Hình 10.6.\\nTa có thể thấy dữ liệu trong mỗi hàng khá giống nhau và giống với centroid ở cột đầu tiên\\nbên trái. Có một vài quan sát thú vị có thể rút ra từ đây:\\n1. Có hai kiểu viết chữ số 1–thẳng và chéo. VàK-means clustering nghĩ rằng đó là hai chữ\\nsố khác nhau. Điều này là dễ hiểu vìK-means clustering là một thuật toán unsupervised\\nlearning. Nếu có sự can thiệp của con người, chúng có thể được nhóm lại thành một.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 131, 'page_label': '120'}, page_content='CHƯƠNG 10. K-MEANS CLUSTERING 120\\nHình 10.5: Hiển thị\\ncác centroid (cột đầu)\\nvà 20 điểmngẫu nhiên\\nđược phân vào từng\\ncluster. Các chữ số trên\\nmỗi hàng thuộc vào\\ncùng một cluster.\\nHình 10.6: Hiển thị\\ncác centroid (cột đầu)\\nvà20điểm gầncentroid\\nnhất được phân vào\\ntừng cluster. Các chữ\\nsố trên mỗi hàng thuộc\\nvào cùng một cluster.\\n2. Ở hàng thứ chín, chữ số 4 và 9 được phân vào cùng một cluster. Sự thật là hai chữ số\\nnày khá giống nhau. Điều tương tự xảy ra đối với hàng thứ bảy với các chữ số 7, 8, 9.\\nK-means clustering có thể được áp dụng để tiếp tục phân nhỏ các cluster đó.\\nTrong clustering có một kỹ thuật thường được sử dụng làclustering phân tầng(hierarchical\\nclustering [Ble08]). Có hai loại hierachical clustering:\\n• Agglomerative tức “đi từ dưới lên”. Ban đầu coi một vài điểm dữ liệu gần nhau là một\\ncluster, sau đó các cặp cluster gần giống nhau được gộp lại làm một cluster lớn hơn. Ở\\nđây, sự giống nhau của hai cluster có thể được xác định dựa trên khoảng cách giữa hai\\ncentroid tương ứng. Cụ thể hơn, ban đầu ta chọnK là một số lớn gần bằng số điểm dữ\\nliệu. Sau khi thực hiệnK-means clustering lần đầu, các cluster gần nhau được ghép lại\\nthành một cluster. Sau bước này, ta được một số lượng cluster nhỏ hơn. Ta tiếp tục làm\\nK-means clustering với điểm khởi tạo là centroid của các nhóm vừa thu được. Lặp lại\\nquá trình này đến khi nhận được kết quả chấp nhận được.\\n• Divisive tức “đi từ trên xuống”. Ban đầu coi tất cả các điểm dữ liệu thuộc cùng một\\ncluster, sau đó chia nhỏ mỗi cluster bằng một thuật toán clustering nào đó. Việc này có\\nthể được thực hiện bằng cách ban đầu chọn một sốK nhỏ làm số lượng cluster, sau đó\\ntrong mỗi cluster thu được, ta tiếp tục làmK-means clustering. Tiếp tục quá trình cho\\ntới khi được kết quả chấp nhận được.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 132, 'page_label': '121'}, page_content='121 CHƯƠNG 10. K-MEANS CLUSTERING\\nHình 10.7: Ảnh:Trọng Vũ(https:\\n//goo.gl/9D8aXW ) .\\n10.5 Tách vật thể trong ảnh\\nK-means clustering có thể được áp dụng vào một bài toán xử lý ảnh khác, bài toántách vật\\nthể trong ảnh(object segmentation). Cho bức ảnh như trong Hình 10.7, hãy xây dựng một\\nthuật toán tự động nhận ra vùng khuôn mặt và tách nó ra.\\nBức ảnh có ba màu chủ đạo: hồng ở khăn và môi; đen ở mắt, tóc, và hậu cảnh; màu da ở\\nvùng còn lại của khuôn mặt. Ảnh này khá rõ nét và các vùng được phân biệt rõ ràng bởi\\nmàu sắc nên chúng ta có thể áp dụng thuật toán K-means clustering. Thuật toán này sẽ\\nphân các pixel ảnh thành ba cluster, cluster chứa phần khuôn mặt có thể được chọn, có thể\\nbằng tay.\\nĐây là một bức ảnh màu, mỗi điểm ảnh sẽ được biểu diễn bởi ba giá trị tương ứng với màu\\nRed, Green, và Blue, mỗi giá trị này cũng là một số tự nhiên không vượt quá 255. Nếu coi\\nmỗi pixel là một điểm dữ liệu mô tả bởi một vector ba chiều chứa các giá trị này, sau đó áp\\ndụng thuật toán K-means clustering, chúng ta có thể có kết quả mong muốn.\\n10.5.1 Làm việc trên Python\\nKhai báo thư viện và load bức ảnh:\\nimport matplotlib.image as mpimg\\nimport matplotlib.pyplot as plt\\nimport numpy as np\\nfrom sklearn.cluster import KMeans\\nimg = mpimg.imread(’girl3.jpg’)\\nplt.imshow(img)\\nimgplot = plt.imshow(img)\\nplt.axis(’off’)\\nplt.show()\\nBiến đổi bức ảnh thành 1 ma trận mà mỗi hàng là 1 pixel với 3 giá trị màu\\nX = img.reshape((img.shape[0]*img.shape[1], img.shape[2]))\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 133, 'page_label': '122'}, page_content='CHƯƠNG 10. K-MEANS CLUSTERING 122\\nHình 10.8:Kết quả nhận được sau\\nkhi thực hiện K-means clustering\\ncho các điểm dữ liệu. Có ba clus-\\nter tương ứng với ba màu đỏ, hồng,\\nđen.\\nPhần còn lại của source code có thể được tìm thấy tạihttps://goo.gl/Tn6Gec .\\nSau khi tìm được các cluster, giá trị của mỗi pixel được thay bằng giá trị của centroid tương\\nứng. Kết quả được minh hoạ trên Hình 10.8. Ba màu đỏ, đen, và màu da đã được phân nhóm\\nkhá thành công. Và khuôn mặt có thể được tách ra từ phần có màu da (và vùng bên trong\\nnó). Như vậy,K-means clustering tạo ra một kết quả chấp nhận được cho bài toán này.\\n10.6 Image Compression (nén ảnh và nén dữ liệu nói chung)\\nTrước hết, xét đoạn code dưới đây.\\nfor K in [5, 10, 15, 20]:\\nkmeans = KMeans(n_clusters=K).fit(X)\\nlabel = kmeans.predict(X)\\nimg4 = np.zeros_like(X)\\n# replace each pixel by its centroid\\nfor k in range(K):\\nimg4[label == k] = kmeans.cluster_centroids_[k]\\n# reshape and display output image\\nimg5 = img4.reshape((img.shape[0], img.shape[1], img.shape[2]))\\nplt.imshow(img5, interpolation=’nearest’)\\nplt.axis(’off’)\\nplt.show()\\nGiải thích: Để ý thấy rằng mỗi một pixel có thể nhận một trong số2563 = 16,777,216 (16\\ntriệu màu). Đây là một số rất lớn (tương đương với 24 bit cho một điểm ảnh). Nếu ta muốn\\nlưu mỗi điểm ảnh với một số bit nhỏ hơn và chấp nhận mất dữ liệu ở một mức nào đó,\\nK-means clustering là một giải pháp đơn giản cho việc này. Trong bài toán segmentation\\nphía trên, có ba cluster, và mỗi một điểm ảnh sau khi xử lý sẽ được biểu diễn bởi một số\\ntương ứng với một cluster. Tuy nhiên, chất lượng bức ảnh rõ ràng đã giảm đi nhiều. Trong\\nđoạn code trên đây, ta đã làm một thí nghiệm nhỏ với số lượng cluster được tăng lên 5, 10,\\n15, 20. Sau khi tìm được centroid cho mỗi cluster, giá trị của một điểm ảnh được thay bằng\\ngiá trị của centroid tương ứng. Kết quả được cho trên Hình 10.9. Ta có thể quan sát thấy\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 134, 'page_label': '123'}, page_content='123 CHƯƠNG 10. K-MEANS CLUSTERING\\nHình 10.9: Chất lượng nén ảnh với số lượng cluster khác nhau.\\nrằng khi số lượng cluster tăng lên, chất lượng bức ảnh đã được cải thiện. Để nén bức ảnh\\nnày, ta chỉ cần lưuK centroid tìm được và label của mỗi điểm ảnh.\\n10.7 Thảo luận\\n10.7.1 Hạn chế củaK-means clustering\\n• Số lượng clusterK cần được xác định trước.Trong thực tế, nhiều trường hợp chúng\\nta không xác định được giá trị này. Bạn đọc có thể tham khảo một cách giúp xác định\\ngiá trịK này có tên là elbow method (https://goo.gl/euYhpK ).\\n• Nghiệm cuối cùng phụ thuộc vào các centroid được khởi tạo ban đầu.Trong\\nthuật toán này, hàm khởi tạokmeans_init_centroids chọn ngẫu nhiênK điểm từ tập dữ\\nliệu làm các centroid ban đầu. Thêm nữa, thuật toánK-means clustering không đảm\\nbảo tìm được nghiệm tối ưu toàn cục, nên nghiệm cuối cùng phụ thuộc rất nhiều vào\\ncác centroid được khởi tạo ban đầu. Hình 10.10 thể hiện các kết quả khác nhau khi các\\ncentroid được khởi tạo khác nhau. Ta cũng thấy rằng trường hợp (a) và (b) cho kết quả\\ntốt, trong khi kết quả thu được ở trường hợp (c) không thực sự tốt. Một điểm nữa có thể\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 135, 'page_label': '124'}, page_content='CHƯƠNG 10. K-MEANS CLUSTERING 124\\n2\\n 0 2 4 6 8 10\\n2\\n0\\n2\\n4\\n6\\n8\\n10\\niteration: 8/8\\n(a)\\n2\\n 0 2 4 6 8 10\\n2\\n0\\n2\\n4\\n6\\n8\\n10\\niteration: 14/14 (b)\\n2\\n 0 2 4 6 8 10\\n2\\n0\\n2\\n4\\n6\\n8\\n10\\niteration: 20/20 (c)\\nHình 10.10: Các giá trị khởi tạo ban đầu khác nhau dẫn đến các nghiệm khác nhau.\\nrút ra là số lượng vòng lặp tới khi thuật toán hội tụ cũng khác nhau. Trường hợp (a) và\\n(b) cùng cho kết quả tốt nhưng (b) chạy trong thời gian gần gấp đôi. Một kỹ thuật giúp\\nhạn chế nghiệm xấu như trường hợp (c) là chạy thuật toánK-means clustering nhiều lần\\nvới các centroid được khởi tạo khác nhau và chọn ra lần chạy cho giá trị hàm mất mát\\nthấp nhất4. Ngoài ra, [KA04], Kmeans++ [AV07,BMV+12] cũng là một vài thuật toán\\nnổi tiếng giúp chọn các centroid ban đầu.\\n• Các cluster cần có số lượng điểm gần bằng nhau. Hình 10.11a minh hoạ kết quả\\nkhi các cluster có số lượng điểm chênh lệch. Trong trường hợp này, nhiều điểm lẽ ra thuộc\\ncluster xanh lam đã bị phân nhầm vào cluster xanh lục.\\n• Các cluster cần có dạng hình tròn (cầu)Khi các cluster vẫn tuân theo phân phối\\nchuẩn nhưng ma trận hiệp phương sai không tỉ lệ với ma trận đơn vị, các cluster sẽ\\ncó dạng không phải là tròn (hoặc cầu trong không gian nhiều chiều). Khi đó,K-means\\nclustering cũng không hoạt động hiệu quả. Lý do chính là vìK-means clustering quyết\\nđịnh cluster của một điểm dữ liệu dựa trên khoảng cách Euclid của nó tới các centroid.\\nTrong trường hợp này, Gaussian mixture models (GMM) [Rey15] có thể cho kết quả tốt\\nhơn5. Trong GMM, mỗi cluster được giả sử tuân theo một phân phối chuẩn với ma trận\\nhiệp phương sai không nhất thiết tỉ lệ với ma trận đơn vị. Ngoài các centroid, các ma\\ntrận hiệp phương sai cũng là các biến cần tối ưu trong GMM.\\n• Khi một cluster bị bao bọc bởi một cluster khácHình 10.12 là một ví dụ kinh điển\\nvề việcK-means clustering không thể phân cụm dữ liệu. Một cách tự nhiên, chúng ta sẽ\\nphân dữ liệu ra thành bốn cluster: mắt trái, mắt phải, miệng, xung quanh mặt. Nhưng'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 135, 'page_label': '124'}, page_content='về việcK-means clustering không thể phân cụm dữ liệu. Một cách tự nhiên, chúng ta sẽ\\nphân dữ liệu ra thành bốn cluster: mắt trái, mắt phải, miệng, xung quanh mặt. Nhưng\\nvì mắt và miệng nằm trong khuôn mặt nênK-means clustering cho kết quả không chính\\nxác. Với dữ liệu như trong ví dụ này, spectral clustering [VL07,NJW02] sẽ cho kết quả tốt\\nhơn. Spectral clustering cũng coi các điểm gần nhau tạo thành một cluster, nhưng không\\ngiả sử về một centroid chung cho cả cluster. Spectral clustering được thực hiện dựa trên\\n4 KMeans–scikit-learn (https://goo.gl/5KavVn ).\\n5 Đọc thêm:Gaussian mixture models–Wikipedia(https://goo.gl/GzdauR ).\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 136, 'page_label': '125'}, page_content='125 CHƯƠNG 10. K-MEANS CLUSTERING\\n2\\n 0 2 4 6 8 10\\n2\\n0\\n2\\n4\\n6\\n8\\n10\\niteration: 17/17\\n(a)\\n2\\n 0 2 4 6 8 10\\n2\\n0\\n2\\n4\\n6\\n8\\n10\\niteration: 6/6 (b)\\nHình 10.11: K-means clustering hoạt động không thực sự tốt trong trường hợp các cluster có\\nsố lượng phần tử chênh lệch hoặc các cluster không có dạng hình tròn (cầu).\\nHình 10.12: Một ví dụ về việc\\nK-means clustering phân nhóm\\nsai.\\nmột đồ thị vô hướng với đỉnh là các điểm dữ liệu và cạnh được nối giữa các điểm gần\\nnhau, mỗi cạnh được đánh trọng số là một hàm của khoảng cách giữa hai điểm.\\n10.7.2 Các ứng dụng khác củaK-means clustering\\nMặc dù có những hạn chế,K-means clustering vẫn cực kỳ quan trọng trong machine learning\\nvà là nền tảng cho nhiều thuật toán phức tạp khác. Dưới đây là một vài ứng dụng khác của\\nK-means clustering.\\n1. Cách thay một điểm dữ liệu bằng centroid tương ứng là một trong số các kỹ thuật có\\ntên chung làVector Quantization – VQ[AM93]). Không chỉ trong nén dữ liệu, VQ còn\\nđược kết hợp với Bag-of-Words [LSP06] áp dụng rộng rãi trong các thuật toán xây dựng\\nvector đặc trưng cho các bài toán phân loại.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 137, 'page_label': '126'}, page_content='CHƯƠNG 10. K-MEANS CLUSTERING 126\\n2. Ngoài ra, VQ còn được áp dụng trong các bài toán tìm kiếm trong cơ sở dữ liệu lớn.\\nKhi lượng điểm dữ liệu rất lớn, việc tìm kiếm trở nên cực kỳ quan trọng. Khó khăn\\nchính của việc này là làm thế nào có thể tìm kiếm một cách nhanh chóng trong lượng\\ndữ liệu khổng lồ đó. Ý tưởng cơ bản là sử dụng các thuật toán clustering để phân các\\nđiểm dữ liệu thành nhiều nhóm nhỏ và xấp xỉ mỗi điểm dữ liệu bằng centroid tương\\nứng. Khi tìm điểm gần nhất của một điểmtruy vấn (query), thay vì tính khoảng cách\\ngiữa điểm truy vấn đó đến từng điểm trong cơ sở dữ liệu, ta sẽ chỉ cần tính khoảng\\ncách từ điểm đó tới các centroid (số lượng nhỏ hơn). Sau đó trả về các điểm được\\nphân vào centroid đó. Bạn đọc có thể đọc thêm các bài báo nổi tiếng gần đây về vấn\\nđề này: Product Quantization [JDS11], Cartesian k-means [NF13,JDJ17], Composite\\nQuantization [ZDW14], Additive Quantization [BL14].\\nSource code cho chương này có thể được tìm thấy tạihttps://goo.gl/QgW5f2 .\\n10.7.3 Đọc thêm\\n1. Clustering documents using k-means–scikit-learn(https://goo.gl/y4xsy2 ).\\n2. Voronoi Diagram - Wikipedia(https://goo.gl/v8WQEv ).\\n3. Cluster centroid initialization algorithm for K-means clustering(https://goo.gl/hBdody ).\\n4. Visualizing K-Means Clustering(https://goo.gl/ULbpUM ).\\n5. Visualizing K-Means Clustering - Standford(https://goo.gl/idzR2i ).\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 138, 'page_label': '127'}, page_content='Chương 11\\nNaive Bayes classifier\\n11.1 Naive Bayes classifier\\nXét các bài toán phân lớp vớiC class khác nhau. Thay vì tìm ra chính xác label của mỗi\\nđiểm dữ liệux ∈Rd, ta có thể đi tìm xác suất để đầu ra đó rơi vào mỗi class:p(y = c|x),\\nhoặc viết gọn thànhp(c|x). Biểu thức này được hiểu là xác suất để đầu ra là classc biết\\nrằng đầu vào là vectorx. Biểu thức này, nếu tính được, có thể giúp xác định class của mỗi\\nđiểm dữ liệu bằng cách chọn ra class có xác suất rơi vào cao nhất:\\nc= argmax\\nc∈{1,...,C}\\np(c|x) (11.1)\\nBiểu thức trong dấuargmax ở = (11.1) nhìn chung khó có cách tính trực tiếp. Thay vào đó,\\nquy tắc Bayes thường được sử dụng:\\nc= argmax\\nc\\np(c|x) = argmax\\nc\\np(x|c)p(c)\\np(x) = argmax\\nc\\np(x|c)p(c) (11.2)\\nDấu bằng thứ hai xảy ra theo quy tắc Bayes, dấu bằng thứ ba xảy ra vìp(x) ở mẫu số\\nkhông phụ thuộc vàoc. Tiếp tục quan sát,p(c) có thể được hiểu là xác suất để một điểmbất\\nkỳ rơi vào classc. Nếu training set lớn, nó có thể được xác định bằng maximum likelihood\\nestimation (MLE)–là tỉ lệ giữa số điểm thuộc classc và số điểm trong training set. Nếu\\ntraining set nhỏ, giá trị này có thể được ước lượng bằng maximum a posteriori (MAP). Cách\\nthứ nhất thường được sử dụng nhiều hơn.\\nThành phần còn lạip(x|c), tức phân phối của các điểm dữ liệu trong classc, thường rất khó\\ntính toán vìx là một biến ngẫu nhiên nhiều chiều. Để có thể ước lượng được phân phối đó,\\ntraining set phải rất lớn. Để giúp cho việc tính toán được đơn giản, người ta thường giả sử\\nrằng các thành phần của biến ngẫu nhiênx là độc lập với nhau khi đã biếtc:\\np(x|c) = p(x1,x2,...,x d|c) =\\nd∏\\ni=1\\np(xi|c) (11.3)'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 139, 'page_label': '128'}, page_content='CHƯƠNG 11. NAIVE BAYES CLASSIFIER 128\\nGiả thiết các chiều của dữ liệu độc lập với nhau là quá chặt và trên thực tế, ít khi tìm được\\ndữ liệu mà các thành phần hoàn toàn độc lập với nhau. Tuy nhiên, giả thiếtngây thơ(naive)\\nnày đôi khi mang lại những kết quả tốt bất ngờ. Giả thiết về sự độc lập của các chiều dữ\\nliệu này được gọi lànaive Bayes. Cách xác định label của dữ liệu dựa trên giả thiết này có\\ntên lànaive Bayes classifier (NBC).\\nNBC, nhờ vào tính đơn giản một cáchngây thơ, có tốc độ huấn luyện và kiểm thử rất nhanh.\\nViệc này giúp nó mang lại hiệu quả cao trong các bài toán large-scale.\\nỞ bước huấn luyện, các phân phốip(c) và p(xi|c),i = 1,...,d sẽ được xác định dựa vào dữ\\nliệu huấn luyện. Việc xác định các giá trị này có thể có thể dựa vào MLE hoặc MAP.\\nỞ bước kiểm thử, label của một điểm dữ liệu mớix được xác đinh bởi\\nc= argmax\\nc∈{1,...,C}\\np(c)\\nd∏\\ni=1\\np(xi|c) (11.4)\\nKhi d lớn và các xác suất nhỏ, biểu thức ở vế phải của (11.4) là một số rất nhỏ, khi tính\\ntoán có thể gặp sai số. Để giải quyết việc này, (11.4) thường được viết lại dưới dạng tương\\nđương bằng cách lấylog của vế phải:\\nc= argmax\\nc∈{1,...,C}\\n(\\nlog(p(c)) +\\nd∑\\ni=1\\nlog(p(xi|c))\\n)\\n(11.5)\\nViệc này không ảnh hưởng tới kết quả vìlog là một hàm đồng biến trên tập các số dương.\\nSự đơn giản của NBC mang lại hiệu quả đặc biệt trong các bài toán phân loại văn bản, ví\\ndụ bài toán lọc tin nhắn hoặc email rác. Trong phần sau của chương này, chúng ta cùng xây\\ndựng một bộ lọc email rác tiếng Anh đơn giản. Cả việc huấn luyện và kiểm thử của NBC\\nlà cực kỳ nhanh khi so với các phương pháp phân loại phức tạp khác. Việc giả sử các thành\\nphần trong dữ liệu là độc lập với nhau khiến cho việc tính toán mỗi phân phốip(xi|c) không\\nmất nhiều thời gian.\\nViệc tính toánp(xi|c) phụ thuộc vào loại dữ liệu. Có ba loại phân bố xác suất thường được\\nsử dụng phổ làGaussian naive Bayes, multinomial naive Bayes, vàBernoulli Naive. Chúng\\nta cùng xem xét vào từng loại.\\n11.2 Các phân phối thường dùng trong NBC\\n11.2.1 Gaussian naive Bayes'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 139, 'page_label': '128'}, page_content='sử dụng phổ làGaussian naive Bayes, multinomial naive Bayes, vàBernoulli Naive. Chúng\\nta cùng xem xét vào từng loại.\\n11.2 Các phân phối thường dùng trong NBC\\n11.2.1 Gaussian naive Bayes\\nMô hình này được sử dụng chủ yếu trong loại dữ liệu mà các thành phần là các biến liên\\ntục. Với mỗi chiều dữ liệui và một classc, xi tuân theo một phân phối chuẩn có kỳ vọng\\nµci và phương saiσ2\\nci:\\np(xi|c) = p(xi|µci,σ2\\nci) = 1√\\n2πσ2\\nci\\nexp\\n(\\n−(xi −µci)2\\n2σ2\\nci\\n)\\n(11.6)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 140, 'page_label': '129'}, page_content='129 CHƯƠNG 11. NAIVE BAYES CLASSIFIER\\nTrong đó, bộ tham sốθ = {µci,σ2\\nci}được xác định bằng MLE dựa trên các điểm trong\\ntraining set thuộc classc.\\n11.2.2 Multinomial naive Bayes\\nMô hình này chủ yếu được sử dụng trong phân loại văn bản mà vector đặc trưng được xây\\ndựng dựa trên ý tưởng bag of words (BoW). Lúc này, mỗi văn bản được biểu diễn bởi một\\nvector có độ dàidchính là số từ trong từ điển. Giá trị của thành phần thứitrong mỗi vector\\nchính là số lần từ thứixuất hiện trong văn bản đó. Khi đó,p(xi|c) tỉ lệ với tần suất từ thứ\\ni (hay đặc trưng thứi cho trường hợp tổng quát) xuất hiện trong các văn bản của classc.\\nGiá trị này có thể được tính bằng\\nλci = p(xi|c) = Nci\\nNc\\n(11.7)\\nTrong đó:\\n• Nci là tổng số lần từ thứi xuất hiện trong các văn bản của classc. Nó chính là tổng của\\ntất cả các đặc trưng thứi của các vector đặc trưng ứng với classc.\\n• Nc là tổng số từ (kể cả lặp) xuất hiện trong classc. Nói cách khác, nó bằng tổng độ dài\\ncủa toàn bộ các văn bản thuộc vào classc. Có thể suy ra rằngNc = ∑d\\ni=1 Nci, từ đó∑d\\ni=1 λci = 1. Ở đâyd là số từ trong từ điển.\\nCách tính này có một hạn chế là nếu có một từ mới chưa bao giờ xuất hiện trong classc\\nthì biểu thức (11.7) sẽ bằng không, dẫn đến vế phải của (11.4) bằng không bất kể các giá\\ntrị còn lại có lớn thế nào (xem thêm ví dụ ở mục sau). Để giải quyết việc này, một kỹ thuật\\nđược gọi làLaplace smoothingđược áp dụng:\\nˆλci = Nci + α\\nNc + dα (11.8)\\nvới α là một số dương, thường bằng 1, để tránh trường hợp tử số bằng không. Mẫu số được\\ncộng vớidαđể đảm bảo tổng xác suất∑d\\ni=1\\nˆλci = 1. Như vậy, mỗi classcsẽ được mô tả bởi\\nmột bộ các số dương có tổng bằng 1:ˆλc = {ˆλc1,..., ˆλcd}.\\n11.2.3 Bernoulli Naive Bayes\\nMô hình này được áp dụng cho các loại dữ liệu mà mỗi thành phần là một giá trị nhị phân–\\nbằng 0 hoặc 1. Ví dụ, cũng với loại văn bản nhưng thay vì đếm tổng số lần xuất hiện của\\nmột từ trong văn bản, ta chỉ cần quan tâm từ đó có xuất hiện hay không.\\nKhi đó,p(xi|c) được tính bằng:\\np(xi|c) = p(i|c)xi + (1 −p(i|c))(1 −xi) (11.9)'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 140, 'page_label': '129'}, page_content='một từ trong văn bản, ta chỉ cần quan tâm từ đó có xuất hiện hay không.\\nKhi đó,p(xi|c) được tính bằng:\\np(xi|c) = p(i|c)xi + (1 −p(i|c))(1 −xi) (11.9)\\nvới p(i|c) có thể được hiểu là xác suất từ thứi xuất hiện trong các văn bản của classc.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 141, 'page_label': '130'}, page_content='CHƯƠNG 11. NAIVE BAYES CLASSIFIER 130\\n11.3 Ví dụ\\n11.3.1 Bắc hay Nam\\nGiả sử trong training set có các văn bản d1, d2, d3, d4 như trong Bảng 11.1. Mỗi văn bản\\nnày thuộc vào một trong hai lớp: B (Bắc) hoặc N (Nam). Hãy xác định lớp của văn bản d5.\\nBảng 11.1: Ví dụ về nội dung của các văn bản trong bài toán Bắc hay Nam\\nVăn bảnNội dung Lớp\\nTập huấn luyện\\nd1 hanoi pho chaolong hanoi B\\nd2 hanoi buncha pho omai B\\nd3 pho banhgio omai B\\nd4 saigon hutiu banhbo pho N\\nKiểm thử d5 hanoi hanoi buncha hutiu ?\\nTa có thể dự đoán rằng d5 thuộc classBắc.\\nBài toán này có thể được giải quyết bằng NBC sử dụng multinomial Naive Bayes hoặc\\nBernoulli naive Bayes. Chúng ta sẽ cùng làm ví dụ với mô hình thứ nhất và triển khai code\\ncho cả hai mô hình. Việc mô hình nào tốt hơn phụ thuộc vào mỗi bài toán. Chúng ta có thể\\nthử cả hai để chọn ra mô hình tốt hơn.\\nNhận thấy rằng ở đây có hai lớp B và N, ta cần đi tìmp(B) và p(N) dựa trên tần số xuất\\nhiện của mỗi class trong tập training. Ta sẽ có\\np(B) = 3\\n4, p (N) = 1\\n4 (11.10)\\nTập hợp toàn bộ các từ trong các văn bản, hay còn gọi là từ điển, là\\nV = {hanoi, pho, chaolong, buncha, omai, banhgio, saigon, hutiu, banhbo}\\nTổng cộng số phần tử trong từ điển là|V|= 9.\\nHình 11.1 minh hoạ quá trình huấn luyện và kiểm thử cho bài toán này khi sử dụng Multi-\\nnomial naive Bayes, trong đó Laplace smoothing được sử dụng vớiα= 1. Chú ý, hai giá trị\\ntìm được 1.5 ×10−4 và 1.75 ×10−5 không phải là hai xác suất cần tìm mà chỉ là hai đại\\nlượng tỉ lệ thuậnvới hai xác suất đó. Để tính cụ thể, ta có thể làm như sau\\np(B|d5) = 1.5 ×10−4\\n1.5 ×10−4 + 1.75 ×10−5 ≈0.8955, p (N|d5) = 1 −p(B|d5) ≈0.1045 (11.11)\\nNhư vậy xác suất để d5 rơi vào class B là 89.55%, vào class N là 10.45%. Bạn đọc có thể tự\\ntính với ví dụ khác: d6 = pho hutiu banhbo. Nếu tính toán đúng, ta sẽ thu được\\np(B|d6) ≈0.29, p (N|d6) ≈0.71 (11.12)\\nvà suy ra d6 thuộc vào class N.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 142, 'page_label': '131'}, page_content='131 CHƯƠNG 11. NAIVE BAYES CLASSIFIER\\nclass = B\\nhanoi pho chaolongbunchaomai banhgiosaigon hutiu banhbo\\nd= |V|= 9\\n2 1 1 0 0 0 0 0 0\\n1 1 0 1 1 0 0 0 0\\n0 1 0 0 1 1 0 0 0\\n3 3 1 1 2 1 0 0 0\\n4/20 4/20 2/20 2/20 3/20 2/20 1/20 1/20 1/20\\n⇒NB = 11\\n(20 =NB + |V|)\\nd1: x1\\nd2: x2\\nd3: x3\\nTotal\\n⇒ˆλB\\nclass = N\\n0 1 0 0 0 0 1 1 1\\n1/13 2/13 1/13 1/13 1/13 1/13 2/13 2/13 2/13\\nd4: x4 ⇒NN = 4\\n(13 =NN + |V|)⇒ˆλN\\nd5: x5 = [2,0,0,1,0,0,0,1,0]\\np(B|d5) ∝p(B) ∏d\\ni=1 p(xi|B)\\n= 3\\n4\\n(4\\n20\\n)2 2\\n20\\n1\\n20 ≈1.5 ×10−4\\np(N|d5) ∝p(N) ∏d\\ni=1 p(xi|N)\\n= 1\\n4\\n(1\\n13\\n)2 1\\n13\\n2\\n13 ≈1.75 ×10−5\\n⇒p(x5|B) >p(x5|N) ⇒d5 ∈class(B)\\nTRAINING TEST\\nHình 11.1: Minh hoạ NBC với Multinomial naive Bayes cho bài toánBắc hay Nam.\\n11.3.2 Naive Bayes Classifier với thư viện scikit-learn\\nĐể kiểm tra lại các phép tính toán phía trên, chúng ta cùng giải quyết bài toán này bằng\\nsikit-learn. Ở đây, dữ liệu huấn luyện và kiểm thử đã được đưa về dạng vector đặc trưng sử\\ndụng BoW.\\nfrom __future__ import print_function\\nfrom sklearn.naive_bayes import MultinomialNB\\nimport numpy as np\\n# train data\\nd1 = [2, 1, 1, 0, 0, 0, 0, 0, 0]\\nd2 = [1, 1, 0, 1, 1, 0, 0, 0, 0]\\nd3 = [0, 1, 0, 0, 1, 1, 0, 0, 0]\\nd4 = [0, 1, 0, 0, 0, 0, 1, 1, 1]\\ntrain_data = np.array([d1, d2, d3, d4])\\nlabel = np.array([’B’, ’B’, ’B’, ’N’])\\n# test data\\nd5 = np.array([[2, 0, 0, 1, 0, 0, 0, 1, 0]])\\nd6 = np.array([[0, 1, 0, 0, 0, 0, 0, 1, 1]])\\n## call MultinomialNB\\nmodel = MultinomialNB()\\n# training\\nmodel.fit(train_data, label)\\n# test\\nprint(’Predicting class of d5:’, str(model.predict(d5)[0]))\\nprint(’Probability of d6 in each class:’, model.predict_proba(d6))\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 143, 'page_label': '132'}, page_content='CHƯƠNG 11. NAIVE BAYES CLASSIFIER 132\\nKết quả:\\nPredicting class of d5: B\\nProbability of d6 in each class: [[ 0.29175335 0.70824665]]\\nKết quả này nhất quán với những kết quả được tính bằng tay ở trên.\\nNếu sử dụng Bernoulli naive Bayes, chúng ta cần thay đổi một chút về feature vector. Lúc\\nnày, các giá trị khác không sẽ đều được đưa về 1 vì ta chỉ quan tâm đến việc từ đó có xuất\\nhiện trong văn bản hay không.\\nfrom __future__ import print_function\\nfrom sklearn.naive_bayes import BernoulliNB\\nimport numpy as np\\n# train data\\nd1 = [1, 1, 1, 0, 0, 0, 0, 0, 0]\\nd2 = [1, 1, 0, 1, 1, 0, 0, 0, 0]\\nd3 = [0, 1, 0, 0, 1, 1, 0, 0, 0]\\nd4 = [0, 1, 0, 0, 0, 0, 1, 1, 1]\\ntrain_data = np.array([d1, d2, d3, d4])\\nlabel = np.array([’B’, ’B’, ’B’, ’N’]) # 0 - B, 1 - N\\n# test data\\nd5 = np.array([[1, 0, 0, 1, 0, 0, 0, 1, 0]])\\nd6 = np.array([[0, 1, 0, 0, 0, 0, 0, 1, 1]])\\n## call MultinomialNB\\nmodel = BernoulliNB()\\n# training\\nmodel.fit(train_data, label)\\n# test\\nprint(’Predicting class of d5:’, str(model.predict(d5)[0]))\\nprint(’Probability of d6 in each class:’, model.predict_proba(d6))\\nKết quả:\\nPredicting class of d5: B\\nProbability of d6 in each class: [[ 0.16948581 0.83051419]]\\nTa thấy rằng, với bài toán nhỏ này, cả hai mô hình đều cho kết quả giống nhau (xác suất\\ntìm được khác nhau nhưng không ảnh hưởng tới quyết định cuối cùng).\\n11.3.3 Naive Bayes Classifier cho bài toán spam filtering\\nTiếp theo, chúng ta cùng làm việc với một bộ cơ sở dữ liệu lớn hơn. Dữ liệu trong ví dụ\\nnày được lấy trongExercise 6: Naive Bayes–Machine Learning, Andrew Ng(https://goo.\\ngl/kbzR3d ). Trong ví dụ này, dữ liệu đã được xử lý, và là một tập con của cơ sở dữ liệu\\nLing-Spam dataset(https://goo.gl/whHCd9 ).\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 144, 'page_label': '133'}, page_content='133 CHƯƠNG 11. NAIVE BAYES CLASSIFIER\\nMô tả dữ liệuTập dữ liệu này bao gồm tổng cộng 960 email tiếng Anh, được tách thành\\ntraining set và test set theo tỉ lệ 700:260 với 50% trong mỗi tập là các spam email.\\nDữ liệu trong cơ sở dữ liệu này đã được xử lý khá đẹp. Các quy tắc xử lý như sau1:\\n1. Loại bỏstop words: Những từ xuất hiện thường xuyên như ‘and’, ‘the’, ‘of’, v.v. được\\nloại bỏ vì chúng xuất hiện ở cả hai loại, không ảnh hưởng nhiều đến việc quyết định.\\n2. Lemmatization:Nhữngtừcócùnggốcđượcđưavềcùngloại.Vídụ,‘include’,‘includes’,\\n‘included’ đều được đưa chung về ‘include’. Tất cả các từ cũng đã được đưa về dạng ký\\ntự thường (không phải HOA).\\n3. Loại bỏnon-words: các chữ số, dấu câu, và các ký tự đặc biệt đã được loại bỏ.\\nDưới đây là một ví dụ của một email không phải spam,trước khi được xử lý.\\nSubject: Re: 5.1344 Native speaker intuitions\\nThe discussion on native speaker intuitions has been extremely interesting, but\\nI worry that my brief intervention may have muddied the waters. I take it that\\nthere are a number of separable issues. The first is the extent to which a\\nnative speaker is likely to judge a lexical string as grammatical or\\nungrammatical per se. The second is concerned with the relationships between\\nsyntax and interpretation (although even here the distinction may not be\\nentirely clear cut).\\nvà sau khi được xử lý:\\nre native speaker intuition discussion native speaker intuition extremely\\ninterest worry brief intervention muddy waters number separable issue first\\nextent native speaker likely judge lexical string grammatical ungrammatical\\nper se second concern relationship between syntax interpretation although\\neven here distinction entirely clear cut\\nVà dưới đây là một ví dụ vềspam email sau khi được xử lý.\\nfinancial freedom follow financial freedom work ethic extraordinary desire earn\\nleast per month work home special skills experience required train personal\\nsupport need ensure success legitimate homebased income opportunity put back'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 144, 'page_label': '133'}, page_content='least per month work home special skills experience required train personal\\nsupport need ensure success legitimate homebased income opportunity put back\\ncontrol finance life ve try opportunity past fail live promise\\nChúng ta thấy rằng trong đoạn này có các từ như:financial, extraordinary, earn, opportunity,\\nv.v. là những từ thường thấy trong các email spam.\\nTrong ví dụ này, chúng ta sẽ sử dụng Multinomial Naive Bayes.\\n1 Bạn đọc có thể tham khảo thư việnNLTK (http://www.nltk.org/ ) cho các công việc xử lý dữ liệu này.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 145, 'page_label': '134'}, page_content='CHƯƠNG 11. NAIVE BAYES CLASSIFIER 134\\nĐể cho bài toán được đơn giản hơn, chúng ta sẽ tiếp tục sử dụng dữ liệu đã được xử lý, có\\nthể được download tạihttps://goo.gl/CSMxHU . Trong folder sau khi giải nén, chúng ta sẽ\\nthấy các file:\\ntest-features.txt\\ntest-labels.txt\\ntrain-features-50.txt\\ntrain-features-100.txt\\ntrain-features-400.txt\\ntrain-features.txt\\ntrain-labels-50.txt\\ntrain-labels-100.txt\\ntrain-labels-400.txt\\ntrain-labels.txt\\ntương ứng với các file chứa dữ liệu của training set và test set. Filetrain−features−50.txt\\nchứa dữ liệu của training set thu gọn với chỉ tổng cộng 50 email. Mỗi filelabels.txt chứa\\nnhiều dòng, mỗi dòng là một ký tự 0 hoặc 1 thể hiện email lànon-spam hoặc spam.\\nMỗi filefeatures.txt chứa nhiều dòng, mỗi dòng có 3 số, chẳng hạn:\\n1 564 1\\n1 19 2\\nTrong đó, số đầu tiên là chỉ số của email, bắt đầu từ 1; số thứ hai là thứ tự của từ trong từ\\nđiển (tổng cộng 2500 từ); số thứ ba là số lượng của từ đó trong email đang xét. Dòng đầu\\ntiên nói rằng trong email thứ nhất, từ thứ 564 trong từ điển xuất hiện một lần. Cách lưu\\ndữ liệu như thế này giúp tiết kiệm bộ nhớ vì một email thường không chứa hết tất cả các\\ntừ trong từ điển mà chỉ chứa một lượng nhỏ, ta chỉ cần lưu các giá trị khác không.\\nNếu biểu diễn mỗi email bằng một vector hàng có độ dài bằng độ dài từ điển (2500) thì\\ndòng thứ nhất nói rằng đặc trưng thứ 564 của vector này bằng 1. Tương tự, đặc trưng thứ\\n19 của vector này bằng 2. Nếu không xuất hiện, các thành phần khác được mặc định bằng\\n0. Dựa trên các thông tin này, chúng ta có thể tiến hành lập trình với thư viện sklearn.\\nKhai báo thư viện và đường dẫn tới files:\\nfrom __future__ import print_function\\nimport numpy as np\\nfrom scipy.sparse import coo_matrix # for sparse matrix\\nfrom sklearn.naive_bayes import MultinomialNB, BernoulliNB\\nfrom sklearn.metrics import accuracy_score # for evaluating results\\n# data path and file name\\npath = ’ex6DataPrepared/’\\ntrain_data_fn = ’train-features.txt’\\ntest_data_fn = ’test-features.txt’'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 145, 'page_label': '134'}, page_content='from sklearn.metrics import accuracy_score # for evaluating results\\n# data path and file name\\npath = ’ex6DataPrepared/’\\ntrain_data_fn = ’train-features.txt’\\ntest_data_fn = ’test-features.txt’\\ntrain_label_fn = ’train-labels.txt’\\ntest_label_fn = ’test-labels.txt’\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 146, 'page_label': '135'}, page_content='135 CHƯƠNG 11. NAIVE BAYES CLASSIFIER\\nTiếp theo ta cần viết hàm số đọc dữ liệu từ filedata_fn với label tương ứng được lưu trong\\nlabel_fn. Chú ý rằng số lượng từ trong từ điển là 2500.\\nDữ liệu sẽ được lưu trong một ma trận mà mỗi hàng là một vector đặc trưng của email. Ma\\ntrận này là một ma trận sparse nên chúng ta sẽ sử dụng hàmscipy.sparse.coo_matrix.\\nnwords = 2500\\ndef read_data(data_fn, label_fn):\\n## read label_fn\\nwith open(path + label_fn) as f:\\ncontent = f.readlines()\\nlabel = [int(x.strip()) for x in content]\\n## read data_fn\\nwith open(path + data_fn) as f:\\ncontent = f.readlines()\\n# remove ’\\\\n’ at the end of each line\\ncontent = [x.strip() for x in content]\\ndat = np.zeros((len(content), 3), dtype = int)\\nfor i, line in enumerate(content):\\na = line.split(’ ’)\\ndat[i, :] = np.array([int(a[0]), int(a[1]), int(a[2])])\\n# remember to -1 at coordinate since we’re in Python\\ndata = coo_matrix((dat[:, 2], (dat[:, 0] - 1, dat[:, 1] - 1)),\\\\\\nshape=(len(label), nwords))\\nreturn (data, label)\\nĐoạn code dưới đây giúp lấy dữ liệu huấn luyện và kiểm thử, sau đó tiến hành phân lớp sử\\ndụng MultinomialNB.\\n(train_data, train_label) = read_data(train_data_fn, train_label_fn)\\n(test_data, test_label) = read_data(test_data_fn, test_label_fn)\\nclf = MultinomialNB()\\nclf.fit(train_data, train_label)\\ny_pred = clf.predict(test_data)\\nprint(’Training size = %d, accuracy = %.2f%%’ % \\\\\\n(train_data.shape[0],accuracy_score(test_label, y_pred)*100))\\nKết quả:\\nTraining size = 700, accuracy = 98.08%\\nVậy là có tới 98.08% các email được phân loại đúng. Chúng ta tiếp tục thử với các bộ dữ\\nliệu training nhỏ hơn.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 147, 'page_label': '136'}, page_content='CHƯƠNG 11. NAIVE BAYES CLASSIFIER 136\\ntrain_data_fn = ’train-features-100.txt’\\ntrain_label_fn = ’train-labels-100.txt’\\ntest_data_fn = ’test-features.txt’\\ntest_label_fn = ’test-labels.txt’\\n(train_data, train_label) = read_data(train_data_fn, train_label_fn)\\n(test_data, test_label) = read_data(test_data_fn, test_label_fn)\\nclf = MultinomialNB()\\nclf.fit(train_data, train_label)\\ny_pred = clf.predict(test_data)\\nprint(’Training size = %d, accuracy = %.2f%%’ % \\\\\\n(train_data.shape[0],accuracy_score(test_label, y_pred)*100))\\ntrain_data_fn = ’train-features-50.txt’\\ntrain_label_fn = ’train-labels-50.txt’\\ntest_data_fn = ’test-features.txt’\\ntest_label_fn = ’test-labels.txt’\\n(train_data, train_label) = read_data(train_data_fn, train_label_fn)\\n(test_data, test_label) = read_data(test_data_fn, test_label_fn)\\nclf = MultinomialNB()\\nclf.fit(train_data, train_label)\\ny_pred = clf.predict(test_data)\\nprint(’Training size = %d, accuracy = %.2f%%’ % \\\\\\n(train_data.shape[0],accuracy_score(test_label, y_pred)*100))\\nKết quả:\\nTraining size = 100, accuracy = 97.69%\\nTraining size = 50, accuracy = 97.31%\\nTa thấy rằng thậm chí khi training set là rất nhỏ, 50 email tổng cộng, kết quả đạt được đã\\nrất ấn tượng.\\nNếu bạn muốn tiếp tục thử mô hìnhBernoulliNB:\\nclf = BernoulliNB(binarize = .5)\\nclf.fit(train_data, train_label)\\ny_pred = clf.predict(test_data)\\nprint(’Training size = %d, accuracy = %.2f%%’ % \\\\\\n(train_data.shape[0],accuracy_score(test_label, y_pred)*100))\\nKết quả:\\nTraining size = 50, accuracy = 69.62%\\nTa thấy rằng trong bài toán này,MultinomialNB hoạt động hiệu quả hơn.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 148, 'page_label': '137'}, page_content='137 CHƯƠNG 11. NAIVE BAYES CLASSIFIER\\n11.4 Thảo luận\\n11.4.1 Tóm tắt\\n• Naive Bayes classifiers (NBC) thường được sử dụng trong các bài toán phân loại văn bản.\\n• NBC có thời gian huấn luyện và kiểm thử rất nhanh. Điều này có được là do giả sử về\\ntính độc lập giữa các thành phần.\\n• Nếu giả sử về tính độc lập được thoả mãn (dựa vào bản chất của dữ liệu), NBC được cho\\nlà cho kết quả tốt hơn so với support vector machine (Phần VIII) và logistic regression\\n(Chương 14) khi có ít dữ liệu huấn luyện.\\n• NBC có thể hoạt động với các vector đặc trưng mà một phần là liên tục (sử dụng Gaussian\\nNaive Bayes), phần còn lại ở dạng rời rạc (sử dụng Multinomial hoặc Bernoulli). Chính\\nsự độc lập giữa các đặc trưng khiến NBC có khả năng này.\\n• Khi sử dụng Multinomial Naive Bayes, Laplace smoothing thường được sử dụng để tránh\\ntrường hợp một từ trong dữ liệu kiểm thử chưa xuất hiện trong training set.\\n• Source code trong chương này có thể được tìm thấy tại đây.\\n11.4.2 Đọc thêm\\n1. Text Classification and Naive Bayes - Stanford(https://goo.gl/HcefLX ).\\n2. 6 Easy Steps to Learn Naive Bayes Algorithm (with code in Python)(https://goo.gl/\\nodQaaY).\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 150, 'page_label': '139'}, page_content='Phần IV\\nNeural networks'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 151, 'page_label': '140'}, page_content='Chương 12\\nGradient descent\\n12.1 Giới thiệu\\nHình 12.1 mô tả sự biến thiên của hàm sốf(x) = 1\\n2 (x−1)2 −2. Điểm màu xanh lục là một\\nđiểm cực tiểu(local minimum), và cũng là điểm làm cho hàm số đạt giá trị nhỏ nhất (global\\nminimum). Global minimum là một trường hợp đặc biệt của local minimum.\\nGiả sử ta đang quan tâm đến một hàm số một biến có đạo hàm mọi nơi. Cùng ôn lại một\\nvài điểm cơ bản:\\n1. Điểm local minimumx∗của hàm số là điểm có đạo hàmf′(x∗) bằng không. Hơn thế nữa,\\ntrong lân cận của nó, đạo hàm của các điểm phía bên tráix∗ là không dương, đạo hàm\\ncủa các điểm phía bên phảix∗ là không âm.\\n2. Đường tiếp tuyến với đồ thị hàm số đó tại một điểm bất kỳ có hệ số góc chính bằng đạo\\nhàm của hàm số tại điểm đó.\\nTrong Hình 12.1, các điểm bên trái của điểm local minimum màu xanh lục có đạo hàm âm,\\ncác điểm bên phải có đạo hàm dương. Và đối với hàm số này, càng xa về phía trái của điểm\\nlocal minimum thì đạo hàm càng âm, càng xa về phía phải thì đạo hàm càng dương.\\nTrong machine learning nói riêng và toán tối ưu nói chung, chúng ta thường xuyên phải tìm\\ncác giá trị lớn nhất hoặc nhỏ nhất của một hàm số. Nếu chỉ xét riêng các hàm khả vi liên\\ntục, việc giải phương trình đạo hàm bằng không thường rất phức tạp hoặc có thể ra vô số\\nnghiệm. Thay vào đó, người ta thường cố gắng tìm các điểm local minimum, và ở một mức\\nđộ nào đó, coi đó là một nghiệm cần tìm của bài toán.\\nCác điểm local minimum là nghiệm của phương trình đạo hàm bằng không (ta vẫn đang giả\\nsử rằng các hàm này liên tục và khả vi). Nếu bằng một cách nào đó có thể tìm được toàn bộ\\n(hữu hạn) các điểm cực tiểu, ta chỉ cần thay từng điểm local minimum đó vào hàm số rồi\\ntìm điểm làm cho hàm có giá trị nhỏ nhất. Tuy nhiên, trong hầu hết các trường hợp, việc'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 152, 'page_label': '141'}, page_content='141 CHƯƠNG 12. GRADIENT DESCENT\\nx\\nf\\n′\\n( x )\\nf ( x )\\n−∞ 1 + ∞\\n0− +\\n+ ∞ + ∞\\n-2\\nf ( x ) =\\n1\\n2\\n( x − 1)\\n2\\n− 2\\nx\\n∗\\nHình 12.1:Khảo sát sự biến thiên\\ncủa một đa thức bậc hai.\\ngiải phương trình đạo hàm bằng không là bất khả thi. Nguyên nhân có thể đến từ sự phức\\ntạp của dạng của đạo hàm, từ việc các điểm dữ liệu có số chiều lớn, hoặc từ việc có quá\\nnhiều điểm dữ liệu. Thực tế cho thấy, trong nhiều bài toán machine learning, các nghiệm\\nlocal minimum thường đã cho kết quả tốt, đặc biệt là trong neural networks.\\nHướng tiếp cận phổ biến nhất để giải quyết các bài toán tối ưu là xuất phát từ một điểm\\nđược coi làgần với nghiệm của bài toán, sau đó dùng một phép toán lặp đểtiến dần đến\\nđiểm cần tìm, tức đến khi đạo hàm gần với không. Gradient descent (GD) và các biến thể\\ncủa nó là một trong những phương pháp được dùng nhiều nhất.\\n12.2 GD cho hàm một biến\\nXét các hàm số một biếnf : R →R. Quay trở lại Hình 12.1 và một vài quan sát đã nêu.\\nGiả sửxt là điểm tìm được sau vòng lặp thứt. Ta cần tìm một thuật toán để đưaxt về càng\\ngần x∗ càng tốt. Có hai quan sát sau đây:\\n1. Nếu đạo hàm của hàm số tạixt là dương (f′(xt) >0) thìxt nằm về bên phải so vớix∗,\\nvà ngược lại. Để điểm tiếp theoxt+1 gần vớix∗ hơn, chúng ta cần di chuyểnxt về phía\\nbên trái, tức về phíaâm. Nói các khác,ta cần di chuyển ngược dấu với đạo hàm:\\nxt+1 = xt + ∆ (12.1)\\nTrong đó∆ là một đại lượng ngược dấu với đạo hàmf′(xt).\\n2. xt càng xa x∗ về phía bên phải thìf′(xt) càng lớn hơn 0 (và ngược lại). Vậy, lượng di\\nchuyển ∆, một cách tự nhiên nhất, là tỉ lệ thuận với−f′(xt).\\nHai nhận xét phía trên cho chúng ta một cách cập nhật đơn giản là\\nxt+1 = xt −ηf′(xt) (12.2)\\nTrong đóη là một số dương được gọi làtốc độ học(learning rate). Dấu trừ thể hiện việc\\nchúng ta phảiđi ngượcvới đạo hàm1. Các quan sát đơn giản phía trên, mặc dù không phải\\nđúng trong tất cả các trường hợp, là nền tảng cho rất nhiều phương pháp tối ưu.\\n1 Đây chính là lý do phương pháp này được gọi là gradient descent–descent nghĩa làđi ngược'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 152, 'page_label': '141'}, page_content='đúng trong tất cả các trường hợp, là nền tảng cho rất nhiều phương pháp tối ưu.\\n1 Đây chính là lý do phương pháp này được gọi là gradient descent–descent nghĩa làđi ngược\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 153, 'page_label': '142'}, page_content='CHƯƠNG 12. GRADIENT DESCENT 142\\n12.2.1 Ví dụ đơn giản với Python\\nXét hàm sốf(x) = x2 + 5 sin(x) với đạo hàmf′(x) = 2x+ 5 cos(x). Giả sử bắt đầu từ một\\nđiểm x0 nào đó, tại vòng lặp thứt, chúng ta sẽ cập nhật như sau:\\nxt+1 = xt −η(2xt + 5 cos(xt)) (12.3)\\nKhi thực hiện trên Python, ta cần viết các hàm số2:\\n1. grad để tính đạo hàm.\\n2. cost để tính giá trị của hàm số. Hàm này không sử dụng trong thuật toán nhưng thường\\nđược dùng để kiểm tra việc tính đạo hàm có đúng không hoặc để xem giá trị của hàm số\\ncó giảm theo mỗi vòng lặp hay không.\\n3. myGD1 là phần chính thực hiện thuật toán GD nêu phía trên. Đầu vào của hàm số này là\\nlearning rate và điểm xuất phát. Thuật toán dừng lại khi đạo hàm có độ lớn đủ nhỏ.\\ndef grad(x):\\nreturn 2*x+ 5*np.cos(x)\\ndef cost(x):\\nreturn x**2 + 5*np.sin(x)\\ndef myGD1(x0, eta):\\nx = [x0]\\nfor it in range(100):\\nx_new = x[-1] - eta*grad(x[-1])\\nif abs(grad(x_new)) < 1e-3: # just a small number\\nbreak\\nx.append(x_new)\\nreturn (x, it)\\nĐiểm xuất phát khác nhau\\nSau khi đã có các hàm cần thiết, chúng ta thử tìm nghiệm với các điểm khởi tạo khác nhau\\nlà x0 = −5 và x0 = 5, với cùng learning rateη= 0.1.\\n(x1, it1) = myGD1(-5, .1)\\n(x2, it2) = myGD1(5, .1)\\nprint(’Solution x1 = %f, cost = %f, after %d iterations’%(x1[-1], cost(x1[-1]), it1))\\nprint(’Solution x2 = %f, cost = %f, after %d iterations’%(x2[-1], cost(x2[-1]), it2))\\nKết quả:\\nSolution x1 = -1.110667, cost = -3.246394, after 11 iterations\\nSolution x2 = -1.110341, cost = -3.246394, after 29 iterations\\n2 Giả sử rằng các thư viện đã được khai báo đầy đủ\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 154, 'page_label': '143'}, page_content='143 CHƯƠNG 12. GRADIENT DESCENT\\n−5 0 5\\niter 0/11, grad = -8.582\\n0\\n10\\n20\\n30\\n−5 0 5\\niter 1/11, grad = -10.984\\n0\\n10\\n20\\n30\\n−5 0 5\\niter 2/11, grad = -11.063\\n0\\n10\\n20\\n30\\n−5 0 5\\niter 3/11, grad = -5.665\\n0\\n10\\n20\\n30\\n−5 0 5\\niter 4/11, grad = -1.747\\n0\\n10\\n20\\n30\\n−5 0 5\\niter 5/11, grad = -0.561\\n0\\n10\\n20\\n30\\n−5 0 5\\niter 7/11, grad = -0.066\\n0\\n10\\n20\\n30\\n−5 0 5\\niter 11/11, grad = -0.001\\n0\\n10\\n20\\n30\\n.\\nHình 12.2: Nghiệm tìm được qua các vòng lặp vớix0 = −5,η = 0.1\\nVậy là với các điểm xuất phát khác nhau, thuật toán tìm được nghiệm gần giống nhau, mặc\\ndù với tốc độ hội tụ khác nhau. Hình 12.2 và Hình 12.3 thể hiện vị trí của nghiệm và đạo\\nhàm qua các vòng lặp với cùng learning rateη = .1 nhưng điểm khởi tạo khác nhau tại−5\\nvà 5.\\nHình 12.2 tương ứng vớix0 = −5, cho thấy nghiệm hội tụ nhanh hơn, vì điểm ban đầux0\\ngần với nghiệmx∗≈−1 hơn. Hơn nữa,đường đi tới nghiệm khá suôn sẻ với đạo hàm luôn\\nâm và càng gần nghiệm thì đạo hàm càng nhỏ.\\nTrong Hình 12.3 tương ứng vớix0 = 5, đường đi của nghiệm có chứa một khu vực có đạo\\nhàm khá nhỏ gần điểm có hoành độ bằng 2.5. Điều này khiến cho thuật toánla cà ở đây\\nkhá lâu. Khi vượt qua được điểm này thì mọi việc diễn ra rất tốt đẹp. Các điểm không phải\\nlà điểm cực tiểu nhưng có đạo hàm gần bằng không rất dễ gây ra hiện tượng nghiệm bịbẫy\\n(trapped) tại đây vì đạo hàm nhỏ khiến nó không thay đổi nhiều ở vòng lặp tiếp theo. Chúng\\nta sẽ thấy một kỹ thuật khác giúpthoát được những chiếc bẫy này.\\nLearning rate khác nhau\\nTốc độ hội tụ của GD không những phụ thuộc vào điểm xuất phát mà còn phụ thuộc vào\\nlearning rate. Hình 12.4 và Hình 12.5 thể hiện vị trí của nghiệm qua các vòng lặp với cùng\\nđiểm khởi tạox0 = −5 nhưng learning rate khác nhau. Ta quan sát thấy hai điều:\\n1. Vớilearning ratenhỏ η = 0.01 (Hình 12.4), tốc độ hội tụ rất chậm. Trong ví dụ này ta\\nchọn tối đa 100 vòng lặp nên thuật toán dừng lại trước khi tớiđích, mặc dù đã rất gần.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 155, 'page_label': '144'}, page_content='CHƯƠNG 12. GRADIENT DESCENT 144\\n−5 0 5\\niter 0/29, grad = 11.418\\n0\\n10\\n20\\n30\\n−5 0 5\\niter 3/29, grad = 1.517\\n0\\n10\\n20\\n30\\n−5 0 5\\niter 6/29, grad = 0.925\\n0\\n10\\n20\\n30\\n−5 0 5\\niter 10/29, grad = 0.983\\n0\\n10\\n20\\n30\\n−5 0 5\\niter 15/29, grad = 2.341\\n0\\n10\\n20\\n30\\n−5 0 5\\niter 20/29, grad = 4.739\\n0\\n10\\n20\\n30\\n−5 0 5\\niter 25/29, grad = 0.071\\n0\\n10\\n20\\n30\\n−5 0 5\\niter 29/29, grad = 0.001\\n0\\n10\\n20\\n30\\n.\\nHình 12.3: Nghiệm tìm được qua các vòng lặp vớix0 = 5,η = 0.1\\n−5 0 5\\niter 0/100, grad = -8.582\\n0\\n10\\n20\\n30\\n−5 0 5\\niter 10/100, grad = -11.230\\n0\\n10\\n20\\n30\\n−5 0 5\\niter 20/100, grad = -10.584\\n0\\n10\\n20\\n30\\n−5 0 5\\niter 30/100, grad = -6.175\\n0\\n10\\n20\\n30\\n−5 0 5\\niter 50/100, grad = -1.476\\n0\\n10\\n20\\n30\\n−5 0 5\\niter 70/100, grad = -0.368\\n0\\n10\\n20\\n30\\n−5 0 5\\niter 90/100, grad = -0.095\\n0\\n10\\n20\\n30\\n−5 0 5\\niter 100/100, grad = -0.049\\n0\\n10\\n20\\n30\\nHình 12.4: Nghiệm tìm được qua các vòng lặp với điểm xuất phátx0 = −5, learning rate\\nη= 0.01.\\nTrong thực tế, khi việc tính toán trở nên phức tạp,learning ratequá thấp sẽ ảnh hưởng\\ntới tốc độ của thuật toán rất nhiều, thậm chí không bao giờ tới được đích.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 156, 'page_label': '145'}, page_content='145 CHƯƠNG 12. GRADIENT DESCENT\\n−5 0 5\\niter 0/100, grad = -8.582\\n0\\n10\\n20\\n30\\n−5 0 5\\niter 1/100, grad = 2.376\\n0\\n10\\n20\\n30\\n−5 0 5\\niter 2/100, grad = -5.398\\n0\\n10\\n20\\n30\\n−5 0 5\\niter 3/100, grad = 5.081\\n0\\n10\\n20\\n30\\n−5 0 5\\niter 50/100, grad = -8.114\\n0\\n10\\n20\\n30\\n−5 0 5\\niter 70/100, grad = 4.663\\n0\\n10\\n20\\n30\\n−5 0 5\\niter 90/100, grad = -7.038\\n0\\n10\\n20\\n30\\n−5 0 5\\niter 100/100, grad = 4.761\\n0\\n10\\n20\\n30\\n.\\nHình 12.5: Nghiệm tìm được qua các vòng lặp vớix0 = −5,η = 0.5\\n2. Vớilearning ratelớn η= 0.5 (Hình 12.5), thuật toán tiến rất nhanh tớigần đíchsau vài\\nvòng lặp. Tuy nhiên, thuật toán không hội tụ được vì sự thay đổi vị trí của nghiệm sau\\nmỗi vòng lặp là quá lớn, khiến nó cứquẩn quanh ở đích mà vẫn không tới được đích.\\nViệc lựa chọnlearning rate rất quan trọng. Việc này phụ thuộc nhiều vào từng bài toán\\nvà phải làm một vài thí nghiệm để chọn ra giá trị tốt nhất. Ngoài ra, tùy vào một số bài\\ntoán, GD có thể làm việc hiệu quả hơn bằng cách chọn ralearning ratephù hợp hoặc chọn\\nlearning ratekhác nhau ở mỗi vòng lặp, thường là giảm dần.\\n12.3 GD cho hàm nhiều biến\\nGiả sử ta cần tìm global minimum cho hàmf(θ) trong đóθ là tập hợp các tham số cần tối\\nưu. Đạo hàm của hàm số đó tại một điểmθ bất kỳ được ký hiệu là∇θf(θ). Tương tự như\\nhàm một biến, thuật toán GD cho hàm nhiều biến cũng bắt đầu bằng một điểm dự đoánθ0,\\nsau đó, ở vòng lặp thứt, quy tắc cập nhật là\\nθt+1 = θt −η∇θf(θt) (12.4)\\nHoặc viết dưới dạng đơn giản hơn:θ←θ−η∇θf(θ).\\nQuay lại với bài toán linear regression\\nTrong mục này, chúng ta quay lại với bài toán linear regression và thử tối ưu hàm mất mát\\ncủa nó bằng thuật toán GD.\\nNhắc lại hàm mất mát của linear regression và đạo hàm theow lần lượt là\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 157, 'page_label': '146'}, page_content='CHƯƠNG 12. GRADIENT DESCENT 146\\n0.0 0.2 0.4 0.6 0.8 1.0\\n0\\n2\\n4\\n6\\n8\\n10\\nHình 12.6: Nghiệm của bài toán\\nlinear regression (đường thằng màu\\nvàng) tìm được bằng thư viện\\nscikit-learn.\\nL(w) = 1\\n2N∥y −XTw∥2\\n2; ∇wL(w) = 1\\nNX(XTw −y) (12.5)\\nSau đây là ví dụ trên Python và một vài lưu ý khi lập trình\\nTrước hết, chúng ta tạo 1000 điểm dữ liệu được chọngần với đường thẳngy= 4 + 3x:\\nfrom sklearn.linear_model import LinearRegression\\nX = np.random.rand(1000)\\ny = 4 + 3 * X + .5*np.random.randn(1000) # noise added\\nmodel = LinearRegression()\\nmodel.fit(X.reshape(-1, 1), y.reshape(-1, 1))\\nw, b = model.coef_[0][0], model.intercept_[0]\\nsol_sklearn = np.array([b, w])\\nprint(sol_sklearn)\\nKết quả:\\nSolution found by sklearn: [ 3.94323245 3.12067542]\\nCác điểm dữ liệu và đường thẳng tìm được bằng linear regression có phương trìnhy ≈\\n3.94 + 3.12x được minh hoạ trong Hình 12.6. Nghiệm tìm được rất gần với mong đợi.\\nTiếp theo, ta sẽ thực hiện tìm nghiệm của linear regression sử dụng GD. Ta cần viết hàm\\nmất mát và đạo hàm theow. Chú ý rằng ở đâyw đã bao gồm cả bias.\\ndef grad(w):\\nN = Xbar.shape[0]\\nreturn 1/N * Xbar.T.dot(Xbar.dot(w) - y)\\ndef cost(w):\\nN = Xbar.shape[0]\\nreturn .5/N*np.linalg.norm(y - Xbar.dot(w))**2\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 158, 'page_label': '147'}, page_content='147 CHƯƠNG 12. GRADIENT DESCENT\\nVới các hàm phức tạp, khi tính xong đạo hàm chúng ta cần kiểm tra đạo hàm thông qua\\nnumerical gradient (xem Mục 2.6). Trường hợp này tương đối đơn giản, việc kiểm tra đạo\\nhàm xin giành lại cho bạn đọc. Dưới đây là thuật toán GD cho bài toán.\\ndef myGD(w_init, grad, eta):\\nw = [w_init]\\nfor it in range(100):\\nw_new = w[-1] - eta*grad(w[-1])\\nif np.linalg.norm(grad(w_new))/len(w_new) < 1e-3:\\nbreak\\nw.append(w_new)\\nreturn (w, it)\\none = np.ones((X.shape[0],1))\\nXbar = np.concatenate((one, X.reshape(-1, 1)), axis = 1)\\nw_init = np.array([[2], [1]])\\n(w1, it1) = myGD(w_init, grad, 1)\\nprint(’Sol found by GD: w = ’, w1[-1].T, ’,\\\\nafter %d iterations.’ %(it1+1))\\nKết quả:\\nSol found by GD: w = [ 3.99026984 2.98702942] ,\\nafter 49 iterations.\\nSau 49 vòng lặp, thuật toán đã hội tụ với một nghiệm khá gần với nghiệm tìm được theo\\nsklearn. Hình 12.7 mô tả đường đi của nghiệm với cùng điểm khởi tạo nhưng với learning\\nrate khác nhau. Các điểm màu lam là các điểm xuất phát. Các điểm màu lục là nghiệm tìm\\nđược bằng thư viện scikit-learn. Các điểm màu đỏ là nghiệm qua các vòng lặp trung gian.\\nTa thấy rằng khieta= 1, thuật toán hội tụ tới (rất gần) nghiệm theo thư viện sau 49 vòng\\nlặp. Với learning rate nhỏ hơn,η= 0.1, sau hơn 100 vòng lặp, nghiệm vẫn còn cách xa đích.\\nNhư vậy, việc chọn learning rate hợp lý là rất quan trọng.\\nỞ đây, chúng ta cùng làm quen với một khái niệm quan trọng:đường đồng mức(level sets).\\nTa thường gặp khái niệmđường đồng mức trong các bản đồ tự nhiên. Các điểm có cùng\\nđộ cao so với mực nước biển thường được nối với nhau. Với các ngọn núi, đường đồng mức\\nthường là các đường kín bao quanh đỉnh núi. Khái niệm tương tự cũng được sử dụng trong\\ntối ưu.Đường đồng mứchay level setscủa một hàm số là tập hợp các điểm làm cho hàm số\\ncó cùng giá trị. Tưởng tượng một hàm số với hai biến, đồ thị của nó là mộtbề mặt(surface)\\ntrong không gian ba chiều. Đường đồng mức có thể được xác định bằng cáchcắt bề mặt này'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 158, 'page_label': '147'}, page_content='có cùng giá trị. Tưởng tượng một hàm số với hai biến, đồ thị của nó là mộtbề mặt(surface)\\ntrong không gian ba chiều. Đường đồng mức có thể được xác định bằng cáchcắt bề mặt này\\nbằng một mặt phẳng song song với đáy và lấy giao điểm của chúng. Với dữ liệu hai chiều,\\nhàm mất mát của linear regression là một hàm bậc hai của hai thành phần trong vector hệ\\nsố w. Đồ thị của nó là một bề mặt parabolic. Vì vậy, các đường đồng mức của hàm này là\\ncác đường ellipse có cùng tâm như trên Hình 12.7. Tâm này chính là đáy của parabolic và là\\ngiá trị nhỏ nhất của hàm mất mát. Các đường đồng mức được biểu diễn bởi các màu khác\\nnhau với màu từ lam đậm đến lục, vàng, cam, đỏ, đỏ đậm thể hiện giá trị tăng dần.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 159, 'page_label': '148'}, page_content='CHƯƠNG 12. GRADIENT DESCENT 148\\n2 3 4 5 6\\n0.5\\n1.0\\n1.5\\n2.0\\n2.5\\n3.0\\n3.5\\n4.0\\n4.5\\n51 iterations\\n(a) η= 1.\\n2 3 4 5 6\\n0.5\\n1.0\\n1.5\\n2.0\\n2.5\\n3.0\\n3.5\\n4.0\\n4.5\\n101 iterations (b) η= 0.1.\\nHình 12.7: Đường đi nghiệm của linear regression với các learning rate khác nhau.\\n12.4 GD với momentum\\nTrước hết, cùng nhắc lại thuật toán GD để tối ưu hàm mất mátJ(θ):\\n1. Dự đoán một điểm khởi tạoθ= θ0.\\n2. Cập nhậtθ đến khi đạt được kết quả chấp nhận được:\\nθ←θ−η∇θJ(θ) (12.6)\\nvới ∇θJ(θ) là đạo hàm của hàm mất mát tạiθ.\\nGradient dưới góc nhìn vật lý\\nThuật toán GD thường được ví với tác dụng của trọng lực lên một hòn bi đặt trên một mặt\\ncó dạng một thung lũng như Hình 12.8a. Bất kể ta đặt hòn bi ở A hay B thì cuối cùng hòn\\nbi cũng sẽ lăn xuống và kết thúc ở vị trí C.\\nTuy nhiên, nếu như bề mặt có hai đáy thung lũng như Hình 12.8b thì tùy vào việc đặt bi ở\\nA hoặc B, vị trí cuối cùng tương ứng của bi sẽ ở C hoặc D (giả sử rằng ma sát đủ lớn và đà\\nchưa quá lớn khiến bi không thể vượt dốc). Điểm D chính là một điểm local minimum.\\nNếu suy nghĩ một cách vật lý hơn, vẫn trong Hình 12.8b, nếu vận tốc ban đầu của bi khi ở\\nđiểm B đủ lớn, khi bi lăn đến điểm D, theođà, bi có thể tiếp tục di chuyển lên dốc phía bên\\ntrái của D. Và nếu giả sử vận tốc ban đầu lớn hơn nữa, bi có thể vượt dốc tới điểm E rồi lăn\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 160, 'page_label': '149'}, page_content='149 CHƯƠNG 12. GRADIENT DESCENT\\nHình 12.8: So sánh GD với các hiện tượng vật lý.\\nxuống C như trong Hình 12.8c. Dựa trên quan sát này, một thuật toán được ra đời nhằm\\ngiúp GD thoát được các local minimum. Thuật toán đó có tên làmomentum (tức theo đà).\\nGD với momentum\\nLàm thế nào để biểu diễnmomentum dưới dạng toán học?\\nTrong GD, chúng ta cần tính lượng thay đổi ở thời điểmtđể cập nhật vị trí mới cho nghiệm\\n(tức hòn bi). Nếu chúng ta coi đại lượng này như vận tốcvt trong vật lý, vị trí mới củahòn\\nbi sẽ làθt+1 = θt−vt, với giả sử rằng mỗi vòng lặp là một đơn vị thời gian. Dấu trừ thể hiện\\nviệc phải di chuyển ngược với đạo hàm. Việc tiếp theo là tính đại lượngvt sao cho nó vừa\\nmang thông tin củađộ dốc(tức đạo hàm), vừa mang thông tin củađà, tức vận tốc trước đó\\nvt−1 (với giả sử rằng vận tốc ban đầuv0 = 0). Một cách đơn giản nhất, ta có thể lấy tổng\\ncó trọng số của chúng:\\nvt = γvt−1 + η∇θJ(θ) (12.7)\\nTrong đóγ thường được chọn là một giá trị nhỏ hơn gần bằng một, thường là khoảng 0.9,\\nvt−1 là vận tốc tại thời điểm trước đó,∇θJ(θ) chính là độ dốc của điểm trước đó. Sau đó,\\nvị trí mới củahòn bi được xác định bởi\\nθ←θ−vt = θ−η∇θJ(θ) −γvt−1 (12.8)\\nSự khác nhau giữa GD thông thường và GD với momentem chỉ nằm ở thành phần cuối cùng\\ncủa (12.8). Thuật toán đơn giản này tỏ ra rất hiệu quả trong các bài toán thực tế. Dưới đây\\nlà một ví dụ trong không gian một chiều. Xét một hàm đơn giản có hai điểm local minimum,\\ntrong đó một điểm là global minimum\\nf(x) = x2 + 10 sin(x) (12.9)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 161, 'page_label': '150'}, page_content='CHƯƠNG 12. GRADIENT DESCENT 150\\n−5 0 5\\niter 0/4, grad = 12.837\\n−10\\n0\\n10\\n20\\n30\\n−5 0 5\\niter 1/4, grad = -0.961\\n−10\\n0\\n10\\n20\\n30\\n−5 0 5\\niter 2/4, grad = -0.208\\n−10\\n0\\n10\\n20\\n30\\n−5 0 5\\niter 4/4, grad = -0.006\\n−10\\n0\\n10\\n20\\n30\\nHình 12.9: GD thông thường.\\n−5 0 5\\niter 0/100, grad = 12.837\\n−10\\n0\\n10\\n20\\n30\\n−5 0 5\\niter 1/100, grad = -0.961\\n−10\\n0\\n10\\n20\\n30\\n−5 0 5\\niter 2/100, grad = -3.535\\n−10\\n0\\n10\\n20\\n30\\n−5 0 5\\niter 10/100, grad = 9.845\\n−10\\n0\\n10\\n20\\n30\\n−5 0 5\\niter 20/100, grad = -10.917\\n−10\\n0\\n10\\n20\\n30\\n−5 0 5\\niter 50/100, grad = 2.289\\n−10\\n0\\n10\\n20\\n30\\n−5 0 5\\niter 75/100, grad = -0.462\\n−10\\n0\\n10\\n20\\n30\\n−5 0 5\\niter 100/100, grad = -0.044\\n−10\\n0\\n10\\n20\\n30\\nHình 12.10: GD với momentum.\\nvới đạo hàmf′(x) = 2x+ 10 cos(x). Hình 12.9 thể hiện đường đi của nghiệm cho bài toán\\nnày khi không sử dụng momentum. Ta thấy rằng thuật toán hội tụ nhanh chóng sau chỉ bốn\\nvòng lặp. Tuy nhiên, nghiệm dừng lại ở một điểm local minimum. Trong khi đó, Hình 12.10\\nthể hiện đường đi của nghiệm khi có sử dụng momentum. Chúng ta thấy rằnghòn bi vượt\\nđược dốc thứ nhất nhờ cóđà, theo quán tính tiếp tục vượt qua điểm global minimum, nhưng\\nquay trở lại điểm này sau 50 vòng lặp rồi chuyển động chậm dần quanh đó tới khi dừng hẳn\\nở vòng lặp thứ 100. Ví dụ này cho thấy momentum thực sự đã giúp nghiệm thoát được khu\\nvực local minimum.\\nNếu biết trước điểmđặt bi ban đầutheta, đạo hàm của hàm mất mát tại một điểm bất kỳ\\ngrad(theta), lượng thông tin lưu trữ từ vận tốc trước đógamma và learning rateeta, chúng ta\\ncó thể viết hàmGD_momentum như sau.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 162, 'page_label': '151'}, page_content='151 CHƯƠNG 12. GRADIENT DESCENT\\nθt−1 gradient step−η∇θJ(θt−1)\\nmomentum\\n−γv\\nt−1\\ncập nhật\\nθt = θt−1−γvt−1−η∇θJ(θt−1)\\n(a) Momentum gradient descent. (b) Nesterov accelerated gradient.\\nθt−1\\ngradient step:\\n−η∇θJ(θt−1 −γvt−1)\\nmomentum\\n−γv\\nt−1\\ncập nhậtθt =\\nθt−1−γvt−1−η∇θJ(θt−1 −γvt−1)\\nToạ độ điểm tính đạo hàm khác đi một chút\\nHình 12.11: Ý tưởng của Nesterov accelerated gradient.\\ndef GD_momentum(grad, theta_init, eta, gamma):\\n# Suppose we want to store history of theta\\ntheta = [theta_init]\\nv_old = np.zeros_like(theta_init)\\nfor it in range(100):\\nv_new = gamma*v_old + eta*grad(theta[-1])\\ntheta_new = theta[-1] - v_new\\nif np.linalg.norm(grad(theta_new))/np.array(theta_init).size < 1e-3:\\nbreak\\ntheta.append(theta_new)\\nv_old = v_new\\nreturn theta\\n12.5 Nesterov accelerated gradient\\nMomentum giúphòn bivượt qua đượcdốc local minimum. Tuy nhiên, có một hạn chế chúng\\nta có thể thấy trong ví dụ trên: khi tới gầnđích, momemtum vẫn mất khá nhiều thời gian\\ntrước khi dừng lại, cũng chính vì cóđà. Một kỹ thuật có tênNesterov accelerated gradient\\n(NAG) [Nes07] giúp cho thuật toán momentum GD hội tụ nhanh hơn.\\nÝ tưởng chính\\nÝ tưởng trung tâm của thuật toán làdự đoán vị trí của nghiệm trước một bước. Cụ thể, nếu\\nsử dụng số hạngmomentum γvt−1 để cập nhật thì ta có thểxấp xỉ được vị trí tiếp theo của\\nnghiệm là θ−γvt−1. Vậy, thay vì sử dụng gradient của điểm hiện tại, NAGđi trước một\\nbước, sử dụng gradient của điểmđược dự đoán làvị trí tiếp theo. Ý tưởng này được thể hiện\\ntrên Hình 12.11.\\n• Với momentum thông thường,lượng thay đổilà tổng của hai vector: momentum vector\\nvà gradient ở thời điểm hiện tại.\\n• Với Nesterove momentum,lượng thay đổi là tổng của hai vector: momentum vector và\\ngradient của điểm được dự đoán là vị trí tiếp theo.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 163, 'page_label': '152'}, page_content='CHƯƠNG 12. GRADIENT DESCENT 152\\nSự khác nhau giữa momentum và NAG nằm ở điểm lấy đạo hàm. Ở momentum, điểm được\\nlấy đạo hàm chính là vị trí hiện tại của nghiệm. Ở NAG, điểm được lấy đạo hàm là điểmcó\\nđược nếu sử dụng momentum.\\nCông thức cập nhật\\nCông thức cập nhật của NAG được cho như sau:\\nvt = γvt−1 + η∇θJ(θ−γvt−1) (12.10)\\nθ←θ−vt (12.11)\\nĐoạn code dưới đây là hàm cho NAG.\\ndef GD_NAG(grad, theta_init, eta, gamma):\\ntheta = [theta_init]\\nv = [np.zeros_like(theta_init)]\\nfor it in range(100):\\nv_new = gamma*v[-1] + eta*grad(theta[-1] - gamma*v[-1])\\ntheta_new = theta[-1] - v_new\\nif np.linalg.norm(grad(theta_new))/np.array(theta_init).size < 1e-3:\\nbreak\\ntheta.append(theta_new)\\nv.append(v_new)\\nreturn theta\\nVí dụ minh họa\\nChúng ta cùng áp dụng cả GD với momentum và GD với NAG cho bài toán linear regression\\nđề cập ở trên. Hình 12.12 thể hiện đường đi của nghiệm khi sử dụng hai phương pháp này.\\nHình 12.12a là đường đi của nghiệm với phương pháp momentum. Nghiệm đi kházigzag và\\nmất nhiều vòng lặp hơn. Hình 12.12b là đường đi của nghiệm với phương pháp NAG, nghiệm\\nhội tụ nhanh hơn, và đường đi ítzigzag hơn.\\n12.6 Stochastic gradient descent\\n12.6.1 Batch gradient descent\\nThuật toán GD được đề cập từ đầu chương tới hiện tại còn được gọi làbatch GD. Batch ở\\nđây được hiểu làtất cả, tức khi cập nhật các tham sốθ, chúng ta sử dụngtất cảcác điểm\\ndữ liệu xi. Hạn chế của việc này là khi lượng cơ sở dữ liệu lớn, có thể tới hàng triệu, việc\\ntính toán đạo hàm trên toàn bộ dữ liệu tại mỗi vòng lặp sẽ tốn rất nhiều thời gian.\\nOnline learninglà khi cơ sở dữ liệu được cập nhật liên tục, mỗi lần tăng thêm vài điểm dữ\\nliệu mới, yêu cầu cập nhật mô hình mới. Kéo theo đó là mô hình cũng phải được thay đổi\\nmột chút để phù hợp với dữ liệu mới. Nếu làm theo batch GD, tức tính lại đạo hàm của hàm\\nmất mát tại tất cả các điểm dữ liệu, độ phức tạp tính toán sẽ rất cao. Lúc đó, thuật toán\\ncó thể không còn mang tínhonline nữa do mất quá nhiều thời gian tính toán.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 163, 'page_label': '152'}, page_content='mất mát tại tất cả các điểm dữ liệu, độ phức tạp tính toán sẽ rất cao. Lúc đó, thuật toán\\ncó thể không còn mang tínhonline nữa do mất quá nhiều thời gian tính toán.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 164, 'page_label': '153'}, page_content='153 CHƯƠNG 12. GRADIENT DESCENT\\n2 3 4 5 6\\n0.5\\n1.0\\n1.5\\n2.0\\n2.5\\n3.0\\n3.5\\n4.0\\n4.5\\n101 iterations\\n(a) GD với momentum.\\n2 3 4 5 6\\n0.5\\n1.0\\n1.5\\n2.0\\n2.5\\n3.0\\n3.5\\n4.0\\n4.5\\n28 iterations (b) GD với NAG.\\nHình 12.12: Đường đi của nghiệm cho bài toán linear regression với hai phương pháp gradient\\ndescent khác nhau. NAG cho nghiệm mượt hơn và nhanh hơn.\\nMột thuật toán đơn giản hơn, chấp nhận việc có sai số một chút nhưng lại lợi ích tính toán\\ncao, thường được sử dụng có tên gọi làstochastic gradient descent(SGD).\\n12.6.2 Stochastic gradient descent\\nTrong SGD, tại một thời điểm (vòng lặp–iteration), ta chỉ tính đạo hàm của hàm mất mát\\ndựa trênchỉ mộtđiểm dữ liệuxi rồi cập nhậtθdựa trên đạo hàm này. Chú ý rằng hàm mất\\nmát thường được lấy trung bình trên mỗi điểm dữ liệu nên đạo hàm tại một điểm cũngđược\\nkỳ vọnglà khá gần với đạo hàm của hàm mất mát trên mọi điểm dữ liệu. Sau khi duyệt qua\\ntất cả các điểm dữ liệu, thuật toán lặp lại quá trình trên. Biến thể đơn giản này trên thực\\ntế làm việc rất hiệu quả.\\nepoch\\nMỗi lần duyệt một lượt quatất cả các điểm trên toàn bộ dữ liệu được gọi là mộtepoch (số\\nnhiều epoches). Với GD thông thường, mỗi epoch ứng với một lần cập nhậtθ. Với SGD, mỗi\\nepoch ứng vớiN lần cập nhậtθ với N là số điểm dữ liệu. Nhìn vào một mặt, việc cập nhật\\ntừng điểm một như thế này có thể làm giảm đi tốc độ thực hiện một epoch. Nhưng nhìn vào\\nmột mặt khác, với SGD, nghiệm có thể hội tụ sau vài epoch. Vì vậy, SGD phù hợp với các\\nbài toán có lượng cơ sở dữ liệu lớn và các bài toán yêu cầu mô hình thay đổi liên tục như\\nonline learning. Với một mô hình đã được huấn luyện từ trước, khi có thêm dữ liệu, ta có\\nthể chỉ cần chạy thêm một vài epoch nữa là đã có nghiệm hội tụ.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 165, 'page_label': '154'}, page_content='CHƯƠNG 12. GRADIENT DESCENT 154\\n0 500 1000 1500 2000 2500\\nnumber of iterations\\n4\\n5\\n6\\n7\\n8\\n9loss function\\nHình 12.13: Ví dụ về giá\\ntrị hàm mất mát sau mỗi\\niteration khi sử dụng mini-\\nbatch gradient descent. Hàm\\nmất mátnhảy lên nhảy xuống\\n(fluctuate) sau mỗi lần cập\\nnhật nhưng nhìn chung giảm\\ndần và có xu hướng hội tụ.\\nThứ tự lựa chọn điểm dữ liệu\\nMột điểm cần lưu ý đó là sau mỗi epoch, chúng ta cầnxáo trộn(shuffle) thứ tự của các dữ\\nliệu để đảm bảo tính ngẫu nhiên. Việc này cũng ảnh hưởng tới hiệu năng của SGD. Đây\\ncũng chính là lý do thuật toán này có chứa từstochastic (ngẫu nhiên).\\nMột cách toán học, quy tắc cập nhật của SGD là\\nθ←θ−η∇θJ(θ; xi,yi) (12.12)\\ntrong đóJ(θ; xi,yi) ≜Ji(θ) là hàm mất mát với chỉ một điểm dữ liệu thứi. Các thuật toán\\nbiến thể của GD như momentum hay NAG hoàn toàn có thể được áp dụng vào SGD.\\n12.6.3 Mini-batch gradient descent\\nKhác với SGD, mini-batch sử dụng một số lượngk lớn hơn một (nhưng vẫn nhỏ hơn tổng\\nsố điểm dữ liệuN rất nhiều) để cập nhật ở mỗiiteration. Giống với SGD, mini-batch GD\\nbắt đầu mỗi epoch bằng việc xáo trộn ngẫu nhiên dữ liệu rồi chia toàn bộ dữ liệu thành các\\nmini-batch, mỗi mini-batch có k điểm dữ liệu (trừ mini-batch cuối có thể có ít hơn nếuN\\nkhông chia hết chok). Ở mỗi vòng lặp, thuật toán này lấy ra một mini-batch để tính toán\\nđạo hàm rồi cập nhật. Một epoch cũng là khi thuật toán chạy hết dữ liệu một lượt. Như vậy,\\nmột epochbao gồm xấp xỉN/k lần iteration. Mini-batch GD được sử dụng trong hầu hết\\ncác thuật toán machine learning, đặc biệt là trong deep learning. Giá trịk được gọi làbatch\\nsize (không phảimini-batch size) thường được chọn là khoảng từ vài chục đến vài trăm.\\nHình 12.13 là ví dụ về giá trị của hàm mất mát của một bài toán khác phức tạp hơn mỗi\\nkhi cập nhật tham sốθ khi sử dụng mini-batch gradient descent. Mặc dù giá trị của hàm\\nmất mát sau các vòng lặp không phải lúc nào cũng giảm, chúng ta vẫn thấy rằng giá trị này\\ncó xu hướng giảm và hội tụ.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 166, 'page_label': '155'}, page_content='155 CHƯƠNG 12. GRADIENT DESCENT\\n12.7 Thảo luận\\n12.7.1 Điều kiện dừng thuật toán\\nCó một điểm chúng ta chưa đề cập kỹ–khi nào thì nên dừng thuật toán gradient descent?\\nTrong thực nghiệm, chúng ta có thể kết hợp các phương pháp sau.\\n1. Giới hạn số vòng lặp. Một nhược điểm của cách làm này là có thể thuật toán dừng lại\\ntrước khi nghiệm đủ tốt. Tuy nhiên, đây là phương pháp phổ biến nhất và cũng để đảm\\nbảo rằng chương trình chạy không quá lâu.\\n2. So sánh gradient của nghiệm tại hai lần cập nhật liên tiếp, khi nào giá trị này đủ nhỏ\\nthì dừng lại. Phương pháp này cũng có một nhược điểm lớn là việc tính đạo hàm đôi khi\\ntrở nên quá phức tạp.\\n3. So sánh giá trị của hàm mất mát của nghiệm tại hai lần cập nhật liên tiếp, khi nào giá\\ntrị này đủ nhỏ thì dừng lại. Nhược điểm của phương pháp này là nếu tại một thời điểm,\\nđồ thị hàm số có dạngbẳng phẳngtại một khu vực nhưng khu vực đó không chứa điểm\\nlocal minimum, thuật toán cũng dừng lại trước khi đạt giá trị mong muốn.\\n4. Vừa chạy gradient descent, vừa kiểm tra kết quả. Một kỹ thuật thường được sử dụng\\nnữa là cho thuật toán chạy với số lượng vòng lặp cực lớn. Trong quá trình chạy, chương\\ntrình thường xuyên kiểm tra chất lượng mô hình bằng cách áp dụng nó lên dữ liệu tập\\nhuấn luyện và/hoặc validation. Đồng thời, mô hình sau một vài vòng lặp được lưu lại\\ntrong bộ nhớ. Mô hình tốt nhất có thể không phải là mô hình với số vòng lặp lớn hơn.\\n12.7.2 Đọc thêm\\nSource code trong chương này có thể được tìm thấy tạihttps://goo.gl/RJrRv7 .\\nNgoài các thuật toán đã đề cập trong chương này, rất nhiều thuật toán khác giúp cải thiện\\ngradient descent được đề xuất gần đây [Rud16]. Bạn đọc có thể đọc thêm AdaGrad [DHS11],\\nRMSProp [TH12], Adam [KB14], v.v..\\nCác trang web và video dưới đây cũng là các tài liệu tốt cho gradient descent.\\n1. An overview of gradient descent optimization algorithms(https://goo.gl/AGwbbg ).\\n2. Stochastic Gradient descent–Wikipedia(https://goo.gl/pmuLzk ).\\n3. Stochastic gradient descent–Andrew Ng(https://goo.gl/jgBf2N ).'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 166, 'page_label': '155'}, page_content='2. Stochastic Gradient descent–Wikipedia(https://goo.gl/pmuLzk ).\\n3. Stochastic gradient descent–Andrew Ng(https://goo.gl/jgBf2N ).\\n4. An Interactive Tutorial on Numerical Optimization(https://goo.gl/t85mvA ).\\n5. Machine Learning cơ bản, Bài 7, 8(https://goo.gl/US17PP ).\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 167, 'page_label': '156'}, page_content='Chương 13\\nPerceptron learning algorithm\\n13.1 Giới thiệu\\nTrong chương này, chúng ta cùng tìm hiểu một trong các thuật toán đầu tiên trong lịch sử\\nmachine learning. Đây là một thuật toán phân lớp đơn giản có tên làperceptron learning\\nalgorithm (PLA [Ros57]). Thuật toán này được thiết kế cho bài toánphân lớp nhị phân\\n(binary classification) với chỉ hai lớp dữ liệu. Đây là nền tảng cho các thuật toán liên quan\\ntới neural networks rồi deep learning sau này.\\nGiả sử có hai class đã được gán nhãn được minh hoạ trong Hình 13.1a tương ứng với tập\\ncác điểm màu xanh và tập các điểm màu đỏ. Bài toán đặt ra là từ dữ liệu của hai tập được\\ngán nhãn cho trước, hãy xây dựng một bộ phân lớp có khả năng dự đoán được nhãn (màu)\\ncủa một điểm dữ liệu mới, chẳng hạn điểm màu xám.\\nNếu coi mỗi vector đặc trưng là một điểm trong không gian nhiều chiều, bài toán phân lớp\\ncó thể được coi như bài toán xác định mỗi điểm trong không gian thuộc vào lớp nào. Nói\\ncách khác, nếu ta coi mỗi lớpchiếm một hoặc vài vùnglãnh thổ trong không gian, ta cần\\nđi tìm ranh giới (boundary) giữa các vùng đó. Ranh giới đơn giản nhất trong không gian\\nhai chiều là một đường thẳng, trong không gian ba chiều là một mặt phẳng, trong không\\ngian nhiều chiều hơn là mộtsiêu mặt phẳnghoặc siêu phẳng(hyperplane). Những ranh giới\\nphẳng này được coi là đơn giản vì chúng có thể được biểu diễn dưới dạng toán học bằng\\nmột hàm số tuyến tính. Tất nhiên, ta đang giả sử rằng tồn tại một siêu phẳng như vậy.\\nHình 13.1b minh họa một đường thẳng phân chia hai lớp trong không gian hai chiều. Lãnh\\nthổ của hai lớp xanh và đỏ được mô tả bởi hai nửa mặt phẳng với màu tương ứng. Trong\\ntrường hợp này, điểm dữ liệu mới hình tam giác được phân vào lớp đỏ.\\nPerceptron learning algorithm (PLA) là một thuật toán đơn giản giúp tìm một ranh giới\\nsiêu phẳng cho bài toán phân lớp nhị phân, với giả sử rằng tồn tại ranh giới phẳng đó. Nếu\\nhai lớp dữ liệu có thể được phân chia hoàn toàn bằng một siêu phẳng, ta nói rằng hai lớp\\nđó linearly separable.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 168, 'page_label': '157'}, page_content='157 CHƯƠNG 13. PERCEPTRON LEARNING ALGORITHM\\nx1\\nx2\\n?\\n(a)\\nx1\\nx2\\n (b)\\nHình 13.1:Bài toán phân lớp nhị phân trong không gian hai chiều. (a) Cho hai lớp dữ liệu vuông\\nxanh và tròn đỏ, hãy xác định điểm dữ liệu tam giác xám thuộc lớp nào. (b) Ví dụ về một ranh\\ngiới phẳng của hai lớp, điểm tam giác được phân vào lớp đỏ với đường ranh giới này.\\n13.2 Thuật toán perceptron\\n13.2.1 Cách phân lớp của perceptron learning algorithm\\nGiả sử X = [x1,x2,..., xN] ∈Rd×N là ma trận chứa các điểm dữ liệu huấn luyện mà mỗi\\ncột xi là một điểm dữ liệu trong không giand chiều. Giả sử thêm các nhãn tương ứng với\\ntừng điểm dữ liệu được lưu trong một vector hàngy = [y1,y2,...,y N] ∈R1×N, vớiyi = 1\\nnếu xi thuộc lớp thứ nhất (vuông xanh) vàyi = −1 nếu xi thuộc lớp còn lại (tròn đỏ).\\nTại một thời điểm, giả sử ta tìm được ranh giới là một siêu phẳng có phương trình\\nfw(x) = w1x1 + ··· + wdxd + w0 = wTx + w0 = 0 (13.1)\\nvới w ∈Rd là vector hệ số vàw0 là số hạng tự do được gọi là bias. Bằng cách sử dụng bias\\ntrick (xem Mục 7.2.4), ta có thể coi phương trình siêu phẳng làfw(x) = wTx = 0 với x ở\\nđây được ngầm hiểu là vector đặc trưng mở rộng thêm một đặc trưng bằng 1. Vector hệ số\\nw cũng chính làvector pháp tuyếncủa siêu phẳngwTx = 0.\\nTrong không gian hai chiều, giả sử đường thẳngw1x1 + w2x2 + w0 = 0 chính là nghiệm cần\\ntìm như Hình 13.2a. Nhận xét rằng các điểm nằm về cùng một phía so với đường thẳng này\\nsẽ làm cho hàm sốfw(x) mang cùng dấu. Chỉ cần đổi dấu củaw nếu cần thiết, ta có thể\\ngiả sử các điểm nằm trong nửa mặt phẳng nền xanh mang dấu dương (+), các điểm nằm\\ntrong nửa mặt phẳng nền đỏ mang dấu âm (-). Các dấu này cũng tương đương với nhãny\\ncủa mỗi nhãn. Vậy nếuw là một nghiệm của bài toán perceptron, với một điểm dữ liệu mới\\nx chưa được gán nhãn, ta có thể xác định nhãn của nó bằng một phép toán đơn giản:\\nlabel(x) =\\n{\\n1 nếu wTx ≥0\\n−1 o.w. (13.2)\\nNói cách khác, label(x) = sgn(wTx) với sgn là hàm xác định dấu, giả sử rằng sgn(0) = 1.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 169, 'page_label': '158'}, page_content='CHƯƠNG 13. PERCEPTRON LEARNING ALGORITHM 158\\nx1\\nx2\\n+ -\\nw1x1\\n+\\nw2x2\\n+\\nw0\\n= 0\\n+ -\\nw1x1\\n+\\nw2x2\\n+\\nw0\\n= 0\\n(a) Đường thẳng phân chia không có lỗi.\\nx1\\nx2\\n+ -\\nw1x1 + w2x2 + w0 = 0 (b) Đường thẳng phân chia có lỗi tại các điểm khoanh tròn.\\nHình 13.2:Ví dụ về các đường thẳng trong không gian hai chiều: (a) một nghiệm của bài toán\\nPLA, (b) không phải nghiệm.\\n13.2.2 Xây dựng hàm mất mát\\nTiếp theo, chúng ta xây dựng một hàm mất mát với tham sốw bất kỳ. Vẫn trong không\\ngian hai chiều, giả sử đường thẳngw1x1 +w2x2 +w0 = 0 được cho như Hình 13.2b. Các điểm\\nđược khoanh tròn là các điểm bịphân lớp lỗi(misclassified). Ta luôn muốn rằng không có\\nđiểm nào bị phân lớp lỗi. Một cách tự nhiên, ta có thể sử dụng hàmđếm số lượng các điểm\\nbị phân lớp lỗi và tìm cách tối thiểu hàm số này.\\nXét một điểmxi bất kỳ với nhãnyi. Nếu nó bị phân lớp lỗi, ta phải có sgn(wTx) ̸= yi. Vì\\nhai giá trị này chỉ bằng1 hoặc −1, ta sẽ cóyisgn(wTx) = −1. Như vậy, hàm số đếm số\\nlượng điểm bị phân lớp lỗi có thể được viết dưới dạng\\nJ1(w) =\\n∑\\nxi∈M\\n(−yisgn(wTxi)) (13.3)\\ntrong đóMký hiệu tập các điểm bị phân lớp lỗi ứng với mỗiw. Mục đích cuối cùng là đi\\ntìm w sao cho không có điểm nào bị phân lớp lỗi, tứcJ1(w) = 0. Một điểm quan trọng, đây\\nlà một hàm số rời rạc nên rất khó được tối ưu. Chúng ta cần tìm một hàm mất mát khác\\nđể việc tối ưu khả thi hơn. Xét hàm mất mát\\nJ(w) =\\n∑\\nxi∈M\\n(−yiwTxi) (13.4)\\nHàm J(w) khác một chút với hàmJ1(w) ở chỗ hàm rời rạc sgn đã được lược bỏ. Ngoài ra,\\nkhi một điểm bị phân lớp lỗixi nằm càng xa ranh giới, giá trị−yiwTxi sẽ càng lớn, nghĩa\\nlà hàm mất mát sẽ lớn lên. Vì tổng vẫn được tính trên các tập điểm bị phân lớp lỗiM, giá\\ntrị nhỏ nhất của hàm mất mát này cũng bằng không nếu không có điểm nào bị phân lớp\\nlỗi. Vì vậy,J(w) được cho là tốt hơnJ1(w) vì nótrừng phạt rất nặng những điểmlấn sâu\\nsang lãnh thổ của lớp kia. Trong khi đó,J1() trừng phạt các điểm phân lớp lỗi một lượng\\nnhư nhau bằng một, bất kể chúng gần hay xa ranh giới.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 170, 'page_label': '159'}, page_content='159 CHƯƠNG 13. PERCEPTRON LEARNING ALGORITHM\\n13.2.3 Tối ưu hàm mất mát\\nTại một thời điểm, nếu ta chỉ quan tâm tới các điểm bị phân lớp lỗi thì hàm sốJ(w) khả vi\\ntại mọiw, vậy ta có thể sử dụng gradient descent hoặc stochastic gradient descent (SGD)\\nđể tối ưu hàm mất mát này. Chúng ta sẽ giải quyết bài toán tối ưu hàm mất mátJ(w) bằng\\nSGD bằng cách cập nhậtw tại mỗi vòng lặp dựa trên chỉ một điểm dữ liệu. Với chỉmột\\nđiểm dữ liệuxi bị phân lớp lỗi, hàm mất mát và đạo hàm của nó lần lượt là\\nJ(w; xi; yi) = −yiwTxi; ∇wJ(w; xi; yi) = −yixi (13.5)\\nVậy quy tắc cập nhậtw sử dụng SGD là\\nw ←w −η(−yixi) = w + ηyixi (13.6)\\nvới η là learning rate. Trong PLA,η được chọn bằng 1. Ta có một quy tắc cập nhật rất gọn:\\nwt+1 = wt + yixi (13.7)\\nNói cách khác, với mỗi điểmxi bị phân lớp lỗi, bằng cách nhân điểm đó với nhãnyi của nó,\\nlấy kết quả cộng vàow hiện tại, ta sẽ đượcw mới. Tiếp theo, ta thấy rằng\\nwT\\nt+1xi = (wt + yixi)Txi = wT\\nt xi + yi∥xi∥2\\n2 (13.8)\\nNếu yi = 1, vìxi bị phân lớp lỗi nênwT\\nt xi <0. Cũng vìyi = 1 nên yi∥xi∥2\\n2 = ∥xi∥2\\n2 ≥1 (chú\\ný xi là một vector đặc trưngmở rộngvới một phần tử bằng 1). Từ đó suy rawT\\nt+1xi >wT\\nt xi.\\nNói cách khác,−yiwT\\nt+1xi <−yiwT\\nt xi. Điều tương tự cũng xảy ra vớiyi = −1. Việc này chỉ\\nra rằng đường thẳng được mô tả bởiwt+1 có xu hướng khiến hàm mất mát tại điểm bị phân\\nlớp lỗixi giảm đi.Chú ý rằng việc này không đảm bảo hàm mất mát trên toàn bộ dữ liệu sẽ\\ngiảm, vì rất có thể đường thẳng mới sẽ làm cho một điểm lúc trước được phân lớp đúng trở\\nthành một điểm bị phân lớp sai. Tuy nhiên, thuật toán này được đảm bảo sẽ hội tụ sau một\\nsố hữu hạn bước.Thuật toán perceptron được tóm tắt dưới đây.\\nThuật toán 13.1: Perceptron\\n1. Tại thời điểmt= 0, chọn ngẫu nhiên một vector hệ sốw0.\\n2. Tại thời điểmt, nếu không có điểm dữ liệu nào bị phân lớp lỗi, dừng thuật toán.\\n3. Giả sửxi là một điểm bị phân lớp lỗi. Cập nhật\\nwt+1 = wt + yixi\\n4. Thay đổit= t+ 1 rồi quay lại Bước 2.\\n13.2.4 Chứng minh hội tụ'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 170, 'page_label': '159'}, page_content='3. Giả sửxi là một điểm bị phân lớp lỗi. Cập nhật\\nwt+1 = wt + yixi\\n4. Thay đổit= t+ 1 rồi quay lại Bước 2.\\n13.2.4 Chứng minh hội tụ\\nGọi w∗là một nghiệm của bài toán phân lớp nhị phân với hai lớp linearly separable. Nghiệm\\nnày luôn tồn tại khi hai lớp là linearly separable. Ta sẽ chứng minh Thuật toán 13.1 kết thúc\\nsau một số hữu hạn bước bằng phản chứng.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 171, 'page_label': '160'}, page_content='CHƯƠNG 13. PERCEPTRON LEARNING ALGORITHM 160\\nGiả sử ngược lại, tồn tại mộtw mà Thuật toán 13.1 chạy mãi mãi. Trước hết ta thấy rằng,\\nvới α >0 bất kỳ, nếuw∗ là nghiệm,αw∗ cũng là nghiệm của bài toán. Xét dãy số không\\nâm uα(t) = ∥wt −αw∗∥2\\n2. Theo giả thiết phản chứng, tồn tại một điểm bị phân lớp lỗi khi\\ndùng nghiệmwt. Giả sử đó là điểmxi với nhãnyi. Ta có\\nuα(t+ 1) = ∥wt+1 −αw∗∥2\\n2 (13.9)\\n= ∥wt + yixi −αw∗∥2\\n2 (13.10)\\n= ∥wt −αw∗∥2\\n2 + y2\\ni∥xi∥2\\n2 + 2yixT\\ni (wt −αw∗) (13.11)\\n<uα(t) + ∥xi∥2\\n2 −2αyixT\\ni w∗ (13.12)\\nDấu nhỏ hơn ở dòng cuối là vìy2\\ni = 1 và 2yixT\\ni wt <0. Nếu tiếp tục đặt\\nβ2 = max\\ni=1,2,...,N\\n∥xi∥2\\n2, γ = min\\ni=1,2,...,N\\nyixT\\ni w∗ (13.13)\\nvà chọnα= β2\\nγ , ta sẽ có0 ≤uα(t+ 1) <uα(t) + β2 −2αγ = uα(t) −β2. Ta có thể chọn giá\\ntrị này vì (13.12) đúng vớiα bất kỳ. Điều này chỉ ra rằng nếu luôn có điểm bị phân lớp lỗi\\nthì dãyuα(t) là một dãy giảm, bị chặn dưới bởi 0, và phần tử sau kém phần tử trước ít nhất\\nmột lượng làβ2 >0. Điều vô lý này chứng tỏ đến một lúc nào đó sẽ không còn điểm nào bị\\nphân lớp lỗi. Nói cách khác, thuật toán perceptron hội tụ sau một số hữu hạn bước.\\n13.3 Ví dụ và minh hoạ trên Python\\nThuật toán 13.1 có thể được triển khai như sau:\\nimport numpy as np\\ndef predict(w, X):\\n’’’ predict label of each row of X, given w\\nX: a 2-d numpy array of shape (N, d), each row is a datapoint\\nw_init: a 1-d numpy array of shape (d) ’’’\\nreturn np.sign(X.dot(w))\\ndef perceptron(X, y, w_init):\\n’’’ perform perceptron learning algorithm\\nX: a 2-d numpy array of shape (N, d), each row is a datapoint\\ny: a 1-d numpy array of shape (N), label of each row of X. y[i] = 1/-1\\nw_init: a 1-d numpy array of shape (d) ’’’\\nw = w_init\\nwhile True:\\npred = predict(w, X)\\n# find indexes of misclassified points\\nmis_idxs = np.where(np.equal(pred, y) == False)[0]\\n# number of misclassified points\\nnum_mis = mis_idxs.shape[0]\\nif num_mis == 0: # no more misclassified points\\nreturn w\\n# random pick one misclassified point\\nrandom_id = np.random.choice(mis_idxs, 1)[0]\\n# update w'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 171, 'page_label': '160'}, page_content='num_mis = mis_idxs.shape[0]\\nif num_mis == 0: # no more misclassified points\\nreturn w\\n# random pick one misclassified point\\nrandom_id = np.random.choice(mis_idxs, 1)[0]\\n# update w\\nw = w + y[random_id]*X[random_id]\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 172, 'page_label': '161'}, page_content='161 CHƯƠNG 13. PERCEPTRON LEARNING ALGORITHM\\n3\\n 2\\n 1\\n 0 1 2 3\\n1\\n0\\n1\\n2\\niter 1/6\\n3\\n 2\\n 1\\n 0 1 2 3\\n1\\n0\\n1\\n2\\niter 2/6\\n3\\n 2\\n 1\\n 0 1 2 3\\n1\\n0\\n1\\n2\\niter 3/6\\n3\\n 2\\n 1\\n 0 1 2 3\\n1\\n0\\n1\\n2\\niter 4/6\\n3\\n 2\\n 1\\n 0 1 2 3\\n1\\n0\\n1\\n2\\niter 5/6\\n3\\n 2\\n 1\\n 0 1 2 3\\n1\\n0\\n1\\n2\\niter 6/6\\nHình 13.3:Minh hoạ thuật toán perceptron. Các điểm màu lam thuộc lớp1, các điểm màu đỏ\\nthuộc lớp −1. Tại mỗi vòng lặp, đường thẳng màu đen là đường ranh giới. Vector màu lục là\\nwt. Điểm được khoanh tròn là một điểm bị phân lớp lỗixi. Vector màu cam thể hiện vectorxi.\\nVector màu đỏ chính làwt+1. Nếuyi = 1 (màu lam), vector màu đỏ bằng tổng hai vector kia.\\nNếu yi = −1, vector màu đỏ bằng hiệu hai vector kia.\\nTrong đó, hàmpredict(w, X) dự đoán nhãn của mỗi hàng củaX dựa trên công thức (13.2).\\nHàm perceptron(X, y, w_init) thực hiện thuật toán PLA với tập dữ liệuX, nhãny và nghiệm\\nban đầuw_init.\\nĐể kiểm tra đoạn code trên, ta áp dụng nó vào một ví dụ với dữ liệu trong không gian hai\\nchiều như dưới đây.\\nmeans = [[-1, 0], [1, 0]]\\ncov = [[.3, .2], [.2, .3]]\\nN = 10\\nX0 = np.random.multivariate_normal(means[0], cov, N)\\nX1 = np.random.multivariate_normal(means[1], cov, N)\\nX = np.concatenate((X0, X1), axis = 0)\\ny = np.concatenate((np.ones(N), -1*np.ones(N)))\\nXbar = np.concatenate((np.ones((2*N, 1)), X), axis = 1)\\nw_init = np.random.randn(Xbar.shape[1])\\nw = perceptron(Xbar, y, w_init)\\nMỗi lớp có 10 phần tử, là các vector ngẫu nhiên lấy theo phân phối chuẩn có ma trận hiệp\\nphương saicov và vector kỳ vọng được lưu trongmeans. Hình 13.3 minh hoạ nghiệm sau mỗi\\nvòng lặp. Ta thấy rằng perceptron cho bài toán này hội tụ sau chỉ sau sáu vòng lặp.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 173, 'page_label': '162'}, page_content='CHƯƠNG 13. PERCEPTRON LEARNING ALGORITHM 162\\n1x0\\nx1\\nx2\\nx3\\nxd\\nΣ\\nz y\\nw0\\nw1\\nw2\\nw3\\nwd\\nz =\\nd∑\\ni=0\\nwixi = wT x\\ny = sgn(z)\\n(a)\\nInput layer Output layer (b)\\nInput layer Output layer (c)\\nHình 13.4: Biểu diễn perceptron và linear regression dưới dạng neural network. (a) perceptron\\nđầy đủ, (b) perceptron thu gọn, (c) linear regression thu gọn.\\n13.4 Mô hình neural network đầu tiên\\nHàm số dự đoán đầu ra của perceptron label(x) = sgn(wTx) có thể được mô tả trên\\nHình 13.4a. Đây chính là dạng đơn giản của neural network.\\nĐầu vào của networkx được minh họa bằng cácnode màu lục với nodex0 luôn luôn bằng\\n1. Tập hợp các node màu lục được gọi làtầng đầu vào(input layer). Số node trong input\\nlayer làd+1 . Đôi khi nodex0 = 1này được ẩn đi. Cáctrọng số w0,w1,...,w d được gán vào\\ncác mũi tên đi tới nodez = ∑d\\ni=0 wixi = wTx. Nodey = sgn(z) là output của network. Ký\\nhiệu hình chữ Z ngược màu lam trong nodey thể hiện đồ thị của hàm sgn. Hàmy= sgn(z)\\nđóng vai trò là mộthàm kích hoạt(activation function). Dữ liệu đầu vào được đặt vào input\\nlayer, lấy tổng có trọng số lưu vào biếnz rồi đi qua hàm kích hoạt để có kết quả ởy. Đây\\nchính là dạng đơn giản nhất của một neural network. Perceptron cũng có thể được vẽ giản\\nlược như Hình 13.4b, với ẩn ý rằng dữ liệu ở input layer được lấy tổng có trọng số trước khi\\nđi qua hàm lấy dấuy= sgn(z).\\nCác neural network có thể có một hoặc nhiều node ở output tạo thành mộttầng đầu ra\\n(output layer), hoặc có thể có thêm các layer trung gian giữainput layer và output layer,\\nđược gọi làtầng ẩn(hidden layer). Các neural network thường có nhiều hidden layer và các\\nlayer có thể có các hàm kích hoạt khác nhau. Chúng ta sẽ đi sâu vào các neural network\\nvới nhiều hidden layer ở Chương 16. Trước đó, chúng ta sẽ tìm hiểu các neural network đơn\\ngiản hơn không có hidden layer.\\nĐể ý rằng nếu ta thayactivation function bởi hàm identity y = z, ta sẽ có một neural\\nnetwork mô tả linear regression như Hình 13.4c. Với đường thẳng chéo màu xanh thể hiện'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 173, 'page_label': '162'}, page_content='Để ý rằng nếu ta thayactivation function bởi hàm identity y = z, ta sẽ có một neural\\nnetwork mô tả linear regression như Hình 13.4c. Với đường thẳng chéo màu xanh thể hiện\\nđồ thị hàm sốy= z. Các trục tọa độ đã được lược bỏ.\\nMô hình perceptron ở trên khá giống với một node nhỏ của dây thần kinh sinh học như\\nHình 13.5.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 174, 'page_label': '163'}, page_content='163 CHƯƠNG 13. PERCEPTRON LEARNING ALGORITHM\\nHình 13.5:Cấu trúc của một neuron thần kinh sinh học. Nguồn:Single-Layer Neural Networks\\nand Gradient Descent(https://goo.gl/RjBREb ).\\nDữ liệu từ nhiều dây thần kinh (tương tự nhưxi) đi về mộtcell nucleus. Cell nucleus đóng\\nvai trò như bộ lấy tổng có trọng số∑d\\ni=0 wixi. Thông tin này sau đó được tổng hợp (tương\\ntự như hàm kích hoạt) và đưa ra ở output. Tên gọineural network hoặc artificial neural\\nnetwork được khởi nguồn từ đây.\\n13.5 Thảo Luận\\nPLA có thể cho vô số nghiệm khác nhau.Nếu hai lớp dữ liệu là linearly separable thì\\ncó vô số đường thằng ranh giới của hai lớp dữ liệu đó như trên Hình 13.6a. Tất cả các đường\\nthẳng màu đen đều có thể đóng vài trò là đường ranh giới. Tuy nhiên, các đường khác nhau\\nsẽ quyết định điểm hình tam giác thuộc các lớp khác nhau. Trong các đường đó, đường nào\\nlà tốt nhất? Và định nghĩa “tốt nhất” được hiểu theo nghĩa nào? Các câu hỏi này sẽ được\\nthảo luận kỹ hơn trong Chương 26.\\nPLA đòi hỏi hai lớp dữ liệu phải linearly separable.Hình 13.6b mô tả hai lớp dữ liệu\\ntương đối linearly separable. Mỗi lớp có một điểm coi nhưnhiễu nằm lẫn trong các điểm\\ncủa lớp kia. PLA sẽ không làm việc, tức không bao giờ dừng lại, trong trường hợp này vì\\nvới mọi đường thẳng ranh giới, luôn có ít nhất hai điểm bị phân lớp lỗi.\\nTrong một chừng mực nào đó, đường thẳng màu đen vẫn có thể coi là một nghiệm tốt vì\\nnó đã giúp phân loại chính xác hầu hết các điểm. Việc không hội tụ với dữ liệugần linearly\\nseparable chính là một nhược điểm lớn của PLA.\\nNhược điểm này có thể được khắc phục bằngpocket algorithmdưới đây.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 175, 'page_label': '164'}, page_content='CHƯƠNG 13. PERCEPTRON LEARNING ALGORITHM 164\\nx1\\nx2\\n(a)\\nx1\\nx2\\n (b)\\nHình 13.6: Với bài toán phân lớp nhị phân, PLA có thể (a) cho vô số nghiệm, hoặc (b) vô\\nnghiệm thậm chí với chỉ một nhiễu nhỏ.\\nPocket algorithm [AMMIL12]:một cách tự nhiên, nếu có một vàinhiễu, ta sẽ đi tìm\\nmột đường thẳng phân chia hai class sao cho có ít điểm bị phân lớp lỗi nhất. Việc này có\\nthể được thực hiện thông qua PLA với một chút thay đổi nhỏ:\\n1. Giới hạn số lượng vòng lặp của PLA. Đặt nghiệmw sau vòng lặp đầu tiên và số điểm bị\\nphân lớp lỗi vào trongtúi quần (pocket).\\n2. Mỗi lần cập nhật nghiệmwt mới, ta đếm xem có bao nhiêu điểm bị phân lớp lỗi. So sánh\\nsố điểm bị phân lớp lỗi này với số điểm bị phân lớp lỗi trongpocket, nếu nhỏ hơn thì lấy\\nnghiệm cũ ra, đặt nghiệm mới này vào. Lặp lại bước này đến khi hết số vòng lặp.\\nThuật toán này giống với thuật toán tìm phần tử nhỏ nhất trong một mảng một chiều.\\nSource code cho chương này có thể được tìm thấy tạihttps://goo.gl/tisSTq .\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 176, 'page_label': '165'}, page_content='Chương 14\\nLogistic regression\\n14.1 Giới thiệu\\n14.1.1 Nhắc lại hai mô hình tuyến tính\\nHai mô hình tuyến tính đã thảo luận trong cuốn sách này, linear regression và perceptron\\n(PLA), đều có thể viết chung dưới dạngy = f(wTx) với f(s) là một hàm kích hoạt. Với\\nf(s) = s trong linear regression, vàf(s) = sgn(s) trong PLA. Trong linear regression, tích\\nvô hướngwTx được trực tiếp sử dụng để dự đoán outputy, loại này phù hợp nếu ta cần dự\\nđoán một đầu ra không bị chặn trên và dưới. Trong PLA, đầu ra chỉ nhận một trong hai\\ngiá trị 1 hoặc −1, phù hợp với các bài toán phân lớp nhị phân. Trong chương này, chúng\\nta sẽ thảo luận một mô hình tuyến tính với một hàm kích hoạt khác, thường được áp dụng\\ncho các bài toán phân lớp nhị phân. Trong mô hình này, đầu ra có thể được thể hiện dưới\\ndạng xác suất. Ví dụ, xác suất thi đỗ nếu biết thời gian ôn thi, xác suất ngày mai có mưa\\ndựa trên những thông tin đo được trong ngày hôm nay, v.v.. Mô hình này có tên làlogistic\\nregression. Mặc dù trong tên có chứa từregression, logistic regression thường được sử dụng\\nnhiều hơn cho các bài toán phân lớp.\\n14.1.2 Một ví dụ nhỏ\\nBảng 14.1: Thời gian ôn thi (Hours) và kết quả thi của 20 sinh viên.\\nHours Pass Hours Pass Hours Pass Hours Pass\\n0.5 0 0.75 0 1 0 1.25 0\\n1.5 0 1.75 0 1.75 1 2 0\\n2.25 1 2.5 0 2.75 1 4 0\\n3.25 1 3.5 0 4 1 4.25 1\\n4.5 1 4.75 1 5 1 5.5 1\\nXét một ví dụ về sự liên quan giữa thời gian ôn thi và kết quả thi của 20 sinh viên được\\ncho trong Bảng 14.1. Bài toán đặt ra là từ dữ liệu này hãy xây dựng một mô hình đánh'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 177, 'page_label': '166'}, page_content='CHƯƠNG 14. LOGISTIC REGRESSION 166\\n0 1 2 3 4 5 6\\nhours studying\\n0\\n1fail(0) / pass(1)\\nHình 14.1: Ví dụ về kết quả thi\\ndựa trên số giờ ôn tập. Trục hoành\\nthể hiển thời gian ôn tập của mỗi\\nsinh viên, trục tung gồm hai giá trị\\n0/fail (các điểm màu đỏ) và 1/pass\\n(các điểm màu xanh).\\n0\\n1\\nhard threshold\\nf(s) = 1\\n1+e−s\\nf(s) = es\\nes+e−s\\nlinear\\nHình 14.2: Một vài ví dụ về\\ncác hàm kích hoạt khác nhau.\\ngiá khả năng đỗ của một sinh viên dựa trên thời gian ôn thi. Dữ liệu trong Bảng 14.1 được\\nmô tả trên Hình 14.1. Nhìn chung, thời gian học càng nhiều thì khả năng đỗ càng cao. Tuy\\nnhiên, không có một ngưỡng nào để có thể khẳng định rằng mọi sinh viên học nhiều thời\\ngian hơn ngưỡng đó sẽ chắc chắn đỗ. Nói cách khác, dữ liệu của hai lớp này là không linearly\\nseparable, và vì vậy PLA sẽ không hữu ích ở đây. Tuy nhiên, thay vì dự đoán chính xác hai\\ngiá trị đỗ/trượt, ta có thể dự đoán xác suất để một sinh viên thi đỗ dựa trên thời gian ôn\\nthi.\\n14.1.3 Mô hình logistic regression\\nQuan sát Hình 14.2 với các hàm kích hoạtf(s) khác nhau.\\n• Đường màu vàng biểu diễn một hàm kích hoạt tuyến tính. Đường này không bị chặn nên\\nkhông phù hợp cho bài toán đang xét với đầu ra là một giá trị trong khoảng[0,1].\\n• Đường màu đỏ tương tự với hàm kích hoạt của PLA với ngưỡng có thể khác không1.\\n• Các đường màu lam và lục phù hợp với bài toán đang xét hơn. Chúng có một vài tính\\nchất quan trọng:\\n– Là các hàm số liên tục nhận giá trị thực, bị chặn trong khoảng(0,1).\\n– Nếu coi điểm có tung độ là 1/2 là ngưỡng, các điểm càng xa ngưỡng về phía bên trái\\ncó giá trị càng gần 0, các điểm càng xa ngưỡng về phía bên phải có giá trị càng gần\\n1. Điều nàykhớp với nhận xét rằng học càng nhiều thì xác suất đỗ càng cao và ngược\\nlại.\\n– Hai hàm này có đạo hàm mọi nơi, vì vậy có thể được lợi trong việc tối ưu.\\n1 Đường này chỉ khác với activation function của PLA ở chỗ hai class là 0 và 1 thay vì -1 và 1.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 178, 'page_label': '167'}, page_content='167 CHƯƠNG 14. LOGISTIC REGRESSION\\nHàm sigmoid và tanh\\nTrong số các hàm số có ba tính chất nói trên, hàmsigmoid:\\nf(s) = 1\\n1 + e−s ≜σ(s) (14.1)\\nđược sử dụng nhiều nhất, vì nó bị chặn trong khoảng(0,1). Thêm nữa,\\nlim\\ns→−∞\\nσ(s) = 0; lim\\ns→+∞\\nσ(s) = 1 (14.2)\\nThú vị hơn,\\nσ′(s) = e−s\\n(1 + e−s)2 = 1\\n1 + e−s\\ne−s\\n1 + e−s = σ(s)(1 −σ(s)) (14.3)\\nVới đạo hàm đơn giản, hàm sigmoid được sử dụng rộng rãi trong neural network.Các bạn\\nsẽ sớm thấy hàm sigmoid được khám phá ra như thế nào.\\nNgoài ra, hàmtanh cũng hay được sử dụng: tanh(s) = es −e−s\\nes + e−s. Hàm số này nhận giá trị\\ntrong khoảng(−1,1). Bạn đọc có thể chứng minh được rằng tanh(s) = 2σ(2s) −1.\\nHàm sigmoid có thể được thực hiện trên Python như sau.\\ndef sigmoid(S):\\n\"\"\"\\nS: an numpy array\\nreturn sigmoid function of each element of S\\n\"\"\"\\nreturn 1/(1 + np.exp(-S))\\n14.2 Hàm mất mát và phương pháp tối ưu\\n14.2.1 Xây dựng hàm mất mát\\nVới các mô hình với hàm mất mát màu lam và lục như trên, ta có thể giả sử rằng xác suất\\nđể một điểm dữ liệux rơi vào lớp thứ nhất làf(wTx) và rơi vào lớp còn lại là1 −f(wTx):\\np(yi = 1|xi; w) = f(wTxi) (14.4)\\np(yi = 0|xi; w) = 1 −f(wTxi) (14.5)\\ntrong đóp(yi = 1|xi; w) được hiểu là xác suất xảy ra sự kiện đầu rayi = 1 khi biết tham\\nsố mô hìnhw và dữ liệu đầu vàoxi. Mục đích cuối cùng là là tìm các hệ sốw sao cho với\\ncác điểm dữ liệu ứng vớiyi = 1, f(wTxi) gần với 1, và ngược lại. Ký hiệuzi = f(wTxi), hai\\nbiểu thức (14.4) và (14.5) có thể được viết chung dưới dạng\\np(yi|xi; w) = zyi\\ni (1 −zi)1−yi (14.6)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 179, 'page_label': '168'}, page_content='CHƯƠNG 14. LOGISTIC REGRESSION 168\\nBiểu thức này tương đương với hai biểu thức (14.4) và (14.5) ở trên vì khiyi = 1, phần thứ\\nhai của vế phải sẽ bằng 1, khiyi = 0, phần thứ nhất sẽ bằng 1. Chúng ta muốn mô hình gần\\nvới dữ liệu đã cho nhất, tức xác suất này đạt giá trị cao nhất.\\nXét toàn bộ test set với ma trận dữ liệuX = [x1,x2,..., xN] ∈Rd×N và vector đầu ra tương\\nứng với mỗi cộty = [y1,y2,...,y N]. Ta cần giải bài toán tối ưu\\nw = arg max\\nw\\np(y|X; w) (14.7)\\nĐây chính là một bài toán maximum likelihood estimation với tham số mô hìnhw cần được\\nước lượng. Giả sử rằng các điểm dữ liệu được sinh ra một cách ngẫu nhiên độc lập với nhau,\\nta có thể viết\\np(y|X; w) =\\nN∏\\ni=1\\np(yi|xi; w) =\\nN∏\\ni=1\\nzyi\\ni (1 −zi)1−yi (14.8)\\nLấy logarit tự nhiên, đổi dấu, và lấy trung bình, ta thu được hàm số\\nJ(w) = −1\\nN log p(y|X; w) = −1\\nN\\nN∑\\ni=1\\n(yilog zi + (1 −yi) log(1−zi)) (14.9)\\nvới chú ý rằngzi là một hàm số củaw vàxi. Hàm số này chính là hàm mất mát của logistic\\nregression. Ta cần đi tìmw để J(w) đạt giá trị nhỏ nhất (vì ta đã đổi dấu của biểu thức\\ntrong dấuargmax của (14.7)).\\n14.2.2 Tối ưu hàm mất mát\\nBài toán tối ưu hàm mất mát của logistic regression có thể được giải quyết bằng stochastic\\ngradient descent (SGD). Tại mỗi vòng lặp,w sẽ được cập nhật dựa trên một điểm dữ liệu\\nngẫu nhiên. Hàm mất mát của logistic regression với chỉ một điểm dữ liệu(xi,yi) và đạo\\nhàm của nó lần lượt là\\nJ(w; xi,yi) = −(yilog zi + (1 −yi) log(1−zi)) (14.10)\\n∇wJ(w; xi,yi) = −(yi\\nzi\\n−1 −yi\\n1 −zi\\n)(∇wzi) = zi −yi\\nzi(1 −zi)(∇wzi) (14.11)\\nở đây ta đã sử dụng quy tắc chuỗi để tính đạo hàm vớizi = f(wTx). Để cho biểu thức này\\ntrở nêngọn và đẹp hơn, ta sẽ tìm hàmz = f(wTx) sao cho mẫu số bị triệt tiêu.\\nNếu đặts= wTx, ta sẽ có\\n∇wzi = ∂zi\\n∂s(∇ws) = ∂zi\\n∂sxi (14.12)\\nMột cách tự nhiên, ta sẽ tìm hàm sốz = f(s) sao cho:\\n∂z\\n∂s = z(1 −z) (14.13)\\nđể triệt tiêu mẫu số trong biểu thức (14.11). Phương trình vi phân này không quá phức tạp.\\nThật vậy, (14.13) tương đương với\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 180, 'page_label': '169'}, page_content='169 CHƯƠNG 14. LOGISTIC REGRESSION\\n∂z\\nz(1 −z) = ∂s\\n⇔ (1\\nz + 1\\n1 −z)∂z = ∂s\\n⇔ log z−log(1 −z) = s+ C\\n⇔ log z\\n1 −z = s+ C\\n⇔ z\\n1 −z = es+C\\n⇔ z = es+C(1 −z)\\n⇔ z = es+C\\n1 + es+C = 1\\n1 + e−s−C = σ(s+ C)\\nvới C là một hằng số. Đơn giản chọnC = 0, ta đượcz = f(wTx) = σ(s). Đây chính là lý\\ndo hàm sigmoid được ra đời. Logistic regression với hàm kích hoạt là hàm sigmoid được sử\\ndụng phổ biến nhất. Mô hình này còn có tên làlogistic sigmoid regression. Khi nói logistic\\nregression, ta ngầm hiểu rằng đó chính là logistic sigmoid regression.\\nThay (14.12) và (14.13) vào (14.11) ta thu được\\n∇wJ(w; xi,yi) = (zi −yi)xi = (σ(wTxi) −yi)xi (14.14)\\nVà công thức cập nhật nghiệm cho logistic sigmoid regression sử dụng SGD là\\nw ←w −η(zi −yi)xi = w −η(σ(wTxi) −yi)xi (14.15)\\nvới η là một learning rate dương.\\n14.2.3 Logistic regression với weight decay\\nMột trong các kỹ thuật phổ biến giúp tránh overfitting với các neural network là sử dụng\\nweight decay. Weight decay là một kỹ thuật regularization, trong đó một đại lượng tỉ lệ với\\nbình phương norm 2 của vector hệ số được cộng vào hàm mất mát để hạn chế độ lớn của\\ncác hệ số. Hàm mất mát trở thành\\n¯J(w) = 1\\nN\\nN∑\\ni=1\\n(\\n−yilog zi −(1 −yi) log(1−zi) + λ\\n2 ∥w∥2\\n2\\n)\\n(14.16)\\nCông thức cập nhật SGD chow với hàm này cũng đơn giản vì phần regularization có đạo\\nhàm đơn giản:\\nw ←w −η\\n(\\n(σ(wTxi) −yi)xi + λw\\n)\\n(14.17)\\n14.3 Triển khai thuật toán trên Python\\nHàm ước lượng xác suất cho mỗi điểm dữ liệu và hàm tính giá trị hàm mất mát với weight\\ndecay có thể được thực hiện như sau trong Python.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 181, 'page_label': '170'}, page_content='CHƯƠNG 14. LOGISTIC REGRESSION 170\\ndef prob(w, X):\\n\"\"\"\\nX: a 2d numpy array of shape (N, d). N datatpoint, each with size d\\nw: a 1d numpy array of shape (d)\\n\"\"\"\\nreturn sigmoid(X.dot(w))\\ndef loss(w, X, y, lam):\\n\"\"\"\\nX, w as in prob\\ny: a 1d numpy array of shape (N). Each elem = 0 or 1\\n\"\"\"\\nz = prob(w, X)\\nreturn -np.mean(y*np.log(z) + (1-y)*np.log(1-z)) + 0.5*lam/X.shape[0]*np.sum(w*w)\\nTừ công thức (14.17), ta có thể thực hiện thuật toán tìmw cho logistic regression như sau.\\ndef logistic_regression(w_init, X, y, lam = 0.001, lr = 0.1, nepoches = 2000):\\n# lam - reg paramether, lr - learning rate, nepoches - number of epoches\\nN, d = X.shape[0], X.shape[1]\\nw = w_old = w_init\\nloss_hist = [loss(w_init, X, y, lam)] # store history of loss in loss_hist\\nep = 0\\nwhile ep < nepoches:\\nep += 1\\nmix_ids = np.random.permutation(N)\\nfor i in mix_ids:\\nxi = X[i]\\nyi = y[i]\\nzi = sigmoid(xi.dot(w))\\nw = w - lr*((zi - yi)*xi + lam*w)\\nloss_hist.append(loss(w, X, y, lam))\\nif np.linalg.norm(w - w_old)/d < 1e-6:\\nbreak\\nw_old = w\\nreturn w, loss_hist\\n14.3.1 Logistic regression cho ví dụ ban đầu\\nÁp dụng vào bài toán ví dụ ban đầu.\\nX = np.array([[0.50, 0.75, 1.00, 1.25, 1.50, 1.75, 1.75, 2.00, 2.25, 2.50,\\n2.75, 3.00, 3.25, 3.50, 4.00, 4.25, 4.50, 4.75, 5.00, 5.50]]).T\\ny = np.array([0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1])\\n# bias trick\\nXbar = np.concatenate((X, np.ones((N, 1))), axis = 1)\\nw_init = np.random.randn(Xbar.shape[1])\\nlam = 0.0001\\nw, loss_hist = logistic_regression(w_init, Xbar, y, lam, lr = 0.05, nepoches = 500)\\nprint(w)\\nprint(loss(w, Xbar, y, lam))\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 182, 'page_label': '171'}, page_content='171 CHƯƠNG 14. LOGISTIC REGRESSION\\n0 1 2 3 4 5 6\\nstudying hours\\n−0.50\\n−0.25\\n0.00\\n0.25\\n0.50\\n0.75\\n1.00\\n1.25\\n1.50\\npredicted probability of pass\\n(a)\\n0 100 200 300 400 500\\nnumber of iterations\\n0.4\\n0.5\\n0.6\\n0.7\\n0.8\\n0.9\\n1.0\\n1.1\\nloss function (b)\\nHình 14.3: Nghiệm của logistic regression cho bài toán dự đoán kết quả thi dựa trên thời gian\\nhọc. (a) Đường màu lục thể hiện xác suất thi đỗ dựa trên thời gian học. Điểm tam giác vàng thể\\nhiện ngưỡng ra quyết định đỗ/trượt. Điểm này có thể thay đổi tuỳ vào bài toán. (b) Giá trị của\\nhàm mất mát qua các vòng lặp. Hàm mất mát giảm rất nhanh và hội tụ rất sớm.\\nKết quả:\\nSolution of Logistic Regression: [ 1.54337021 -4.06486702]\\nFinal loss: 0.402446724975\\nTừ đây ta có thể rút ra xác suất thi đỗ dựa trên công thức:\\nprobability_of_pass ≈sigmoid(1.54 * hours_of_studying - 4.06)\\nBiểu thức này cũng chỉ ra rằng xác suất thi đỗ tăng khi thời gian ôn tập tăng, do sigmoid\\nlà một hàm đồng biến. Nghiệm của mô hình logistic regression và giá trị hàm mất mát qua\\nmỗi epoch được mô tả trên Hình 14.3.\\n14.3.2 Ví dụ với dữ liệu hai chiều\\nChúng ta xét thêm một ví dụ nhỏ trong không gian hai chiều. Giả sử có hai lớp xanh và đỏ\\nvới dữ liệu được phân bố như Hình 14.4a. Với dữ liệu đầu vào nằm trong không gian hai\\nchiều, hàm sigmoid có dạng như thác nước như Hình 14.4b.\\nKết quả tìm được khi áp dụng mô hình logistic regression được minh họa như Hình 14.5 với\\nmàu nền thể hiện xác suất điểm đó thuộc class đỏ. Màu xanh đậm thể hiện giá trị 0, màu\\nđỏ đậm thể hiện giá trị rất gần với 1.\\nKhi phải lựa chọn một ranh giới thay vì xác suất, ta quan sát thấy các đường thẳng nằm\\ntrong khu vực lục và vàng là một lựa chọn hợp lý. Ta sẽ chứng minh ở phần sau rằng tập\\nhợp các điểm cho cùng xác suất đầu ra tạo thành một siêu phẳng.\\nSource code cho chương này có thể được tìm thấy tạihttps://goo.gl/9e7sPF.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 183, 'page_label': '172'}, page_content='CHƯƠNG 14. LOGISTIC REGRESSION 172\\nx1\\nx2\\n(a) Dữ liệu cho bài toán phân lớp trong không gian hai chiều.\\n(b) Đồ thị hàm sigmoid trong không gian hai chiều.\\nHình 14.4: Ví dụ về dữ liệu trong không gian hai chiều và hàm sigmoid trong không gian đó.\\nx1\\nx2\\nHình 14.5: Ví dụ về Logistic Re-\\ngression với dữ liệu hai chiều. Vùng\\nmàu đỏ càng đậm thể hiện xác suất\\nthuộc lớp dữ liệu đỏ càng cao, vùng\\nmàu xanh càng đậm thể hiện xác\\nsuất thuộc lớp dữ liệu đỏ càng thấp\\n- tức xác suất thuộc lớp dữ liệu\\nxanh càng cao. Vùng biên giữa hai\\nlớpthểhiệncácđiểmthuộcvàomỗi\\nlớp với xác suất thấp hơn (độ tin\\ncậy thấp hơn).\\nCách sử dụng logistic regression trong thư viện scikit-learn có thể được tìm thấy tại\\nhttps://goo.gl/BJLJNx.\\n14.4 Tính chất của logistic regression\\n1. Logistic Regression được sử dụng nhiều trong các bài toán Classification.\\nMặc dù trong tên có từ regression, logistic regression được sử dụng nhiều trong các bài\\ntoán classification. Sau khi tìm được mô hình, việc xác định classy cho một điểm dữ liệu\\nx được xác định bằng việc so sánh hai biểu thức xác suất\\nP(y= 1|x; w); P(y= 0|x; w) (14.18)\\nNếu biểu thức thứ nhất lớn hơn, ta kết luận điểm dữ liệu thuộc class 1, và ngược lại. Vì\\ntổng hai biểu thức này luôn bằng một nên một cách gọn hơn, ta chỉ cần xác định xem\\nP(y= 1|x; w) lớn hơn 0.5 hay không.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 184, 'page_label': '173'}, page_content='173 CHƯƠNG 14. LOGISTIC REGRESSION\\n2. Đường ranh giới tạo bởi logistic regression là một siêu phẳng\\nThật vậy, giả sử những điểm có xác suất đầu ra lớn hơn 0.5 được coi là thuộc vào lớp có\\nnhãn là 1. Tập hợp các điểm này là nghiệm của bất phương trình\\nP(y= 1|x; w) >0.5 ⇔ 1\\n1 + e−wT x >0.5 ⇔e−wT x <1 ⇔wTx >0 (14.19)\\nNói cách khác, tập hợp các điểm thuộc lớp 1 tạo thành nửa không gian (halfspace)\\nwTx >0, tập hợp các điểm thuộc lớp 0 tạo thành nửa không gian còn lại. Ranh giới giữa\\nhai lớp chính là siêu phẳngwTx = 0.\\nChính vì điều này, logistic regression được coi như một bộ phân lớp tuyến tính.\\n3. Logistic regression không yêu cầu giả thiết linearly separable.\\nMột điểm cộng của logistic regression so với PLA là nó không cần có giả thiết dữ liệu hai\\nlớp là linearly separable. Tuy nhiên, ranh giới tìm được vẫn có dạng tuyến tính. Vì vậy,\\nmô hình này chỉ phù hợp với loại dữ liệu mà hai lớp gần với linearly separable, tức chỉ\\ncó một vài điểm dữ liệu phá vỡ tính linearly separable của hai lớp.\\n4. Ngưỡng ra quyết định có thể thay đổi.\\nHàm dự đoán đầu ra của các điểm dữ liệu mới có thể được viết như sau.\\ndef predict(w, X, threshold = 0.5):\\n\"\"\"\\npredict output of each row of X\\nX: a numpy array of shape (N, d)\\nthreshold: a threshold between 0 and 1\\nreturn a 1d numpy array, each element is 0 or 1\\n\"\"\"\\nres = np.zeros(X.shape[0])\\nres[np.where(prob(w, X) > threshold)[0]] = 1\\nreturn res\\nTrong các ví dụ đã nêu, ngưỡng ra quyết định đều được lấy tại 0.5. Trong nhiều trường\\nhợp, ngưỡng này có thể được thay đổi. Ví dụ, việc xác định các giao dịch là lừa đảo của\\nmột công ty tín dụng là rất quan trọng. Việc phân lớp nhầm một giao dịch lừa đảo thành\\nmột giao dịch thông thường gây ra hậu quả nghiêm trọng hơn chiều ngược lại. Trong bài\\ntoán đó, ngưỡng phân loại có thể giảm xuống còn 0.3. Nghĩa là các giao dịch được dự\\nđoán là lừa đảo với xác suất lớn hơn 0.3 sẽ được xếp vào lớp lừa đảo và nên được tiếp\\ntục đánh giá bằng các bước khác.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 184, 'page_label': '173'}, page_content='đoán là lừa đảo với xác suất lớn hơn 0.3 sẽ được xếp vào lớp lừa đảo và nên được tiếp\\ntục đánh giá bằng các bước khác.\\n5. Khi biểu diễn theo neural networks, linear regression, PLA, và logistic regression có thể\\nđược biểu diễn như trên Hình 14.6. Sự khác nhau chỉ nằm ở lựa chọn hàm kích hoạt.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 185, 'page_label': '174'}, page_content='CHƯƠNG 14. LOGISTIC REGRESSION 174\\nHình 14.6: Biểu diễn linear regression, PLA, và logistic regression dưới dạng neural network.\\n14.5 Bài toán phân biệt hai chữ số viết tay\\nChúng ta cùng làm một ví dụ thực tế hơn với bài toán phân biệt hai chữ số 0 và 1 trong\\nbộ cơ sở dữ liệu MNIST. Trong mục này, chúng ta sẽ sử dụng classLogisticRegression trong\\nthư viện scikit-learn. Trước tiên, ta khai báo các thư viện và tải về bộ cơ sở dữ liệu MNIST.\\nimport numpy as np\\nfrom sklearn.datasets import fetch_mldata\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.metrics import accuracy_score\\nmnist = fetch_mldata(’MNIST original’, data_home=’../../data/’)\\nN, d = mnist.data.shape\\nCó tổng cộng 70000 điểm dữ liệu trong tập dữ liệu MNIST, mỗi điểm là một mảng 784 phần\\ntử tương ứng với 784 pixel. Mỗi chữ số từ 0 đến 9 chiếm khoảng 10%. Chúng ta sẽ lấy ra tất\\ncả các điểm ứng với chữ số 0 và 1, sau đó lấy ra ngẫu nhiên 2000 điểm làm test set, phần\\ncòn lại đóng vai trò training set.\\nX_all = mnist.data\\ny_all = mnist.target\\nX0 = X_all[np.where(y_all == 0)[0]] # all digit 0\\nX1 = X_all[np.where(y_all == 1)[0]] # all digit 1\\ny0 = np.zeros(X0.shape[0]) # class 0 label\\ny1 = np.ones(X1.shape[0]) # class 1 label\\nX = np.concatenate((X0, X1), axis = 0) # all digits\\ny = np.concatenate((y0, y1)) # all labels\\n# split train and test\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=2000)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 186, 'page_label': '175'}, page_content='175 CHƯƠNG 14. LOGISTIC REGRESSION\\nHình 14.7: Các chữ số bị phân lớp lỗi\\ntrong bài toán phân lớp nhị phân với hai\\nchữ số 0 và 1.\\nTiếp theo, ta xây dựng mô hình logistic regression trên test set và dự đoán nhãn của các\\nđiểm trong test set. Kết quả này được so sánh với nhãn thật của mỗi điểm dữ liệu để tính\\nđộ chính xác của bộ phân lớp trên tập kiểm thử.\\nmodel = LogisticRegression(C = 1e5) # C is inverse of lam\\nmodel.fit(X_train, y_train)\\ny_pred = model.predict(X_test)\\nprint(\"Accuracy %.2f %%\" % (100*accuracy_score(y_test, y_pred.tolist())))\\nTuyệt vời, gần như 100% được phân loại chính xác. Điều này là dễ hiểu vì hai chữ số 0 và 1\\nkhác nhau rất nhiều.\\nTiếp theo, ta cùng đi tìm những ảnh bị phân loại sai và hiển thị chúng.\\nmis = np.where((y_pred - y_test) !=0)[0]\\nXmis = X_test[mis, :]\\nfrom display_network import *\\nfilename = ’mnist_mis.pdf’\\nwith PdfPages(filename) as pdf:\\nplt.axis(’off’)\\nA = display_network(Xmis.T, 1, Xmis.shape[0])\\nf2 = plt.imshow(A, interpolation=’nearest’ )\\nplt.gray()\\npdf.savefig(bbox_inches=’tight’)\\nplt.show()\\nChỉ có hai chữ số bị phân lớp lỗi được cho trên Hình 14.7. Trong đó, chữ số 0 bị phân lớp\\nlỗi là dễ hiểu vì nó trông rất giống chữ số 1.\\nBạn đoc có thể xem thêm ví dụ về bài toán xác định giới tính dựa trên ảnh khuôn mặt tại\\nhttps://goo.gl/9V8wdD.\\n14.6 Bộ phân lớp nhị phân cho bài toán phân lớp đa lớp\\nLogistic regression được áp dụng cho các bài toán phân lớp nhị phân. Các bài toán phân lớp\\nthực tế có thể có nhiều hơn hai lớp dữ liệu rất nhiều, được gọi là bài toánphân lớp đa lớp\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 187, 'page_label': '176'}, page_content='CHƯƠNG 14. LOGISTIC REGRESSION 176\\n(multi-class classification). Với một vài kỹ thuật nhỏ, ta có thể áp dụng logistic regression\\ncho các bài toán phân lớp đa lớp.\\nCó ít nhấtbốn cách để áp dụng logistic regression hay các bộ phân lớp nhị phân vào các bài\\ntoán phân lớp đa lớp.\\n14.6.1 One-vs-one\\nXây dựng rất nhiều các bộ phân lớp nhị phân cho từng cặp hai lớp dữ liệu. Bộ thứ nhất\\nphân biệt lớp thứ nhất và thứ hai, bộ thứ hai phân biệt lớp thứ nhất và lớp thứ ba, v.v.. Dữ\\nliệu mới được đưa vào tất cả các bộ phân lớp nhị phân nêu trên. Kết quả cuối cùng có thể\\nđược xác định bằng cách xem lớp nào mà điểm dữ liệu đó được phân vào nhiều nhất. Hoặc\\nvới logistic regression thì ta có thể tínhtổng các xác suấtmà điểm dữ liệu đó rơi vào mỗi\\nlớp. Như vậy, nếu cóC lớp thì số bộ phân lớp cần dùng làC(C−1)\\n2 . Đây là một con số lớn,\\ncách làm này không lợi về tính toán. Hơn nữa, nếu một chữ số thực ra là chữ số1, nhưng\\nlại được đưa vào bộ phân lớp giữa các chữ số5 và 6, thì cả hai khả năng đều không hợp lý.\\n14.6.2 Phân tầng\\nCách làm nhưone-vs-onesẽ mất rất nhiều thời gian huấn luyện vì có quá nhiều bộ phân lớp\\ncầnđượcxâydựng.Mộtcáchgiúpgiảmsốbộphânlớpnhịphânlà phân tầng(hierarchical).\\nÝ tưởng của phương pháp này có thể được thấy qua ví dụ sau.\\nGiả sử ta có bài toán phân lớp 4 chữ số 4, 5, 6, 7 trong MNIST. Vì chữ số 4 và 7 khá giống\\nnhau, chữ số 5 và 6 khá giống nhau nên trước tiên ta xây dựng bộ phân lớp [4, 7]vs [5, 6].\\nSau đó xây dựng thêm hai bộ 4vs 7 và 5vs 6. Tổng cộng, ta cần ba bộ phân lớp. Chú ý\\nrằng có nhiều cách chia khác nhau, ví dụ [4, 5, 6]vs 7, [4, 5]vs 6, rồi 4vs 5. Ưu điểm của\\nkỹ thuật này là nó sử dụng ít bộ phân lớp tuyến tính hơnone-vs-one. Hạn chế lớn nhất của\\nnó là việc nếu chỉ một bộ phân lớp cho kết quả sai thì kết quả cuối cùng chắc chắn sẽ sai.\\nVí dụ, nếu một ảnh chứa chữ số 5 bị phân lớp lỗi bởi bộ phân lớp đầu tiên, nó sẽ bị phân\\nsang nhánh [4, 7]. Cuối cùng, nó sẽ bị phân vào lớp 4 hoặc 7, cả hai đều không chính xác.\\n14.6.3 Binary coding'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 187, 'page_label': '176'}, page_content='Ví dụ, nếu một ảnh chứa chữ số 5 bị phân lớp lỗi bởi bộ phân lớp đầu tiên, nó sẽ bị phân\\nsang nhánh [4, 7]. Cuối cùng, nó sẽ bị phân vào lớp 4 hoặc 7, cả hai đều không chính xác.\\n14.6.3 Binary coding\\nCó một cách giảm số binary classifiers hơn nữa làbinary coding, tứcmã hóaoutput của mỗi\\nlớp bằng một số nhị phân. Ví dụ, nếu có bốn lớp dữ liệu thì các lớp được mã hoá là 00, 01,\\n10, và 11. Với cách làm này, số bộ phân lớp nhị phân cần xây dựng chỉ làm = ⌈log2(C)⌉\\ntrong đó C là số lớp,⌈a⌉là số nguyên nhỏ nhất không nhỏ hơna. Bộ thứ nhất đi tìm bit\\nđầu tiên của output (đã được mã hóa nhị phân), bộ thứ hai sẽ đi tìm bit thứ hai, v.v.. Cách\\nlàm này sử dụng một số lượng nhỏ nhất các bộ phân lớp tuyến tính. Tuy nhiên, nó có một\\nhạn chế rất lớn là chỉ cần một bit bị phân loại sai sẽ dẫn đến dữ liệu bị phân loại sai. Hơn\\nnữa, nếu số lớp không phải là lũy thừa của hai, mã nhị phân nhận được có thể là một giá\\ntrị không tương ứng với lớp nào.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 188, 'page_label': '177'}, page_content='177 CHƯƠNG 14. LOGISTIC REGRESSION\\na)\\n b)\\n c)\\nHình 14.8: Một số ví dụ về phân phối của các lớp dữ liệu trong bài toán phân lớp đa lớp.\\n14.6.4 one-vs-rest hay one-hot coding\\nKỹ thuật được sử dụng nhiều nhất làone-vs-rest (một số tài liệu gọi làove-vs-all, one-\\nagainst-rest, hoặcone-against-all). Cụ thể, nếu cóC lớp thì ta sẽ xây dựngC bộ phân\\nlớp nhị phân, mỗi bộ tương ứng với một lớp. Bộ thứ nhất giúp phân biệt lớp thứ nhất với\\ncác lớp còn lại, tức xem một điểm có thuộc lớp thứ nhất hay không, hoặc xác suất để một\\nđiểm rơi vào lớp đó là bao nhiêu. Tương tự như thế, bộ thứ hai sẽ phân biệt lớp thứ hai với\\ncác lớp còn lại, v.v.. Kết quả cuối cùng có thể được xác định bằng cách xác định lớp mà một\\nđiểm rơi vào với xác suất cao nhất.\\nLogistic regression trong thư viện sklearn có thể được dùng trực tiếp để áp dụng vào các\\nbài toán phân lớp đa lớp với kỹ thuậtone-vs-rest. Với bài toán MNIST, để dùng logistic\\nregression kết hợp với one-vs-rest (mặc định trong scikit-learn), ta có thể làm như sau.\\n# all class\\nX_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=10000)\\nmodel = LogisticRegression(C = 1e5) # C is inverse of lam\\nmodel.fit(X_train, y_train)\\ny_pred = model.predict(X_test)\\nprint(\"Accuracy %.2f %%\" % (100*accuracy_score(y_test, y_pred.tolist())))\\nKết quả thu được khoảng 91.7%. Đây vẫn là một kết quả quá thấp so với con số 99.7% mà\\ndeep learning đã đạt được. Ngay cả K-nearest neighbors cũng đã đạt khoảng 96 %.\\n14.7 Thảo luận\\n14.7.1 Kết hợp các phương pháp trên\\nTrong nhiều trường hợp, ta cần phải kết hợp hai hoặc ba trong số bốn kỹ thuật đã đề cập.\\nXét ba ví dụ trong Hình 14.8.\\n• Hình 14.8a: cả 4 phương pháp trên đây đều có thể áp dụng được.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 189, 'page_label': '178'}, page_content='CHƯƠNG 14. LOGISTIC REGRESSION 178\\n• Hình 14.8b: one-vs-rest không phù hợp vì lớp màu lục và hợp của lớp lam và lớp đỏ là\\nkhông (gần)linearly separable. Lúc này, one-vs-one hoặc hierarchical phù hợp hơn.\\n• Hình 14.8c: Tương tự như trên, ba lớp lam, lục, đỏ thẳng hàng nên sẽ không dùng được\\none-vs-rest. Trong khi đó, one-vs-one vẫn hiệu quả vì từng cặp lớp dữ liệu làlinearly\\nseparable. Tương tự hierarchical cũng làm việc nếu ta phân chia các nhóm một cách hợp\\nlý. Hoặc chúng ta có thể kết hợp nhiều phương pháp. Ví dụ: dùng one-vs-rest để tìmđỏ\\nvới không đỏ. Nếu một điểm dữ liệu làkhông đỏ, với ba lớp còn lại, ta lại quay lại trường\\nhợp Hình 14.8a và có thể dùng các phương pháp khác. Nhưng khó khăn vẫn nằm ở việc\\nphân nhóm như thế nào, liệu rằng những lớp nào có thể cho vào cùng một nhóm?\\nVới bài toán phân lớp đa lớp, nhìn chung các kỹ thuật sử dụng các bộ phân lớp nhị phân\\nđã trở nên ít hiệu quả hơn so với các phương pháp mới. Mời bạn đọc thêm Chương 15 và\\nChương 29 để tìm hiểu về các bộ phân lớp đa lớp phổ biến nhất hiện nay.\\n14.7.2 Biểu diễn các kỹ thuật đã nêu dưới dạng neural network\\nLấy ví dụ với bài toán có bốn lớp dữ liệu 1, 2, 3, 4; ta có thể biểu diễn các mô hình được\\nđề cập trong Mục 14.6 dưới dạng neural network như trên Hình 14.9. Các node màu đỏ thể\\nhiện đầu ra là một trong hai giá trị.\\nCác network này đều có nhiều node ở output layer, và một vector trọng sốw bây giờ đã trở\\nthành ma trận trọng sốW mà mỗi cột của nó tương ứng với vector trọng số của một node\\noutput. Việc tối ưu đồng thời các bộ phân lớp nhị phân trong mỗi network cũng được tổng\\nquát lên nhờ các phép tính với ma trận. Lúc này, công thức cập nhật của logistic regression\\nw ←w −η(zi −yi)xi (14.20)\\ncó thể được tổng quát thành\\nW ←W −ηxi(zi −yi)T (14.21)\\nVớiW,yi,zi lần lượt là ma trận trọng số, vector (cột) outputthật với toàn bộ các bộ phân\\nlớp nhị phân tương ứng với điểm dữ liệuxi, và vector output tìm được của networks tại thời'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 189, 'page_label': '178'}, page_content='VớiW,yi,zi lần lượt là ma trận trọng số, vector (cột) outputthật với toàn bộ các bộ phân\\nlớp nhị phân tương ứng với điểm dữ liệuxi, và vector output tìm được của networks tại thời\\nđiểm đang xét nếu đầu vào mỗi network làxi. Chú ý rằng vectoryi là một vector nhị phân,\\nvector zi gồm các phần tử nằm trong khoảng(0,1).\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 190, 'page_label': '179'}, page_content='179 CHƯƠNG 14. LOGISTIC REGRESSION\\n1 vs 2\\n1 vs 3\\n1 vs 4\\n2 vs 3\\n2 vs 4\\n3 vs 4\\none-vs-one\\n1,2 vs 3,4\\n1 vs 2\\n3 vs 4\\nHierarchical\\nbit 0 vs bit 1\\nbit 0 vs bit 1\\nclass 1 = ’00’\\nclass 2 = ’01’\\nclass 3 = ’10’\\nclass 4 = ’11’\\nBinary coding\\n1 vs rest\\n2 vs rest\\n3 vs rest\\n4 vs rest\\none-vs-rest\\nHình 14.9: Mô\\nhình neural net-\\nworks cho các kỹ\\nthuật sử dụng các\\nbộ phân lớp nhị\\nphânchobàitoán\\nphân lớp đa lớp.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 191, 'page_label': '180'}, page_content='Chương 15\\nSoftmax regression\\nCác bài toán phân lớp thực tế thường có rất nhiều lớp dữ liệu. Như đã thảo luận trong\\nChương 14, các bộ phân lớp nhị phân tuy có thể kết hợp được với nhau để giải quyết các bài\\ntoán này, chúng vẫn có những hạn chế nhất định. Trong chương này, một phương pháp mở\\nrộng của logistic regression có tên làsoftmax regressionsẽ được giới thiệu nhằm khắc phục\\nnhững hạn chế đã đề cập. Một lần nữa, mặc dù trong tên có chứa từ “regression”, softmax\\nregression được sử dụng cho các bài toán phân lớp. Nó cũng chính là một trong những thành\\nphần phổ biến nhất trong các bộ phân lớp hiện nay.\\n15.1 Giới thiệu\\nVới bài toán phân lớp nhị phân sử dụng logistic regression, đầu ra của neural network là\\nmột số thực trong khoảng(0,1), đóng vai trò như là xác suất để đầu vào thuộc một trong\\nhai lớp. Ý tưởng này cũng có thể mở rộng cho bài toán phân lớp đa lớp, ở đó cóC node ở\\noutput layer và giá trị mỗi node đóng vai trò như xác suất để đầu vào rơi vào lớp tương ứng.\\nNhư vậy, các đầu ra này liên kết với nhau qua việc chúng đều là các số dương và có tổng\\nbằng một. Mô hình softmax regression thảo luận trong chương này đảm bảo tính chất đó.\\nNhắc lại kỹ thuậtone-vs-rest được trình bày trong chương trước được biểu diễn dưới dạng\\nneuron network như trong Hình 15.1. Output layer màu đỏ có thể phân tách thành hai\\nsublayer và mỗi thành phần của sublayer thứ haiai chỉ phụ thuộc vào thành phần tương\\nứng ở sublayer thứ nhấtzi thông qua hàm sigmoidai = σ(zi). Các giá trị đầu raai đều\\nlà các số dương nhưng vì không có ràng buộc giữa chúng, tổng của chúng có thể là một số\\ndương bất kỳ.\\nChú ý rằng các mô hình linear regression, PLA, và logistic regression chỉ có một node ở\\noutput layer. Trong các trường hợp đó, tham số mô hình chỉ là một vectorw. Trong trường\\nhợp output layer có nhiều hơn một node, tham số mô hình sẽ là tập hợp tham sốwi ứng\\nvới từng node. Lúc này, ta có mộtma trận trọng số(weight matrix) W = [w1,w2,..., wC],\\nmỗi cột ứng với một node ở output layer.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 192, 'page_label': '181'}, page_content='181 CHƯƠNG 15. SOFTMAX REGRESSION\\n1x0\\nx1\\nx2\\nxd\\nx\\nW\\nΣ\\nΣ\\nΣ\\nΣ\\nz1\\nz2\\nzC\\nz\\na1\\na2\\naC\\na\\n1 vs rest\\n2 vs rest\\nC vs rest\\nxi Σ\\nzj\\nwij\\nw0j: biases, don’t forget!\\nd: data dimension\\nC: number of classes\\nx ∈ Rd+1\\nW ∈ R(d+1)×C\\nzi = wT\\ni x\\nz = WT x ∈ RC\\nai = sigmoid(zi) ∈ R\\n0 < ai < 1\\nHình 15.1: Phân lớp đa lớp với logistic regression và one-vs-rest.\\n15.2 Softmax function\\n15.2.1 Công thức của Softmax function\\nChúng ta cần một mô hình xác suất sao cho với mỗi inputx, ai thể hiện xác suất để input\\nđó rơi vào lớp thứi. Vậy điều kiện cần là cácai phải dương và tổng của chúng bằng một.\\nNgoài ra, ta sẽ thêm một điều kiện cũng rất tự nhiên nữa, đó là giá trịzi = wT\\ni x càng lớn\\nthì xác suất dữ liệu rơi vào lớp thứi càng cao. Điều kiện cuối này chỉ ra rằng ta cần một\\nquan hệ đồng biến ở đây.\\nChú ý rằngzi có thể nhận giá trị cả âm và dương vì nó là một tổ hợp tuyến tính của các\\nthành phần của vector đặc trưngx. Một hàm số khả vi đơn giản có thể chắc chắn biếnzi\\nthành một giá trị dương, và hơn nữa, đồng biến, là hàmexp(zi) =ezi. Điều kiện khả vi để\\nthuận lợi cho việc sử dụng đạo hàm cho việc tối ưu. Điều kiện cuối cùng, tổng cácai bằng\\nmột có thể được đảm bảo nếu\\nai = exp(zi)∑C\\nj=1 exp(zj)\\n, ∀i= 1,2,...,C (15.1)\\nMối quan hệ này, với mỗiai phụ thuộc vào tất cả cáczi, thoả mãn tất cả các điều kiện đã\\nxét: dương, tổng bằng một, giữ đượcthứ tựcủa zi. Hàm số này được gọi làsoftmax function.\\nLúc này, ta có thể coi rằng\\np(yk = i|xk; W) =ai (15.2)\\nTrong đó,p(y = i|x; W) được hiểu là xác suất để một điểm dữ liệux rơi vào lớp thứi nếu\\nbiết tham số mô hình là ma trận trọng sốW. Hình 15.2 thể hiện mô hình softmax regression\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 193, 'page_label': '182'}, page_content='CHƯƠNG 15. SOFTMAX REGRESSION 182\\n1x0\\nx1\\nx2\\nxd\\nx\\nW\\nΣ\\nΣ\\nΣ\\nΣ\\nz1\\nz2\\nzC\\nz\\na1\\na2\\naC\\na\\nxi Σ\\nzj\\nwij\\nw0j: biases, don’t forget!\\nd: data dimension\\nC: number of classes\\nx ∈ Rd+1\\nW ∈ R(d+1)×C\\nzi = wT\\ni x\\nz = WT x ∈ RC\\na = softmax(z) ∈ RC\\nai > 0,\\nC∑\\ni=1\\nai = 1\\nx\\na\\nz = softmax(WT x)\\nshort form\\nHình 15.2: Mô hình softmax regression dưới dạng neural network.\\ndưới dạng neural network. Sự khác nhau giữa mô hình này và mô hình one-vs-rest nằm ở\\nchỗ nó có các liên kết giữa mọi node của hai sublayer màu đỏ.\\n15.2.2 Softmax function trong Python\\nDưới đây là một đoạn code thực hiện hàm softmax. Đầu vào là một ma trận với mỗihàng\\nlà một vectorz, đầu ra cũng là một ma trận mà mỗi hàng có giá trị làa = softmax(z). Các\\ngiá trị củaz còn được gọi làscores.\\nimport numpy as np\\ndef softmax(Z):\\n\"\"\"\\nCompute softmax values for each sets of scores in V.\\neach column of V is a set of scores.\\nZ: a numpy array of shape (N, C)\\nreturn a numpy array of shape (N, C)\\n\"\"\"\\ne_Z = np.exp(Z)\\nA = e_Z / e_Z.sum(axis = 1, keepdims = True)\\nreturn A\\n15.2.3 Một vài ví dụ\\nHình 15.3 mô tả một vài ví dụ về mối quan hệ giữa đầu vào và đầu ra của hàm softmax.\\nHàng trên màu xanh nhạt thể hiện các scoreszi với giả sử rằng số lớp dữ liệu là ba. Hàng\\ndưới màu đỏ nhạt thể hiện các giá trị đầu raai của hàm softmax.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 194, 'page_label': '183'}, page_content='183 CHƯƠNG 15. SOFTMAX REGRESSION\\n2\\n2\\n2\\nz1 z2 z3\\n0.333\\n0.333\\n0.333\\na1 a2 a3\\nsoftmax\\n2\\n1.8\\n0\\nz1 z2 z3\\n0.512\\n0.419\\n0.069\\na1 a2 a3\\n-1\\n-1.5\\n-2\\nz1 z2 z3\\n0.507\\n0.307\\n0.186\\na1 a2 a3\\n3\\n3\\n.1\\nz1 z2 z3\\n0.486\\n0.486\\n0.027\\na1 a2 a3\\nHình 15.3: Một số ví dụ về đầu vào và đầu ra của hàm softmax.\\nCó một vài quan sát như sau:\\n• Cột 1: Nếu cáczi bằng nhau (bằng 2 hoặc một số bất kỳ), thì cácai cũng bằng nhau và\\nbằng 1/3.\\n• Cột 2: Nếu giá trị lớn nhất trong cáczi là z1 vẫn bằng 2, thì mặc dù xác suất tương ứng\\na1 vẫn là lớn nhất, nó đã thay đổi lên hơn 0.5. Sự chênh lệch ở đầu ra là đáng kể, nhưng\\nthứ tự tương ứng không thay đổi.\\n• Cột 3: Khi các giá trịzi là âm thì các giá trịai vẫn là dương và thứ tự vẫn được đảm bảo.\\n• Cột 4: Nếuz1 = z2, thìa1 = a2.\\nBạn đọc có thể thử với các giá trị khác trực tiếp trên trình duyệt tạihttps://goo.gl/pKxQYc ,\\nphần Softmax.\\n15.2.4 Phiên bản ổn định hơn của softmax function\\nKhi một trong các zi quá lớn, việc tính toán exp(zi) có thể gây ra hiện tượng tràn số\\n(overflow), ảnh hưởng lớn tới kết quả của hàm softmax. Có một cách khắc phục hiện tượng\\nnày bằng cách dựa trên quan sát\\nexp(zi)∑C\\nj=1 exp(zj)\\n= exp(−c) exp(zi)\\nexp(−c)∑C\\nj=1 exp(zj)\\n= exp(zi −c)∑C\\nj=1 exp(zj −c)\\n(15.3)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 195, 'page_label': '184'}, page_content='CHƯƠNG 15. SOFTMAX REGRESSION 184\\nvới c là một hằng số bất kỳ. Vậy một phương pháp đơn giản giúp khắc phục hiện tượng\\noverflow là trừ tất cả cáczi đi một giá trị đủ lớn. Trong thực nghiệm, giá trị đủ lớn này\\nthường được chọn làc= maxizi. Vậy chúng ta có thể sửa đoạn code cho hàmsoftmax phía\\ntrên bằng cách trừ mỗi hàng của ma trận đầu vàoZ đi giá trị lớn nhất trong hàng đó. Ta có\\nphiên bản ổn định hơn làsoftmax_stable1.\\ndef softmax_stable(Z):\\n\"\"\"\\nCompute softmax values for each sets of scores in Z.\\neach row of Z is a set of scores.\\n\"\"\"\\n# Z = Z.reshape(Z.shape[0], -1)\\ne_Z = np.exp(Z - np.max(Z, axis = 1, keepdims = True))\\nA = e_Z / e_Z.sum(axis = 1, keepdims = True)\\nreturn A\\n15.3 Hàm mất mát và phương pháp tối ưu\\n15.3.1 Cross entropy\\nĐầu ra của softmax network không còn là một giá trị biểu thị lớp cho dữ liệu mà đã trở\\nthành một vector ở dạng one-hot với chỉ một phần tử bằng 1 tại vị trí tương ứng với lớp đó\\n(tính từ 1), các phần tử còn lại bằng 0.\\nVới mỗi đầu vàox, đầu ra tương ứng qua softmax network sẽ là vectora = softmax(WTx);\\nđầu ra này được gọi làđầu ra dự đoán. Trong khi đó,đầu ra thực sựcủa nó là một vector ở\\ndạng one-hot.\\nHàm mất mát của softmax regression được xây dựng dựa trên bài toán tối thiểu sự khác\\nnhau giữađầu ra dự đoána và đầu ra thực sựy (ở dạng one-hot). Khi cả hai là các vector\\nthể hiện xác suất, khoảng cách giữa chúng thường được đo bằng một đại lượng được gọi là\\ncross entropy. Một đặc điểm nổi bật của đại lượng này là nếu cố định một vector xác suất,\\ngiá trị của nóđạt giá trị nhỏ nhất khi hai vector xác suất bằng nhau, và rất lớn khi hai vector\\nđó lệch nhau nhiều.\\nCross entropy giữa hai vector phân phốip và q rời rạc được định nghĩa bởi\\nH(p,q) = −\\nC∑\\ni=1\\npilog qi (15.4)\\nHình 15.4 thể hiển rõ ưu điểm của hàm cross entropy so với hàm bình phương khoảng cách\\nEuclid. Đây là ví dụ trong trường hợpC = 2 và p1 lần lượt nhận các giá trị0.5,0.1 và 0.8.\\nChú ý rằngp2 = 1 −p1. Có hai nhận xét quan trọng sau đây:'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 195, 'page_label': '184'}, page_content='Euclid. Đây là ví dụ trong trường hợpC = 2 và p1 lần lượt nhận các giá trị0.5,0.1 và 0.8.\\nChú ý rằngp2 = 1 −p1. Có hai nhận xét quan trọng sau đây:\\n1. Giá trị nhỏ nhất của cả hai hàm số đạt được khiq= p tại hoành độ các điểm màu lục.\\n1 Xem thêm về cách xử lý mảng numpy trong Python tạihttps://fundaml.com\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 196, 'page_label': '185'}, page_content='185 CHƯƠNG 15. SOFTMAX REGRESSION\\n(a)\\n (b)\\n (c)\\nHình 15.4: So sánh giữa hàm cross entropy và hàm bình phương khoảng cách. Các điểm màu\\nlục thể hiện các giá trị nhỏ nhất của mỗi hàm.\\n2. Quan trọng hơn, hàm cross entropy nhận giá trị rất cao (tức mất mát rất cao) khiq ở\\nxa p. Trong khi đó, sự chênh lệch giữa các mất mát ở gần hay xa nghiệm của hàm bình\\nphương khoảng cách(q−p)2 là ít đáng kể hơn. Về mặt tối ưu, hàm cross entropy sẽ cho\\nnghiệm gần với p hơn vì những nghiệm ở xa bịtrừng phạt rất nặng.\\nHai tính chất trên đây khiến cho cross entropy được sử dụng rộng rãi khi tính khoảng cách\\ngiữa hai phân phối xác suất. Tiếp theo, chúng ta sẽ chứng minh nhận định sau.\\nCho p ∈RC\\n+ là một vector với các thành phần dương và tổng bằng 1. Bài toán tối ưu\\nq = arg min\\nq\\nH(p,q)\\nthoả mãn:\\nC∑\\ni=1\\nqi = 1; qi >0\\ncó nghiệmq = p.\\nBài toán này có thể giải quyết bằng phương pháp nhân tử Lagrange (xem Phụ lục A).\\nLagrangian của bài toán này là\\nL(q1,q2,...,q C,λ) = −\\nC∑\\ni=1\\npilog(qi) + λ(\\nC∑\\ni=1\\nqi −1)\\nTa cần giải hệ phương trình\\n∇q1,...,qC,λL(q1,...,q C,λ) = 0 ⇔\\n{−pi\\nqi\\n+ λ= 0, i = 1,...,C\\nq1 + q2 + ··· + qC = 1\\nTừ phương trình thứ nhất ta cópi = λqi. Vì vậy,1 = ∑C\\ni=1 pi = λ∑C\\ni=1 qi = λ ⇒λ = 1.\\nĐiều này tương đương vớiqi = pi,∀i. □\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 197, 'page_label': '186'}, page_content='CHƯƠNG 15. SOFTMAX REGRESSION 186\\nChú ý\\n1. Hàm cross entropy không có tính đối xứngH(p,q) ̸= H(q,p). Điều này có thể dễ\\ndàng nhận ra ở việc các thành phần củap trong công thức(1) có thể nhận giá trị\\nbằng 0, trong khi đó các thành phần củaq phải là dương vìlog(0) không xác định.\\nChính vì vậy, khi sử dụng cross entropy trong các bài toán phân lớp,p là đầu ra\\nthực sự vì nó là một vector ở dang one-hot,q là đầu ra dự đoán. Trong các thành\\nphần thể hiện xác suất củaq, không có thành phần nào tuyệt đối bằng 1 hoặc tuyệt\\nđối bằng 0 (do hàmexp luôn trả về một giá trị dương).\\n2. Khi p là một vector ở dạng one-hot, giả sử chỉ cópc = 1, khi đó biểu thức cross\\nentropy trở thành−log(qc). Biểu thức này đạt giá trị nhỏ nhất nếuqc = 1, điều\\nnày là không khả thi vì nghiệm này không thuộc miền xác định của bài toán. Tuy\\nnhiên, giá trị cross entropy tiệm cận tới 0 khiqc tiến đến 1. Điều này xảy ra khi\\nzc rất rất lớn so với cáczi còn lại.\\n15.3.2 Xây dựng hàm mất mát\\nTrong trường hợp cóC lớp dữ liệu,mất mátgiữa đầu ra dự đoán và đầu ra thực sự của một\\nđiểm dữ liệuxi với label (one-hot)yi được tính bởi\\nJi(W) ≜J(W; xi,yi) = −\\nC∑\\nj=1\\nyji log(aji) (15.5)\\nvới yji và aji lần lượt là phần tử thứj của vector xác suấtyi và ai. Nhắc lại rằng đầu raai\\nphụ thuộc vào đầu vàoxi và ma trận trọng sốW. Tới đây, nếu để ý rằng chỉ có đúng một\\nj sao choyji = 1,∀i, biểu thức (15.5) chỉ còn lại một số hạng tương ứng với giá trịj đó. Để\\ntránh việc sử dụng quá nhiều ký hiệu, chúng ta giả sử rằngyi là nhãn của điểm dữ liệuxi\\n(các nhãn là các số tự nhiên từ 1 tớiC), khi đój chính bằngyi. Sau khi có ký hiệu này, ta\\ncó thể viết lại\\nJi(W) = −log(ayi,i) (15.6)\\nvới ayi,i là phần tử thứyi của vectorai.\\nKết hợp tất cả các cặp dữ liệuxi,yi,i = 1,2,...,N , hàm mất mát cho softmax regression\\nđược xác định bởi\\nJ(W; X,Y) = −1\\nN\\nN∑\\ni=1\\nlog(ayi,i) (15.7)\\nỞ đây, ma trận trọng sốW là biến cần tối ưu. Mặc dù hàm mất mát này trông phức tạp,\\nđạo hàm của nó rất gọn. Ta cũng có thể thêm weight decay để tránh overfitting bằng cách'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 197, 'page_label': '186'}, page_content='N\\nN∑\\ni=1\\nlog(ayi,i) (15.7)\\nỞ đây, ma trận trọng sốW là biến cần tối ưu. Mặc dù hàm mất mát này trông phức tạp,\\nđạo hàm của nó rất gọn. Ta cũng có thể thêm weight decay để tránh overfitting bằng cách\\ncộng thêm một đại lượng tỉ lệ với∥W∥2\\nF.\\n¯J(W; X,Y) = −1\\nN\\n( N∑\\ni=1\\nlog(ayi,i) + λ\\n2 ∥W∥2\\nF\\n)\\n(15.8)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 198, 'page_label': '187'}, page_content='187 CHƯƠNG 15. SOFTMAX REGRESSION\\nTrong các mục tiếp theo, chúng ta sẽ làm việc với hàm mất mát (15.7). Việc mở rộng cho\\nhàm mất mát với regularization (15.8) không phức tạp vì đạo hàm của số hạng regularized\\nλ\\n2 ∥W∥2\\nF đơn giản làλW. Hàm mất mát (15.7) có thể được thực hiện trên Python như sau2.\\ndef softmax_loss(X, y, W):\\n\"\"\"\\nW: 2d numpy array of shape (d, C),\\neach column correspoding to one output node\\nX: 2d numpy array of shape (N, d), each row is one data point\\ny: 1d numpy array -- label of each row of X\\n\"\"\"\\nA = softmax_stable(X.dot(W))\\nid0 = range(X.shape[0]) # indexes in axis 0, indexes in axis 1 are in y\\nreturn -np.mean(np.log(A[id0, y]))\\nChú ý\\n1. Khi biểu diễn dưới dạng toán học, mỗi điểm dữ liệu là một cột của ma trậnX;\\nnhưng khi làm việc với numpy, mỗi điểm dữ liệu được đọc theoaxis = 0 của mảng\\nhai chiềuX. Việc này thống nhất với các thư viện scikit-learn hay tensorflow ở chỗ\\nX[i] được dùng để chỉ điểm dữ liệu thứi, tính từ0. Tức là, nếu cóN điểm dữ liệu\\ntrong không giand chiều thìX ∈Rd×N, nhưngX.shape == (N, d).\\n2. W ∈Rd×C, W.shape == (d, c).\\n3. WTX sẽ được biểu diễn bởiX.dot(W), và cóshape == (N, C).\\n4. Khi làm việc với phép nhân ma trận hay mảng nhiều chiều trong numpy, ta luôn\\nnhớ chú ý tới kích thước của các ma trận sao cho các phép nhân thực hiện được.\\n15.3.3 Tối ưu hàm mất mát\\nHàm mất mát sẽ được tối ưu bằng gradient descent, cụ thể là mini-batch gradient descent.\\nMỗi lần cập nhật của mini-batch gradient descent được thực hiện trên mộtbatch có số phần\\ntử 1 <k ≪N. Để tính được đạo hàm của hàm mất mát theo tập con này, trước hết ta xem\\nxét đạo hàm của hàm mất mát tại một điểm dữ liệu.\\nVới chỉ một cặp dữ liệu(xi,yi), ta lại dùng (15.5)\\nJi(W) = −\\nC∑\\nj=1\\nyji log(aji) = −\\nC∑\\nj=1\\nyji log\\n(\\nexp(wT\\nj xi)\\n∑C\\nk=1 exp(wT\\nkxi)\\n)\\n= −\\nC∑\\nj=1\\n(\\nyjiwT\\nj xi −yji log\\n( C∑\\nk=1\\nexp(wT\\nkxi)\\n))\\n= −\\nC∑\\nj=1\\nyjiwT\\nj xi + log\\n( C∑\\nk=1\\nexp(wT\\nkxi)\\n)\\n(15.9)\\n2 Xem thêm: Truy cập vào nhiều phần tử của mảng hai chiều trong numpy - FundaMLhttps://goo.gl/SzLDxa .'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 198, 'page_label': '187'}, page_content='j xi −yji log\\n( C∑\\nk=1\\nexp(wT\\nkxi)\\n))\\n= −\\nC∑\\nj=1\\nyjiwT\\nj xi + log\\n( C∑\\nk=1\\nexp(wT\\nkxi)\\n)\\n(15.9)\\n2 Xem thêm: Truy cập vào nhiều phần tử của mảng hai chiều trong numpy - FundaMLhttps://goo.gl/SzLDxa .\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 199, 'page_label': '188'}, page_content='CHƯƠNG 15. SOFTMAX REGRESSION 188\\nTiếp theo ta sử dụng công thức\\n∇WJi(W) =\\n[\\n∇w1 Ji(W),∇w2 Ji(W),..., ∇wC Ji(W)\\n]\\n(15.10)\\nTrong đó, gradient theo từng cột củawj có thể tính được dựa theo (15.9) và quy tắc chuỗi\\ntính gradient\\n∇wj Ji(W) = −yjixi + exp(wT\\nj xi)\\n∑C\\nk=1 exp(wT\\nkxi)\\nxi\\n= −yjixi + ajixi = xi(aji −yji)\\n= ejixi (với eji = aji −yji) (15.11)\\nGiá trịeji = aji −yji chính là sự sai khác giữa đầu ra dự đoán và đầu ra thực sự tại thành\\nphần thứj. Kết hợp (15.10) và (15.11) vớiei = ai −yi, ta có\\n∇WJi(W) = xi[e1i,e2i,...,e Ci] = xieT\\ni (15.12)\\n⇒∇WJ(W) = 1\\nN\\nN∑\\ni=1\\nxieT\\ni = 1\\nNXET (15.13)\\nvớiE = A −Y.Côngthứctínhđạohàmđơngiảnthếnàygiúpchocảbatchgradientdescent,\\nvà mini-batch gradient descent đều có thể dễ dàng được áp dụng. Trong trường hợp mini-\\nbatch gradient, giả sử kích thước batch làk, ký hiệuXb ∈Rd×k,Yb ∈{0,1}C×k,Ab ∈RC×k\\nlà dữ liệu ứng với một batch, công thức cập nhật cho một batch sẽ là\\nW ←W − η\\nNb\\nXbET\\nb (15.14)\\nvới Nb là kích thước của mỗi batch. Hàm số tính đạo hàm theoW trong Python có thể được\\nthực hiện như sau:\\ndef softmax_grad(X, y, W):\\n\"\"\"\\nW: 2d numpy array of shape (d, C),\\neach column correspoding to one output node\\nX: 2d numpy array of shape (N, d), each row is one data point\\ny: 1d numpy array -- label of each row of X\\n\"\"\"\\nA = softmax_stable(X.dot(W)) # shape of (N, C)\\nid0 = range(X.shape[0])\\nA[id0, y] -= 1 # A - Y, shape of (N, C)\\nreturn X.T.dot(A)/X.shape[0]\\nHàm này đã được kiểm chứng lại bằng hàmcheck_grad.\\nTừ đó, ta có thể viết hàm số huấn luyện softmax regression như sau:\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 200, 'page_label': '189'}, page_content='189 CHƯƠNG 15. SOFTMAX REGRESSION\\ndef softmax_fit(X, y, W, lr = 0.01, nepoches = 100, tol = 1e-5, batch_size = 10):\\nW_old = W.copy()\\nep = 0\\nloss_hist = [loss(X, y, W)] # store history of loss\\nN = X.shape[0]\\nnbatches = int(np.ceil(float(N)/batch_size))\\nwhile ep < nepoches:\\nep += 1\\nmix_ids = np.random.permutation(N) # mix data\\nfor i in range(nbatches):\\n# get the i-th batch\\nbatch_ids = mix_ids[batch_size*i:min(batch_size*(i+1), N)]\\nX_batch, y_batch = X[batch_ids], y[batch_ids]\\nW -= lr*softmax_grad(X_batch, y_batch, W) # update gradient descent\\nloss_hist.append(softmax_loss(X, y, W))\\nif np.linalg.norm(W - W_old)/W.size < tol:\\nbreak\\nW_old = W.copy()\\nreturn W, loss_hist\\nCuối cùng là hàm dự đoán nhãn của các điểm dữ liệu mới. Nhãn của một điểm dữ liệu mới\\nđược xác định bằng chỉ số của lớp dữ liệu có xác suất rơi vào cao nhất, và cũng chính là chỉ\\nsố của score cao nhất.\\ndef pred(W, X):\\n\"\"\"\\npredict output of each columns of X . Class of each x_i is determined by\\nlocation of max probability. Note that classes are indexed from 0.\\n\"\"\"\\nreturn np.argmax(X.dot(W), axis =1)\\n15.4 Ví dụ trên Python\\nĐể minh hoạ ranh giới của các lớp dữ liệu khi sử dụng softmax regression, chúng ta cùng\\nlàm một ví dụ nhỏ trong không gian hai chiều với 5 lớp dữ liệu:\\nC, N = 5, 500 # number of classes and number of points per class\\nmeans = [[2, 2], [8, 3], [3, 6], [14, 2], [12, 8]]\\ncov = [[1, 0], [0, 1]]\\nX0 = np.random.multivariate_normal(means[0], cov, N)\\nX1 = np.random.multivariate_normal(means[1], cov, N)\\nX2 = np.random.multivariate_normal(means[2], cov, N)\\nX3 = np.random.multivariate_normal(means[3], cov, N)\\nX4 = np.random.multivariate_normal(means[4], cov, N)\\nX = np.concatenate((X0, X1, X2, X3, X4), axis = 0) # each row is a datapoint\\nXbar = np.concatenate((X, np.ones((X.shape[0], 1))), axis = 1) # bias trick\\ny = np.asarray([0]*N + [1]*N + [2]*N+ [3]*N + [4]*N)\\nW_init = np.random.randn(Xbar.shape[1], C)\\nW, loss_hist = softmax_fit(Xbar, y, W_init, batch_size = 10, nepoches = 100, lr =\\n0.05)'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 200, 'page_label': '189'}, page_content='y = np.asarray([0]*N + [1]*N + [2]*N+ [3]*N + [4]*N)\\nW_init = np.random.randn(Xbar.shape[1], C)\\nW, loss_hist = softmax_fit(Xbar, y, W_init, batch_size = 10, nepoches = 100, lr =\\n0.05)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 201, 'page_label': '190'}, page_content='CHƯƠNG 15. SOFTMAX REGRESSION 190\\n0 20 40 60 80 100\\nnumber of epoches\\n0\\n2\\n4\\n6\\n8\\n10loss\\n(a)\\n (b)\\nHình 15.5: Ví dụ về sử dụng softmax regression cho năm lớp dữ liệu. (a) Nghiệm qua các\\nepoches. (b) Kết quả phân lớp cuối cùng.\\nGiá trị của hàm mất mát qua các vòng lặp được cho trên Hình 15.5a. Ta thấy rằng hàm mất\\nmát giảm rất nhanh sau đó hội tụ. Các điểm dữ liệu huấn luyện của mỗi lớp là các điểm có\\nmàu khác nhau trong Hình 15.5b. Các phần có màu nền khác nhau là cáclãnh thổ của mỗi\\nlớp dữ liệu tìm được bằng softmax regression. Ta có thể thấy rằng các đường ranh giới có\\ndạng đường thẳng. Kết quả phân chia lãnh thổ cũng khá tốt, chỉ có một số ít điểm trong\\ntập huấn luyện bị phân lớp sai. Để ý thấy rằng dùng softmax regression tốt hơn rất nhiều\\nso với phương pháp kết hợp các bộ phân lớp nhị phân.\\nMNIST với softmax regression trong scikit-learn\\nTrong scikit-learn, softmax regression được tích hợp trong class sklearn.linear_model.\\nLogisticRegression. Như sẽ thấy trong phần thảo luận, logistic regression chính là softmax\\nregression cho bài toán binary classification. Với bài toán multi-class classification, thư viện\\nnày mặc định sử dụng kỹ thuật one-vs-rest. Để sử dụng softmax regression, ta thay đổi thuộc\\ntính multi_class = ’multinomial’ vàsolver = ’lbfgs’. Ở đây,’lbfgs’ là một phương pháp tối\\nưu rất mạnh cũng dựa trên đạo hàm. Trong khuôn khổ của cuốn sách, chúng ta sẽ không\\nthảo luận về phương pháp này.\\nQuay lại với bài toán phân lớp chữ số viết tay trong cơ sở dữ liệu MNIST. Đoạn code dưới\\nđây thực hiện việc lấy ra 10000 điểm dữ liệu trong số 70000 điểm làm tập kiểm thử, còn lại\\nlà tập huấn luyện. Bộ phân lớp được sử dụng là softmax regression.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 202, 'page_label': '191'}, page_content='191 CHƯƠNG 15. SOFTMAX REGRESSION\\nimport numpy as np\\nfrom sklearn.datasets import fetch_mldata\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import accuracy_score\\nmnist = fetch_mldata(’MNIST original’, data_home=’../../data/’)\\nX = mnist.data\\ny = mnist.target\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=10000)\\nmodel = LogisticRegression(C = 1e5,\\nsolver = ’lbfgs’, multi_class = ’multinomial’) # C is inverse of lam\\nmodel.fit(X_train, y_train)\\ny_pred = model.predict(X_test)\\nprint(\"Accuracy %.2f %%\" % (100*accuracy_score(y_test, y_pred.tolist())))\\nKết quả:\\nAccuracy: 92.19 %\\nSo với kết quả hơn 91.7% của one-vs-rest logistic regression, kết quả của softmax regression\\nđã được cải thiện được một chút. Kết quả thấp như thế này là có thể dự đoán được vì thực\\nra softmax regression vẫn chỉ tạo ra các đường ranh giới là các đường tuyến tính. Kết quả\\ntốt nhất của bài toán phân loại chữ số trong MNIST hiện nay vào khoảng hơn 99.7%, đạt\\nđược bằng một convolutional neural network với rất nhiều hidden layer và layer cuối cùng\\nchính là một softmax regression.\\n15.5 Thảo luận\\n15.5.1 Logistic regression là một trường hợp đặt biệt của softmax regression\\nKhi C = 2, softmax regression và logistic regression là giống nhau. Thật vậy, vớiC = 2, đầu\\nra của hàm softmax cho một đầu vàox là\\na1 = exp(wT\\n1 x)\\nexp(wT\\n1 x) + exp(wT\\n2 x) = 1\\n1 + exp((w2 −w1)Tx); a2 = 1 −a1 (15.15)\\nTừ đây ta thấy rằng,a1 có dạng là một hàm sigmoid với vector hệ sốw = −(w2 −w1).\\nKhi C = 2, bạn đọc cũng có thể thấy rằng hàm mất mát của logistic regression và softmax\\nregression là như nhau. Hơn nữa, mặc dù có hai outputs, softmax regression có thể biểu diễn\\nbởi một output vì tổng của hai outputs luôn luôn bằng 1.\\nSoftmax regression còn có các tên gọi khác là multinomial logistic regression, hay maximum\\nentropy classifier. Giống như logisticregression, softmaxregression được sử dụng trong các'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 202, 'page_label': '191'}, page_content='Softmax regression còn có các tên gọi khác là multinomial logistic regression, hay maximum\\nentropy classifier. Giống như logisticregression, softmaxregression được sử dụng trong các\\nbài toánclassification. Các tên gọi này được giữ lại vì vấn đề lịch sử.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 203, 'page_label': '192'}, page_content='CHƯƠNG 15. SOFTMAX REGRESSION 192\\n15.5.2 Ranh giới tạo bởi softmax regression là một mặt tuyến tính\\nThật vậy, dựa vào hàm softmax thì một điểm dữ liệux được dự đoán là rơi vào classj nếu\\naj ≥ak, ∀k̸= j. Bạn đọc có thể chứng minh được rằng\\naj ≥ak ⇔zj ≥zk ⇔wT\\nj x ≥wT\\nkx ⇔(wj −wk)Tx ≥0 (15.16)\\nNhư vậy, một điểm thuộc lớp thứj nếu và chỉ nếu(wj −wk)Tx ≥0, ∀k̸= j. Như vậy,lãnh\\nthổ của mỗi lớp dữ liệu là giao của các nửa không gian. Nói cách khác, đường ranh giới giữa\\ncác lớp là các mặt tuyến tính.\\n15.5.3 Softmax Regression là một trong hai classifiers phổ biến nhất\\nSoftmax regression cùng với multi-class support vector machine (Chương 29) là hai bộ phân\\nlớp phổ biến nhất được dùng hiện nay. Softmax regression đặc biệt được sử dụng nhiều trong\\ncác deep neural network với rất nhiều hidden layer. Những layer phía trước có thể được coi\\nnhư một bộ tạo vector đặc trưng, layer cuối cùng thường là một softmax regression.\\n15.5.4 Source code\\nSource code cho chương này có thể được tìm thấy tạihttps://goo.gl/XU8ZXm .\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 204, 'page_label': '193'}, page_content='Chương 16\\nMultilayer neural network và\\nbackpropagation\\n16.1 Giới thiệu\\n16.1.1 Perceptron cho các hàm logic cơ bản\\nChúng ta cùng xét khả năng biểu diễn của perceptron (PLA) cho các bài toán biểu diễn các\\nhàm logic nhị phân: NOT, AND, OR, và XOR1. Để có thể sử dụng perceptron (với đầu ra\\nlà 1 hoặc -1), chúng ta sẽ thay các giá trị bằng 0 (false) của tại đầu ra của các hàm này bởi\\n-1. Quan sát hàng trên của Hình 16.1, các điểm hình vuông màu xanh là các điểm có nhãn\\nbằng 1, các điểm hình tròn màu đỏ là các điểm có nhãn bằng -1. Hàng dưới của Hình 16.1\\nlà các mô hình perceptron với các hệ số tương ứng.\\nNhận thấy rằng với các bài toán NOT, AND, và OR, dữ liệu hai lớp là linearly separable,\\nvì vậy ta có thể tìm được các hệ số cho perceptron giúp biểu diễn chính xác mỗi hàm\\nsố. Chẳng hạn với hàm NOT, khix1 = 0 , ta có a = sgn(−2 ×0 + 1) = 1 ; khi x1 = 1 ,\\na= sgn(−2 ×1 + 1) = −1. Trong cả hai trường hợp, đầu ra dự đoán đều giống với đầu ra\\nthực sự. Bạn đọc có thể tự kiểm chứng các hệ số với hàm AND và OR.\\n16.1.2 Biểu diễn hàm XOR với nhiều perceptron\\nHàm XOR, vì dữ liệu không linearly separable, không thể biểu diễn bằng một perceptron.\\nNếu thay perceptron bằng logistic regression tức thay hàm kích hoạt từ hàm sign sang hàm\\nsigmoid, ta cũng không tìm được các hệ số thỏa mãn, vì về bản chất, logistic regression (hay\\ncả softmax regression) cũng chỉ tạo ra các ranh giới có dạng tuyến tính. Như vậy là các mô\\nhình neural network chúng ta đã biết không thể biểu diễn được hàm số logic đơn giản này.\\n1 đầu ra bằng 1 (true) nếu và chỉ nếu hai đầu vào logic khác nhau.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 205, 'page_label': '194'}, page_content='CHƯƠNG 16. MULTILAYER NEURAL NETWORK VÀ BACKPROPAGATION 194\\n0 1\\nx1\\n0\\n1\\nx2\\n2x1 + 2\\nx2 −3 = 0\\n+\\n−\\nAND problem\\n1x0\\nx1\\nx2 a\\n−3\\n2\\n2\\na = sgn(2x1 + 2x2 − 3)\\n0 1\\nx1\\n0\\n1\\nx2\\n 2x1 + 2\\nx2 −1 = 0\\n+−\\nOR problem\\n1x0\\nx1\\nx2 a\\n−1\\n2\\n2\\na = sgn(2x1 + 2x2 − 1)\\n0 1\\nx1 −2x1+ 1 = 0\\n+ -\\nNOT problem\\n1x0\\nx1\\na\\n1\\n−2\\na = sgn(−2x1 + 1)\\n0 1\\nx1\\n0\\n1\\nx2\\n?\\nXOR problem\\n1x0\\nx1\\nx2 a\\n?\\n?\\n?\\nNo solution!\\nHình 16.1: Biểu diễn các hàm logic cơ bản sử dụng perceptron learning algorithm.\\n0 1\\nx1\\n0\\n1\\nx2\\n−2x1 −2x2 + 3 = 0\\n2x1 + 2\\nx2 −1 = 0\\n−\\n+\\n+−\\nXOR problem (2 layers)\\nInput layer\\n1\\nx0\\nx1\\nx2\\nW (1)\\nb (1)\\nHidden layer\\na(1)\\n1\\na(1)\\n2\\n1\\na(1)\\n0\\n−1\\n2\\n2\\n3\\n−2\\n−2\\nW (2)\\nb (2)\\nOutput layer\\na(2)\\n1\\n1\\n−1\\n(a) (b)\\nW(1) =\\n[−2 2\\n−2 2\\n]\\n; b(1) =\\n[ 3\\n−1\\n]\\nW(2) =\\n[1\\n1\\n]\\n; b(2) =\\n[−1]\\nx =\\n[x1\\nx2\\n]\\n; a(1) =\\n[\\na(1)\\n1\\na(1)\\n2\\n]\\na(1) = f\\n(\\nW(1)T x + b(1)\\n)\\na(2) = f\\n(\\nW(2)T a(1) + b(2)\\n)\\nf(.) =sgn(.) (element-wise)\\nHình 16.2: Ba perceptron biểu diễn hàm XOR.\\nNhận thấy rằng nếu cho phép sử dụng hai đường thẳng, bài toán biểu diễn hàm XOR có thể\\nđược giải quyết như Hình 16.2. Các hệ số tương ứng với hai đường thẳng trong Hình 16.2a\\nđược minh họa trên Hình 16.2b bằng các mũi tên xuất phát từ các điểm màu lục và cam.\\nĐầu raa(1)\\n1 bằng 1 với các điểm nằm về phía (+) của đường thẳng3 −2x1 −2x2 = 0, bằng\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 206, 'page_label': '195'}, page_content='195 CHƯƠNG 16. MULTILAYER NEURAL NETWORK VÀ BACKPROPAGATION\\n-1 với các điểm nằm về phía (-). Tương tự, đầu raa2 bằng 1 với các điểm nằm về phía (+)\\ncủa đường thẳng −1 + 2x1 + 2x2 = 0 . Như vậy, hai đường thằng ứng với hai perceptron\\nnày tạo ra hai đầu ra tại các nodea(1)\\n1 ,a(1)\\n2 . Vì hàm XOR chỉ có một đầu ra nên ta cần làm\\nthêm một bước nữa: coia1,a2 như là đầu vào của một perceptron khác. Trong perceptron\\nmới này, input là các node màu cam (đừng quên bias node luôn có giá trị bằng 1), đầu ra là\\nnode màu đỏ. Các hệ số được cho trên Hình 16.2b. Kiểm tra lại một chút, với các điểm hình\\nvuông xanh (Hình 16.2a),a(1)\\n1 = a(1)\\n2 = 1, khi đóa(2) = sgn(−1 + 1 + 1) = 1. Với các điểm\\nhình tròn đỏ, vìa(1)\\n1 = −a(1)\\n2 nên a(2) = sgn(−1 + a(1)\\n1 + a(1)\\n2 ) = sgn(−1) = −1. Trong cả hai\\ntrường hợp, đầu ra dự đoán đều giống với đầu ra thực sự. Vậy, nếu sử dụng ba perceptron\\ntương ứng với các đầu raa(1)\\n1 ,a(1)\\n2 ,a(2), ta sẽ biểu diễn được hàm XOR. Ba perceptron kể\\ntrên được xếp vào hailayers. Layer thứ nhất: đầu vào - lục, đầu ra - cam. Layer thứ hai:\\nđầu vào - cam, đầu ra - đỏ. Ở đây, đầu ra của layer thứ nhất chính là đầu vào của layer thứ\\nhai. Tổng hợp lại ta được một mô hình mà ngoài layer đầu vào (lục) và đầu ra (đỏ), ta còn\\ncó một layer nữa (cam).\\nMột neural network với nhiều hơn hai layer còn được gọi là multilayer neural network,\\nmultilayer perceptrons(MLPs), deep feedforward networkhoặc feedforward neural network.\\nTừ feedforward được hiểu là dữ liệu đithẳng từ đầu vào tới đầu ra theo các mũi tên mà\\nkhông quay lại ở điểm nào, tức là network có dạng mộtacyclic graph (đồ thị không chứa\\nchu trình kín). Tên gọiperceptronở đây có thể gây nhầm lẫn một chút2, vì cụm từ này để\\nchỉ neural network với nhiều layer và mỗi layer không nhất thiết, nếu không muốn nói là rất\\nhiếm khi, là một hoặc nhiều perceptron. Hàm kích hoạt có thể là các hàm phi tuyến khác\\nthay vì hàm sgn.\\nCụ thể hơn, một multilayer neural network là một neural network có nhiều layer, làm nhiệm'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 206, 'page_label': '195'}, page_content='hiếm khi, là một hoặc nhiều perceptron. Hàm kích hoạt có thể là các hàm phi tuyến khác\\nthay vì hàm sgn.\\nCụ thể hơn, một multilayer neural network là một neural network có nhiều layer, làm nhiệm\\nvụ xấp xỉ mối quan hệ giữa các cặp quan hệ(x,y) trong tập huấn luyện bằng một hàm số\\ncó dạng\\ny ≈g(L) (\\ng(L−1) (\\n... (g(2)(g(1)(x)))\\n))\\n, (16.1)\\nTrong đó, layer thứ nhất đóng vai trò như hàma(1) ≜g(1)(x); layer thứ hai đóng vai trò như\\nhàm a(2) ≜g(2)(g(1)(x)) = f(2)(a(1)), v.v..\\nTrong phạm vi cuốn sách, chúng ta quan tâm tới các layer đóng vai trò như các hàm có dạng\\ng(l)(a(l−1)) = f(l)(W(l)Ta(l−1) + b(l)) (16.2)\\nvới W(l),b(l) là ma trận và vector với số chiều phù hợp,f(l) là một hàm số được gọi làhàm\\nkích hoạt(activation function).\\nMột vài lưu ý:\\n• Để cho đơn giản, chúng ta sử dụng ký hiệuW(l)T để thay cho(W(l))T (ma trận chuyển\\nvị). Trong Hình 16.2b, ký hiệu ma trậnW(2) được sử dụng, mặc dù đúng ra nó phải là\\n2 Geofrey Hinton,phù thuỷ Deep Learning, từng thừa nhận trong khoá học “Neural Networks for Machine Learning”\\n(https://goo.gl/UfdT1t ) rằng “Multilayer Neural Networks should never have been called Multilayer Perceptron.\\nIt is partly my fault, and I’m sorry.”.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 207, 'page_label': '196'}, page_content='CHƯƠNG 16. MULTILAYER NEURAL NETWORK VÀ BACKPROPAGATION 196\\nInput\\nW(1)\\nHidden 1\\nW(2)\\nHidden 2\\nW(3)\\nOutput\\nHình 16.3: MLP với hai hidden\\nlayers (các biases đã bị ẩn).\\nvector, để biểu diễn tổng quát cho trường hợp output layer có thể có nhiều hơn một node.\\nTương tự với biasb(2).\\n• Khác với các chương trước về neural network, khi làm việc với multilayer neural network,\\nta nên tách riêng phần bias và ma trận hệ số. Điều này đồng nghĩa với việc vector input\\nx là vector KHÔNG mở rộng.\\nĐầu ra của multilayer neural network loại này ứng với một đầu vàox có thể được tính theo\\na(0) = x (16.3)\\nz(l) = W(l)Ta(l−1) + b(l), l = 1,2,...,L (16.4)\\na(l) = f(l)(z(l)), l = 1,2,...,L (16.5)\\nˆ y= a(L) (16.6)\\nĐây chính là đầu ra dự đoán. Bước này được gọi làfeedforward vì cách tính toán được thực\\nhiện từ đầu đến cuối của network. Hàm mất mát thoả mãn đạt giá trị nhỏ khi đầu ra này\\ngần với đầu ra thực sự. Tuỳ vào bài toán, là classification hoặc regression, chúng ta cần thiết\\nkế các hàm mất mát phù hợp.\\n16.2 Các ký hiệu và khái niệm\\n16.2.1 Layer\\nNgoài input layer và output layer, một multilayer neural network có thể có nhiềuhidden\\nlayer ở giữa. Cáchidden layertheo thứ tự từ input layer đến output layer được đánh số thứ\\nthự làhidden layer 1, hidden layer 2, v.v.. Hình 16.3 là một ví dụ về một multilayer neural\\nnetwork với hai hidden layer.\\nSố lượng layer trong một multilayer neural network, được ký hiệu làL, được tính bằng số\\nhidden layer cộng với một. Khi đếm số layer của một multilayer neural network, ta không\\ntính input layer. Trong Hình 16.3,L= 3.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 208, 'page_label': '197'}, page_content='197 CHƯƠNG 16. MULTILAYER NEURAL NETWORK VÀ BACKPROPAGATION\\nz(l−1) a(l−1)\\n(l −1)th layer\\n1\\nz(l−1)\\n1 a(l−1)\\n1...\\nz(l−1)\\ni a(l−1)\\ni...\\nz(l−1)\\nd(l−1) a(l−1)\\nd(l−1)\\nW ( l ) ∈ R d\\n( l − 1)\\n× d\\n( l )\\nb ( l ) ∈ R d\\n( l )\\n× 1\\nz\\n( l )\\nj = w\\n( l ) T\\nj a ( l − 1) + b\\n( l )\\nj\\nz ( l ) = W ( l ) T a ( l − 1) + b ( l )\\na ( l ) = f ( z ( l ) )\\nlth layer\\nz(l) a(l)\\nz(l)\\n1 a(l)\\n1\\nz(l)\\n2 a(l)\\n2...\\nz(l)\\nj a(l)\\nj...\\nz(l)\\nd(l) a(l)\\nd(l)\\nw(l)\\nij\\nb(l)\\nj\\nHình 16.4: Các ký hiệu sử\\ndụng trong multilayer neural\\nnetwork.\\n16.2.2 Units\\nQuan sát Hình 16.4, mỗinode hình tròn trong một layer được gọi là mộtunit. Unit ở input\\nlayer, các hidden layer, và output layer được lần lượt gọi là input unit, hidden unit, và output\\nunit. Đầu vào của hidden layer thứl được ký hiệu bởiz(l), đầu ra của mỗi unit thường được\\nký hiệu làa(l) (thể hiện activation, tức giá trị của mỗi unit sau khi ta áp dụng activation\\nfunction lên đầu vàoz(l)). Đầu ra của unit thứi trong layer thứl được ký hiệu làa(l)\\ni . Giả\\nsử thêm rằng số unit trong layer thứl (không tính bias) làd(l). Vector biểu diễn output của\\nlayer thứl được ký hiệu làa(l) ∈Rd(l)\\n.\\n16.2.3 Weights và Biases\\nCó Lma trận trọng số cho một multilayer neural network cóLlayer. Các ma trận này được\\nký hiệu làW(l) ∈Rd(l−1)×d(l)\\n,l = 1,2,...,L trong đóW(l) thể hiện cáckết nối từ layer thứ\\nl−1 tới layer thứl (nếu ta coi input layer là layer thứ0). Cụ thể hơn, phần tửw(l)\\nij thể hiện\\nkết nối từ node thứicủa layer thứ(l−1) tới node từj của layer thứ(l). Các bias của layer\\nthứ (l) được ký hiệu làb(l) ∈Rd(l)\\n. Các trọng số này được ký hiệu như trên Hình 16.4. Khi\\ntối ưu một multilayer neural network cho một công việc nào đó, chúng ta cần đi tìm các\\nweight và bias này. Tập hợp các weight và bias lần lượt được ký hiệu làW và b.\\n16.3 Activation function–Hàm kích hoạt\\nMỗi output của một layer (trừ input layer) được tính dựa vào công thức\\na(l) = f(l)(W(l)Ta(l−1) + b(l)) (16.7)\\nTrong đóf(l)(.) là một hàm kích hoạt phi tuyến. Nếu hàm kích hoạt tại một layer là một'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 208, 'page_label': '197'}, page_content='Mỗi output của một layer (trừ input layer) được tính dựa vào công thức\\na(l) = f(l)(W(l)Ta(l−1) + b(l)) (16.7)\\nTrong đóf(l)(.) là một hàm kích hoạt phi tuyến. Nếu hàm kích hoạt tại một layer là một\\nhàm tuyến tính, layer này và layer tiếp theo có thể rút gọn thành một layer vìhợp của các\\nhàm tuyến tính là một hàm tuyến tính.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 209, 'page_label': '198'}, page_content='CHƯƠNG 16. MULTILAYER NEURAL NETWORK VÀ BACKPROPAGATION 198\\n−2 0 2\\nz\\n0.0\\n0.2\\n0.4\\n0.6\\n0.8\\n1.0\\na = 1/(1 + e−z)\\nsigmoid function\\n(a)\\n−2 0 2\\nz\\n−1.0\\n−0.5\\n0.0\\n0.5\\n1.0\\na = (ez − e−z/(ez + e−z)\\ntanh function (b)\\nHình 16.5: Ví dụ về đồ thị của hàm (a)sigmoid và (b)tanh.\\nHàm kích hoạt thường là một hàm số áp dụng lêntừng phần tử của ma trận hoặc vector\\nđầu vào, nói cách khác, hàm kích hoạt thường làelement-wise3.\\n16.3.1 Hàmsgn không được sử dụng trong MLP\\nHàm sgn chỉ được sử dụng trong perceptron. Trong thực tế, hàmsgn không được sử dụng\\nvì và đạo hàm tại hầu hết các điểm bằng 0 (trừ tại điểm 0 không có đạo hàm). Việc đạo\\nhàm bằng 0 này khiến cho các thuật toán dựa trên gradient không hoạt động.\\n16.3.2 Sigmoid và tanh\\nHàm sigmoid có dạng sigmoid(z) = 1/(1 + exp(−z)) với đồ thị như trong Hình 16.5a. Nếu\\nđầu vào lớn, hàm số sẽ cho đầu ra gần với 1. Với đầu vào nhỏ (rất âm), hàm số sẽ cho đầu ra\\ngần với 0. Trước đây, hàm kích hoạt này được sử dụng nhiều vì có đạo hàm rấtđẹp. Những\\nnăm gần đây, hàm số này ít khi được sử dụng. Một hàm tương tự thường được sử dụng và\\nmang lại hiệu quả tốt hơn là hàm tanh với tanh(z) = exp(z) −exp (−z)\\nexp(z) + exp(−z) . Hàm số này có\\ntính chất đầu ra chạy từ -1 đến 1, khiến cho nó có tính chất zero-centered, thay vì chỉ dương\\nnhư hàm sigmoid. Gần đây, hàm sigmoid chỉ được sử dụng ở output layer khi yêu cầu của\\nđầu ra là các giá trị nhị phân. Một nhược điểm dễ nhận thấy là khi đầu vào có trị tuyệt\\nđối lớn (rất âm hoặc rất dương), đạo hàm của cả sigmoid và tanh sẽ rất gần với 0. Điều\\nnày đồng nghĩa với việc các hệ số tương ứng với unit đang xét sẽ gần như không được cập\\nnhật khi sử dụng công thức cập nhật gradient desent. Thêm nữa, khi khởi tạo các hệ số cho\\nmultilayer neural network với hàm kích hoạt sigmoid, chúng ta phải tránh trường hợp đầu\\nvào một hidden layer nào đó quá lớn, vì khi đó đầu ra của hidden layer đó sẽ rất gần với 0\\nhoặc 1, dẫn đến đạo hàm bằng 0 và gradient desent hoạt động không hiệu quả.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 209, 'page_label': '198'}, page_content='vào một hidden layer nào đó quá lớn, vì khi đó đầu ra của hidden layer đó sẽ rất gần với 0\\nhoặc 1, dẫn đến đạo hàm bằng 0 và gradient desent hoạt động không hiệu quả.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 210, 'page_label': '199'}, page_content='199 CHƯƠNG 16. MULTILAYER NEURAL NETWORK VÀ BACKPROPAGATION\\n−3 −2 −1 0 1 2 3\\nz\\n0.0\\n0.5\\n1.0\\n1.5\\n2.0\\n2.5\\n3.0\\na = max(z, 0)\\nReLU function\\n(a)\\n(b)\\nHình 16.6: Hàm ReLU và tốc độ hội tụ khi so sánh với hàm tanh.\\n16.3.3 ReLU\\nReLU (Rectified Linear Unit) được sử dụng rộng rãi gần đây vì tính đơn giản của nó. Đồ\\nthị của hàm ReLU được minh họa trên Hình 16.6a. Hàm ReLU có công thức toán học\\nf(z) = max(0 ,z) - rất đơn giản, rất lợi về mặt tính toán. Đạo hàm của nó bằng 0 tại các\\nđiểm âm, bằng 1 tại các điểm dương. ReLU được chứng minh giúp cho việc huấn luyện các\\nmultilayer neural network và deep network (rất nhiều hidden layer) nhanh hơn rất nhiều so\\nvới hàm tanh [KSH12]. Hình 16.6b so sánh sự hội tụ của hàm mất mát khi sử dụng hai hàm\\nkích hoặc ReLU và tanh. Sự tăng tốc này được cho là vì ReLU được tính toán gần như tức\\nthời và gradient của nó cũng được tính cực nhanh.\\nMặc dù cũng có nhược điểm đạo hàm bằng 0 với các giá trị đầu vào âm, ReLU được chứng\\nminh bằng thực nghiệm rằng có thể khắc phục việc này bằng việc tăng số hidden unit4.\\nReLU trở thành hàm kích hoạt đầu tiên chúng ta nên thử khi thiết kế một multilayer neural\\nnetwork. Hầu hết các network đều có hàm kích hoạt là ReLU trong các hidden unit, trừ hàm\\nkích hoạt ở output layer phụ thuộc vào đầu ra thực sự của mỗi bài toán (có thể nhận giá trị\\nâm, hoặc nhị phân, v.v.).\\nNgoài ra, các biến thể của ReLU như leaky rectified linear unit (Leaky ReLU), parametric\\nrectified linear unit (PReLU) và randomized leaky rectified linear units (RReLU) [XWCL15]\\ncũng được sử dụng và được báo cáo có kết quả tốt. Trong thực tế, trước khi thiết kế, ta\\nthường không biết chính xác hàm kích hoạt nào sẽ cho kết quả tốt nhất. Tuy nhiên, ta nên\\nbắt đầu bằng ReLU, nếu kết quả chưa khả quan thì có thể thay thế bằng các biến thể của\\nnó và so sánh kết quả.\\n3 Hàm softmax không phải là một hàmelement-wise vì nó sử dụng mọi thành phần của vector đầu vào.\\n4 Neural Networks and Deep Learning – Activation function(https://goo.gl/QGjKmU ).'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 210, 'page_label': '199'}, page_content='3 Hàm softmax không phải là một hàmelement-wise vì nó sử dụng mọi thành phần của vector đầu vào.\\n4 Neural Networks and Deep Learning – Activation function(https://goo.gl/QGjKmU ).\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 211, 'page_label': '200'}, page_content='CHƯƠNG 16. MULTILAYER NEURAL NETWORK VÀ BACKPROPAGATION 200\\n16.4 Backpropagation\\nPhương pháp phổ biến nhất để tối ưu multilayer neural network chính là gradient descent\\n(GD). Để áp dụng GD, chúng ta cần tính được đạo hàm của hàm mất mát theo từng ma\\ntrận trọng sốW(l) và vector biasb(l).\\nGiả sửJ(W,b,X,Y) là một hàm mất mát của bài toán, trong đóW,b là tập hợp tất cả\\ncác ma trận trọng số giữa các layer và vector bias của mỗi layer.X,Y là cặp dữ liệu huấn\\nluyện với mỗi cột tương ứng với một điểm dữ liệu. Để có thể áp dụng các phương pháp\\ngradient descent, chúng ta cần tính được các∇W(l) J; ∇b(l) J, ∀l= 1,2,...,L .\\nNhắc lại quá trình feedforward\\na(0) = x (16.8)\\nz(l) = W(l)Ta(l−1) + b(l), l = 1,2,...,L (16.9)\\na(l) = f(l)(z(l)), l = 1,2,...,L (16.10)\\nˆ y= a(L) (16.11)\\nMột ví dụ của hàm mất mát là hàm mean square error (MSE):\\nJ(W,b,X,Y) = 1\\nN\\nN∑\\nn=1\\n∥yn −ˆ yn∥2\\n2 = 1\\nN\\nN∑\\nn=1\\n∥yn −a(L)\\nn ∥2\\n2 (16.12)\\nvới N là số cặp dữ liệu(x,y) trong tập huấn luyện. Theo các công thức này, việc tính toán\\ntrực tiếp các giá trị đạo hàm là cực kỳ phức tạp vì hàm mất mát không phụ thuộc trực\\ntiếp vào các ma trận hệ số và vector bias. Phương pháp phổ biến nhất được dùng có tên là\\nbackpropagation giúp tính đạo hàm ngược từ layer cuối cùng đến layer đầu tiên. Layer cuối\\ncùng được tính toán trước vì nógần gũihơn vớiđầu ra dự đoánvà hàm mất mát. Việc tính\\ntoán đạo hàm của các ma trận hệ số trong các layer trước được thực hiện dựa trên một quy\\ntắc chuỗi quen thuộc chođạo hàm của hàm hợp.\\nStochastic gradient descent có thể được sử dụng để tính gradient cho các ma trận trọng số\\nvà biases dựa trên một cặp điểm trainingx,y. Để cho đơn giản, ta coiJ là hàm mất mát\\nnếu chỉ xét cặp điểm này, ở đâyJ là hàm mất mát bất kỳ, không chỉ hàm MSE như ở trên.\\nĐạo hàm của hàm mất mát theochỉ một thành phầncủa ma trận trọng số của output layer\\n∂J\\n∂w(L)\\nij\\n= ∂J\\n∂z(L)\\nj\\n.∂z(L)\\nj\\n∂w(L)\\nij\\n= e(L)\\nj a(L−1)\\ni (16.13)\\ntrong đóe(L)\\nj = ∂J\\n∂z(L)\\nj\\nthường là một đại lượngkhông quá khó để tính toánvà ∂z(L)\\nj\\n∂w(L)\\nij\\n= a(L−1)'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 211, 'page_label': '200'}, page_content='∂J\\n∂w(L)\\nij\\n= ∂J\\n∂z(L)\\nj\\n.∂z(L)\\nj\\n∂w(L)\\nij\\n= e(L)\\nj a(L−1)\\ni (16.13)\\ntrong đóe(L)\\nj = ∂J\\n∂z(L)\\nj\\nthường là một đại lượngkhông quá khó để tính toánvà ∂z(L)\\nj\\n∂w(L)\\nij\\n= a(L−1)\\ni\\nvì z(L)\\nj = w(L)T\\nj a(L−1) + b(L)\\nj . Tương tự, đạo hàm của hàm mất mát theo bias của layer cuối\\ncùng là\\n∂J\\n∂b(L)\\nj\\n= ∂J\\n∂z(L)\\nj\\n.∂z(L)\\nj\\n∂b(L)\\nj\\n= e(L)\\nj (16.14)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 212, 'page_label': '201'}, page_content='201 CHƯƠNG 16. MULTILAYER NEURAL NETWORK VÀ BACKPROPAGATION\\nz(l−1) a(l−1)\\n(l −1)th layer\\n1\\nz(l−1)\\n1 a(l−1)\\n1...\\nz(l−1)\\ni a(l−1)\\ni...\\nz(l−1)\\nd(l−1) a(l−1)\\nd(l−1)\\nW(l) ∈Rd(l−1)×d(l)\\nb(l) ∈Rd(l)×1\\nz(l)\\nj = w(l)T\\nj a(l−1) + b(l)\\nj\\nz(l) = W(l)T a(l−1) + b(l)\\na(l) = f(z(l))\\nlth layer\\nz(l) a(l)\\nz(l)\\n1 a(l)\\n1\\nz(l)\\n2 a(l)\\n2...\\nz(l)\\nj a(l)\\nj...\\nz(l)\\nd(l) a(l)\\nd(l)\\nw(l)\\nij\\nb(l)\\nj\\n(l + 1)th layer\\nz(l+1) a(l+1)\\nz(l+1)\\n1 a(l+1)\\n1\\nz(l+1)\\nk a(l+1)\\nk\\n...\\nz(l+1)\\nd(l+1) a(l+1)\\nd(l+1)\\n...\\nw(l+1)\\njk\\nHình 16.7: Mô phỏng cách tính backpropagation. Layer cuối có thể là output layer.\\nVới đạo hàm theo hệ số ở các lớpl thấp hơn, chúng ta hãy xem Hình 16.7. Ở đây, tại mỗi\\nunit, đầu vàoz và đầu raa được viết riêng để chúng ta tiện theo dõi.\\nDựa vào Hình 16.7, bằng quy nạp ngược từ cuối, ta có thể tính được\\n∂J\\n∂w(l)\\nij\\n= ∂J\\n∂z(l)\\nj\\n.∂z(l)\\nj\\n∂w(l)\\nij\\n= e(l)\\nj a(l−1)\\ni (16.15)\\nvới\\ne(l)\\nj = ∂J\\n∂z(l)\\nj\\n= ∂J\\n∂a(l)\\nj\\n.∂a(l)\\nj\\n∂z(l)\\nj\\n(16.16)\\n=\\n\\uf8eb\\n\\uf8ed\\nd(l+1)\\n∑\\nk=1\\n∂J\\n∂z(l+1)\\nk\\n.∂z(l+1)\\nk\\n∂a(l)\\nj\\n\\uf8f6\\n\\uf8f8f(l)′\\n(z(l)\\nj ) =\\n\\uf8eb\\n\\uf8ed\\nd(l+1)\\n∑\\nk=1\\ne(l+1)\\nk w(l+1)\\njk\\n\\uf8f6\\n\\uf8f8f(l)′\\n(z(l)\\nj ) (16.17)\\ntrong đóe(l+1) = [e(l+1)\\n1 ,e(l+1)\\n2 ,...,e (l+1)\\nd(l+1) ]T ∈Rd(l+1)×1 và w(l+1)\\nj: được hiểu làhàng thứ j của\\nma trậnW(l+1) (chú ý dấu hai chấm, khi không có dấu này, chúng ta mặc định dùng nó để\\nký hiệu cho vectorcột). Dấu ∑tính tổng ở dòng thứ hai trong phép tính trên xuất hiện\\nvì a(l)\\nj đóng gópvào việc tính tất cả cácz(l+1)\\nk ,k = 1,2,...,d (l+1). Biểu thức đạo hàm ngoài\\ndấu ngoặc lớn là vìa(l)\\nj = f(l)(z(l)\\nj ). Tới đây, ta có thể thấy rằng việc activation function có\\nđạo hàm đơn giản sẽ có ích rất nhiều trong việc tính toán. Với cách làm tương tự, bạn đọc\\ncó thể suy ra\\n∂J\\n∂b(l)\\nj\\n= e(l)\\nj . (16.18)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 213, 'page_label': '202'}, page_content='CHƯƠNG 16. MULTILAYER NEURAL NETWORK VÀ BACKPROPAGATION 202\\nNhận thấy rằng trong các công thức trên đây, việc tính cáce(l)\\nj đóng một vài trò quan trọng.\\nHơn nữa, để tính được giá trị này, ta cần tính được cáce(l+1)\\nj . Nói cách khác, ta cần tính\\nngược các giá trị này từ cuối. Cái tênbackpropagation cũng xuất phát từ việc này.\\nViệc tính toán các đạo hàm khi sử dụng SGD có thể tóm tắt như sau\\nThuật toán 16.1: Backpropagation tớiw(l)\\nij ,b(l)\\ni\\n1. Bước feedforward: Với 1 giá trị đầu vàox, tính giá trị đầu ra của network, trong\\nquá trình tính toán, lưu lại các giá trị activationa(l) tại mỗi layer.\\n2. Với mỗi unitj ở output layer, tính\\ne(L)\\nj = ∂J\\n∂z(L)\\nj\\n; ∂J\\n∂w(L)\\nij\\n= a(L−1)\\ni e(L)\\nj ; ∂J\\n∂b(L)\\nj\\n= e(L)\\nj (16.19)\\n3. Vớil= L−1,L −2,..., 1, tính:\\ne(l)\\nj =\\n(\\nw(l+1)\\nj: e(l+1)\\n)\\nf′(z(l)\\nj ) (16.20)\\n4. Cập nhật đạo hàm cho từng hệ số\\n∂J\\n∂w(l)\\nij\\n= a(l−1)\\ni e(l)\\nj ; ∂J\\n∂b(l)\\nj\\n= e(l)\\nj (16.21)\\nPhiên bảnvectorization của thuật toán trên có thể được thực hiện như sau.\\nThuật toán 16.2: Backpropagation tớiW(l) và vector biasb(l)\\n1. Bước feedforward: Với một giá trị đầu vàox, tính giá trị đầu ra của network, trong\\nquá trình tính toán, lưu lại các activationa(l) tại mỗi layer.\\n2. Với output layer, tính\\ne(L) = ∇z(L) J ∈Rd(L)\\n; ∇W(L) J = a(L−1)e(L)T ∈Rd(L−1)×d(L)\\n; ∇b(L) J = e(L)\\n3. Vớil= L−1,L −2,..., 1, tính:\\ne(l) =\\n(\\nW(l+1)e(l+1))\\n⊙f′(z(l)) ∈Rd(l)\\n(16.22)\\ntrong đó⊙là element-wise product hay Hadamard product tức lấy từng thành phần\\ncủa hai vector nhân với nhau để được vector kết quả.\\n4. Cập nhật đạo hàm cho các ma trận trọng số và vector bias:\\n∇W(l) J = a(l−1)e(l)T ∈Rd(l−1)×d(l)\\n; ∇b(l) J = e(l) (16.23)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 214, 'page_label': '203'}, page_content='203 CHƯƠNG 16. MULTILAYER NEURAL NETWORK VÀ BACKPROPAGATION\\nKhi làm việc với các phép tính đạo hàm phức tạp, ta luôn cần nhớ hai điều sau.\\n1. Đạo hàm của một hàm có đầu ra là một số vô hướng theo một vector hoặc ma trận là\\nmột đại lượng có cùng chiều với vector hoặc ma trận đó.\\n2. Để các phép nhân các ma trận, vector thực hiện được, ta cần đảm bảo chiều của chúng\\nphù hợp.\\nTrong công thức∇W(L) J = a(L−1)e(L)T, vế trái là một ma trận thuộcRd(L−1)×d(L)\\n, vậy vế\\nphải cũng phải là một đại lượng có chiều tương tự. Từ đó bạn đọc có thể thấy tại sao vế\\nphải phải làa(L−1)e(L)T mà không thể làa(L−1)e(L) hay e(L)a(L−1).\\n16.4.1 Backpropagation cho batch (mini-batch) gradient descent\\nNếu ta muốn thực hiện batch hoặc mini-batch GD thì thế nào? Trong thực tế, mini-batch GD\\nđược sử dụng nhiều nhất với các bài toán mà tập huấn luyện lớn. Nếu lượng dữ liệu là nhỏ,\\nbatch GD trực tiếp được sử dụng. Khi đó, cặp (input, output) sẽ ở dạng ma trận(X,Y). Giả\\nsử rằng mỗi lần tính toán, ta lấyN dữ liệu để tính toán. Khi đó,X ∈Rd(0)×N,Y ∈Rd(L)×N.\\nVới d(0) = d là chiều của dữ liệu đầu vào (không tính bias).\\nKhi đó các activation sau mỗi layer sẽ có dạngA(l) ∈Rd(l)×N. Tương tự,E(l) ∈Rd(l)×N. Và\\nta cũng có thể suy ra công thức cập nhật như sau.\\nThuật toán 16.3: Backpropagation tớiW(l) và biasb(l) (mini-batch)\\n1. Bước feedforward: Với toàn bộ dữ liệu (batch) hoặc một nhóm dữ liệu (mini-batch)\\nđầu vàoX, tính giá trị đầu ra của network, trong quá trình tính toán, lưu lại các\\nactivation A(l) tại mỗi layer. Mỗi cột củaA(l) tương ứng với một cột củaX, tức\\nmột điểm dữ liệu đầu vào.\\n2. Với output layer, tính\\nE(L) = ∇Z(L) J; ∇W(L) J = A(L−1)E(L)T; ∇b(L) J =\\nN∑\\nn=1\\ne(L)\\nn (16.24)\\n3. Vớil= L−1,L −2,..., 1, tính:\\nE(l) =\\n(\\nW(l+1)E(l+1))\\n⊙f′(Z(l)) (16.25)\\ntrong đó⊙là element-wise product hay Hadamard product tức lấy từng thành phần\\ncủa hai ma trận nhân với nhau để được ma trận kết quả.\\n4. Cập nhật đạo hàm cho ma trận trọng số và vector biases:\\n∇W(l) J = A(l−1)E(l)T; ∇b(l) J =\\nN∑\\nn=1\\ne(l)\\nn (16.26)'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 214, 'page_label': '203'}, page_content='của hai ma trận nhân với nhau để được ma trận kết quả.\\n4. Cập nhật đạo hàm cho ma trận trọng số và vector biases:\\n∇W(l) J = A(l−1)E(l)T; ∇b(l) J =\\nN∑\\nn=1\\ne(l)\\nn (16.26)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 215, 'page_label': '204'}, page_content='CHƯƠNG 16. MULTILAYER NEURAL NETWORK VÀ BACKPROPAGATION 204\\n(a)\\n (b)\\nHình 16.8: Dữ liệu giả trong không gian hai chiều và ví dụ về các ranh giới tốt.\\nInput layer\\nW(1)\\nHidden layer\\nW(2)\\nOutput\\nSoftmax Regression\\nHình 16.9: Multilayer neural net-\\nworkvớiinputlayercóhaiunit(bias\\nđã được ẩn), một hidden layer với\\nhàm kích hoạt ReLU (có thể có số\\nlượng hidden unit tuỳ ý), và output\\nlayer là một softmax regression với\\nba phần tử đại diện cho ba lớp dữ\\nliệu.\\n16.5 Ví dụ trên Python\\nTrong mục này, chúng ta sẽ tạo dữ liệu giả trong không gian hai chiều sao cho đường ranh\\ngiới giữa các classkhông có dạng tuyến tính. Điều này khiến cho softmax regression không\\nlàm việc được. Tuy nhiên, bằng cách thêm một hidden layer, chúng ta sẽ thấy rằng neural\\nnetwork này làm việc rất hiệu quả.\\n16.5.1 Tạo dữ liệu giả\\nCác điểm dữ liệu giả của ba lớp được tạo và minh hoạ bởi các màu khác nhau trên Hình 16.8a.\\nTa thấy rõ ràng rằng đường ranh giới giữa các lớp dữ liệu không thể là các đường thẳng.\\nHình 16.8b là một ví dụ về các đường ranh giới được coi là tốt với hầu hết các điểm dữ\\nliệu nằm đúng vào khu vực có màu nền tương ứng. Các đường biên này được tạo sử dụng\\nmultilayer neural network với một hidden layer sử dụng ReLU làm hàm kích hoạt và output\\nlayer là một softmax regression như trên Hình 16.9. Chúng ta cùng đi sâu vào xây dựng bộ\\nphân lớp dựa trên dữ liệu huấn luyện này.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 216, 'page_label': '205'}, page_content='205 CHƯƠNG 16. MULTILAYER NEURAL NETWORK VÀ BACKPROPAGATION\\nNhắc lại hàm ReLUf(z) = max(z,0), với đạo hàm\\nf′(z) =\\n{\\n0 nếu z ≤0\\n1 o.w (16.27)\\nVì lượng dữ liệu huấn luyện là nhỏ với 100 điểm cho mỗi lớp, ta có thể dùng batch GD để\\ncập nhật các ma trận hệ số và vector bias. Trước hết, ta cần tính đạo hàm của hàm mất\\nmát theo các ma trận và vector này bằng cách áp dụng backpropagation.\\n16.5.2 Tính toán Feedforward\\nGiả sử các cặp dữ liệu huấn luyện là(xi,yi) với yi là một vector ở dạng one-hot. Các điểm\\ndữ liệu này xếp cạnh nhau tạo thành các ma trận đầu vàoX và ma trận đầu raY. Bước\\nfeedforward của neural network này được thực hiện như sau.\\nZ(1) = W(1)TX + B(1) (16.28)\\nA(1) = max(Z(1),0) (16.29)\\nZ(2) = W(2)TA(1) + B(2) (16.30)\\nˆY = A(2) = softmax(Z(2)) (16.31)\\nTrong đóB(1),B(2) là các ma trận bias với tất cả các cột bằng nhau và lần lượt bằngb(1)\\nvà b(2)5. Hàm mất mát được tính dựa trên hàm cross-entropy\\nJ ≜J(W,b; X,Y) = −1\\nN\\nN∑\\ni=1\\nC∑\\nj=1\\nyji log(ˆyji) (16.32)\\n16.5.3 Tính toán Backpropagation\\nÁp dụng Thuật toán 16.3, ta có\\nE(2) = ∇Z(2) = 1\\nN(A(2) −Y) (16.33)\\n∇W(2) = A(1)E(2)T; ∇b(2) =\\nN∑\\nn=1\\ne(2)\\nn (16.34)\\nE(1) =\\n(\\nW(2)E(2))\\n⊙f′(Z(1)) (16.35)\\n∇W(1) = A(0)E(1)T = XE(1)T; ∇b(1) =\\nN∑\\nn=1\\ne(1)\\nn (16.36)\\nCác công thức toán học phức tạp này sẽ được lập trình một cách đơn giản hơn trên numpy.\\n5 Ta cần xếp các vector bias giống nhau để tạo thành các ma trận bias vì trong toán học, không có định nghĩa tổng\\ncủa một ma trận và một vector. Khi lập trình, việc này là khả thi.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 217, 'page_label': '206'}, page_content='CHƯƠNG 16. MULTILAYER NEURAL NETWORK VÀ BACKPROPAGATION 206\\n16.5.4 Triển khai thuật toán trên numpy\\nTrước hết, ta viết lại hàm softmax và cross-entropy. Sau đó viết các hàm khởi tạo và dự\\nđoán nhãn của các điểm dữ liệu.\\ndef softmax_stable(Z):\\n\"\"\"\\nCompute softmax values for each sets of scores in Z.\\neach ROW of Z is a set of scores.\\n\"\"\"\\ne_Z = np.exp(Z - np.max(Z, axis = 1, keepdims = True))\\nA = e_Z / e_Z.sum(axis = 1, keepdims = True)\\nreturn A\\ndef crossentropy_loss(Yhat, y):\\n\"\"\"\\nYhat: a numpy array of shape (Npoints, nClasses) -- predicted output\\ny: a numpy array of shape (Npoints) -- ground truth.\\nNOTE: We don’t need to use the one-hot vector here since most of elements\\nare zeros. When programming in numpy, in each row of Yhat, we need to access\\nto the corresponding index only.\\n\"\"\"\\nid0 = range(Yhat.shape[0])\\nreturn -np.mean(np.log(Yhat[id0, y]))\\ndef mlp_init(d0, d1, d2):\\n\"\"\"\\nInitialize W1, b1, W2, b2\\nd0: dimension of input data\\nd1: number of hidden unit\\nd2: number of output unit = number of classes\\n\"\"\"\\nW1 = 0.01*np.random.randn(d0, d1)\\nb1 = np.zeros(d1)\\nW2 = 0.01*np.random.randn(d1, d2)\\nb2 = np.zeros(d2)\\nreturn (W1, b1, W2, b2)\\ndef mlp_predict(X, W1, b1, W2, b2):\\n\"\"\"\\nSuppose that the network has been trained, predict class of new points.\\nX: data matrix, each ROW is one data point.\\nW1, b1, W2, b2: learned weight matrices and biases\\n\"\"\"\\nZ1 = X.dot(W1) + b1 # shape (N, d1)\\nA1 = np.maximum(Z1, 0) # shape (N, d1)\\nZ2 = A1.dot(W2) + b2 # shape (N, d2)\\nreturn np.argmax(Z2, axis=1)\\nTiếp theo là hàm chính huấn luyện softmax regression.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 218, 'page_label': '207'}, page_content='207 CHƯƠNG 16. MULTILAYER NEURAL NETWORK VÀ BACKPROPAGATION\\ndef mlp_fit(X, y, W1, b1, W2, b2, eta):\\nloss_hist = []\\nfor i in xrange(20000): # number of epoches\\n# feedforward\\nZ1 = X.dot(W1) + b1 # shape (N, d1)\\nA1 = np.maximum(Z1, 0) # shape (N, d1)\\nZ2 = A1.dot(W2) + b2 # shape (N, d2)\\nYhat = softmax_stable(Z2) # shape (N, d2)\\nif i %1000 == 0: # print loss after each 1000 iterations\\nloss = crossentropy_loss(Yhat, y)\\nprint(\"iter %d, loss: %f\" %(i, loss))\\nloss_hist.append(loss)\\n# back propagation\\nid0 = range(Yhat.shape[0])\\nYhat[id0, y] -=1\\nE2 = Yhat/N # shape (N, d2)\\ndW2 = np.dot(A1.T, E2) # shape (d1, d2)\\ndb2 = np.sum(E2, axis = 0) # shape (d2,)\\nE1 = np.dot(E2, W2.T) # shape (N, d1)\\nE1[Z1 <= 0] = 0 # gradient of ReLU, shape (N, d1)\\ndW1 = np.dot(X.T, E1) # shape (d0, d1)\\ndb1 = np.sum(E1, axis = 0) # shape (d1,)\\n# Gradient Descent update\\nW1 += -eta*dW1\\nb1 += -eta*db1\\nW2 += -eta*dW2\\nb2 += -eta*db2\\nreturn (W1, b1, W2, b2, loss_hist)\\nSau khi đã hoàn thành các hàm chính của multilayer neural network này, chúng ta đưa dữ\\nliệu vào, xác định số hidden unit, và huấn luyện network.\\n# suppose X, y are training input and output, respectively\\nd0 = 2 # data dimension\\nd1 = h = 100 # number of hidden units\\nd2 = C = 3 # number of classes\\neta = 1 # learning rate\\n(W1, b1, W2, b2) = mlp_init(d0, d1, d2)\\n(W1, b1, W2, b2, loss_hist) =mlp_fit(X, y, W1, b1, W2, b2, eta)\\ny_pred = mlp_predict(X, W1, b1, W2, b2)\\nacc = 100*np.mean(y_pred == y)\\nprint(’training accuracy: %.2f %%’ % acc)\\nKết quả:\\niter 0, loss: 1.098628\\niter 2000, loss: 0.030014\\niter 4000, loss: 0.021071\\niter 6000, loss: 0.018158\\niter 8000, loss: 0.016914\\ntraining accuracy: 99.33 %\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 219, 'page_label': '208'}, page_content='CHƯƠNG 16. MULTILAYER NEURAL NETWORK VÀ BACKPROPAGATION 208\\n#hidden units = 2, accuracy =65.0%\\n(a)\\n#hidden units = 5, accuracy =85.6666666667% (b)\\n#hidden units = 15, accuracy = 99.00\\n(c)\\n#hidden units = 30, accuracy = 99.33 (d)\\nHình 16.10: Kết quả với số lượng units trong hidden layer là khác nhau.\\nTa có thể thấy rằng hàm mất mát giảm dần và hội tụ. Kết quả phân lớp trên tập huấn luyện\\nrất tốt, chỉ một vài điểm bị phân lớp lỗi, nhiều khả năng chúng nằm ở khu vực trung tâm.\\nVới chỉ một hidden layer, network đã thực hiện công việc gần như hoàn hảo.\\nBằng cách thay đổi số lượng hidden unit (biếnd1) và huấn luyện lại các network, minh hoạ\\nranh giới giữa các lớp dữ liệu, chúng ta thu được các kết quả như trên Hình 16.10. Khi chỉ\\ncó hai hidden unit, các đường ranh giới vẫn gần như đường thẳng, kết quả là có tới 35% số\\nđiểm dữ liệu trong tập huấn luyện bị phân lớp lỗi. Khi số lượng hidden unit là 5, độ chính\\nxác được cải thiện thêm khoảng 20%, tuy nhiên, các đường ranh giới vẫn chưa thực sự tốt.\\nThậm chí lớp đỏ và lam còn bị chia cắt một cách không tự nhiên. Nếu tiếp tục tăng số lượng\\nhidden unit, ta thấy rằng các đường ranh giới tương đối hoàn hảo.\\nCó thể chứng minh được rằng với một hàm số liên tục bất kỳf(x) và một sốε >0, luôn\\nluôn tồn tại một neural network với đầu ra có dạngg(x) với một hidden layer (với số hidden\\nunit đủ lớn và hàm kích hoạt phi tuyến phù hợp) sao cho với mọix,|f(x) −g(x)|< ε. Nói\\ncách khác, neural network có khả năng xấp xỉ bất kỳ hàm liên tục nào [Cyb89].\\nTrên thực tế, việc tìm ra số lượng hidden unit và hàm kích hoạt nói trên hầu như bất khả\\nthi. Thay vào đó, thực nghiệm chứng minh rằng neural network với nhiều hidden layer kết\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 220, 'page_label': '209'}, page_content='209 CHƯƠNG 16. MULTILAYER NEURAL NETWORK VÀ BACKPROPAGATION\\nhợp với các hàm kích hoạt đơn giản, ví dụ ReLU, có khả năng xấp xỉ dữ liệu tốt hơn tốt\\nhơn. Tuy nhiên, khi số lượng hidden layer lớn lên, số lượng hệ số cần tối ưu cũng lớn lên và\\nmô hình sẽ trở nên phức tạp. Sự phức tạp này ảnh hưởng tới hai khía cạnh. Thứ nhất, tốc\\nđộ tính toán sẽ bị chậm đi rất nhiều. Thứ hai, nếu mô hình quá phức tạp, nó có thể biểu\\ndiễn rất tốt dữ liệu huấn luyện, nhưng có thể không biểu diễn tốt dữ liệu kiểm thử. Đây\\nchính là hiện tượng overfitting.\\nVậy có các kỹ thuật nào giúp tránh overfitting cho multilayer neural network? Ngoài kỹ\\nthuật toán cross-validation, chúng ta quan tâm hơn tới các phương pháp regularization. Các\\nneural network với regularization được gọi làregularized neural network. Kỹ thuật phổ biến\\nnhất được dùng để tránh overfitting làweight decay.\\n16.6 Tránh overfitting cho neural network bằng weight decay\\nVới weight decay, hàm mất mát sẽ được cộng thêm một đại lượng regularization có dạng\\nλR(W) = λ\\nL∑\\nl=1\\n∥W(l)∥2\\nF\\ntức tổng bình phương Frobenius norm của tất cả các ma trận hệ số. Chú ý rằng khi làm việc\\nvới multilayer neural network, bias hiếm khi đượcregularized. Đây cũng là lý do vì sao ta\\nnên tách rời ma trận hệ số và vector bias khi làm việc với multilayer neural network. Việc\\ntối thiểu hàm mất mát mới (với số hạng regularization) sẽ khiến cho các thành phần của\\ncác vector hệ sốW(l) không quá lớn, thậm chí nhiều thành phần sẽ gần với không. Điều này\\nkhiến cho việc có nhiều hidden unit vẫn an toàn vì nhiều trong số chúng gần với không.\\nTiếp theo, chúng ta sẽ làm một ví dụ nữa trong không gian hai chiều. Lần này, chúng ta sẽ\\nsử dụng thư viện scikit-learn.\\nfrom __future__ import print_function\\nimport numpy as np\\nfrom sklearn.neural_network import MLPClassifier\\nmeans = [[-1, -1], [1, -1], [0, 1]]\\ncov = [[1, 0], [0, 1]]\\nN = 20\\nX0 = np.random.multivariate_normal(means[0], cov, N)\\nX1 = np.random.multivariate_normal(means[1], cov, N)'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 220, 'page_label': '209'}, page_content='means = [[-1, -1], [1, -1], [0, 1]]\\ncov = [[1, 0], [0, 1]]\\nN = 20\\nX0 = np.random.multivariate_normal(means[0], cov, N)\\nX1 = np.random.multivariate_normal(means[1], cov, N)\\nX2 = np.random.multivariate_normal(means[2], cov, N)\\nX = np.concatenate((X0, X1, X2), axis = 0)\\ny = np.asarray([0]*N + [1]*N + [2]*N)\\nalpha = 1e-1 # regularization parameter\\nclf = MLPClassifier(solver=’lbfgs’, alpha=alpha, hidden_layer_sizes=(100))\\nclf.fit(X, y)\\ny_pred = clf.predict(X)\\nacc = 100*np.mean(y_pred == y)\\nprint(’training accuracy: %.2f %%’ % acc)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 221, 'page_label': '210'}, page_content='CHƯƠNG 16. MULTILAYER NEURAL NETWORK VÀ BACKPROPAGATION 210\\n#alpha = 0.01, accuracy =100.0%\\n(a)\\n#alpha = 0.1, accuracy =100.0% (b)\\n#alpha = 1.0, accuracy =80.0%\\n(c)\\n#alpha = 10.0, accuracy =80.0% (d)\\nHình 16.11: Kết quả với số lượng units trong hidden layer là khác nhau.\\nKết quả:\\ntraining accuracy: 100.00 %\\nTrong đoạn code trên, thuộc tínhalpha chính là tham số regularizationλ. alpha càng lớn sẽ\\nkhiến các thành phần trong các ma trận hệ số càng nhỏ. Thuộc tínhhidden_layer_sizes chính\\nlà số lượng hidden unit trong mỗi hidden layer. Nếu có nhiều hidden layer, chẳng hạn hai\\nvới số lượng hidden unit lần lượt là 10 và 100, ta cần khai báohidden_layer_sizes=(10, 100).\\nHình 16.11 minh hoạ ranh giới giữa các lớp tìm được với các giá trịalpha khác nhau, tức mức\\nđộ regularization khác nhau. Khialpha nhỏ cỡ 0.01, các ranh giới tìm được trông không được\\ntự nhiên và vùng xác định lớp màu lục không được liên tục. Mặc dù độ chính xác trên tập\\nhuấn luyện này là 100%, ta có thể quan sát thấy rằng overfitting đã xảy ra. Vớialpha = 0.1,\\nkết quả cho thấylãnh thổ của các lớp đã liên tục, nhưng overfitting vẫn xảy ra. Khialpha\\ncao hơn, độ chính xác đã giảm xuống nhưng các đường ranh giới tự nhiên hơn. Bạn đọc có\\nthể thay đổi các giá trịalpha trong source code (https://goo.gl/czxrSf ) và quan sát các hiện\\ntượng xảy ra. Đặc biệt, khialpha = 100, độ chính xác còn 33.33%. Tại sao lại như vậy? Hy\\nvọng bạn đọc có thể tự trả lời được.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 222, 'page_label': '211'}, page_content='211 CHƯƠNG 16. MULTILAYER NEURAL NETWORK VÀ BACKPROPAGATION\\n16.7 Đọc thêm\\n1. Neural Networks: Setting up the Architecture,AndrejKarpathy( https://goo.gl/rfzCVK ).\\n2. Neural Networks, Case study, Andrej Karpathy (https://goo.gl/3ihCxL ).\\n3. Lecture Notes on Sparse Autoencoders, Andrew Ng (https://goo.gl/yTgtLe ).\\n4. Yes you should understand backprop(https://goo.gl/8B3h1b ).\\n5. Backpropagation, Intuitions, Andrej Karpathy (https://goo.gl/fjHzNV ).\\n6. How the backpropagation algorithm works, Michael Nielsen (https://goo.gl/mwz2kU ).\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 224, 'page_label': '213'}, page_content='Phần V\\nRecommendation systems–Hệ thống khuyến nghị\\nCác bạn có lẽ đã gặp những hiện tượng sau đây nhiều lần. Youtube tự động chạy các clip\\nliên quan đến clip bạn đang xem, hoặc tự động gợi ý những clip mà có thể bạn sẽ thích. Khi\\nbạn mua một món hàng trên Amazon, hệ thống sẽ tự động gợi ý những sản phẩmfrequently\\nbought together, hoặc nó biết bạn có thể thích món hàng nào dựa trên lịch sử mua hàng của\\nbạn. Facebook hiển thị quảng cáo những sản phẩm có liên quan đến từ khoá bạn vừa tìm\\nkiếm trên Google. Facebook gợi ý kết bạn. Netflix tự động gợi ý phim cho người dùng. Và\\ncòn rất nhiều ví dụ khác mà hệ thống có khả năng tự động gợi ý cho ngừời dùng những\\nsản phẩm họcó thể thích. Bằng cáchquảng cáo hướng đúng đối tượngđó, hiệu quả của việc\\nmarketing cũng sẽ tăng lên.\\nNhững thuật toán đằng sau những ứng dụng này là những thuật toán machine learning có\\ntên gọi chung làhệ thống khuyến nghị(recommender systemhoặc recommendation system).\\nTrong phần này của cuốn sách, chúng ta sẽ cùng tìm hiểu ba thuật toán cơ bản nhất trong\\nrất nhiều các thuật toánrecommendation system.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 225, 'page_label': '214'}, page_content='Chương 17\\nContent-based recommendation\\nsystem\\n17.1 Giới thiệu\\nRecommendation system là một mảng khá rộng của machine learning, và cótuổi đời ít hơn\\nso với classification hay regression vì internet mới chỉ thực sự bùng nổ khoảng 10-15 năm gần\\nđây. Có hai thực thể chính trong một recommendation system làuser vàitem. User là người\\ndùng; item là sản phẩm, ví dụ như các bộ phim, bài hát, cuốn sách, clip, hoặc cũng có thể\\nlà các người dùng khác trong bài toán gợi ý kết bạn. Mục đích chính của các recommender\\nsystem là dự đoánmức độ quan tâmcủa một người dùng tới một sản phẩm nào đó, qua đó\\ncó chiến lượcrecommendation phù hợp.\\n17.1.1 Hiện tượnglong tail trong thương mại\\nChúng ta cùng đi vào việc so sánh điểm khác nhau căn bản giữa cáccửa hàng thựcvà các\\ncửa hàng điện tử, xét trên khía cạnh lựa chọn sản phẩm để quảng bá. Ở đây, chúng ta tạm\\nquên đi khía cạnhcó cảm giác thật chạm vào sản phẩmcủa các cửa hàng thực. Hãy cùng\\ntập trung vào phần làm thế nào để quảng bá đúng sản phẩm tới đúng khách hàng.\\nCó thể các bạn đã biết tớiNguyên lý Pareto (hay quy tắc 20/80)(https://goo.gl/NujWjH ):\\nphần lớn kết quả được gây ra bởi phẩn nhỏ nguyên nhân. Phần lớn số từ sử dụng hàng ngày\\nchỉ là một phần nhỏ số từ trong bộ từ điển. Phần lớn của cải được sở hữu bởi phần nhỏ số\\nngười. Khi làm thương mại cũng vậy, những sản phẩm bán chạy nhất chỉ chiếm phần nhỏ\\ntổng số sản phẩm.\\nCác cửa hàng thựcthường có hai khu vực, một là khu trưng bày, hai là kho. Nguyên tắc dễ\\nthấy để đạt doanh thu cao là trưng ra các sản phẩm phổ biến nhất ở những nơi dễ nhìn thấy\\nvà cất những sản phẩm ít phổ biến trong kho. Cách làm này có một hạn chế rõ rệt: những\\nsản phẩm được trưng ra mang tính phổ biến chứ chưa chắc đã phù hợp với một khách hàng'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 226, 'page_label': '215'}, page_content='215 CHƯƠNG 17. CONTENT-BASED RECOMMENDATION SYSTEM\\ncụ thể. Một cửa hàng có thể có món hàng một khách hàng tìm kiếm nhưng có thể không\\nbán được vì khách hàng không nhìn thấy sản phẩm đó trên giá; việc này dẫn đến việc khách\\nhàng không tiếp cận được sản phẩm ngay cả khi chúng đã được trưng ra. Ngoài ra, vì không\\ngian có hạn, cửa hàng không thể trưng ra tất cả các sản phẩm mà mỗi loại chỉ đưa ra một\\nsố lượng nhỏ. Ở đây, phần lớn doanh thu (80%) đến từ phần nhỏ số sản phẩm phổ biến nhất\\n(20%). Nếu sắp xếp các sản phẩm của cửa hàng theo doanh số từ cao đến thấp, ta sẽ nhận\\nthấy có thể phần nhỏ các sản phẩm tạo ra phần lớn doanh số; và một danh sách dài phía sau\\nchỉ tạo ra một lượng đóng góp nhỏ. Hiện tượng này còn được gọi làlong tail phenomenon,\\ntức phầnđuôi dài của những sản phẩm ít phổ biến.\\nVới cáccửa hàng điện tử, nhược điểm trên hoàn toàn có thể tránh được. Vìgian trưng bày\\ncủa cáccửa hàng điện tửgần như là vô tận, mọi sản phẩm đều có thể được trưng ra. Hơn\\nnữa, việc sắp xếp online là linh hoạt, tiện lợi với chi phí chuyển đổi gần như bằng 0 khiến\\nviệc mang đúng sản phẩm tới khách hàng trở nên thuận tiện hơn. Doanh thu, vì thế có thể\\nđược tăng lên.\\n17.1.2 Hai nhóm chính của recommendation system\\nCác recommendation system thường được chia thành hai nhóm lớn:\\n1. Content-based system: khuyến nghị dựa trên đặc tính của sản phẩm. Ví dụ, một người\\ndùng xem rất nhiều các bộ phim về cảnh sát hình sự, vậy thì gơi ý một bộ phim trong\\ncơ sở dữ liệu có chung đặc tínhhình sự tới người dùng này, ví dụ phimNgười phán xử.\\nCách tiếp cận này yêu cầu việc sắp xếp các sản phẩm vào từng nhóm hoặc đi tìm các\\nđặc trưng của từng sản phẩm. Tuy nhiên, có những sản phẩm không có nhóm cụ thể và\\nviệc xác định nhóm hoặc đặc trưng của từng sản phẩm đôi khi là bất khả thi.\\n2. Collaborative filtering: hệ thống khuyến nghị các sản phẩm dựa trên sự tương quan\\n(similarity) giữa các người dùng và/hoặc sản phẩm. Có thể hiểu rằng ở nhóm này một'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 226, 'page_label': '215'}, page_content='2. Collaborative filtering: hệ thống khuyến nghị các sản phẩm dựa trên sự tương quan\\n(similarity) giữa các người dùng và/hoặc sản phẩm. Có thể hiểu rằng ở nhóm này một\\nsản phẩm đượckhuyến nghị tới một người dùng dựa trên những người dùng cóhành vi\\ntương tự. Ví dụ, ba người dùngA, B, C đều thích các bài hát của Noo Phước Thịnh.\\nNgoài ra, hệ thống biết rằng người dùngB, C cũng thích các bài hát của Bích Phương\\nnhưng chưa có thông tin về việc liệu người dùngA có thích Bích Phương hay không. Dựa\\ntrên thông tin của những người dùng tương tự làB và C, hệ thống có thể dự đoán rằng\\nA cũng thích Bích Phương và gợi ý các bài hát của ca sĩ này tớiA.\\nTrong chương này, chúng ta sẽ làm quen với nhóm thứ nhất,content-based system. Nhóm\\nthứ hai,collaborative filtering, sẽ được thảo luận trong các chương còn lại của chương.\\n17.2 Utility matrix\\nNhư đã đề cập, có hai thực thể chính trong các recommendation system làuser vàitem. Mỗi\\nuser sẽ cómức độ quan tâm(degree of preference) tới từngitem khác nhau. Mức độ quan\\ntâm này,nếu đã biết trước, được gán cho một giá trị ứng với mỗi cặpuser-item. Thông tin\\nvề mức độ quan tâm của mộtuser tới một item có thể được thu thập thông qua một hệ\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 227, 'page_label': '216'}, page_content='CHƯƠNG 17. CONTENT-BASED RECOMMENDATION SYSTEM 216\\nA\\n5\\n5\\n?\\n1\\n1\\nB\\n5\\n?\\n4\\n1\\n0\\nC\\n0\\n?\\n1\\n4\\n5\\nD\\n0\\n0\\n?\\n4\\n?\\nE\\n1\\n?\\n?\\n4\\n?\\nF\\n?\\n?\\n1\\n?\\n?\\nMưa nửa đêm\\nCỏ úa\\nVùng lá me bay\\nCon cò bé bé\\nEm yêu trường em\\nHình 17.1: Ví dụ về utility matrix\\nvới hệ thống khuyến nghị bài hát.\\nCác bài hát (item) được người dùng\\n(user) đánh giá theo mức độ từ 0\\nđến 5 sao. Các dấu ’?’ nền màu\\nxám ứng với việc dữ liệu chưa tồn\\ntại trong cơ sở dữ liệu. Recommen-\\ndation system cần phảitự điềncác\\ngiá trị này.\\nthống đánh giá (review và rating); hoặc có thể dựa trên việcuser đã click vào thông tin của\\nitem trên website; hoặc có thể dựa trên việc thời gian và số lần mộtuser xem thông tin của\\nmột item. Các ví dụ trong phần này đều dựa trên hệ thốngrating.\\n17.2.1 Ví dụ về utility matrix\\nVới một hệ thốngrating, mức độ quan tâmcủa mộtuser tới mộtitem được đo bằng giá trị\\nuser đó đã đánh giá choitem đó, chẳng hạn số sao trên tổng cộng năm sao. Tập hợp tất cả\\ncác rating, bao gồm cả những giá trị chưa biết cần được dự đoán, tạo nên một ma trận gọi\\nlà ma trậnutility. Xét ví dụ như trong Hình 17.1. Trong ví dụ này, có sáuuser A, B, C, D,\\nE, F và năm bài hát. Các ô màu xanh thể hiện việc mộtuser đã đánh giá một bài hát với\\nrating từ 0 (không thích) đến 5 (rất thích). Các ô có dấu ’?’ màu xám tương ứng với các ô\\nchưa có dữ liệu. Công việc của một recommendation system là dự đoán giá trị tại các ô màu\\nxám này, từ đó đưa ra gợi ý chouser. Vì vậy, bài toán recommendation system đôi khi được\\ncoi là bài toánhoàn thiện ma trận(matrix completion).\\nTrong ví dụ đơn giản này, dễ nhận thấy có hai thể loại nhạc khác nhau: ba bài đầu là nhạc\\nbolero và hai bài sau là nhạcthiếu nhi. Từ dữ liệu này, ta cũng có thể đoán được rằngA, B\\nthích thể loại nhạcBolero; trong khiC, D, E, Fthích thể loại nhạcThiếu nhi. Từ đó, một\\nhệ thống tốt nên gợi ýCỏ úa cho B; Vùng lá me baycho A; Em yêu trường emcho D, E,\\nF. Giả sử chỉ có hai thể loại nhạc này, khi có một bài hát mới, ta chỉ cần phân lớp nó vào\\nthể loại nào, từ đó đưa ra gợi ý với từnguser.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 227, 'page_label': '216'}, page_content='F. Giả sử chỉ có hai thể loại nhạc này, khi có một bài hát mới, ta chỉ cần phân lớp nó vào\\nthể loại nào, từ đó đưa ra gợi ý với từnguser.\\nThông thường, có rất nhiềuuser và item trong hệ thống, và mỗiuser thường chỉrate một\\nsố lượng rất nhỏ cácitem, thậm chí có nhữnguser không rateitem nào. Vì vậy, lượng ô màu\\nxám của ma trận utility thường là rất lớn, và lượng các ô đã được điền là một số rất nhỏ.\\nRõ ràng rằng càng nhiều ô được điền thì độ chính xác của hệ thống sẽ càng được cải thiện.\\nVì vậy, các hệ thống luôn khuyến khíchuser bày tỏ sự quan tâm của họ tới cácitem thông\\nqua việc đánh giá cácitem đó. Việc đánh giá cácitem, vì thế, không những giúp cácuser\\nkhác biết được chất lượng củaitem đó mà còn giúp hệ thốngbiết được sở thích củauser,\\nqua đó có chính sách quảng cáo hợp lý.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 228, 'page_label': '217'}, page_content='217 CHƯƠNG 17. CONTENT-BASED RECOMMENDATION SYSTEM\\n17.2.2 Xây dựng ma trận utility\\nKhông có ma trận utility, hệ thống gần như không thể gợi ý đượcitem tới user, ngoài cách\\nluôn luôn gợi ý cácitem phổ biến nhất. Vì vậy, trong các recommender system, việc xây\\ndựng ma trận utility là tối quan trọng. Tuy nhiên, việc xây dựng ma trận này thường có\\ngặp nhiều khó khăn. Có hai hướng tiếp cận phổ biến để xác định giá trịrating cho mỗi cặp\\nuser-item trong utility matrix:\\n1. Nhờ user đánh giáitem. Amazon luônnhờ user đánh giá cácitem của họ bằng cách gửi\\ncác email nhắc nhở nhiều lần. Tuy nhiên, cách tiếp cận này cũng có một vài hạn chế, vì\\nthường thìuser ít khi đánh giá sản phẩm. Và nếu có, đó có thể là những đánh giá thiên\\nlệch bởi những người sẵn sàng đáng giá.\\n2. Hướng tiếp cận thứ hai là dựa trên hành vi củauser. Nếu mộtuser mua mộtitem trên\\nAmazon, xem một clip trên Youtube (có thể là nhiều lần), hay đọc một bài báo, có thể\\nkhẳng định user đó có xu hướng thích item đó. Facebook cũng dựa trên việc bạnlike\\nnhững nội dung nào để hiển thị trênnewsfeed của bạn những nội dung liên quan. Bạn\\ncàng đam mê Facebook, Facebook càng được hưởng lợi, thế nên nó luôn mang tới bạn\\nnhững thông tin mà khả năng cao là bạnmuốn đọc. Thường thì với cách này, ta chỉ xây\\ndựng được một ma trận với các thành phần là1 và 0, với1 thể hiệnuser thích item, 0\\nthể hiện chưa có thông tin. Trong trường hợp này,0 không có nghĩa là thấp hơn1, nó\\nchỉ có nghĩa làuser chưa cung cấp thông tin. Chúng ta cũng có thể xây dựng ma trận\\nvới các giá trị cao hơn 1 thông qua thời gian hoặc số lượt màuser xem mộtitem nào đó.\\nNgoài ra, đôi khi nútdislike cũng mang lại những lợi ích nhất định cho hệ thống, lúc này\\ncó thể gán giá trị tương ứng bằng−1.\\n17.3 Content-based recommendation\\n17.3.1 Xây dựngitem profile\\nTrong các hệ thốngcontent-based, tức dựa trênnội dung của mỗi item, chúng ta cần xây\\ndựng một bộ hộ sơ(profile) cho mỗiitem. Profile này được biểu diễn dưới dạng toán học'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 228, 'page_label': '217'}, page_content='17.3.1 Xây dựngitem profile\\nTrong các hệ thốngcontent-based, tức dựa trênnội dung của mỗi item, chúng ta cần xây\\ndựng một bộ hộ sơ(profile) cho mỗiitem. Profile này được biểu diễn dưới dạng toán học\\nlà một vector đặc trưng. Trong những trường hợp đơn giản, vector này được trực tiếp trích\\nxuất từitem. Ví dụ, xem xét các thông tin của một bài hát mà có thể được sử dụng trong\\ncác recommendation system:\\n1. Ca sĩ. Cùng là bàiThành phố buồnnhưng có người thích bản của Đan Nguyên, có người\\nlại thích bản của Đàm Vĩnh Hưng.\\n2. Nhạc sĩ sáng tác. Cùng là nhạc trẻ nhưng có người thích Phan Mạnh Quỳnh, người khác\\nlại thích MTP.\\n3. Năm sáng tác. Một số người thích nhạc xưa cũ hơn nhạc hiện đại.\\n4. Thể loại. Quan họ và Bolero sẽ có thể thu hút những nhóm người khác nhau.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 229, 'page_label': '218'}, page_content='CHƯƠNG 17. CONTENT-BASED RECOMMENDATION SYSTEM 218\\nA\\n5\\n5\\n?\\n1\\n1\\nB\\n5\\n?\\n4\\n1\\n0\\nC\\n0\\n?\\n1\\n4\\n5\\nD\\n0\\n0\\n?\\n4\\n?\\nE\\n1\\n?\\n?\\n4\\n?\\nF\\n?\\n?\\n1\\n?\\n?\\nitem’s feature vectors\\nx1 = [0.99,0.02]T\\nx2 = [0.91,0.11]T\\nx3 = [0.95,0.05]T\\nx4 = [0.01,0.99]T\\nx5 = [0.03,0.98]T\\n←need to optimizeθ1 θ2 θ3 θ4 θ5 θ6\\nMưa nửa đêm\\nCỏ úa\\nVùng lá me bay\\nCon cò bé bé\\nEm yêu trường em\\nUser’s models\\nHình 17.2:Giả sử feature vector cho mỗi sản phẩm được cho trong cột cuối cùng. Với mỗi người\\ndùng, chúng ta cần tìm một mô hìnhθi tương ứng sao cho mô hình thu được là tốt nhất.\\nCó rất nhiều đặc trưng khác của một bài hát có thể được sử dụng. Ngoại trừThể loại khó\\nđịnh nghĩa, các yếu tố khác đều có thể được xác định rõ ràng.\\nTrong ví dụ ở Hình 17.1, chúng ta đơn giản hoá bài toán bằng việc xây dựng một vector đặc\\ntrưng hai chiều cho mỗi bài hát: chiều thứ nhất là mức độBolero, chiều thứ hai là mức độ\\nThiếu nhi của bài đó. Gọi các vector đặc trưng cho mỗi bài hát làx1,x2,x3,x4,x5. Giả sử\\ncác vector đặc trưng (ở dạng cột) cho mỗi bài hát được cho trong Hình 17.2. Ở đây, chúng\\nta tạm coi các vector này đã được xác định bằng một cách nào đó.\\nTương tự như thế, hành vi của mỗiuser cũng có thể được mô hình hoá dưới dạng tập các\\ntham sốθ. Dữ liệu huấn luyện để xây dựng mỗi mô hìnhθu là các cặp (item profile, rating)\\ntương ứng với cácitem mà user đó đã đánh giá. Việc điền các giá trị còn thiếu trong ma\\ntrận utility chính là việc dự đoán mức độ quan tâm khi áp dụng mô hìnhθu lên chúng.\\nĐầu ra này có thể được viết dưới dạng một hàmf(θu,xi). Việc lựa chọn dạng củaf(θu,xi)\\ntuỳ thuộc vào mỗi bài toán. Trong chương này, chúng ta sẽ quan tâm tới dạng đơn giản\\nnhất–dạng tuyến tính.\\n17.3.2 Xây dựng hàm mất mát\\nGiả sử rằng số lượnguser là N, số lượngitem là M. Ma trậnprofile X = [x1,x2,..., xM] ∈\\nRd×M, và ma trận utility làY ∈RM×N. Thành phần ở hàng thứm, cột thứncủa Y là mức\\nđộ quan tâm(ở đây là số sao đãrate) củauser thứ n lên item thứ m mà hệ thống đã thu'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 229, 'page_label': '218'}, page_content='Rd×M, và ma trận utility làY ∈RM×N. Thành phần ở hàng thứm, cột thứncủa Y là mức\\nđộ quan tâm(ở đây là số sao đãrate) củauser thứ n lên item thứ m mà hệ thống đã thu\\nthập được. Ma trậnY bị khuyết rất nhiều thành phần tương ứng với các giá trị mà hệ thống\\ncần dự đoán. Thêm nữa, gọiR là ma trậnrated or notthể hiện việc mộtuser đã đánh giá\\nmột item hay chưa. Cụ thể,rmn bằng 1 nếuitem thứ m đã được đánh giá bởiuser thứ n,\\nbằng 0 trong trường hợp ngược lại.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 230, 'page_label': '219'}, page_content='219 CHƯƠNG 17. CONTENT-BASED RECOMMENDATION SYSTEM\\nMô hình tuyến tính\\nGiả sử rằng ta có thể tìm được một mô hình cho mỗiuser, được minh hoạ bởi một vector\\ncột hệ sốwn ∈Rd và biasbn sao chomức độ quan tâmcủa mộtuser tới mộtitem có thể\\ntính được bằng một hàm tuyến tính:\\nymn = wT\\nnxm + bn (17.1)\\nXét mộtuser thứ n bất kỳ, nếu ta coi tập huấn luyện là tập hợp các thành phần đã được\\nđiền của yn (cột thứ n của ma trậnY), ta có thể xây dựng hàm mất mát tương tự như\\nridge regression(linear regression vớil2 regularization) như sau:\\nLn(wn,bn) = 1\\n2sn\\n∑\\nm:rmn=1\\n(wT\\nnxm + bn −ymn)2 + λ\\n2sn\\n∥wn∥2\\n2 (17.2)\\ntrong đó, thành phần thứ hai là regularization vàλ là một tham số dương;sn là số lượng\\ncác item mà user thứ nđã đánh giá, là tổng các phần tử trên cột thứncủa ma trậnR, tức\\nsn = ∑M\\nm=1 rmn. Chú ý rằng regularization thường không được áp dụng lên biasbn.\\nVì biểu thức hàm mất mát (17.2) chỉ phụ thuộc vào cácitem đã được đánh giá, ta có thể\\nrút gọn nó bằng cách đặtˆyn ∈Rsn là vector con của yn, được xây dựng bằng cách trích\\ncác thành phần khác dấu ‘?’ ở cột thứn của Y. Đồng thời, đặtˆXn ∈Rd×sn là ma trận con\\ncủa ma trận đặc trưngX, được tạo bằng cách trích các cột tương ứng với cácitem đã được\\nđánh giá bởiuser thứ n. (Xem ví dụ phía dưới để hiểu rõ hơn). Khi đó, biểu thức hàm mất\\nmát của mô hình chouser thứ n được viết gọn thành:\\nLn(wn,bn) = 1\\n2sn\\n∥ˆXT\\nnwn + bnen −ˆyn∥2\\n2 + λ\\n2sn\\n∥wn∥2\\n2 (17.3)\\ntrong đó, en là vector cột với tất cả các thành phần là 1. Đây chính xác là hàm mất\\nmát của ridge regression. Cặp nghiệmwn,bn có thể được tìm thông qua các thuật toán\\ngradient descent. Trong chương này, chúng ta sẽ trực tiếp sử dụng classRidge trong sklearn\\n.linear_model. Có một điểm đáng lưu ý ở đây làwn chỉ được xác định nếuuser thứ n đã\\nđánh giá ít nhất một sản phẩm.\\nChúng ta cùng theo dõi ví dụ nhỏ sau đây.\\n17.3.3 Ví dụ về hàm mất mát cho user E\\nQuay trở lại với ví dụ trong Hình 17.2, ma trận đặc trưng cho cácitem (mỗi cột tương ứng\\nvới mộtitem) là\\nX =\\n[0.99 0 .91 0 .95 0 .01 0 .03'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 230, 'page_label': '219'}, page_content='17.3.3 Ví dụ về hàm mất mát cho user E\\nQuay trở lại với ví dụ trong Hình 17.2, ma trận đặc trưng cho cácitem (mỗi cột tương ứng\\nvới mộtitem) là\\nX =\\n[0.99 0 .91 0 .95 0 .01 0 .03\\n0.02 0 .11 0 .05 0 .99 0 .98\\n]\\n(17.4)\\nXét trường hợp củauser E với n= 5, y5 = [1,?,?,4,?]T ⇒r5 = [1,0,0,1,0]T. VìE mới chỉ\\nđánh giáitem thứ nhất và thứ tư nêns5 = 2. Hơn nữa,\\nˆX5 =\\n[0.99 0 .01\\n0.02 0.99\\n]\\n,ˆy5 =\\n[1\\n4\\n]\\n, e5 =\\n[1\\n1\\n]\\n(17.5)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 231, 'page_label': '220'}, page_content='CHƯƠNG 17. CONTENT-BASED RECOMMENDATION SYSTEM 220\\nKhi đó, hàm mất mát cho hệ số tương ứng vớiuser E là:\\nL5(w5,b5) = 1\\n4\\n\\ued79\\ued79\\ued79\\ued79\\n[0.99 0 .02\\n0.01 0.99\\n]\\nw5 + b5\\n[1\\n1\\n]\\n−\\n[1\\n4\\n]\\ued79\\ued79\\ued79\\ued79\\n2\\n2\\n+ λ\\n4 ∥w5∥2\\n2 (17.6)\\nChúng ta sẽ áp dụng những phân tích trên đây để đi tìm nghiệm cho một bài toán gần với\\nthực tế dưới đây.\\n17.4 Bài toán với cơ sở dữ liệu MovieLens 100k\\n17.4.1 Cơ sở dữ liệu MovieLens 100k\\nBộ cơ sở dữ liệu MovieLens 100k (https://goo.gl/BzHgtq ) được công bố năm 1998 bởi\\nGroupLens (https://grouplens.org). Bộ cơ sở dữ liệu này bao gồm 100,000 (100k) đánh giá\\ntừ 943user cho 1682 bộ phim. Các bạn cũng có thể tìm thấy các bộ cơ sở dữ liệu tương tự\\nvới khoảng 1M, 10M, 20M đánh giá.\\nSau khi download và giải nén, chúng ta sẽ thu được rất nhiều các file nhỏ, chúng ta chỉ cần\\nquan tâm các file sau:\\n• u.data: Chứa toàn bộ các đánh giá của 943 người dùng cho 1682 bộ phim. Mỗi người dùng\\nđánh giá ít nhất 20 movie. Thông tin về thời điểm đánh giá cũng được cho nhưng chúng\\nta không sử dụng trong ví dụ này.\\n• ua.base, ua.test, ub.base, ub.test: là hai cách chia toàn bộ dữ liệu ra thành hai tập con,\\nmột cho huấn luyện, một cho kiểm thử. Chúng ta sẽ thực hành trênua.base và ua.test.\\nBạn đọc có thể thử với cách chia dữ liệu còn lại.\\n• u.user: Chứa thông tin về người dùng, bao gồm: id, tuổi, giới tính, nghề nghiệp, zipcode\\n(vùng miền), vì những thông tin này cũng có thể ảnh hưởng tới sở thích của các người\\ndùng. Tuy nhiên, trong ví dụ này, chúng ta sẽ không sử dụng các thông tin này, trừ thông\\ntin vềid để xác định các user khác nhau.\\n• u.genre: Chứa tên của 19 thể loại phim. Các thể loại bao gồm:unknown, Action, Adventure,\\nAnimation, Children‘s, Comedy, Crime, Documentary, Drama, Fantasy, Film−Noir, Horror,\\nMusical, Mystery, Romance, Sci−Fi, Thriller, War, Western,\\n• u.item: thông tin về mỗi bộ phim. Một vài dòng đầu tiên của file:\\n1|Toy Story (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?Toy%20Story%20(1995)\\n|0|0|0|1|1|1|0|0|0|0|0|0|0|0|0|0|0|0|0'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 231, 'page_label': '220'}, page_content='• u.item: thông tin về mỗi bộ phim. Một vài dòng đầu tiên của file:\\n1|Toy Story (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?Toy%20Story%20(1995)\\n|0|0|0|1|1|1|0|0|0|0|0|0|0|0|0|0|0|0|0\\n2|GoldenEye (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?GoldenEye%20(1995)\\n|0|1|1|0|0|0|0|0|0|0|0|0|0|0|0|0|1|0|0\\n3|Four Rooms (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?Four%20Rooms\\n%20(1995)|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0|1|0|0\\n4|Get Shorty (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?Get%20Shorty\\n%20(1995)|0|1|0|0|0|1|0|0|1|0|0|0|0|0|0|0|0|0|0\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 232, 'page_label': '221'}, page_content='221 CHƯƠNG 17. CONTENT-BASED RECOMMENDATION SYSTEM\\nTrong mỗi dòng, chúng ta sẽ thấyid của phim, tên phim, ngày phát hành, link trên imdb,\\nvà các số nhị phân0, 1 phía cuối để chỉ ra bộ phim thuộc các thể loại nào trong 19 thể loại\\nđã cho trongu.genre. Một bộ phim có thể thuộc nhiều thể loại khác nhau. Thông tin về thể\\nloại này sẽ được dùng để xây dựng item profiles.\\nVới cơ sở dữ liệu này, chúng ta sẽ sử dụng thêm thư viện pandas (http://pandas.pydata.org)\\nđể đọc dữ liệu.\\nfrom __future__ import print_function\\nimport numpy as np\\nimport pandas as pd\\n# Reading user file:\\nu_cols = [’user_id’, ’age’, ’sex’, ’occupation’, ’zip_code’]\\nusers = pd.read_csv(’ml-100k/u.user’, sep=’|’, names=u_cols)\\nn_users = users.shape[0]\\nprint(’Number of users:’, n_users)\\n#Reading ratings file:\\nr_cols = [’user_id’, ’movie_id’, ’rating’, ’unix_timestamp’]\\nratings_base = pd.read_csv(’ml-100k/ua.base’, sep=’\\\\t’, names=r_cols)\\nratings_test = pd.read_csv(’ml-100k/ua.test’, sep=’\\\\t’, names=r_cols)\\nrate_train = ratings_base.as_matrix()\\nrate_test = ratings_test.as_matrix()\\nprint(’Number of traing rates:’, rate_train.shape[0])\\nprint(’Number of test rates:’, rate_test.shape[0])\\nKết quả:\\nNumber of users: 943\\nNumber of traing rates: 90570\\nNumber of test rates: 9430\\nVì ta đang dựa trên thể loại của phim để xây dựng profile, ta sẽ chỉ quan tâm tới 19 giá trị\\nnhị phân ở cuối mỗi hàng:\\nX0 = items.as_matrix()\\nX_train_counts = X0[:, -19:]\\n17.4.2 Xây dựng item profiles\\nCông việc quan trọng trong content-based recommendation system là xây dựng profile cho\\nmỗi item, tức vector đặc trưng cho mỗiitem. Trước hết, chúng ta cần load toàn bộ thông\\ntin về cácitem vào biếnitems:\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 233, 'page_label': '222'}, page_content='CHƯƠNG 17. CONTENT-BASED RECOMMENDATION SYSTEM 222\\n#Reading items file:\\ni_cols = [’movie id’, ’movie title’ ,’release date’,’video release date’, ’IMDb URL’,\\n’unknown’, ’Action’, ’Adventure’, ’Animation’, ’Children\\\\’s’, ’Comedy’, ’Crime’, ’\\nDocumentary’, ’Drama’, ’Fantasy’, ’Film-Noir’, ’Horror’, ’Musical’, ’Mystery’, ’\\nRomance’, ’Sci-Fi’, ’Thriller’, ’War’, ’Western’]\\nitems = pd.read_csv(’ml-100k/u.item’, sep=’|’, names=i_cols)\\nn_items = items.shape[0]\\nprint(’Number of items:’, n_items)\\nKết quả:\\nNumber of items: 1682\\nTiếp theo, chúng ta hiển thị một số hàng đầu tiên của ma trậnrate_train\\nprint(rate_train[:4, :])\\nKết quả:\\n[[ 1 1 5 874965758]\\n[ 1 2 3 876893171]\\n[ 1 3 4 878542960]\\n[ 1 4 3 876893119]]\\nHàng thứ nhất được hiểu làuser thứ nhất đánh giámovie thứ nhất 5 sao. Cột cuối cùng là\\nmột số chỉ thời điểm đánh giá, chúng ta sẽ bỏ qua thông số này.\\nTiếp theo, chúng ta sẽ xây dựng feature vector cho mỗi item dựa trên ma trận thể loại phim\\nvà feature TF-IDF (https://goo.gl/bpDdQ8 ) trong thư việnsklearn.\\n#tfidf\\nfrom sklearn.feature_extraction.text import TfidfTransformer\\ntransformer = TfidfTransformer(smooth_idf=True, norm =’l2’)\\nX = transformer.fit_transform(X_train_counts.tolist()).toarray()\\nSau bước này, mỗi hàng củaX tương ứng với vector đặc trưng của một bộ phim.\\n17.4.3 Tìm mô hình cho mỗi user\\nVới mỗi người dùng, chúng ta cần đi tìm những bộ phim nào mà người dùng đó đã đánh\\ngiá, và giá trị của cácrating đó.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 234, 'page_label': '223'}, page_content='223 CHƯƠNG 17. CONTENT-BASED RECOMMENDATION SYSTEM\\ndef get_items_rated_by_user(rate_matrix, user_id):\\n\"\"\"\\nreturn (item_ids, scores)\\n\"\"\"\\ny = rate_matrix[:,0] # all users\\n# item indices rated by user_id\\n# we need to +1 to user_id since in the rate_matrix, id starts from 1\\n# but id in python starts from 0\\nids = np.where(y == user_id +1)[0]\\nitem_ids = rate_matrix[ids, 1] - 1 # index starts from 0\\nscores = rate_matrix[ids, 2]\\nreturn (item_ids, scores)\\nBây giờ, ta có thể đi tìm các hệ số của Ridge Regression cho mỗi người dùng:\\nfrom sklearn.linear_model import Ridge\\nfrom sklearn import linear_model\\nd = X.shape[1] # data dimension\\nW = np.zeros((d, n_users))\\nb = np.zeros(n_users)\\nfor n in range(n_users):\\nids, scores = get_items_rated_by_user(rate_train, n)\\nmodel = Ridge(alpha=0.01, fit_intercept = True)\\nXhat = X[ids, :]\\nmodel.fit(Xhat, scores)\\nW[:, n] = model.coef_\\nb[n] = model.intercept_\\nSau khi tính được các hệ sốW và b, rating mà mỗi người dùng đánh giá mỗi bộ phim được\\ndự đoán bằng cách:\\n# predicted scores\\nYhat = X.dot(W) + b\\nDưới đây là một ví dụ với người dùng cóid là 10.\\nn = 10\\nnp.set_printoptions(precision=2) # 2 digits after .\\nids, scores = get_items_rated_by_user(rate_test, n)\\nprint(’Rated movies ids :’, ids )\\nprint(’True ratings :’, scores)\\nprint(’Predicted ratings:’, Yhat[ids, n])\\nKết quả:\\nRated movies ids : [ 37 109 110 226 424 557 722 724 731 739]\\nTrue ratings : [3 3 4 3 4 3 5 3 3 4]\\nPredicted ratings: [3.18 3.13 3.42 3.09 3.35 5.2 4.01 3.35 3.42 3.72]\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 235, 'page_label': '224'}, page_content='CHƯƠNG 17. CONTENT-BASED RECOMMENDATION SYSTEM 224\\n17.4.4 Đánh giá mô hình\\nĐể đánh giá mô hình tìm được, chúng ta sẽ sử dụng Root Mean Squared Error (RMSE), tức\\ncăn bậc hai của trung bình cộng bình phương của lỗi.\\ndef evaluate(Yhat, rates, W, b):\\nse = cnt = 0\\nfor n in xrange(n_users):\\nids, scores_truth = get_items_rated_by_user(rates, n)\\nscores_pred = Yhat[ids, n]\\ne = scores_truth - scores_pred\\nse += (e*e).sum(axis = 0)\\ncnt += e.size\\nreturn np.sqrt(se/cnt)\\nprint(’RMSE for training: %.2f’ %evaluate(Yhat, rate_train, W, b))\\nprint(’RMSE for test : %.2f’ %evaluate(Yhat, rate_test, W, b))\\nKết quả:\\nRMSE for training: 0.91\\nRMSE for test : 1.27\\nNhư vậy, với training set, sai số vào khoảng 0.91 (sao); với test set, sai số lớn hơn một chút,\\nkhoảng 1.27. Các kết quả này chưa thực sự tốt vì mô hình đã được đơn giản hoá quá nhiều.\\nKết quả tốt hơn có thể được thấy trong các chương tiếp theo về collaborative filtering.\\n17.5 Thảo luận\\n• Content-based recommendation system là phương pháp đơn giản nhất trong các hệ thống\\nrecommendation system. Đặc điểm của phương pháp này là việc xây dựng mô hình cho\\nmỗi user không phụ thuộc vào cácuser khác.\\n• Việc xây dựng mô hình cho mỗi user có thể được coi như bài toán regression hoặc\\nclasssification với dữ liệu huấn luyện là các cặp (item profile, rating) màuser đó đã đánh\\ngiá. Item profile không phụ thuộc vàouser mà phụ thuộc vào các đặc điểm mô tả của\\nitem hoặc cũng có thể được xác định bằng cách yêu cầu người dùng gắntag.\\n• Source code trong chương này có thể được tìm thấy tạihttps://goo.gl/u9M3vb .\\nĐọc thêm\\n1. Recommendation Systems–Stanford InfoLab(https://goo.gl/P1pesC ).\\n2. Recommendation systems–Machine Learning, Andrew Ng(https://goo.gl/jdFvej ).\\n3. Content Based Recommendations–Stanford University(https://goo.gl/3wnbZ4 ).\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 236, 'page_label': '225'}, page_content='Chương 18\\nNeighborhood-based collaborative\\nfiltering\\n18.1 Giới thiệu\\nTrong content-based recommendation system, chúng ta đã làm quen với một hệ thống gợi\\ný item đơn giản dựa trên vector đặc trưng của mỗi item. Đặc điểm của content-based\\nrecommendation system là việc xây dựng mô hình cho mỗiuser không phụ thuộc vào các\\nuser khác mà phụ thuộc vàoprofile của cácitem. Việc làm này có lợi thế là tiết kiệm bộ nhớ\\nvà thời gian tính toán. Cách làm này có hai nhược điểm cơ bản.Thứ nhất, khi xây dựng mô\\nhình cho một user, các hệ thống content-based không tận dụng được thông tin từ cácuser\\nkhác. Những thông tin này thường rất hữu ích vì hành vi mua hàng của cácuser thường\\nđược nhóm thành một vài nhóm đơn giản. Nếu biết hành vi mua hàng của một vàiuser\\ntrong nhóm, hệ thống nên có khả năngsuy luậnra hành vi của nhữnguser còn lại.Thứ hai,\\nkhông phải lúc nào chúng ta cũng có thể xây dựngprofile cho mỗiitem.\\nNhững nhược điểm này có thể được giải quyết bằng một kỹ thuật có tên làcollaborative\\nfiltering1 (CF) [SFHS07,ERK+11]. Trong chương này, chúng ta cùng làm quen với một\\nphương pháp CF có tên làneighborhood-based collaborative filtering (NBCF). Chương tiếp\\ntheo sẽ trình bày về một phương pháp CF khác có tênmatrix factorization collaborative\\nfiltering. Khi chỉ nóicollaborative filtering, ta sẽ ngầm hiểu rằng đó làneighborhood-based\\ncollaborative filtering.\\nÝ tưởng của NBCF là xác địnhmức độ quan tâmcủa mộtuser tới mộtitem dựa trên hành\\nvi của cácuser khác gần giốngvới user này. Việcgần giống nhaugiữa cácuser có thể được\\nxác định thông quamức độ quan tâmcủa cácuser này tới cácitem khác mà hệ thống đã\\nbiết. Ví dụ,A, B đều thích phimCảnh sát hình sự, đều đã đánh giá bộ phim này 5 sao. Ta\\nđã biếtA cũng thíchNgười phán xử, vậy nhiều khả năngB cũng thích bộ phim này.\\n1 Tiếng Việt có tài liệu dịch làlọc cộng hưởng.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 237, 'page_label': '226'}, page_content='CHƯƠNG 18. NEIGHBORHOOD-BASED COLLABORATIVE FILTERING 226\\nCác bạn có thể đã hình dung ra, hai câu hỏi quan trọng nhất trong một hệ thống\\nneighborhood-based collaborative filtering là\\n1. Làm thế nào xác định đượcsự giống nhaugiữa haiuser?\\n2. Khi đã xác định được cácuser gần giống nhau(similar user) rồi, làm thế nào dự đoán\\nđược mức độ quan tâmcủa mộtuser lên mộtitem?\\nViệc xác định mức độ quan tâm của mỗiuser tới mộtitem dựa trên mức độ quan tâm của\\nuser tương tự tớiitem đó còn được gọi làuser-user collaborative filtering. Có một hướng\\ntiếp cận khác được cho là làm việc hiệu quả hơn làitem-item collaborative filtering. Trong\\nhướng tiếp cận này, thay vì xác định sự giống nhau giữa cácuser, hệ thống sẽ xác định sự\\ngiống nhau giữa cácitem. Từ đó, hệ thống gợi ý nhữngitem gần giống vớinhững item mà\\nuser đó có mức độ quan tâm cao.\\nCấu trúc của chương như sau: Mục 18.2 trình bàyuser-user collaborative filtering. Mục 18.3\\nnêu một số hạn chế củauser-user collaborative filteringvà cách khắc phục bằngitem-item\\ncollaborative filtering. Kết quả của hai phương pháp này được trình bày qua ví dụ trên cơ sở\\ndữ liệu MovieLens 100k trong Mục 18.4. Mục 18.5 thảo luận các ưu nhược điểm của NBCF.\\n18.2 User-user collaborative filtering\\n18.2.1 Hàm xác định độ giống nhau\\nCông việc quan trọng nhất phải làm trước tiên trong user-user collaborative filtering là phải\\nxác định đượcsự giống nhau(similarity) giữa haiuser. Giả sử dữ liệu duy nhất chúng ta\\ncó làutility matrix Y, vậysự giống nhaucần được xác định dựa trên các cột tương ứng với\\nhai user trong ma trận này. Xét ví dụ trong Hình 18.1.\\nGiả sử có cácuser từ u0 đến u6 và cácitem từ i0 đến i4 trong đó các số trong mỗi ô vuông\\nthể hiệnsố saomà mỗiuser đã đánh giáitem đó với giá trị cao hơn thể hiệnmức độ quan\\ntâm cao hơn. Các dấu hỏi chấm là các giá trị mà hệ thống cần phải đi tìm. Đặtmức độ\\ngiống nhau của haiuser ui,uj là sim(ui,uj). Quan sát đầu tiên có thể nhận thấy làu0,u1'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 237, 'page_label': '226'}, page_content='tâm cao hơn. Các dấu hỏi chấm là các giá trị mà hệ thống cần phải đi tìm. Đặtmức độ\\ngiống nhau của haiuser ui,uj là sim(ui,uj). Quan sát đầu tiên có thể nhận thấy làu0,u1\\nthích i0,i1,i2 và không thíchi3,i4 cho lắm. Điều ngược lại xảy ra ở cácuser còn lại. Vì vậy,\\nmột hàm đo sự giống nhau similiarity functiontốt cần đảm bảo\\nsim(u0,u1) >sim(u0,ui), ∀i> 1. (18.1)\\nĐể xác địnhmức độ quan tâmcủa u0 lên i2, chúng ta nên dựa trênhành vi của u1 lên item\\nnày. Rất may rằngu1 đã thích i2 nên hệ thống cần khuyến nghịi2 tới u0.\\nCâu hỏi đặt ra là, hàm sốsimilarity cần được xây dựng như thế nào? Để đosimilarity giữa\\nhai user, cách thường làm là xây dựng một vector đặc trưng cho mỗiuser rồi áp dụng một\\nhàm có khả năng đosimilarity giữa hai vector đó. Chú ý rằng việc xây dựng vector đặc trưng\\nnày khác với việc xây dựngitem profilenhư trong content-based recommendation systems.\\nCác vector này được xây dựng trực tiếp dựa trên ma trận utility chứ không dùng thêm thông\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 238, 'page_label': '227'}, page_content='227 CHƯƠNG 18. NEIGHBORHOOD-BASED COLLABORATIVE FILTERING\\nu0\\n5\\n3\\n?\\n2\\n2\\nu1\\n5\\n?\\n4\\n2\\n0\\nu2\\n2\\n?\\n1\\n3\\n4\\nu3\\n0\\n0\\n?\\n4\\n?\\nu4\\n1\\n?\\n?\\n4\\n?\\nu5\\n?\\n?\\n1\\n?\\n?\\nu6\\n?\\n?\\n2\\n4\\n5\\ni0\\ni1\\ni2\\ni3\\ni4\\nHình 18.1: Ví dụ về utility ma-\\ntrix dựa trên số sao mộtuser đánh\\ngiá mộtitem. Một cách trực quan,\\nhành vi của u0 giống vớiu1 hơn là\\nu2,u3,u4,u5,u6. Từ đó có thể dự\\nđoán rằngu0 sẽ quan tâm tớii2 vì\\nu1 cũng quan tâm tớiitem này.\\ntin bên ngoài như item profile. Với mỗiuser, thông tin duy nhất chúng ta biết là cácrating\\nmà user đó đã thực hiện, tức cột tương ứng vớiuser đó trong ma trận utility. Tuy nhiên,\\nkhó khăn là các cột này thường có rất nhiều giá trị bị khuyết (các dấu ‘?’ trong Hình 18.1)\\nvì mỗiuser thường chỉ đánh giá một số lượng rất nhỏ cácitem. Một cách khắc phục là giúp\\nhệ thống ban đầuước lượng thôcác giá trị này sao cho việc điền không làm ảnh hưởng nhiều\\ntới sự giống nhaugiữa hai vector. Việcước lượng này chỉ phục vụ cho việc tínhsimilarity,\\nkhông phải là kết quả cuối cùng hệ thống cần ước lượng.\\nVậy mỗi dấu ‘?’ nên được thay bởi giá trị nào để hạn chế việc ước lượng bị sai lệch? Lựa\\nchọn đầu tiên có thể nghĩ đén là thay các dấu ‘?’ bằng giá trị 0. Điều này không thực sự tốt\\nvì giá trị 0 tương ứng với mức độ quan tâm thấp nhất; và mộtuser chưa đánh giá mộtitem\\nkhông có nghĩa là họ hoàn toàn không quan tâm tớiitem đó. Một giá trịan toànhơn là 2.5\\nvì nó là trung bình cộng của 0, mức thấp nhất, và 5, mức cao nhất. Tuy nhiên, giá trị này\\ncó hạn chế đối với nhữnguser dễ tính hoặc khó tính. Nhữnguser dễ tính có thể đánh giá\\nba sao cho cácitem họ không thích, ngược lại, nhữnguser khó tính có thể đánh giá ba sao\\ncho nhữngitem họ thích. Việc thay đồng loạt các phần tử khuyết bởi 2.5 trong trường hợp\\nnày chưa mang lại hiệu quả. Một giá trị khả dĩ hơn cho việc này là ước lượng các phần tử\\nkhuyết như là giá trị trung bình mà mộtuser đánh giá. Điều này giúp tránh việc mộtuser\\nquá khó tính hoặc dễ tính. Và các giá trị ước lượng này phụ thuộc vào từnguser. Quan sát\\nví dụ trong Hình 18.2.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 238, 'page_label': '227'}, page_content='khuyết như là giá trị trung bình mà mộtuser đánh giá. Điều này giúp tránh việc mộtuser\\nquá khó tính hoặc dễ tính. Và các giá trị ước lượng này phụ thuộc vào từnguser. Quan sát\\nví dụ trong Hình 18.2.\\nHàng cuối cùng trong Hình 18.2a là trung bình của các đánh giá của mỗiuser. Các giá trị\\ncao tương ứng với cácuser dễ tínhvà ngược lại. Khi đó, nếu tiếp tục trừ từ mỗirating đi giá\\ntrị trung bình này và thay các giá trị chưa biết bằng 0, ta sẽ được mộtma trận utility chuẩn\\nhoá(normalized utility matrix) như trong Hình 18.2b. Việc làm này có một vài ưu điểm:\\n• Việc trừ đi trung bình cộng của mỗicột khiến mỗi cột có cả những giá trị dương và âm.\\nNhững item ứng với các giá trị dương có thể được coi như cácitem mà user đó quan tâm\\nhơn so nhữngitem ứng với các giá trị âm. Nhữngitem mang giá trị bằng 0 chủ yếu ứng\\nvới việcchưa xác địnhđược độ quan tâm củauser đó.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 239, 'page_label': '228'}, page_content='CHƯƠNG 18. NEIGHBORHOOD-BASED COLLABORATIVE FILTERING 228\\na) Original utility matrixY\\nand mean user ratings.\\n↓ ↓ ↓ ↓ ↓ ↓ ↓\\nu0\\n5\\n4\\n?\\n2\\n2\\nu1\\n5\\n?\\n4\\n2\\n0\\nu2\\n2\\n?\\n1\\n3\\n4\\nu3\\n0\\n0\\n?\\n4\\n?\\nu4\\n1\\n?\\n?\\n4\\n?\\nu5\\n?\\n2\\n1\\n?\\n?\\nu6\\n?\\n?\\n1\\n4\\n5\\ni0\\ni1\\ni2\\ni3\\ni4\\n¯uj 3.25 2.75 2.5 1.33 2.5 1.5 3.33\\nb) Normalized utility matrix¯Y.\\nu0\\n1.75\\n0.75\\n0\\n-1.25\\n-1.25\\nu1\\n2.25\\n0\\n1.25\\n-0.75\\n-2.75\\nu2\\n-0.5\\n0\\n-1.5\\n0.5\\n1.5\\nu3\\n-1.33\\n-1.33\\n0\\n2.67\\n0\\nu4\\n-1.5\\n0\\n0\\n1.5\\n0\\nu5\\n0\\n0.5\\n-0.5\\n0\\n0\\nu6\\n0\\n0\\n-2.33\\n0.67\\n1.67\\ni0\\ni1\\ni2\\ni3\\ni4\\nc) User similarity matrixS.\\nu0\\n1\\n0.83\\n-0.58\\n-0.79\\n-0.82\\n0.2\\n-0.38\\nu1\\n0.83\\n1\\n-0.87\\n-0.40\\n-0.55\\n-0.23\\n-0.71\\nu2\\n-0.58\\n-0.87\\n1\\n0.27\\n0.32\\n0.47\\n0.96\\nu3\\n-0.79\\n-0.40\\n0.27\\n1\\n0.87\\n-0.29\\n0.18\\nu4\\n-0.82\\n-0.55\\n0.32\\n0.87\\n1\\n0\\n0.16\\nu5\\n0.2\\n-0.23\\n0.47\\n-0.29\\n0\\n1\\n0.56\\nu6\\n-0.38\\n-0.71\\n0.96\\n0.18\\n0.16\\n0.56\\n1\\nu0\\nu1\\nu2\\nu3\\nu4\\nu5\\nu6\\nd) ˆY\\nu0\\n1.75\\n0.75\\n0.91\\n-1.25\\n-1.25\\nu1\\n2.25\\n1.25\\n-0.75\\n-2.75\\nu2\\n-0.5\\n-0.17\\n-1.5\\n0.5\\n1.5\\nu3\\n-1.33\\n-1.33\\n-1.84\\n2.67\\n1.57\\nu4\\n-1.5\\n-1.33\\n-1.78\\n1.5\\n1.56\\nu5\\n0.18\\n0.5\\n-0.5\\n0.59\\n1.59\\nu6\\n-0.63\\n0.05\\n-2.33\\n0.67\\n1.67\\ni0\\ni1\\ni2\\ni3\\ni4\\n0.48\\ne) Example\\nPredict normalized rating of u1 on i1 with k = 2\\nUsers who rated i1 : {u0 , u3 , u5 }\\nCorresponding similarities: {0.83, -0.40, -0.23 }\\n⇒ most similar users: N(u1 , i1 ) = {u0 , u5 }\\nwith normalized ratings {0.75, 0.5 }\\n⇒ ˆy i 1 ,u 1 =\\n0 .83 ∗0 .75+( −0 .23) ∗0 .5\\n0 .83+ |− 0 .23 | ≈ 0 .48\\nf) Full Y\\nu0\\n5\\n4\\n4.15\\n2\\n2\\nu1\\n5\\n3.23\\n4\\n2\\n0\\nu2\\n2\\n2.33\\n1\\n3\\n4\\nu3\\n0\\n0\\n-0.5\\n4\\n2.9\\nu4\\n1\\n1.67\\n0.71\\n4\\n4.06\\nu5\\n1.68\\n2\\n1\\n2.10\\n3.10\\nu6\\n2.70\\n3.38\\n1\\n4\\n5\\ni0\\ni1\\ni2\\ni3\\ni4\\nHình 18.2: Ví dụ mô tả User-user Collaborative Filtering. a) Utility Matrix ban đầu. b) Utility\\nMatrix đã được chuẩn hoá. c) User similarity matrix. d) Dự đoán các (normalized)ratings còn\\nthiếu. e) Ví dụ về cách dự đoán normalized rating củau1 cho i1. f) Dự đoán các (denormalized)\\nratings còn thiếu.\\n• Về mặt kỹ thuật, số chiều của ma trận utility là rất lớn với hàng triệuuser và item, nếu\\nlưu toàn bộ các giá trị này trong một ma trận thì khả năng cao là sẽ không đủ bộ nhớ.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 239, 'page_label': '228'}, page_content='ratings còn thiếu.\\n• Về mặt kỹ thuật, số chiều của ma trận utility là rất lớn với hàng triệuuser và item, nếu\\nlưu toàn bộ các giá trị này trong một ma trận thì khả năng cao là sẽ không đủ bộ nhớ.\\nQuan sát thấy rằng vì số lượng đánh giá biết trước thường là một số rất nhỏ so với kích\\nthước của ma trận utility, sẽ tốt hơn nếu chúng ta lưu ma trận này dưới dạng một ma\\ntrận sparse, tức chỉ lưu các giá trị khác không và vị trí của chúng. Vì vậy, tốt hơn hết,\\ncác dấu ’?’ nên được thay bằng giá trị ’0’, tức chưa xác định liệuuser có thíchitem hay\\nkhông. Việc này không những tối ưu bộ nhớ mà việc tính toán ma trậnsimilarity sau\\nnày cũng hiệu quả hơn. Ở đây, phần tử ở hàng thứi, cột thứj của ma trậnsimilarity là\\nđộ similarity của user thứ i và thứj.\\nSau khi dữ liệu đã được chuẩn hoá, hàmsimilarity thường được sử dụng làcosine similarity:\\ncosine_similarity(u1,u2) =cos(u1,u2) = uT\\n1 u2\\n∥u1∥2.∥u2∥2\\n(18.2)\\nTrong đóu1,2 là các vector tương ứng vớiuser 1 vàuser 2 như ở trên. Có một hàm trong\\nPython phục vụ cách tính giá trị này một cách hiệu quả, chúng ta sẽ thấy trong phần lập\\ntrình.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 240, 'page_label': '229'}, page_content='229 CHƯƠNG 18. NEIGHBORHOOD-BASED COLLABORATIVE FILTERING\\nMức độsimilarity của hai vector là một số thực trong đoạn [-1, 1]. Giá trị bằng 1 thể hiện\\nhai vector hoàn toànsimilar nhau. Hàm số cos của một góc bằng 1 nghĩa là góc giữa hai\\nvector bằng 0, tức hai vector có cùng phương và cùng hướng. Giá trị cos bằng -1 thể hiện\\nhai vector này hoàn toàn trái ngược nhau, tức cùng phương nhưng khác hương. Điều này\\nđồng nghĩa với việc nếuhành vicủa haiuser là hoàn toàn ngược nhau thì mức độsimilarity\\ngiữa hai vector đó là thấp nhất.\\nVí dụ vềcosine similarity của các user (đã được chuẩn hoá) trong Hình 18.2b được cho\\ntrong Hình 18.2c. Ma trận similarityS là một ma trận đối xứng vìcos là một hàm chẵn2 ,\\nvà nếuuser A giống user Bthì điều ngược lại cũng đúng. Các ô màu xanh trên đường chéo\\nđều là cos của góc giữa một vector và chính nó, tức cos(0) = 1 . Khi tính toán ở các bước\\nsau, chúng ta không cần quan tâm tới các giá trị 1 này. Tiếp tục quan sát các vector hàng\\ntương ứng vớiu0,u1,u2, chúng ta sẽ thấy một vài điều thú vị:\\n• u0 gần với u1 và u5 (độ giống nhau là dương) hơn cácuser còn lại. Việcsimilarity cao\\ngiữa u0 vàu1 là dễ hiểu vì cả hai đều có xu hướng quan tâm tớii0,i1,i2 hơn cácitem còn\\nlại. Việcu0 gần với u5 thoạt đầu có vẻ vô lý vìu5 đánh giá thấp cácitem mà u0 đánh giá\\ncao (Hình 18.2a); tuy nhiên khi nhìn vào ma trận utility đã chuẩn hoá ở Hình 18.2b, ta\\nthấy rằng điều này là hợp lý vìitem duy nhất mà cả haiuser này đã cung cấp thông tin\\nlà i1 với các giá trị tương ứng đều làtích cực.\\n• u1 gần vớiu0 và xa cácuser còn lại.\\n• u2 gần vớiu3,u4,u5,u6 và xa cácuser còn lại.\\nTừ ma trậnsimilarity này, chúng ta có thể phân nhóm cácuser ra làm hai nhóm(u0,u1)\\nvà (u2,u3,u4,u5,u6). Vì ma trậnS này nhỏ nên chúng ta có thể dễ dàng quan sát thấy điều\\nnày; khi sốuser lớn hơn, việc xác định bằngmắt thường là không khả thi. Việc xây dựng\\nthuật toán phân nhóm cácuser (users clustering) sẽ được trình bày trong chương tiếp theo.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 240, 'page_label': '229'}, page_content='này; khi sốuser lớn hơn, việc xác định bằngmắt thường là không khả thi. Việc xây dựng\\nthuật toán phân nhóm cácuser (users clustering) sẽ được trình bày trong chương tiếp theo.\\nCó một chú ý quan trọng ở đây là khi số lượnguser lớn, ma trậnS cũng rất lớn và nhiều\\nkhả năng là không có đủ bộ nhớ để lưu trữ, ngay cả khi chỉ lưu hơn một nửa số các phần\\ntử của ma trận đối xứng này. Với các trường hợp đó, mới mỗiuser, chúng ta chỉ cần tính và\\nlưu kết quả của một hàng củasimilarity matrix, tương ứng với việc độgiống nhaugiữa user\\nđó và cácuser còn lại.\\n18.2.2 Điền các giá trị khuyết trong ma trận utility\\nViệc dự đoán mức độ quan tâm(predicted rating) của mộtuser lên mộtitem dựa trên các\\nuser gần nhấtnày rất giống với những gì chúng ta thấy trongK-nearest neighbors(KNN)\\nvới hàm khoảng cách làcosine similarity.\\nTương tự như KNN, NBCF cũng dùng thông tin củak user lân cận để dự đoán. Tất nhiên,\\nđể đánh giá độ quan tâm của mộtuser lên một item, chúng ta chỉ quan tâm tới cácuser\\n2 Một hàm sốf : R →R được gọi làchẵn nếu f(x) =f(−x), ∀x∈R.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 241, 'page_label': '230'}, page_content='CHƯƠNG 18. NEIGHBORHOOD-BASED COLLABORATIVE FILTERING 230\\ntrong lân cậnđã đánh giáitem đó. Giá trị cần điềnthường được xác định làtrung bình có\\ntrọng số của cácrating đã chuẩn hoá. Có một điểm cần lưu ý, trong KNN, các trọng số\\nđược xác định dựa trên khoảng cách giữa hai điểm, và các khoảng cách này là các số không\\nâm. Trong NBCF, các trọng số được xác định dựa trênsimilarity giữa haiuser, những trọng\\nsố này có thể nhỏ hơn 0. Công thức phổ biến được sử dụng để dự đoán số sao màuser u\\nđánh giáitem i là3\\nˆyi,u =\\n∑\\nuj∈N(u,i) ¯yi,uj sim(u,uj)\\n∑\\nuj∈N(u,i) |sim(u,uj)| (18.3)\\ntrong đóN(u,i) là tập hợpk user gần giống nhất, tức cósimilarity cao nhất củauđã đánh\\ngiá i. Hình 18.2d thể hiện việcđiền các giá trị còn thiếu trong ma trậnutility đã chuẩn hoá.\\nCác ô màu nền đỏ thể hiện các giá trị dương, tức cácitem mà có thểuser đó quan tâm. Ở\\nđây, ngưỡng được lấy là 0, ngưỡng này hoàn toàn có thể được thay đổi tuỳ thuộc vào việc\\nta muốn gợi ý nhiều hay ítitem.\\nMột ví dụ về việc tínhnormalized rating của u1 cho i1 được cho trong Hình 18.2e với số\\nnearest neighborslà k= 2. Các bước thực hiện như sau\\n1. Xác định cácuser đã đánh giái1, chúng làu0,u3,u5.\\n2. Mức độsimilarity của u1 với cácuser này lần lượt là{0.83,−0.40,−0.23}. Hai (k = 2)\\ngiá trị lớn nhất là0.83 và −0.23 tương ứng vớiu0 và u5.\\n3. Xác định các đánh giá (đã chuẩn hoá) củau0 và u5 cho i1, ta thu được hai giá trị lần\\nlượt là0.75 và 0.5.\\n4. Dự đoán kết quả\\nˆyi1,u1 = 0.83 ×0.75 + (−0.23) ×0.5\\n0.83 + |−0.23| ≈0.48 (18.4)\\nViệc quy đổi các giá trị đánh giá đã chuẩn hoá về thang 5 có thể được thực hiện bằng cách\\ncộng các cột của ma trậnˆY với giá trị đánh giá trung bình của mỗiuser như đã tính trong\\nHình 18.2a. Việc hệ thống quyết định gợi ýitem nào cho mỗiuser có thể được xác định\\nbằng nhiều cách khác nhau. Hệ thống có thể sắp xếp cácitem chưa được đánh giá theo độ\\ngiảm dần củapredicted rating, hoặc có thể chỉ chọn cácitem có normalized predicted rating\\ndương–tương ứng với việcuser này có nhiều khả năng thích hơn.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 241, 'page_label': '230'}, page_content='giảm dần củapredicted rating, hoặc có thể chỉ chọn cácitem có normalized predicted rating\\ndương–tương ứng với việcuser này có nhiều khả năng thích hơn.\\n18.3 Item-item collaborative filtering\\nUser-user CF có một số hạn chế như sau:\\n• Khi số lượnguser lớn hơn số lượngitem rất nhiều (điều này thường xảy ra), kích thước\\nma trận similarity là rất lớn (mỗi chiều của ma trận này có số phần tử chính bằng số\\nuser). Việc lưu trữ một ma trận với kích thước lớn nhiều khi không khả thi.\\n3 Sự khác biệt so với trung bình có trọng số là mẫu số có sử dụng trị tuyệt đối để xử lý các số âm.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 242, 'page_label': '231'}, page_content='231 CHƯƠNG 18. NEIGHBORHOOD-BASED COLLABORATIVE FILTERING\\n• Ma trận utilityY thường rấtsparse, tức chỉ có một tỉ lệ nhỏ các phần tử đã biết. Với số\\nlượng user rất lớn so với số lượngitem, rất nhiều cột của ma trận này có rất ít, thậm chí\\nkhông có phần tử khác 0 vì cácuser thường lười đánh giáitem. Cũng chính vì thế, một\\nkhi user đó thay đổi cácrating trước đó hoặc đánh giá thêmitem, trung bình cộng các\\nrating cũng như vector chuẩn hoá tương ứng vớiuser này thay đổi nhiều. Kéo theo đó,\\nviệc tính toán ma trận similarity, vốn tốn nhiều bộ nhớ và thời gian, cũng cần được thực\\nhiện lại.\\nCó một cách tiếp cận khác, thay vì tìm sự giống nhau giữa cácuser, ta có thể tìm sự giống\\nnhau giữa cácitem. Từ đó nếu mộtuser thích một item thì hệ thống nên gợi ý cácitem\\ntương tự tớiuser đó. Việc này có một số ưu điểm:\\n• Khi số lượngitem nhỏ hơn số lượnguser, ma trận similarity có kích thước nhỏ hơn, việc\\nnày khiến việc lưu trữ và tính toán ở các bước sau được thực hiện một cách hiệu quả hơn.\\n• Cũng giả sử rằng số lượngitem ít hơn số lượnguser. Vì tổng lượng đánh giá là không đổi,\\nsố lượng trung bình cácitem được đánh giá bởi mộtuser sẽ ít hơn số lượng trung bình\\ncác user đã đánh giá mộtitem. Nói cách khác, nếu ma trận utility có số hàng ít hơn số\\ncột, số lượng phần tử trung bình đã biết trong mỗi hàng sẽ nhiều hơn số lượng phần tử\\ntrung bình đã biết trong mỗi cột. Kéo theo đó, thông tin về mỗiitem là nhiều hơn thông\\ntin về mỗiuser, việc tính độsimilarity giữa các hàng cũng đáng tin cậy hơn. Hơn nữa,\\ngiá trị trung bình của mỗi hàng cũng thay đổi ít hơn khi có thêm một vài đánh giá. Như\\nvậy, việc cập nhật ma trận similarity có thể được thực hiện ít thường xuyên hơn.\\nCách tiếp cận thứ hai này được gọi làitem-item collaborative filtering(item-item CF). Khi\\nsố lượngitem ít hơn số lượnguser, phương pháp này được ưu tiên sử dụng hơn.\\nQuy trình dự đoán các đánh giá bị khuyết cũng tương tự như trong user-user CF, chỉ khác\\nlà bây giờ ta cần tính độgiống nhau giữa các hàng.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 242, 'page_label': '231'}, page_content='Quy trình dự đoán các đánh giá bị khuyết cũng tương tự như trong user-user CF, chỉ khác\\nlà bây giờ ta cần tính độgiống nhau giữa các hàng.\\nLiên hệ giữa item-item CF và user-user CF\\nVề mặt tính toán, item-item CF có thể nhận được từ user-user CF bằng cách chuyển\\nvị (transpose) ma trận utility, và coi như item đang đánh giá ngược user. Sau khi tính\\nra kết quả cuối cùng, ta lại chuyển vị một lần nữa để thu được kết quả.\\nHình 18.3 mô tả quy trình này với ví dụ nêu ở phần trên. Có một điểm thú vị trong ma\\ntrận similarity ở Hình 18.3c là có các phần tử trong hai khu vực hình vuông xanh và đỏ\\nđều là các số không âm, các phần tử bên ngoài là các số âm. Việc này thể hiện rằng các\\nitem có thể được chia thành hai nhóm rõ rệt với nhữngitem có similarity không âm trong\\nmột nhóm cột vào một nhóm. Như vậy, một cáchvô tình, chúng ta đã thực hiện việcitem\\nclustering. Việc này sẽ giúp ích rất nhiều trong việc dự đoán ở phần sau vì cácitem gần\\ngiống nhau rất có thể đã được phân vào một nhóm. Kết quả cuối cùng về việc chọnitem\\nnào đểrecommend cho mỗiuser được thể hiện bởi các ô màu đỏ trong Hình 18.3d. Kết quả\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 243, 'page_label': '232'}, page_content='CHƯƠNG 18. NEIGHBORHOOD-BASED COLLABORATIVE FILTERING 232\\na) Original utility matrixY\\nand mean item ratings.\\n→\\n→\\n→\\n→\\n→\\nu0\\n5\\n4\\n?\\n2\\n2\\nu1\\n5\\n?\\n4\\n2\\n0\\nu2\\n2\\n?\\n1\\n3\\n4\\nu3\\n0\\n0\\n?\\n4\\n?\\nu4\\n1\\n?\\n?\\n4\\n?\\nu5\\n?\\n2\\n1\\n?\\n?\\nu6\\n?\\n?\\n1\\n4\\n5\\ni0\\ni1\\ni2\\ni3\\ni4\\n2.6\\n2\\n1.75\\n3.17\\n2.75\\nb) Normalized utility matrix¯Y.\\nu0\\n2.4\\n2\\n0\\n-1.17\\n-0.75\\nu1\\n2.4\\n0\\n2.25\\n-1.17\\n-2.75\\nu2\\n-.6\\n0\\n-0.75\\n-0.17\\n1.25\\nu3\\n-2.6\\n-2\\n0\\n0.83\\n0\\nu4\\n-1.6\\n0\\n0\\n0.83\\n0\\nu5\\n0\\n0\\n-0.75\\n0\\n0\\nu6\\n0\\n0\\n-0.75\\n0.83\\n2.25\\ni0\\ni1\\ni2\\ni3\\ni4\\nc) Item similarity matrixS.\\ni0\\n1\\n0.77\\n0.49\\n-0.89\\n-0.52\\ni1\\n0.77\\n1\\n0\\n-0.64\\n-0.14\\ni2\\n0.49\\n0\\n1\\n-0.55\\n-0.88\\ni3\\n-0.89\\n-0.64\\n-0.55\\n1\\n0.68\\ni4\\n-0.52\\n-0.14\\n-0.88\\n0.68\\n1\\ni0\\ni1\\ni2\\ni3\\ni4\\nd) Normalized utility matrix¯Y.\\nu0\\n2.4\\n2\\n2.4\\n-1.17\\n-0.75\\nu1\\n2.4\\n2.4\\n2.25\\n-1.17\\n-2.75\\nu2\\n-.6\\n-0.6\\n-0.75\\n-0.17\\n1.25\\nu3\\n-2.6\\n-2\\n-2.6\\n0.83\\n1.03\\nu4\\n-1.6\\n-1.25\\n-1.20\\n0.83\\n1.16\\nu5\\n-0.29\\n0\\n-0.75\\n0.34\\n0.65\\nu6\\n-1.52\\n-2.25\\n-0.75\\n0.83\\n2.25\\ni0\\ni1\\ni2\\ni3\\ni4\\nHình 18.3: Ví dụ mô tả item-item CF. a) Ma trận utility ban đầu. b) Ma trận utility đã được\\nchuẩn hoá. c) User similarity matrix. d) Dự đoán các (normalized)rating còn thiếu.\\nnày có khác một chút so với kết quả tìm được bởi user-user CF ở hai cột cuối cùng tương\\nứng vớiu5,u6. Dường như kết quả nàyhợp lý hơn vì từ utility matrix, ta nhận thấy có hai\\nnhóm user thích hai nhómitem khác nhau. Nhóm thứ nhất làu0 vàu1; nhóm thứ hai là các\\nuser còn lại.\\nMục 18.4 sau đây mô tả cách lập trình cho NNCF trên Python. Chú ý rằng thư việnsklearn\\nchưa hỗ trợ các module cho recommendation system. Một thư viện khác khá tốt trên python\\nbạn đọc có thể tham khảo làsurprise (http://surpriselib.com/ ).\\n18.4 Lập trình trên Python\\nThuật toán collaborative filtering trong chương này tương đối đơn giản và không chứa bài\\ntoán tối ưu nào. Chúng ta tiếp tục sử dụng bộ cơ sở dữ liệu MovieLens 100k như trong chương\\ntrước. Dưới đây là đoạn code thể hiệnclass uuCF cho user-user collaborative filtering. Có\\nhai phương thức chính củaclass này làfit–tính ma trận similarity, vàpredict–dự đoán số\\nsao mà mộtuser sẽ đánh giá mộtitem.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 243, 'page_label': '232'}, page_content='hai phương thức chính củaclass này làfit–tính ma trận similarity, vàpredict–dự đoán số\\nsao mà mộtuser sẽ đánh giá mộtitem.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 244, 'page_label': '233'}, page_content='233 CHƯƠNG 18. NEIGHBORHOOD-BASED COLLABORATIVE FILTERING\\nfrom __future__ import print_function\\nimport pandas as pd\\nimport numpy as np\\nfrom sklearn.metrics.pairwise import cosine_similarity\\nfrom scipy import sparse\\nclass uuCF(object):\\ndef __init__(self, Y_data, k, sim_func = cosine_similarity):\\nself.Y_data = Y_data # a 2d array of shape (n_users, 3)\\n# each row of Y_data has form [user_id, item_id, rating]\\nself.k = k # number of neighborhood\\nself.sim_func = sim_func # similarity function, default: cosine_similarity\\nself.Ybar = None # normalize data\\nself.n_users = int(np.max(self.Y_data[:, 0])) + 1 # number of users\\nself.n_items = int(np.max(self.Y_data[:, 1])) + 1 # number of items\\ndef fit(self):\\n# normalized Y_data -> Ybar\\nusers = self.Y_data[:, 0] # all users - first column of Y_data\\nself.Ybar = self.Y_data.copy()\\nself.mu = np.zeros((self.n_users,))\\nfor n in xrange(self.n_users):\\n# row indices of ratings made by user n\\nids = np.where(users == n)[0].astype(np.int32)\\n# indices of all items rated by user n\\nitem_ids = self.Y_data[ids, 1]\\n# ratings made by user n\\nratings = self.Y_data[ids, 2]\\n# avoid zero division\\nself.mu[n] = np.mean(ratings) if ids.size > 0 else 0\\nself.Ybar[ids, 2] = ratings - self.mu[n]\\n## form the rating matrix as a sparse matrix.\\n# see more: https://goo.gl/i2mmT2\\nself.Ybar = sparse.coo_matrix((self.Ybar[:, 2],\\n(self.Ybar[:, 1], self.Ybar[:, 0])), (self.n_items, self.n_users)).tocsr()\\nself.S = self.sim_func(self.Ybar.T, self.Ybar.T)\\ndef pred(self, u, i):\\n\"\"\" predict the rating of user u for item i\"\"\"\\n# find item i\\nids = np.where(self.Y_data[:, 1] == i)[0].astype(np.int32)\\n# all users who rated i\\nusers_rated_i = (self.Y_data[ids, 0]).astype(np.int32)\\n# similarity of u and users who rated i\\nsim = self.S[u, users_rated_i]\\n# most k similar users\\nnns = np.argsort(sim)[-self.k:]\\nnearest_s = sim[nns] # and the corresponding similarities\\n# the corresponding ratings\\nr = self.Ybar[i, users_rated_i[nns]]\\neps = 1e-8 # a small number to avoid zero division'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 244, 'page_label': '233'}, page_content='nearest_s = sim[nns] # and the corresponding similarities\\n# the corresponding ratings\\nr = self.Ybar[i, users_rated_i[nns]]\\neps = 1e-8 # a small number to avoid zero division\\nreturn (r*nearest_s).sum()/(np.abs(nearest_s).sum() + eps) + self.mu[u]\\nTiếp theo, ta áp dụng vào MoviesLen 100k:\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 245, 'page_label': '234'}, page_content='CHƯƠNG 18. NEIGHBORHOOD-BASED COLLABORATIVE FILTERING 234\\nr_cols = [’user_id’, ’movie_id’, ’rating’, ’unix_timestamp’]\\nratings_base = pd.read_csv(’ml-100k/ua.base’, sep=’\\\\t’, names=r_cols)\\nratings_test = pd.read_csv(’ml-100k/ua.test’, sep=’\\\\t’, names=r_cols)\\nrate_train = ratings_base.as_matrix()\\nrate_test = ratings_test.as_matrix()\\n# indices start from 0\\nrate_train[:, :2] -= 1\\nrate_test[:, :2] -= 1\\nrs = uuCF(rate_train, k = 40)\\nrs.fit()\\nn_tests = rate_test.shape[0]\\nSE = 0 # squared error\\nfor n in xrange(n_tests):\\npred = rs.pred(rate_test[n, 0], rate_test[n, 1])\\nSE += (pred - rate_test[n, 2])**2\\nRMSE = np.sqrt(SE/n_tests)\\nprint(’User-user CF, RMSE =’, RMSE)\\nKết quả:\\nUser-user CF, RMSE = 0.976614028929\\nNhư vậy, trung bình mỗirating bị dự đoán sai lệch khoảng 0.976. Kết quả này có tốt hơn\\nkết quả có được bởi content-based recommendation system.\\nTiếp theo, chúng ta áp dụng item-item CF vào tập cơ sở dữ liệu này. Để áp dụng item-item\\nCF, chúng ta chỉ cần chuyển vị ma trận utility. Trong trường hợp này, vì ma trận utility\\nđược lưu dưới dạng[user_id, item_id, rating] nên ta chỉ cần đổi chỗ cột thứ nhất cho cột\\nthứ hai củaY_data:\\nrate_train = rate_train[:, [1, 0, 2]]\\nrate_test = rate_test[:, [1, 0, 2]]\\nrs = uuCF(rate_train, k = 40)\\nrs.fit()\\nn_tests = rate_test.shape[0]\\nSE = 0 # squared error\\nfor n in xrange(n_tests):\\npred = rs.pred(rate_test[n, 0], rate_test[n, 1])\\nSE += (pred - rate_test[n, 2])**2\\nRMSE = np.sqrt(SE/n_tests)\\nprint(’Item-item CF, RMSE =’, RMSE)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 246, 'page_label': '235'}, page_content='235 CHƯƠNG 18. NEIGHBORHOOD-BASED COLLABORATIVE FILTERING\\nKết quả:\\nItem-item CF, RMSE = 0.968846083868\\nNhư vậy, trong trường hợp này item-item collaborative filtering cho kết quả tốt hơn, ngay\\ncả khi sốitem (1682) lớn hơn số lượnguser (943). Với các bài toán khác, chúng ta nên thử\\ncả hai trên một tập validation và chọn ra phương pháp cho kết quả tốt hơn. Chúng ta cũng\\ncó thể thaykích thước lân cậnk bằng các giá trị khác và so sánh các kết quả.\\n18.5 Thảo luận\\n• CF là một phương pháp gợi ýitem với ý tưởng chính dựa trên hành vi của cácuser tương\\ntự khác lên cùng mộtitem. Việc suy ra này được thực hiện dựa trên ma trậnsimilarity\\nđo độ giống nhau giữa cácuser.\\n• Để tính ma trận similarity, trước tiên ta cần chuẩn hoá dữ liệu. Phương pháp phổ biến\\nlà mean offset, tức trừ cácratings đi giá trị trung bình mà mộtuser đưa ra cho cácitem.\\n• Similarity function thường được dụng làcosine similarity.\\n• Một hướng tiếp cận tương tự là thay vì đi tìm cácuser gần giống với mộtuser (user-\\nuser CF), ta đi tìm cácitem gần với mộtitem cho trước (item-item CF). Trên thực tế,\\nitem-item CF thường cho kết quả tốt hơn.\\n• Source code của chương này có thể được tìm thấy tạihttps://goo.gl/vGKjbo .\\nĐọc thêm\\n1. M.Ekstrand et al.,Collaborative filtering recommender systems.(https://goo.gl/GVn8av )\\nFoundations and Trends® in Human–Computer Interaction 4.2 (2011): 81-173.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 247, 'page_label': '236'}, page_content='Chương 19\\nMatrix factorization collaborative\\nfiltering\\n19.1 Giới thiệu\\nTrong Chương 18, chúng ta đã làm quen với một phương pháp collaborative filtering (CF)\\ndựa trên hành vi của cácuser hoặc item lân cận. Trong chương này, chúng ta sẽ làm quen\\nvới một hướng tiếp cận khác cho collaborative filtering dựa trên bài toánphân tích ma trận\\nthành nhân tử(matrix factorizationhoặc matrix decomposition). Phương pháp này được gọi\\nlà matrix factorization collaborative filtering(MFCF) [KBV09].\\nNhắc lại rằng trong content-based recommendation systems, mỗiitem được mô tả bằng một\\nvector x được gọi làitem profile. Trong phương pháp đó, ta cần tìm một vector hệ sốw\\ntương ứng với mỗiuser sao chorating đã biết màuser đó choitem xấp xỉ với\\ny≈wTx = xTw (19.1)\\nVới cách làm này, ma trận utilityY, giả sử đã được điền hết, sẽ xấp xỉ với:\\nY ≈\\n\\uf8ee\\n\\uf8ef\\uf8ef\\uf8ef\\uf8f0\\nxT\\n1 w1 xT\\n1 w2 ... xT\\n1 wN\\nxT\\n2 w1 xT\\n2 w2 ... xT\\n2 wN\\n... ... ... ...\\nxT\\nMw1 xT\\nMw2 ... xT\\nMwN\\n\\uf8f9\\n\\uf8fa\\uf8fa\\uf8fa\\uf8fb=\\n\\uf8ee\\n\\uf8ef\\uf8ef\\uf8f0\\nxT\\n1\\nxT\\n2\\n...\\nxT\\nM\\n\\uf8f9\\n\\uf8fa\\uf8fa\\uf8fb\\n[\\nw1 w2 ... wN\\n]\\n= XTW (19.2)\\nvới M,N lần lượt là số lượngitem và user. Chú ý rằng trong content-based collaborative\\nfiltering, x được xây dựng dựa trên thông tin mô tả củaitem và quá trình xây dựng này độc\\nlập với quá trình đi tìm hệ số phù hợp cho mỗiuser. Như vậy, việc xây dựngitem profile\\nđóng vai trò rất quan trọng và có ảnh hưởng trực tiếp lên hiệu năng của mô hình. Thêm\\nnữa, việc xây dựng từng mô hình riêng lẻ cho mỗiuser dẫn đến kết quả chưa thực sự tốt vì\\nkhông khai thác được mối quan hệ giữa cácuser.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 248, 'page_label': '237'}, page_content='237 CHƯƠNG 19. MATRIX FACTORIZATION COLLABORATIVE FILTERING\\nY\\n(Full) Utility matrix\\nN\\nM ≈ X TM\\nK\\n×\\nItem features\\nY ≈ ˆY = X T W\\nWK\\nN\\nUser features\\nHình 19.1: Matrix factorization. Ma trận utilityY ∈RM×N được phân tích thành tích của hai\\nma trậnX ∈RM×K và W ∈RK×N.\\nBây giờ, giả sử rằng ta không cần xây dựng từ trước cácitem profilex mà vector đặc trưng\\ncho mỗiitem này có thể đượchuấn luyệnđồng thời với mô hình của mỗiuser (ở đây là một\\nvector hệ số). Điều này nghĩa là, biến số trong bài toán tối ưu là cảX và W; trong đó,X là\\nma trận của toàn bộitem profile, mỗicột tương ứng với mộtitem, W là ma trận của toàn\\nbộ user model, mỗicột tương ứng với mộtuser.\\nVới cách làm này, chúng ta đang cố gắng xấp xỉ ma trận utilityY ∈RM×N bằng tích của\\nhai ma trậnX ∈RK×M và W ∈RK×N. Thông thường,K được chọn là một số nhỏ hơn rất\\nnhiều so vớiM,N . Khi đó, cả hai ma trậnX và W đều có rank không vượt quáK. Chính\\nvì vậy, phương pháp này còn được gọi làlow-rank matrix factorization(xem Hình 19.1).\\nCó một vài điểm cần lưu ý:\\n• Ý tưởng chính đằng sau matrix factorization cho recommendation system là tồn tại các\\nđặc trưng ẩn(latent feature) mô tả sự liên quan giữa cácitem và cácuser. Ví dụ, trong\\nhệ thống khuyến nghị các bộ phim, tính chất ẩn có thể làhình sự, chính trị, hành động,\\nhài, v.v.; cũng có thể là một sự kết hợp nào đó của các thể loại này; hoặc cũng có thể là\\nbất cứ điều gì mà chúng ta không thực sự cần đặt tên. Mỗiitem sẽ mang tính chất ẩn ở\\nmột mức độ nào đó tương ứng với các hệ số trong vectorx của nó, hệ số càng cao tương\\nứng với việc mang tính chất đó càng cao. Tương tự, mỗiuser cũng sẽ có xu hướng thích\\nnhững tính chất ẩn nào đó và được mô tả bởi các hệ số trong vectorw của nó. Hệ số cao\\ntương ứng với việcuser thích các bộ phim có tính chất ẩn đó. Giá trị của biểu thứcxTw\\nsẽ cao nếu các thành phần tương ứng củax và w đều cao (và dương). Điều này nghĩa là\\nitem mang các tính chất ẩn màuser thích, vậy ta nên gợi ýitem này chouser đó.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 248, 'page_label': '237'}, page_content='sẽ cao nếu các thành phần tương ứng củax và w đều cao (và dương). Điều này nghĩa là\\nitem mang các tính chất ẩn màuser thích, vậy ta nên gợi ýitem này chouser đó.\\n• Tại sao matrix factorization lại được xếp vào collaborative filtering? Câu trả lời đến từ\\nviệc đi tối ưu hàm mất mát mà chúng ta sẽ thảo luận ở Mục 19.2. Về cơ bản, để tìm\\nnghiệm của bài toán tối ưu, ta phải lần lượt đi tìmX và W khi thành phần còn lại được\\ncố định. Như vậy, mỗi cột củaX sẽ phụ thuộc vào toàn bộ các cột củaW. Ngược lại,\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 249, 'page_label': '238'}, page_content='CHƯƠNG 19. MATRIX FACTORIZATION COLLABORATIVE FILTERING 238\\nmỗi cột củaW lại phụ thuộc vào toàn bộ các cột củaX. Như vậy, có những mỗi quan\\nhệ ràng buộcchằng chịt giữa các thành phần của hai ma trận trên. Tức chúng ta cần sử\\ndụng thông tin của tất cả để suy ra tất cả. Vậy nên phương pháp này cũng được xếp vào\\ncollaborative filtering.\\n• Trong các bài toán thực tế, số lượngitem M và số lượnguser N thường rất lớn. Việc\\ntìm ra các mô hình đơn giản giúp dự đoán cácrating cần được thực hiện một cách nhanh\\nnhất có thể. Neighborhood-based collaborative filtering không yêu cầu việc huấn luyện\\nquá nhiều, nhưng trong quá trình dự đoán, ta cần đi tìm độsimilarity của user đang xét\\nvới toàn bộ các user còn lại rồi suy ra kết quả. Ngược lại, với matrix factorization, việc\\nhuấn luyện có thể hơi phức tạp một chút vì phải lặp đi lặp lại việc tối ưu một ma trận\\nkhi cố định ma trận còn lại, nhưng việc dự đoán đơn giản hơn vì ta chỉ cần lấy tích vô\\nhướng của hai vectorxTw, mỗi vector có độ dàiK là một số nhỏ hơn nhiều so vớiM,N .\\nVì vậy, quá trình dự đoán không yêu cầu khả năng tính toán cao. Việc này khiến nó phù\\nhợp với các mô hình có tập dữ liệu lớn.\\n• Thêm nữa, việc lưu trữ hai ma trậnX vàW yêu cầu lượng bộ nhớ nhỏ so với việc lưu toàn\\nbộ ma trận utility và similarity trong neighborhood-based collaborative filtering. Cụ thể,\\nta cần bộ nhớ để chứaK(M + N) phần tử thay vìM2 hoặc N2 của ma trậnsimilarity.\\n19.2 Xây dựng và tối ưu hàm mất mát\\n19.2.1 Xấp xỉ các đánh giá đã biết\\nNhư đã đề cập, đánh giá củauser n lên item m có thể được xấp xỉ bởiymn = xT\\nmwn. Ta\\ncũng có thể thêm các bias vào công thức xấp xỉ này và tối ưu các bias đó. Cụ thể:\\nymn ≈xT\\nmwn + bm + dn (19.3)\\nTrong đó,bm và dn lượt lượt là các hệ số tự do tương tứng vớiitem m và user n. Vector\\nb = [b1,b2,...,b M]T là vector bias cho cácitem, vectord = [d1,d2,...,d N]T là vector bias\\ncho cácuser. Giống như trong neighborhood-based collaborative filtering (NBCF), các giá trị'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 249, 'page_label': '238'}, page_content='b = [b1,b2,...,b M]T là vector bias cho cácitem, vectord = [d1,d2,...,d N]T là vector bias\\ncho cácuser. Giống như trong neighborhood-based collaborative filtering (NBCF), các giá trị\\nnày cũng có thể được coi là các giá trị giúp chuẩn hoá dữ liệu vớib tương ứng với item-item\\nCF vàd tương ứng với user-user CF. Không giống như trong NBCF, các giá trị này sẽ được\\ntối ưu để tìm ra các giá trị giúp xấp xỉ tập huấn luyện tốt nhất. Thêm vào đó, huấn luyện\\ncùng lúc cảd và b giúp kết hợp cả user-user CF và item-item CF vào trong một bài toán\\ntối ưu. Vì vậy, chúng ta mong đợi rằng phương pháp này sẽ mang lại hiệu quả tốt hơn.\\n19.2.2 Hàm mất mát\\nHàm mất mát cho MFCF có thể được viết như sau\\nL(X,W,b,d) = 1\\n2s\\nN∑\\nn=1\\n∑\\nm:rmn=1\\n(xT\\nmwn + bm + dn −ymn)\\n\\ued19 \\ued18\\ued17 \\ued1a\\ndata loss\\n+ λ\\n2 (∥X∥2\\nF + ∥W∥2\\nF)\\n\\ued19 \\ued18\\ued17 \\ued1a\\nregularization loss\\n(19.4)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 250, 'page_label': '239'}, page_content='239 CHƯƠNG 19. MATRIX FACTORIZATION COLLABORATIVE FILTERING\\ntrong đórmn = 1 nếu item thứ mđã được đánh giá bởiuser thứ n, slà số lượngrating trong\\ntập huấn luyện,ymn là rating chưa chuẩn hoá1 của user thứ ncho item thứ m. Thành phần\\nthứ nhất của hàm mất mát,data loss, chính là trung bình sai số của mô hình. Thành phần\\nthứ hai,regularization loss, làl2 regularization, thành phần này giúp tránh overfitting2.\\nViệc tối ưu đồng thờiX,W,b,d là tương đối phức tạp. Thay vào đó, phương pháp được sử\\ndụng là lần lượt tối ưu một trong hai cặp(X,b), (W,d) khi cố định cặp còn lại. Quá trình\\nnày được lặp đi lặp lại tới khi hàm mất mát hội tụ.\\n19.2.3 Tối ưu hàm mất mát\\nKhi cố định cặp(X,b), bài toán tối ưu cặp(W,d) có thể được tách thànhN bài toán nhỏ:\\nL1(wn,dn) = 1\\n2s\\n∑\\nm:rmn=1\\n(xT\\nmwn + bm + dn −ymn)2 + λ\\n2 ∥wn∥2\\nF (19.5)\\nMỗi bài toán có thể được tối ưu bằng gradient descent. Công việc quan trọng của chúng\\nta là tính các đạo hàm của từng hàm mất mát nhỏ này theown và dn. Vì biểu thức trong\\ndấu ∑chỉ phụ thuộc vào cácitem đã được đánh giá bởiuser đang xét (tương ứng với các\\nrmn = 1), ta có thể đơn giản (19.5) bằng cách đặtˆXn là ma trận con được tạo bởi các cột\\ncủa X tương ứng với cácitem đã được đánh giá bởiuser n, ˆbn là vector bias con tương ứng,\\nvà ˆyn là cácrating tương ứng. Khi đó,\\nL1(wn,dn) = 1\\n2s∥ˆXT\\nnwn + ˆbn + dn1 −ˆyn∥2 + λ\\n2 ∥wn∥2\\n2 (19.6)\\nvới 1 là vector với mọi phần tử bằng 1 và kích thước phù hợp. Đạo hàm của nó là\\n∇wnL1 = 1\\ns\\nˆXn( ˆXT\\nnwn + ˆbn + dn1 −ˆyn) + λwn (19.7)\\n∇bnL1 = 1\\ns1T( ˆXT\\nnwn + ˆbn + dn1 −ˆyn) (19.8)\\nCông thức cập nhật chown và dn\\nwn ←wn −η\\n(1\\ns\\nˆXn( ˆXT\\nnwn + ˆbn + dn1 −ˆyn) + λwn\\n)\\n(19.9)\\ndn ←dn −η\\n(1\\ns1T( ˆXT\\nnwn + ˆbn + dn1 −ˆyn)\\n)\\n(19.10)\\nTương tự như thế, mỗi cộtxm của X, tức vector đặc trưng cho mỗiitem, vàbm sẽ được tìm\\nbằng cách tối ưu bài toán\\nL2(xm,bm) = 1\\n2s\\n∑\\nn:rmn=1\\n(wT\\nnxm + dn + bm −ymn)2 + λ\\n2 ∥xm∥2\\n2 (19.11)\\n1 việc chuẩn hoá sẽ được tự động thực hiện thông qua việc huấn luyệnb và d\\n2 Bạn đọc có thể thử cộng thêm∥b∥2\\n2 + ∥d∥2'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 250, 'page_label': '239'}, page_content='L2(xm,bm) = 1\\n2s\\n∑\\nn:rmn=1\\n(wT\\nnxm + dn + bm −ymn)2 + λ\\n2 ∥xm∥2\\n2 (19.11)\\n1 việc chuẩn hoá sẽ được tự động thực hiện thông qua việc huấn luyệnb và d\\n2 Bạn đọc có thể thử cộng thêm∥b∥2\\n2 + ∥d∥2\\n2 vào trong dấu ngoặc của regularization loss. Kết quả có thể thay đổi,\\nnhưng không đáng kể.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 251, 'page_label': '240'}, page_content='CHƯƠNG 19. MATRIX FACTORIZATION COLLABORATIVE FILTERING 240\\nĐặt ˆWm là ma trận được tạo bằng các cột củaW ứng với cácuser đã đánh giáitem m, ˆdm\\nlà vector con bias tương ứng, vàˆym là vectorrating tương ứng. Bài toán (19.11) trở thành\\nL(xm,bm) = 1\\n2s∥ˆWT\\nmxm + ˆdm + bn1 −ˆym∥+ λ\\n2 ∥xm∥2\\n2 (19.12)\\nTương tự như trên, ta có\\nCông thức cập nhật choxm và bm\\nxm ←xm −η\\n(1\\ns\\nˆWm( ˆWT\\nmxm + ˆdm + bn1 −ˆym) + λxm\\n)\\n(19.13)\\nbm ←bm −η\\n(1\\ns1T( ˆWT\\nmxm + ˆdm + bn1 −ˆym)\\n)\\n(19.14)\\nTrong mục tiếp theo, chúng ta sẽ giải quyết bài toán này trên Python.\\n19.3 Lập trình Python\\nTrước hết, chúng ta sẽ viết mộtclass MF thực hiện việc tối ưu các biến với một ma trận\\nutility được cho dưới dạngY_data giống như với NBCF.\\nTrước tiên, ta khai báo một vài thư viện cần thiết và khởi tạoclass MF\\nfrom __future__ import print_function\\nimport pandas as pd\\nimport numpy as np\\nfrom sklearn.metrics.pairwise import cosine_similarity\\nfrom scipy import sparse\\nclass MF(object):\\ndef __init__(self, Y, K, lam = 0.1, Xinit = None, Winit = None,\\nlearning_rate = 0.5, max_iter = 1000, print_every = 100):\\nself.Y = Y # represents the utility matrix\\nself.K = K #\\nself.lam = lam # regularization parameter\\nself.learning_rate = learning_rate # for gradient descent\\nself.max_iter = max_iter # maximum number of iterations\\nself.print_every = print_every # print loss after each a few iters\\nself.n_users = int(np.max(Y[:, 0])) + 1\\nself.n_items = int(np.max(Y[:, 1])) + 1\\nself.n_ratings = Y.shape[0] # number of known ratings\\nself.X = np.random.randn(self.n_items, K) if Xinit is None else Xinit\\nself.W = np.random.randn(K, self.n_users) if Winit is None else Winit\\nself.b = np.random.randn(self.n_items) # item biases\\nself.d = np.random.randn(self.n_users) # user biases\\nTiếp theo, chúng ta viết các phương thứcloss, updateXb, updateWd cho class MF.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 252, 'page_label': '241'}, page_content='241 CHƯƠNG 19. MATRIX FACTORIZATION COLLABORATIVE FILTERING\\ndef loss(self):\\nL = 0\\nfor i in range(self.n_ratings):\\n# user_id, item_id, rating\\nn, m, rating = int(self.Y[i, 0]), int(self.Y[i, 1]), self.Y[i, 2]\\nL += 0.5*(self.X[m].dot(self.W[:, n]) + self.b[m] + self.d[n] - rating)**2\\nL /= self.n_ratings\\n# regularization, don’t ever forget this\\nreturn L + 0.5*self.lam*(np.sum(self.X**2) + np.sum(self.W**2))\\ndef updateXb(self):\\nfor m in range(self.n_items):\\n# get all users who rated item m and get the corresponding ratings\\nids = np.where(self.Y[:, 1] == m)[0] # row indices of items m\\nuser_ids, ratings = self.Y[ids, 0].astype(np.int32), self.Y[ids, 2]\\nWm, dm = self.W[:, user_ids], self.d[user_ids]\\nfor i in range(30): # 30 iteration for each sub problem\\nxm = self.X[m]\\nerror = xm.dot(Wm) + self.b[m] + dm - ratings\\ngrad_xm = error.dot(Wm.T)/self.n_ratings + self.lam*xm\\ngrad_bm = np.sum(error)/self.n_ratings\\n# gradient descent\\nself.X[m] -= self.learning_rate*grad_xm.reshape(-1)\\nself.b[m] -= self.learning_rate*grad_bm\\ndef updateWd(self): # and d\\nfor n in range(self.n_users):\\n# get all items rated by user n, and the corresponding ratings\\nids = np.where(self.Y[:,0] == n)[0] # row indices of items rated by user n\\nitem_ids, ratings = self.Y[ids, 1].astype(np.int32), self.Y[ids, 2]\\nXn, bn = self.X[item_ids], self.b[item_ids]\\nfor i in range(30): # 30 iteration for each sub problem\\nwn = self.W[:, n]\\nerror = Xn.dot(wn) + bn + self.d[n] - ratings\\ngrad_wn = Xn.T.dot(error)/self.n_ratings + self.lam*wn\\ngrad_dn = np.sum(error)/self.n_ratings\\n# gradient descent\\nself.W[:, n] -= self.learning_rate*grad_wn.reshape(-1)\\nself.d[n] -= self.learning_rate*grad_dn\\nPhần tiếp theo là quá trình tối ưu chính của MF (fit), dự đoánrating mới (pred) và đánh\\ngiá chất lượng mô hình bằng root-mean-square error (evaluate_RMSE).\\ndef fit(self):\\nfor it in range(self.max_iter):\\nself.updateWd()\\nself.updateXb()\\nif (it + 1) % self.print_every == 0:\\nrmse_train = self.evaluate_RMSE(self.Y)'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 252, 'page_label': '241'}, page_content='def fit(self):\\nfor it in range(self.max_iter):\\nself.updateWd()\\nself.updateXb()\\nif (it + 1) % self.print_every == 0:\\nrmse_train = self.evaluate_RMSE(self.Y)\\nprint(’iter = %d, loss = %.4f, RMSE train = %.4f’%(it + 1,\\nself.loss(), rmse_train))\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 253, 'page_label': '242'}, page_content='CHƯƠNG 19. MATRIX FACTORIZATION COLLABORATIVE FILTERING 242\\ndef pred(self, u, i):\\n\"\"\"\\npredict the rating of user u for item i\\n\"\"\"\\nu, i = int(u), int(i)\\npred = self.X[i, :].dot(self.W[:, u]) + self.b[i] + self.d[u]# + bias\\nreturn max(0, min(5, pred)) # pred should be between 0 and 5 in MoviesLen\\ndef evaluate_RMSE(self, rate_test):\\nn_tests = rate_test.shape[0] # number of test\\nSE = 0 # squared error\\nfor n in range(n_tests):\\npred = self.pred(rate_test[n, 0], rate_test[n, 1])\\nSE += (pred - rate_test[n, 2])**2\\nRMSE = np.sqrt(SE/n_tests)\\nreturn RMSE\\nTới đây, chúng ta đã xây dựng trong classMF với các phương thức cần thiết. Tiếp theo, chúng\\nta kiểm tra chất lượng mô hình khi nó được áp dụng lên tập dữ liệu MoviesLen 100k.\\nr_cols = [’user_id’, ’movie_id’, ’rating’, ’unix_timestamp’]\\nratings_base = pd.read_csv(’ml-100k/ua.base’, sep=’\\\\t’, names=r_cols)\\nratings_test = pd.read_csv(’ml-100k/ua.test’, sep=’\\\\t’, names=r_cols)\\nrate_train = ratings_base.as_matrix()\\nrate_test = ratings_test.as_matrix()\\n# indices start from 0\\nrate_train[:, :2] -= 1\\nrate_test[:, :2] -= 1\\nrs = MF(rate_train, K = 50, lam = .01, print_every = 5, learning_rate = 50,\\nmax_iter = 30)\\nrs.fit()\\n# evaluate on test data\\nRMSE = rs.evaluate_RMSE(rate_test)\\nprint(’\\\\nMatrix Factorization CF, RMSE = %.4f’ %RMSE)\\nKết quả:\\niter = 5, loss = 0.4447, RMSE train = 0.9429\\niter = 10, loss = 0.4215, RMSE train = 0.9180\\niter = 15, loss = 0.4174, RMSE train = 0.9135\\niter = 20, loss = 0.4161, RMSE train = 0.9120\\niter = 25, loss = 0.4155, RMSE train = 0.9114\\niter = 30, loss = 0.4152, RMSE train = 0.9110\\nMatrix Factorization CF, RMSE = 0.9621\\nRMSE thu được là 0.9621, tốt hơn so với NBCF trong chương trước (0.9688).\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 254, 'page_label': '243'}, page_content='243 CHƯƠNG 19. MATRIX FACTORIZATION COLLABORATIVE FILTERING\\n19.4 Thảo luận\\n• Nonnegative matrix factorization. Khi dữ liệu chưa được chuẩn hoá, chúng đều mang\\ncác giá trị không âm. Kể cả trong trường hợp dải giá trị củarating có chứa giá trị âm,\\nta chỉ cần cộng thêm vào ma trận utility một giá trị hợp lý để có được cácrating là các\\nsố không âm. Khi đó, một phương pháp matrix factorization khác với thêm ràng buộc\\ncũng được sử dụng rất nhiều và mang lại hiệu quả cao trong recommendation system là\\nnonnegative matrix factorization(NMF) [ZWFM06], tức phân tích ma trận thành tích\\ncác ma trận có các phần tử không âm.\\nThông qua matrix factorization, cácuser vàitem được liên kết với nhau bởi cácđặc trưng\\nẩn. Độ liên kết của mỗiuser và item tới mỗi đặc trưng ẩn được đo bằng thành phần\\ntương ứng trong vector đặc trung của chúng, giá trị càng lớn thể hiện việcuser hoặc item\\ncó liên quan đến đặc trưng ẩn đó càng lớn. Bằng trực giác, sự liên quan của mộtuser\\nhoặc item đến một đặc trưng ẩn nên là một số không âm với giá trị 0 thể hiện việckhông\\nliên quan. Hơn nữa, mỗiuser và item chỉ liên quanđến một vài đặc trưng ẩn nhất định.\\nVì vậy, các vector đặc trưng chouser vàitem nên là các vector không âm và có rất nhiều\\ngiá trị bằng 0. Những nghiệm này có thể đạt được bằng cách cho thêm ràng buộc không\\nâm vào các thành phần củaX và W. Đây chính là nguồn gốc của ý tưởng và tên gọi\\nnonnegative matrix factorization.\\n• Incremental matrix factorization. Như đã đề cập, thời gian dự đoán của một recom-\\nmendation system sử dụng matrix factorization là rất nhanh nhưng thời gian huấn luyện\\nlà khá lâu với các tập dữ liệu lớn. Thực tế cho thấy, ma trận utility thay đổi liên tục vì có\\nthêm user, item cũng như cácrating mới hoặcuser muốn thay đổirating của họ, vì vậy\\ncác tham số mô hình cũng phải thường xuyên được cập nhật. Điều này đồng nghĩa với\\nviệc ta phải tiếp tục thực hiện quá trìnhtraining vốn tốn khá nhiều thời gian. Việc này'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 254, 'page_label': '243'}, page_content='các tham số mô hình cũng phải thường xuyên được cập nhật. Điều này đồng nghĩa với\\nviệc ta phải tiếp tục thực hiện quá trìnhtraining vốn tốn khá nhiều thời gian. Việc này\\nđược giải quyết phần nào bằngincremental matrix factorization[VJG14]. Từincremental\\ncó thể được hiểu làđiều chỉnh nhỏcho phù hợp với dữ liệu.\\n• Bài toán tối ưu của matrix factorization có nhiều hướng giải quyết khác ngoài cách\\náp dụng gradient descent. Bạn đọc có thể xem thêmAlternating Least Square (ALS)\\n(https://goo.gl/g2M4fb ), Generalized Low Rank Models(https://goo.gl/DrDWyW ), và\\nSingular Value Decomposition[SKKR02,Pat07]. Chương 20 sẽ bàn kỹ hơn về Singular\\nValue Decomposition.\\n• Source code trong chương này có thể được tìm thấy tạihttps://goo.gl/XbbFH4 .\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 256, 'page_label': '245'}, page_content='Phần VI\\nDimensionality reduction–Giảm chiều dữ liệu\\nSố lượng điểm dữ liệu và kích thước của các vector đặc trưng thường rất lớn trong các bài\\ntoán thực tế. Nếu thực hiện lưu trữ và tính toán trực tiếp trên dữ liệu có số chiều cao\\nnày thì sẽ gặp khó khăn cả về việc lưu trữ và tốc độ tính toán. Vì vậy,giảm chiều dữ liệu\\n(dimensionality reduction hoặc dimension reduction) là một bước quan trọng trong nhiều\\nbài toán machine learning.\\nMột cách toán học, giảm chiều dữ liệu là việc đi tìm một hàm sốf : RD →RK với K <D\\nbiến một điểm dữ liệux trong không gian có số chiều lớnRD thành một điểmz trong không\\ngian có số chiều nhỏ hơnRD. Việc giảm chiều dữ liệu có thể được thực hiện nhằm vào các\\nmục đích khác nhau. Nó có thể phục vụ việcnén thông tin sao chox có thể được suy ngược\\nlại (xấp xỉ) từz. Nó cũng có thể phục vụ các bài toán phân lớp bằng cách chọn ra những đặc\\ntrưng quan trọng (feature selection) hoặc tạo ra các đặc trưng mới từ đặc trưng cũ (feature\\nextraction) sao cho kết quả của bài toán phân lớp được cải thiện.\\nTrong nhiều trường hợp, làm việc trên dữ liệu được giảm chiều cho kết quả tốt hơn dữ liệu\\ntrong không gian ban đầu.\\nTrong phần này, chúng ta sẽ xem xét các phương pháp giảm chiều dữ liệu phổ biến nhất:\\nprinciple component analysischo bài toán giảm chiều dữ liệu vẫn giữ được tối đa lượng thông\\ntin, vàlinear discriminant analysischo bài toán giữ lại những đặc trưng quan trọng nhất\\ncho việc phân lớp. Trước hết, chúng ta cùng tìm hiểu một phương pháp phân tích ma trận\\nthành nhân tử vô cùng quan trọng –singular value decomposition.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 257, 'page_label': '246'}, page_content='Chương 20\\nSingular value decomposition\\n20.1 Giới thiệu\\nNhắc lại bài toán chéo hoá ma trận: Một ma trận vuôngA ∈Rn×n được gọi làchéo hoá\\nđược (diagonalizable) nếu tồn tại ma trận đường chéoD và ma trận khả nghịchP sao cho:\\nA = PDP−1 (20.1)\\nSố lượng phần tử khác 0 của ma trận đường chéoD chính là rank của ma trậnA.\\nNhân cả hai vế của (20.1) vớiP ta có:\\nAP = PD (20.2)\\nGọi pi,di lần lượt là cột thứi của ma trậnP và D. Vì mỗi một cột của vế trái và vế phải\\ncủa (20.2) phải bằng nhau, ta cần có\\nApi = Pdi = diipi (20.3)\\nvới dii là phần tử thứicủa di. Dấu bằng thứ hai xảy ra vìD là ma trận đường chéo, tứcdi\\nchỉ có thành phầndii là khác 0. Biểu thức (20.3) chỉ ra rằng mỗi phần tửdii phải là một trị\\nriêng củaA và mỗi vector cộtpi phải là một vector riêng củaA ứng với trị riêngdii.\\nCách phân tích một ma trận vuông thành nhân tử như (20.1) còn được gọi làEigen Decom-\\nposition. Một điểm quan trọng là cách phân tích này chỉ được áp dụng với ma trận vuông\\nvà không phải lúc nào cũng tồn tại. Nó chỉ tồn tại nếu ma trậnA có nvector riêng độc lập\\ntuyến tính, vì nếu không thì không tồn tại ma trậnP khả nghịch. Thêm nữa, cách phân tích\\nnày cũng không phải là duy nhất vì nếuP,D thoả mãn (20.1) thìkP,D cũng thoả mãn với\\nk là một số thực khác 0 bất kỳ.\\nViệc phân tích một ma trận ra thành tích của nhiều ma trận đặc biệt khác (matrix factor-\\nization hoặc matrix decomposition) mang lại nhiều ích lợi quan trọng mà các bạn sẽ thấy:'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 258, 'page_label': '247'}, page_content='247 CHƯƠNG 20. SINGULAR VALUE DECOMPOSITION\\ngiảm số chiều dữ liệu, nén dữ liệu, tìm hiểu các đặc tính của dữ liệu, giải các hệ phương\\ntrình tuyến tính, clustering, và nhiều ứng dụng khác. Hệ thống khuyến nghị cũng là một\\ntrong rất nhiều ứng dụng của matrix factorization.\\nTrong chương này, chúng ta sẽ làm quen với một trong những phương pháp matrix factor-\\nization rất đẹp của đại số tuyến tính có tên làsingular value decomposition(SVD) [GR70].\\nCác bạn sẽ thấy, mọi ma trận, không nhất thiết là vuông, đều có thể được phân tích thành\\ntích của ba ma trận đặc biệt.\\n20.2 Singular value decomposition\\nĐể hạn chế nhầm lẫn trong các phép toán nhân ma trận, chúng ta cần để ý tới kích thước\\ncủa mỗi ma trận. Trong chương này, ta sẽ ký hiệu một ma trận cùng với số chiều của nó, ví\\ndụ Am×n dùng để ký hiệu một ma trậnA ∈Rm×n.\\n20.2.1 Phát biểu SVD\\nSingular value decomposition\\nMột ma trậnAm×n bất kỳ đều có thể phân tích thành dạng:\\nAm×n = Um×mΣm×n(Vn×n)T (20.4)\\nTrong đó,U,V là các ma trận trực giao,Σ là một ma trận đường chéo cùng kích\\nthước vớiA. Các phần tử trên đường chéo chính củaΣ là không âm và được theo thứ\\ntự giảm dầnσ1 ≥σ2 ≥···≥ σr ≥0 = 0 = ··· = 0. Số lượng các phần tử khác 0 trong\\nΣ chính là rank của ma trậnA: r= rank(A).\\nSVD của một ma trận bất ký luôn tồn tại. Bạn đọc có thể tìm thấy chứng minh cho việc\\nnày tạihttps://goo.gl/TdtWDQ . Cách biểu diễn (20.4) không là duy nhất vì ta chỉ cần đổi\\ndấu của cảU và V thì (20.4) vẫn thoả mãn.\\nHình 20.1 mô tả SVD của ma trậnAm×n trong hai trường hợp:m < nvà m > n. Trường\\nhợp m= n có thể xếp vào một trong hai trường hợp trên.\\n20.2.2 Nguồn gốc tên gọi singular value decomposition\\nTạm bỏ qua chiều của mỗi ma trận, từ (20.4) ta có:\\nAAT = UΣVT(UΣVT)T (20.5)\\n= UΣVTVΣTUT (20.6)\\n= UΣΣTUT = UΣΣTU−1 (20.7)\\nDấu bằng ở (20.6) xảy ra vìVTV = I do V là một ma trận trực giao. Dấu bằng ở (20.7)\\nxảy ra vìU là một ma trận trực giao.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 259, 'page_label': '248'}, page_content='CHƯƠNG 20. SINGULAR VALUE DECOMPOSITION 248\\nAm×n = ×Um×m ... Σm×n ×\\nVT\\nn×n\\n(a) (m < n)\\n(b) (m > n)\\nAm×n\\n= ×\\nUm×m\\n...\\nΣm×n\\n× VT\\nn×n\\nHình 20.1: SVD cho ma trậnA khi: m < n(hình trên), vàm > n(hình dưới).Σ là một ma\\ntrận đường chéo với các phần tử trên đó giảm dần và không âm. Màu đỏ càng đậm thể hiện giá\\ntrị càng cao. Các ô màu trắng trên ma trận này thể hiện giá trị 0.\\nQuan sát thấy rằngΣΣT là một ma trận đường chéo với các phần tử trên đường chéo là\\nσ2\\n1,σ2\\n2,... . Vậy (20.7) chính là một eigen decomposition củaAAT. Thêm nữa, σ2\\n1,σ2\\n2,...\\nchính là các trị riêng củaAAT. Ma trậnAAT luôn là ma trận nửa xác định dương nên các\\ntrị riêng của nó là không âm. Cácσi, là căn bậc hai của các trị riêng củaAAT, còn được\\ngọi làsingular value của A. Tên gọisingular value decompositionxuất phát từ đây.\\nCũng theo đó, mỗi cột củaU chính là một vector riêng củaAAT. Ta gọi mỗi cột này là một\\nleft-singular vectorcủa A. Tương tự như thế,ATA = VΣTΣVT và các cột củaV còn được\\ngọi là cácright-singular vectorscủa A.\\nTrong Python, để tính SVD của một ma trận, chúng ta sử dụng modulelinalg của numpy:\\nfrom __future__ import print_function\\nimport numpy as np\\nfrom numpy import linalg as LA\\nm, n = 3, 4\\nA = np.random.rand(m, n)\\nU, S, V = LA.svd(A) # A = U*S*V (no V transpose here)\\n# checking if U, V are orthogonal and S is a diagonal matrix with\\n# nonnegative decreasing elements\\nprint(’Frobenius norm of (UU^T - I) =’, LA.norm(U.dot(U.T) - np.eye(m)))\\nprint(’S = ’, S)\\nprint(’Frobenius norm of (VV^T - I) =’, LA.norm(V.dot(V.T) - np.eye(n)))\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 260, 'page_label': '249'}, page_content='249 CHƯƠNG 20. SINGULAR VALUE DECOMPOSITION\\nKết quả:\\nFrobenius norm of (UU^T - I) = 4.09460889695e-16\\nS = [ 1.76321041 0.59018069 0.3878011 ]\\nFrobenius norm of (VV^T - I) = 5.00370755311e-16\\nLưu ý rằng biếnS được trả về chỉ bao gồm các phần tử trên đường chéo củaΣ. BiếnV trả\\nvề làVT trong (20.4).\\n20.2.3 Singular value của một ma trận nửa xác định dương\\nGiả sửA là một ma trận đối xứng vuông nửa xác định dương, ta sẽ chứng minh rằng các\\nsingular value củaA chính là các trị riêng của nó. Thật vậy, gọiλlà một trị riêng củaA và\\nx là một vector riêng ứng với trị riêng đó, hơn nữa∥x∥2 = 1. VìA là nửa xác định dương,\\nta phải cóλ≥0. Ta có\\nAx = λx ⇒ATAx = λAx = λ2x (20.8)\\nNhư vậy,λ2 là một trị riêng củaATA ⇒singular value củaA chính là\\n√\\nλ2 = λ.\\n20.2.4 Compact SVD\\nViết lại biểu thức (20.4) dưới dạng tổng của các ma trận có rank bằng 1:\\nA = σ1u1vT\\n1 + σ2u2vT\\n2 + ··· + σrurvT\\nr (20.9)\\nvới chú ý rằng mỗiuivT\\ni ,1 ≤i≤r, là một ma trận có rank bằng 1.\\nRõ ràng trong cách biểu diễn này, ma trậnA chỉ phụ thuộc vàor cột đầu tiên củaU,V và\\nr giá trị khác 0 trên đường chéo của ma trậnΣ. Vì vậy ta có một cách phân tíchgọn hơn\\nvà gọi làcompact SVD:\\nA = UrΣr(Vr)T (20.10)\\nvới Ur,Vr lần lượt là ma trận được tạo bởir cột đầu tiên củaU và V. Σr là ma trận con\\nđược tạo bởir hàng đầu tiên vàr cột đầu tiên củaΣ. Nếu ma trậnA có rank nhỏ hơn rất\\nnhiều so với số hàng và số cộtr≪m,n, ta sẽ được lợi nhiều về việc lưu trữ.\\nDưới đây là ví dụ minh hoạ vớim= 4,n = 6,r = 2.\\n20.2.5 Truncated SVD\\nNhắc lại rằng trong ma trận Σ, các giá trị trên đường chéo là không âm và giảm dần\\nσ1 ≥σ2 ≥..., ≥σr ≥0 = 0 = ··· = 0. Thông thường, chỉ một lượng nhỏ cácσi mang giá\\ntrị lớn, các giá trị còn lại thường nhỏ và gần 0. Khi đó ta có thể xấp xỉ ma trậnA bằng tổng\\ncủa k <rma trận có rank 1:\\nA ≈Ak = UkΣk(Vk)T = σ1u1vT\\n1 + σ2u2vT\\n2 + ··· + σkukvT\\nk (20.11)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 261, 'page_label': '250'}, page_content='CHƯƠNG 20. SINGULAR VALUE DECOMPOSITION 250\\nA\\n=\\nU r Σ r ( V r )\\nT\\nσ 1 u 1 v\\nT\\n1\\n+=\\nσ 2 u 2 v\\nT\\n2\\nHình 20.2: Biểu diễn SVD dạng thu gọn và biểu diễn ma trận dưới dạng tổng các ma trận có\\nrank bằng 1. Các khối ma trận đặt cạnh nhau thể hiện phép nhân ma trận.\\nDưới đây là một định lý thú vị. Định lý này nói rằng sai số do cách xấp xỉ trên chính là căn\\nbậc hai của tổng bình phương của các singular value mà ta đã bỏ qua ở phần cuối củaΣ. Ở\\nđây sai số được định nghĩa là Frobineous norm của hiệu hai ma trận.\\nĐịnh lý 20.1: Sai số do xấp xỉ bởi truncated SVD\\nNếu xấp xỉ một ma trậnA có rankr bởi truncated SVD vớik <rphần tử, sai số do\\ncách xấp xỉ này là\\n∥A −Ak∥2\\nF =\\nr∑\\ni=k+1\\nσ2\\ni (8) (20.12)\\nChứng minh: Sử dụng tính chất∥X∥2\\nF = trace(XXT) và trace(XY) = trace(YX) với mọi\\nma trậnX,Y ta có\\n∥A −Ak∥2\\nF =\\n\\ued79\\ued79\\ued79\\ued79\\ued79\\nr∑\\ni=k+1\\nσiuivT\\ni\\n\\ued79\\ued79\\ued79\\ued79\\ued79\\n2\\nF\\n= trace\\n\\uf8f1\\n\\uf8f2\\n\\uf8f3\\n( r∑\\ni=k+1\\nσiuivT\\ni\\n)( r∑\\nj=k+1\\nσjujvT\\nj\\n)T\\n\\uf8fc\\n\\uf8fd\\n\\uf8fe(20.13)\\n= trace\\n{ r∑\\ni=k+1\\nr∑\\nj=k+1\\nσiσjuivT\\ni vjuT\\nj\\n}\\n= trace\\n{ r∑\\ni=k+1\\nσ2\\niuiuT\\ni\\n}\\n(20.14)\\n= trace\\n{ r∑\\ni=k+1\\nσ2\\niuT\\ni ui\\n}\\n(20.15)\\n= trace\\n{ r∑\\ni=k+1\\nσ2\\ni\\n}\\n=\\nr∑\\ni=k+1\\nσ2\\ni (20.16)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 262, 'page_label': '251'}, page_content='251 CHƯƠNG 20. SINGULAR VALUE DECOMPOSITION\\nDấu bằng thứ hai ở (20.14) xảy ra vìV có các cột vuông góc với nhau. Dấu bằng ở (20.15)\\nxảy ra vì hàm trace có tính chất giao hoán. Dấu bằng ở (20.16) xảy ra vì biểu thức trong\\ndấu ngoặc là một số vô hướng. □\\nThay k= 0 ta sẽ có\\n∥A∥2\\nF =\\nr∑\\ni=1\\nσ2\\ni (20.17)\\nTừ đó\\n∥A −Ak∥2\\nF\\n∥A∥2\\nF\\n=\\n∑r\\ni=k+1 σ2\\ni∑r\\nj=1 σ2\\nj\\n(20.18)\\nNhư vậy,sai số do xấp xỉ càng nhỏ nếu các singular value bịtruncated có giá trị\\ncàng nhỏ so với các singular value được giữ lại.Đây là một định lý quan trọng giúp\\nxác định việc xấp xỉ ma trận dựa trên lượng thông tin muốn giữ lại. Với giả sử rằnglượng\\nthông tin được định nghĩa là tổng bình phương của các singular value. Ví dụ, nếu ta muốn\\ngiữ lại ít nhất 90% lương thông tin trongA, trước hết ta tính∑r\\nj=1 σ2\\nj, sau đó chọnk là số\\nnhỏ nhất sao cho ∑k\\ni=1 σ2\\ni∑r\\nj=1 σ2\\nj\\n≥0.9 (20.19)\\nKhi k nhỏ, ma trậnAk có rank làk, là một ma trận có rank nhỏ. Vì vậy, Truncated SVD\\ncòn được coi là một phương pháplow-rank approximation.\\n20.2.6 Xấp xỉ rankk tốt nhất\\nNgười ta chứng minh được rằng1 Ak chính là nghiệm của bài toán tối ưu sau đây:\\nmin\\nB\\n∥A −B∥F\\nthoả mãn: rank(B) = k\\n(20.20)\\nvà như đã chứng minh ở trên∥A −Ak∥2\\nF = ∑r\\ni=k+1 σ2\\ni.\\nNếu sử dụngℓ2 norm của ma trận (xem Phụ lục A) thay vì Frobenius norm để đo sai số,Ak\\ncũng là nghiệm của bài toán tối ưu\\nmin\\nB\\n∥A −B∥2\\nthoả mãn: rank(B) = k\\n(20.21)\\nvà sai số∥A −Ak∥2\\n2 = σ2\\nk+1. Trong đó, norm 2 của một ma trận được định nghĩa bởi\\n∥A∥2 = max\\n∥x∥2=1\\n∥Ax∥2 (20.22)\\nFrobenius norm vàℓ2 norm là hai norm được sử dụng nhiều nhất trong ma trận. Như vậy,\\nxét trên cả hai norm này, truncated SVD đều cho xấp xỉ tốt nhất. Vì vậy, truncated SVD\\ncòn được coi làxấp xỉ rank thấp tốt nhất(best low-rank approximation).\\n1 Singular Value Decomposition – Princeton (https://goo.gl/hU38GF ).\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 263, 'page_label': '252'}, page_content='CHƯƠNG 20. SINGULAR VALUE DECOMPOSITION 252\\n(a)\\n0 200 400 600 800 1000\\nk\\n101\\n102\\n103\\n104\\n105\\nσk (b)\\n0 200 400 600 800 1000\\nk\\n0.875\\n0.900\\n0.925\\n0.950\\n0.975\\n1.000\\n∥A − Ak∥2\\nF /∥A∥2\\nF (c)\\nk = 5: error = 0.0448\\n(d)\\nk = 50: error = 0.0059 (e)\\nk = 100: error = 0.0026 (f)\\nHình 20.3: Ví dụ về SVD cho ảnh. (a) Bức ảnh gốc là một ảnh xám, là một ma trận cỡ\\n960 ×1440. (b) Giá trị của các singular values của ma trận ảnh theo logscale. Có thể thấy rằng\\ncác singular value giảm nhanh ở khoảngk= 200. (c) Biểu diễn lượng thông tin được giữ lại khi\\nchọn cáck khác nhau. Có thể nhận thấy từ khoảngk= 200, lượng thông tin giữ lại là gần bằng\\n1. Vậy ta có thể xấp xỉ ma trận ảnh này bằng một ma trận có rank nhỏ hơn. (d), (e), (f) Các\\nảnh xấp xỉ vớik lần lượt là 5, 50, 100.\\n20.3 SVD cho image compression\\nXét ví dụ trong Hình 20.3. Bức ảnh gốc trong Hình 20.3a là một ảnh xám có kích thước\\n960 ×1440 pixel. Bức ảnh này có thể được coi là một ma trậnA ∈R960×1440. Ta có thể quan\\nsát thấy rằng ma trận này làlow-rank vì rất nhiềutầng của toà nhà nhìn tương tự nhau.\\nHình 20.3b là giá trị của các singular value của bức ảnh được sắp xếp theo thứ tự giảm dần.\\nChú ý rằng giá trị của các singular value được biểu diễn trên thang log10 nên các giá trị\\nsingular đầu tiên rất lớn so với các giá trị singular ở cuối. Hình 20.3c mô tả chất lượng của\\nviệc xấp xỉA bởi Ak bằng truncated SVD. Ta cũng thấy rằng giá trị này xấp xỉ bằng 1 tại\\nk = 200. Hình 20.3d, 20.3e, 20.3f là các bức ảnh xấp xỉ khi chọn các giá trịk khác nhau.\\nKhi k gần 100, lượng thông tin mất đi rơi vào khoảng nhỏ hơn 3%, ảnh thu được có chất\\nlượng gần như ảnh gốc.\\nĐể lưu ảnh với truncated SVD, ta sẽ lưu các ma trậnUk ∈Rm×k,Σk ∈Rk×k,Vk ∈Rn×k.\\nTổng số phần tử phải lưu làk(m+ n+ 1) với chú ý rằng ta chỉ cần lưu các giá trị trên đường\\nchéo củaΣk. Giả sử mỗi phần tử được lưu bởi một số thực bốn byte, thế thì số byte cần lưu\\ntrữ là4k(m+ n+ 1). Nếu so giá trị này với ảnh gốc có kích thướcmn, mỗi giá trị là một số\\nnguyên một byte, tỉ lệ nén là'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 263, 'page_label': '252'}, page_content='trữ là4k(m+ n+ 1). Nếu so giá trị này với ảnh gốc có kích thướcmn, mỗi giá trị là một số\\nnguyên một byte, tỉ lệ nén là\\n4k(m+ n+ 1)\\nmn (20.23)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 264, 'page_label': '253'}, page_content='253 CHƯƠNG 20. SINGULAR VALUE DECOMPOSITION\\nKhi k ≪m,n, ta được một tỉ lệ nhỏ hơn 1. Trong ví dụ trên,m= 960,n = 1440,k = 100,\\ntỉ lệ nén là xấp xỉ 0.69, tức đã tiết kiệm được khoảng 30% bộ nhớ.\\n20.4 Thảo luận\\n• Ngoài ứng dụng nêu trên, SVD còn được ứng dụng trong việc giải phương trình tuyến\\ntính thông qua giả nghịch đảo Moore Penrose (https://goo.gl/4wrXue ), recommendation\\nsystem [SKKR00], dimensionality reduction [Cyb89], image debluring [HNO06], cluster-\\ning [DFK+04], v.v..\\n• Khi ma trậnA lớn, việc tính toán SVD của nó tốn nhiều thời gian. Cách tính Truncated\\nSVD vớik nhỏ bằng cách tính SVD như được sử dụng trở nên không khả thi. Thay vào\\nđó, có một phương pháp lặp giúp tính các trị riêng và vector riêng của một ma trận lớn\\nmột cách hiệu quả, và ta chỉ cần tìmk trị riêng lớn nhất củaAAT và các vector riêng\\ntương ứng, việc này sẽ tiết kiệm được khá nhiều thời gian. Bạn đọc có thể tìm đọc thêm\\nPower method for approximating eigenvalues(https://goo.gl/PfDqsn ).\\n• Source code trong chương này có thể được tìm thấy tạihttps://goo.gl/Z3wbsU .\\nĐọc thêm\\n1. Singular Value Decomposition - Stanford University(https://goo.gl/Gp726X ).\\n2. Singular Value Decomposition - Princeton(https://goo.gl/HKpcsB ).\\n3. CS168: The Modern Algorithmic Toolbox Lecture #9: The Singular Value Decomposition\\n(SVD) and Low-Rank Matrix Approximations - Stanford(https://goo.gl/RV57KU ).\\n4. The Moore-Penrose Pseudoinverse (Math 33A - UCLA)(https://goo.gl/VxMYx1 ).\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 265, 'page_label': '254'}, page_content='Chương 21\\nPrincipal component analysis\\n21.1 Principal component analysis\\n21.1.1 Ý tưởng\\nGiả sử dữ liệu ban đầu làx ∈RD và dữ liệu đã được giảm chiều làz ∈RK với K < D.\\nCách đơn giản nhất để giảm chiều dữ liệu từD về K < Dlà chỉ giữ lạiK phần tử quan\\ntrọng nhất. Có hai câu hỏi lập tức được đặt ra ở đây. Thứ nhất, làm thế nào để xác định\\ntầm quan trọngcủa mỗi chiều dữ liệu? Thứ hai, nếu tầm quan trọng của các chiều dữ liệu\\nlà như nhau, ta cần bỏ đi những chiều nào?\\nĐể trả lời câu hỏi thứ nhất, ta hãy quan sát Hình 21.1a. Giả sử các điểm dữ liệu có thành\\nphần thứ hai (phương đứng) giống hệt nhau hoặc sai khác nhau rất ít (phương sai nhỏ). Như\\nvậy, thành phần này hoàn toàn có thể được lược bỏ đi, và ta ngầm hiểu rằng nó sẽ được xấp\\nxỉ bằng kỳ vọng của thành phần đó trên toàn bộ các điểm dữ liệu. Ngược lại, việc làm này\\nnếu được áp dụng lên thành phần thứ nhất (phương ngang) sẽ khiếnlượng thông tinbị mất\\nđi rất nhiều do sai số xấp xỉ là quá lớn. Lượng thông tin theo mỗi thành phần, vì vậy, có thể\\nđược đo bằng phương sai của dữ liệu trên thành phần đó. Tổng lượng thông tin có thể được\\ncoi là tổng phương sai trên toàn bộ các thành phần. Lấy một ví dụ về việc có hai camera\\nđược đặt dùng để chụp một con người, một camera đặt phía trước người và một camera đặt\\ntrên đầu. Rõ ràng, hình ảnh thu được từ camera đặt phía trước người mang nhiều thông tin\\nhơn so với hình ảnh nhìn từ phía trên đầu. Vì vậy, bức ảnh chụp từ phía trên đầu có thể\\nđược bỏ qua mà không có quá nhiều thông tin về hình dáng của người đó bị mất.\\nCâu hỏi thứ hai tương ứng với trường hợp Hình 21.1b. Trong cả hai chiều, phương sai của\\ndữ liệu đều lớn; việc bỏ đi một trong hai chiều đều dẫn đến việc lượng thông tin bị mất đi\\nlà lớn. Tuy nhiên, quan sát ban đầu của chúng ta là nếu xoay trục toạ độ đi một góc phù\\nhợp, một trong hai chiều dữ liệu có thể được giảm đi vì dữ liệu có xu hướng phân bố xung\\nquanh một đường thẳng.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 266, 'page_label': '255'}, page_content='255 CHƯƠNG 21. PRINCIPAL COMPONENT ANALYSIS\\nσ1\\nσ2 e1\\ne2\\n(a)\\ne1\\ne2\\nσ1\\nσ2\\n(b)\\nHình 21.1: Ví dụ về phương sai của dữ liệu trong không gian hai chiều. (a) Chiều thứ hai có\\nphương sai (tỉ lệ với độ rộng của đường hình chuông) nhỏ hơn chiều thứ nhất. (b) Cả hai chiều\\ncó phương sai đáng kể. Phương sai của mỗi chiều là phương sai của thành phần tương ứng được\\nlấy trên toàn bộ dữ liệu. Phương sai tỉ lệ thuận với độ phân tán của dữ liệu.\\nX\\nOriginal data\\nN\\nD = U K ˆU K\\nAn orthogonal matrix\\nK D − K\\nD ×\\nZ\\nY\\nCoordinates in new basis\\nN\\nK\\nD − K\\nU K\\nK\\nD\\n×= Z\\nN\\nK +\\nˆU KD\\n× Y\\nHình 21.2: Ý tưởng chính của PCA: Tìm một hệ trực chuẩn mới sao cho trong hệ này, các\\nthành phần quan trọng nhất nằm trongK thành phần đầu tiên.\\nPrinciple component analysis (PCA) là một phương pháp đi tìm một phép xoay trục toạ độ\\nđể được một hệ trục toạ độ mới sao cho trong hệ mới này, thông tin của dữ liệu chủ yếu tập\\ntrung ở một vài thành phần. Phần còn lại chưa ít thông tin hơn có thể được lược bỏ.\\nPhép xoay trục toạ độ có liên hệ chặt chẽ tới hệ trực chuẩn và ma trận trực giao (xem\\nMục 1.9 và 1.10). Giả sử hệ cơ sở trực chuẩn mới làU (mỗi cột củaU là một vector đơn\\nvị cho một chiều) và chúng ta muốn giữ lạiK toạ độ trong hệ cơ sở mới này. Không mất\\ntính tổng quát, giả sử đó làK thành phần đầu tiên. Quan sát Hình 21.2 với cơ sở mới\\nU = [UK, ˆUK]là một hệ trực chuẩn vớiUK là ma trận con tạo bởiK cột đầu tiên củaU.\\nVới cơ sở mới này, ma trận dữ liệu có thể được viết thành\\nX = UKZ + ˆUKY (21.1)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 267, 'page_label': '256'}, page_content='CHƯƠNG 21. PRINCIPAL COMPONENT ANALYSIS 256\\nTừ đây ta cũng suy ra\\n[Z\\nY\\n]\\n=\\n[UT\\nK\\nˆUT\\nK\\n]\\nX ⇒ Z = UT\\nKX\\nY = ˆUT\\nKX (21.2)\\nMục đích của PCA là đi tìm ma trận trực giaoU sao cho phần lớn thông tin được giữ lại\\nở phần màu xanhUKZ và phần màu đỏˆUKY sẽ được lược bỏ và thay bằng một ma trận\\nkhông phụ thuộc vào từng điểm dữ liệu. Cụ thể, ta sẽ xấp xỉY bởi một ma trận có toàn bộ\\ncác cột là như nhau.Chú ý rằng các cột này có thể phụ thuộc vào dữ liệu huấn luyện nhưng\\nkhông phụ thuộc vào dữ liệu kiểm thử.Gọi mỗi cột đó làb và có thể coi nó là bias, khi đó,\\nta sẽ xấp xỉY ≈b1T, trong đó1T ∈R1×N là một vector hàng có toàn bộ các phần tử bằng\\n1. Giả sử đã tìm đượcU, ta cần tìmb thoả mãn:\\nb = argminb∥Y −b1T∥2\\nF = argminb∥ˆUT\\nKX −b1T∥2\\nF (21.3)\\nGiải phương trình đạo hàm theob của hàm mục tiêu bằng0:\\n(b1T −ˆUT\\nKX)1 = 0 ⇒Nb = ˆUT\\nKX1 ⇒b = ˆUT\\nKx (21.4)\\nở đây ta đã sử dụng1T1 = N và x = 1\\nNX1 là vector trung bình của toàn bộ các cột củaX.\\nVới giá trịb tìm được này, dữ liệu ban đầu sẽ được xấp xỉ bởi\\nX = UKZ + ˆUkY ≈UKZ + ˆUkb1T = UKZ + ˆUK ˆUT\\nK¯x1T ≜˜X (21.5)\\n21.1.2 Hàm mất mát\\nHàm mất mát của PCA có thể được coi như sai số của phép xấp xỉ, và được định nghĩa là\\n1\\nN∥X −˜X∥2\\nF = 1\\nN∥ˆUKY −ˆUK ˆUT\\nKx1T∥2\\nF = 1\\nN∥ˆUK ˆUT\\nKX −ˆUK ˆUT\\nK¯x1T∥2\\nF\\n= 1\\nN∥ˆUkˆUT\\nk(X −x1T)∥2\\nF ≜J (21.6)\\nChú ý rằng, nếu các cột của một ma trậnV bất kỳ tạo thành một hệ trực chuẩn thì với một\\nma trậnW bất kỳ, ta luôn có\\n∥VW∥2\\nF = trace(WTVTVW) = trace(WTW) = ∥W∥2\\nF (21.7)\\nĐặt ˆX = X −x1T. Ma trận này có được bằng cách trừ mỗi cột (mỗi điểm dữ liệu) củaX\\nđi trung bình các cột của nó. Ta gọi ma trận nàyˆX là zero-corrected datahoặc dữ liệu đã\\nđược chuẩn hoá. Có thể nhận thấyˆxn = xn −¯xj, ∀n= 1,2,...,N .\\nVì vậy hàm mất mát trong (21.6) có thể được viết lại thành:\\nJ = 1\\nN∥ˆUT\\nK ˆX∥2\\nF = 1\\nN∥ˆXT ˆUK∥2\\nF = 1\\nN\\nD∑\\ni=K+1\\n∥ˆXTui∥2\\n2 (21.8)\\n= 1\\nN\\nD∑\\ni=K+1\\nuT\\ni ˆXˆXTui =\\nD∑\\ni=K+1\\nuT\\ni Sui (21.9)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 268, 'page_label': '257'}, page_content='257 CHƯƠNG 21. PRINCIPAL COMPONENT ANALYSIS\\nvới S = 1\\nN\\nˆXˆXT là ma trận hiệp phương sai của dữ liệu và luôn là một ma trận nửa xác định\\ndương (xem Mục 3.1.7).\\nCông việc còn lại là tìm cácui để mất mát là nhỏ nhất. Trước hết, chúng ta có một nhận\\nxét thú vị. Với ma trậnU trực giao bất kỳ, thayK = 0 vào (21.9) ta có\\nL=\\nD∑\\ni=1\\nuT\\ni Sui = 1\\nN∥ˆXTU∥2\\nF = 1\\nNtrace( ˆXTUUT ˆX) (21.10)\\n= 1\\nNtrace( ˆXT ˆX) = 1\\nNtrace( ˆXˆXT) = trace(S) =\\nD∑\\ni=1\\nλi (21.11)\\nVớiλ1 ≥λ2 ≥···≥ λD ≥0 là các trị riêng của ma trận nửa xác định dươngS. Chú ý rằng\\ncác trị riêng này là thực và không âm1.\\nNhư vậyL không phụ thuộc vào cách chọn ma trận trực giaoU và bằng tổng các\\nphần tử trên đường chéo củaS. Nói cách khác,Lchính là tổng của các phương sai theo từng\\nthành phần của dữ liệu ban đầu2.\\nVì vậy, việc tối thiểu hàm mất mátJ được cho bởi (21.9) tương đương với việc tối đa\\nF = L−J =\\nK∑\\ni=1\\nuiSuT\\ni (21.12)\\n21.1.3 Tối ưu hàm mất mát\\nNghiệm của bài toán tối ưu hàm mất mát cho PCA được tìm dựa trên khẳng định sau đây.\\nNếu S là một ma trận nửa xác định dương, bài toán tối ưu\\nmax\\nUK\\nK∑\\ni=1\\nuT\\ni Sui (21.13)\\nthoả mãn:UT\\nKUK = I (21.14)\\ncó nghiệmu1,..., uK là các vector riêng ứng vớiK trị riêng (kể cả lặp) lớn nhất của\\nS. Khi đó, giá trị của hàm mục tiêu là∑K\\ni=1 λi, với λ1 ≥λ2 ≥···≥ λD là các trị\\nriêng củaS.\\nKhẳng định này có thể được chứng minh bằng quy nạp3.\\n1 Tổng các trị riêng của một ma trận vuông bất kỳ luôn bằng trace của ma trận đó.\\n2 Mỗi thành phần trên đường chéo chính của ma trận hiệp phương sai chính là phương sai của thành phần dữ liệu\\ntương ứng.\\n3 Xin được bỏ qua phần chứng minh. Bạn đọc có thể xem Excercise 12.1 trong tài liệu tham khảo [Bis06] với lời giải\\ntại https://goo.gl/sM32pB .\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 269, 'page_label': '258'}, page_content='CHƯƠNG 21. PRINCIPAL COMPONENT ANALYSIS 258\\nˆσ1\\nˆσ2\\nu1\\nu2\\ne1\\ne2\\nσ1\\nσ2\\nHình 21.3:PCA có thể được coi là phương\\npháp đi tìm một hệ cơ sở trực chuẩn đóng\\nvai trò một phép xoay, sao cho trong hệ cơ\\nsở mới này, phương sai theo một số chiều\\nnào đó là rất nhỏ, và ta có thể bỏ qua.\\nTrị riêng lớn nhấtλ1 của ma trận hiệp phương saiS còn được gọi làthành phần chính thứ\\nnhất (the first principal component), trị riêng thứ haiλ2 còn được gọi làthành phần chính\\nthứ hai, v.v.. Tên gọiphân tích thành phần chính(principal component analysis) bắt nguồn\\ntừ đây. Ta chỉ giữ lạiK thành phần chính đầu tiên khi giảm chiều dữ liệu dùng PCA.\\nHình 21.3 minh hoạ các thành phần chính với dữ liệu hai chiều. Trong không gian ban đầu\\nvới các vector cơ sở màu đene1,e2, phương sai theo mỗi chiều dữ liệu (độ rộng của các hình\\nchuông màu lục) đều lớn. Trong không gian mới với các vector cơ sở màu đỏu1,u2, phương\\nsai theo chiều thứ haiˆσ2 rất nhỏ so vớiˆσ1. Điều này nghĩa là khi chiếu dữ liệu lênu2 ta\\nđược các điểm rất gần nhau và gần với giá trị trung bình theo chiều đó. Trong trường hợp\\nnày, giá trị trung bình theo mọi chiều bằng 0 nên ta có thể thay thế toạ độ theo chiềuu2\\nbằng 0. Rõ ràng là nếu dữ liệu có phương sai càng nhỏ theo một chiều nào đó thì khi xấp\\nxỉ chiều đó bằng một hằng số, sai số xấp xỉ càng nhỏ. PCA thực chất là đi tìm một phép\\nxoay tương ứng với một ma trận trực giao sao cho trong hệ toạ độ mới, tồn tại các chiều\\ncó phương sai nhỏ mà ta có thể bỏ qua; ta chỉ cần giữ lại các chiều/thành phần khác quan\\ntrọng hơn. Như đã khẳng định ở trên, tổng phương sai theo mọi chiều trong hệ cơ sở nào\\ncũng là như nhau và bằng tổng các trị riêng của ma trận hiệp phương sai. Vì vậy, PCA còn\\nđược coi là phương pháp giảm số chiều dữ liệu sao tổng phương sai còn lại là lớn nhất.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 270, 'page_label': '259'}, page_content='259 CHƯƠNG 21. PRINCIPAL COMPONENT ANALYSIS\\n21.2 Các bước thực hiện PCA\\nTừ các suy luận phía trên, ta có thể tóm tắt lại các bước trong PCA như sau:\\n1. Tính vector kỳ vọng của toàn bộ dữ liệu:¯x = 1\\nN\\n∑N\\nn=1 xn.\\n2. Trừ mỗi điểm dữ liệu đi vector kỳ vọng của toàn bộ dữ liệu để được dữ liệu chuẩn hoá:\\nˆxn = xn −¯x (21.15)\\n3. Đặt ˆX = [ˆx1,ˆx2,..., ˆxD] là ma trận dữ liệu chuẩn hoá, tính ma trận hiệp phương sai\\nS = 1\\nN\\nˆXˆXT (21.16)\\n4. Tính các trị riêng và vector riêng tương ứng cóℓ2 norm bằng 1 của ma trận này, sắp xếp\\nchúng theo thứ tự giảm dần của trị riêng.\\n5. Chọn K vector riêng ứng vớiK trị riêng lớn nhất để xây dựng ma trậnUK có các cột\\ntạo thành một hệ trực giao.K vectors này, còn được gọi là các thành phần chính, tạo\\nthành một không gian congần với phân bố của dữ liệu ban đầu đã chuẩn hoá.\\n6. Chiếu dữ liệu ban đầu đã chuẩn hoáˆX xuống không gian con tìm được.\\n7. Dữ liệu mới chính là toạ độ của các điểm dữ liệu trên không gian mới:Z = UT\\nK ˆX.\\nDữ liệu ban đầu có thể tính được xấp xỉ theo dữ liệu mới bởix ≈UKZ + ¯x.\\nMột điểm dữ liệu mớiv ∈RD (có thể không nằm trong tập huấn luyện) sẽ được giảm chiều\\nbằng PCA theo công thứcw = UT\\nK(v −x) ∈RK. Ngược lại, nếu biếtw, ta có thể xấp xỉv\\nbởi UKw + x. Các bước thực hiện PCA được minh hoạ trong Hình 21.4.\\n21.3 Mối quan hệ giữa PCA và SVD\\nGiữa PCA và SVD có mỗi quan hệ đặc biệt với nhau. Để nhận ra điều này, tôi xin được\\nnhắc lại hai điểm đã trình bày sau đây:\\n21.3.1 SVD cho bài toán xấp xỉ low-rank tốt nhất\\nNghiệm A của bài toán xấp xỉ một ma trận bởi một ma trận có rank không vượt quák:\\nmin\\nA\\n∥X −A∥F\\nthoả mãn: rank(A) = K\\n(21.17)\\nchính là truncated SVD củaA.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 271, 'page_label': '260'}, page_content='CHƯƠNG 21. PRINCIPAL COMPONENT ANALYSIS 260\\nPCA procedure\\nX\\n1. Find mean vector\\ne1\\ne2\\nˆX\\n2. Subtract mean 3. Compute covariance\\nmatrix:\\nS = 1\\nN\\nˆX ˆX T\\n4. Computer eigenvalues\\nand eigenvectors of S :\\n(λ1 ,u 1 ),..., (λD ,u D )\\nRemember the or-\\nthonormality of u i .\\nu1\\ne1\\ne2\\n5. Pick K eigenvectors w/\\nhighest eigenvalues\\n6. Project data to selected\\neigenvectors.\\ne1\\ne2\\nu1\\n7. Obtain projected points\\nin low dimension.\\nu1\\ne1\\ne2\\nZ\\nHình 21.4: Các bước thực hiện PCA.\\nCụ thể, nếu SVD củaX ∈RD×N là\\nX = UΣVT (21.18)\\nvới U ∈RD×D và V ∈RN×N là các ma trận trực giao, vàΣ ∈RD×N là ma trận đường chéo\\n(không nhất thiết vuông) với các phần tử trên đường chéo không âm giảm dần. Nghiệm của\\nbài toán (21.17) chính là:\\nA = UKΣKVT\\nK (21.19)\\nvới U ∈RD×K và V ∈RN×K là các ma trận tạo bởi K cột đầu tiên của U và V, và\\nΣK ∈RK×K là ma trận đường chéo con ứng vớiK hàng đầu tiên vàK cột đầu tiên củaΣ.\\n21.3.2 Ý tưởng của PCA\\nTrong PCA, như đã chứng minh ở (21.5), PCA là bài toán đi tìm ma trận trực giaoU và\\nma trận mô tả dữ liệu ở không gian thấp chiềuZ sao cho việc xấp xỉ sau đây là tốt nhất:\\nX ≈˜X = UKZ + ˆUK ˆUT\\nK¯x1T (21.20)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 272, 'page_label': '261'}, page_content='261 CHƯƠNG 21. PRINCIPAL COMPONENT ANALYSIS\\nvới UK, ˆUK lần lượt là các ma trận được tạo bởiK cột đầu tiên vàD−K cột cuối cùng\\ncủa ma trận trực giaoU, và¯x là vector kỳ vọng của dữ liệu.\\nGiả sử rằng vector kỳ vọng¯x = 0. Khi đó, (21.20) tương đương với\\nX ≈˜X = UKZ (21.21)\\nBài toán tối ưu của PCA sẽ trở thành:\\nUK,Z = arg min\\nUK,Z\\n∥X −UKZ∥F\\nthoả mãn: UT\\nKUK = IK\\n(21.22)\\nvới IK ∈RK×K là ma trận đơn vị trong không gianK chiều, và điều kiện ràng buộc là để\\nđảm bảo các cột củaUK tạo thành một hệ trực chuẩn.\\n21.3.3 Quan hệ giữa PCA và SVD\\nBạn có nhận ra điểm tương đồng giữa hai bài toán tối ưu (21.17) và (21.22) với nghiệm của\\nbài toán đầu tiên được cho trong (21.19)? Bạn có thể nhận ra ngay nghiệm của bài toán\\n(21.22) chính là\\nUK trong (21.22) = UKtrong (21.19)\\nZ trong (21.22) = ΣKVT\\nKtrong (21.19)\\nVậy, nếu các điểm dữ liệu được biễu diễn bởi các cột của một ma trận, và trung bình cộng\\ncủa mỗi hàng của ma trận đó bằng 0 (để cho vector trung bình bằng 0), thì nghiệm của bài\\ntoán PCA được rút ra trực tiếp từ truncated SVD của ma trận đó. Nói cách khác, việc đi\\ntìm nghiệm cho PCA chính là việc giải một bài toán matrix factorization thông qua SVD.\\n21.4 Làm thế nào để chọn số chiều của dữ liệu mới\\nMột câu hỏi được đặt ra là, làm thế nào để chọn ra giá trịK – chiều của dữ liệu mới – với\\ntừng dữ liệu cụ thể?\\nCó một cách xác địnhK là dựa trên việclượng thông tin muốn giữ lại. Như đã trình bày,\\nPCA còn được gọi là phương pháp tối đatổng phương sai được giữ lại. Vậy ta có thể coi\\ntổng các phương sai được giữ lại là lượng thông tin được giữ lại.\\nNhắc lại rằng trong mọi hệ trục toạ độ, tổng phương sai của dữ liệu là như nhau và bằng\\ntổng các trị riêng của ma trận hiệp phương sai∑D\\ni=1 λi. Thêm nữa, PCA giúp giữ lại lượng\\nthông tin (tổng các phương sai) là∑K\\ni=1 λi. Vậy ta có thể coi biểu thức:\\nrK =\\n∑K\\ni=1 λi\\n∑D\\nj=1 λj\\n(21.23)\\nlà tỉ lệ thông tin được giữ lại khi số chiều dữ liệu mới sau PCA làK. Như vậy, giả sử ta'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 272, 'page_label': '261'}, page_content='thông tin (tổng các phương sai) là∑K\\ni=1 λi. Vậy ta có thể coi biểu thức:\\nrK =\\n∑K\\ni=1 λi\\n∑D\\nj=1 λj\\n(21.23)\\nlà tỉ lệ thông tin được giữ lại khi số chiều dữ liệu mới sau PCA làK. Như vậy, giả sử ta\\nmuốn giữ lại 99% dữ liệu, ta chỉ cần chọnK là số tự nhiên nhỏ nhất sao chorK ≥0.99.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 273, 'page_label': '262'}, page_content='CHƯƠNG 21. PRINCIPAL COMPONENT ANALYSIS 262\\nKhi dữ liệu phân bố quanh một không gian con, các giá trị phương sai lớn nhất ứng với các\\nλi đầu tiên lớn hơn nhiều so với các phương sai còn lại. Khi đó, ta có thể chọn đượcK khá\\nnhỏ để đạt đượcrK ≥0.99.\\n21.5 Lưu ý về tính PCA trong các bài toán thực tế\\nCó hai trường hợp trong thực tế mà chúng ta cần lưu ý về PCA. Trường hợp thứ nhất là\\nlượng dữ liệu có được nhỏ hơn rất nhiều so với số chiều dữ liệu. Trường hợp thứ hai là khi\\nlượng dữ liệu trong tập huấn luyện là rất lớn, có thể lên tới cả triệu. Việc tính toán ma trận\\nhiệp phương sai và trị riêng đôi khi trở nên bất khả thi. Có những hướng giải quyết hiệu\\nquả cho các trường hợp này.\\nTrong mục này, ta sẽ coi như dữ liệu đã được chuẩn hoá, tức đã được trừ đi vector kỳ vọng.\\nKhi đó, ma trận hiệp phương sai sẽ làS = 1\\nNXXT.\\n21.5.1 Số chiều dữ liệu nhiều hơn số điểm dữ liệu\\nĐó là trường hợpD > N, tức ma trận dữ liệuX là mộtma trận cao. Khi đó, số trị riêng\\nkhác không của ma trận hiệp phương saiS sẽ không vượt quá rank của nó, tức không vượt\\nquá N. Vậy ta cần chọnK ≤N vì không thể chọn ra được nhiều hơnN trị riêng khác 0 của\\nmột ma trận có rank bằngN.\\nViệc tính toán các trị riêng và vector riêng cũng có thể được thực hiện một cách hiệu quả\\ndựa trên các tính chất sau đây:\\nTính chất 1:Trị riêng củaA cũng là trị riêng củakA với k ̸= 0 bất kỳ. Điều này có thể\\nđược suy ra trực tiếp từ định nghĩa của trị riêng và vector riêng.\\nTính chất 2:Trị riêng củaAB cũng là trị riêng củaBA với A ∈Rd1×d2 ,B ∈Rd2×d1 là các\\nma trận bất kỳ vàd1,d2 là các số tự nhiên khác không bất kỳ.\\nNhư vậy, thay vì tìm trị riêng của ma trận hiệp phương saiS ∈RD×D, ta đi tìm trị riêng\\ncủa ma trậnT = XTX ∈RN×N có số chiều nhỏ hơn (vìN <D).\\nTính chất 3:Giả sử(λ,u) là một cặp trị riêng - vector riêng củaT, thế thì(λ,Xu) là một\\ncặp trị riêng - vector riêng củaS. Thật vậy,\\nXTXu = Tu = λu ⇒(XXT)(Xu) = λ(Xu) (21.24)\\nDấu bằng thứ nhất xảy ra theo định nghĩa của trị riêng và vector riêng. Từ (21.24) ta suy\\nra Tính chất 3.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 273, 'page_label': '262'}, page_content='cặp trị riêng - vector riêng củaS. Thật vậy,\\nXTXu = Tu = λu ⇒(XXT)(Xu) = λ(Xu) (21.24)\\nDấu bằng thứ nhất xảy ra theo định nghĩa của trị riêng và vector riêng. Từ (21.24) ta suy\\nra Tính chất 3.\\nNhư vậy, ta có thể hoàn toàn tính được trị riêng và vector riêng của ma trận hiệp phương sai\\nS dựa trên một ma trậnT có kích thước nhỏ hơn. Việc này trong nhiều trường hợp khiến\\nthời gian tính toán giảm đi đáng kể.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 274, 'page_label': '263'}, page_content='263 CHƯƠNG 21. PRINCIPAL COMPONENT ANALYSIS\\n21.5.2 Với các bài toán large-scale\\nTrong rất nhiều bài toán, cảD và N đều là các số rất lớn, đồng nghĩa với việc ta phải\\ntìm trị riêng cho một ma trận rất lớn. Ví dụ, có một triệu bức ảnh 1000×1000 pixel,\\nnhư vậyD = N = 106 là một số rất lớn, việc trực tiếp tính toán trị riêng và vector riêng\\ncho ma trận hiệp phương sai là không khả thi. Tuy nhiên, có một phương pháp cho phép\\ntính xấp xỉ các giá trị này một cách nhanh hơn. Phương pháp đó có tên làpower method\\n(https://goo.gl/eBRPxH ).\\n21.6 Một vài ứng dụng của PCA\\nỨng dụng đầu tiên có thể thấy của PCA chính là việc giảm chiều dữ liệu, giúp việc lưu trữ\\nvà tính toán được thuận tiện hơn. Thực tế cho thấy, nhiều khi làm việc trên dữ liệu đã được\\ngiảm chiều mang lại kết quả tốt hơn cho với dữ liệu gốc. Thứ nhất, có thể phần dữ liệu mang\\nthông tin nhỏ bị lược đi chính là phần gây nhiễu, những thông tin quan trọng hơn đã được\\ngiữ lại. Thứ hai, số điểm dữ liệu nhiều khi ít hơn số chiều dữ liệu. Khi có quá ít dữ liệu và\\nsố chiều dữ liệu quá lớn, overfitting rất dễ xảy ra. Việc giảm chiều dữ liệu phần nào giúp\\nkhắc phục hiện tượng này.\\nDưới đây là hai ví dụ về ứng dụng của PCA trong bài toánface classificationvà anomaly\\ndetection (dò điểm bất thường).\\n21.6.1 Eigenface\\nEigenface từng là một trong các kỹ thuật phổ biến nhất trong bài toán nhận dạng khuôn\\nmặt. Giả sử rằng vị trí các khuôn mặt đã được xác định trong ảnh và có kích thước như\\nnhau, bài toán đặt ra là xác định đó là khuôn mặt của ai. Ý tưởng của eigenface là đi tìm\\nmột không gian có số chiều nhỏ hơn để mô tả mỗi khuôn mặt, từ đó sử dụng vector trong\\nkhông gian thấp này như là vector đặc trưng đưa vào các bộ phân lớp. Điều đáng nói là\\nmột bức ảnh khuôn mặt có kích thước khoảng 200×200 sẽ có số chiều là 40k – là một số\\nrất lớn, trong khi đó, vector đặc trưng thường chỉ có số chiều bằng vài trăm hoặc vài nghìn.\\nEigenface thực ra chính là PCA. Các eigenface chính là các vector riêng (eigenvector) ứng'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 274, 'page_label': '263'}, page_content='rất lớn, trong khi đó, vector đặc trưng thường chỉ có số chiều bằng vài trăm hoặc vài nghìn.\\nEigenface thực ra chính là PCA. Các eigenface chính là các vector riêng (eigenvector) ứng\\nvới các trị riêng lớn nhất của ma trận hiệp phương sai.\\nTrong phần này, chúng ta cùng làm một thí nghiệm nhỏ trên cơ sở dữ liệu Yale face database\\n(https://goo.gl/LNg8LS ). Các bức ảnh trong thí nghiệm này đã được căn chỉnh cho cùng\\nvới kích thước và khuôn mặt nằm trọn vẹn trong một hình chữ nhật có kích thước116 ×98\\npixel. Có tất cả 15 người khác nhau, mỗi người có 11 bức ảnh được chụp ở các điều kiện\\nánh sáng và cảm xúc khác nhau, bao gồm’centerlight’, ’glasses’, ’happy’, ’leftlight’, ’\\nnoglasses’, ’normal’, ’rightlight’,’sad’, ’sleepy’, ’surprised’, và’wink’. Hình 21.5 minh\\nhoạ các bức ảnh của người có id là 10.\\nTa có thể thấy rằng số chiều dữ liệu là116 ×98 = 11368 là một số khá lớn. Tuy nhiên, vì\\nchỉ có tổng cộng15 ×11 = 165 bức ảnh nên ta có thể nén các bức ảnh này về dữ liệu mới\\ncó chiều nhỏ hơn 165. Trong ví dụ này, chúng ta chọnK = 100.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 275, 'page_label': '264'}, page_content='CHƯƠNG 21. PRINCIPAL COMPONENT ANALYSIS 264\\nHình 21.5: Ví dụ về ảnh của một người trong Yale Face Database.\\nDưới đây là đoạn code thực hiện PCA cho toàn bộ dữ liệu. Ở đây chúng ta trực tiếp sử dụng\\nPCA trongsklearn.\\nimport numpy as np\\nfrom scipy import misc # for loading image\\nnp.random.seed(1)\\n# filename structure\\npath = ’unpadded/’ # path to the database\\nids = range(1, 16) # 15 persons\\nstates = [’centerlight’, ’glasses’, ’happy’, ’leftlight’,\\n’noglasses’, ’normal’, ’rightlight’,’sad’,\\n’sleepy’, ’surprised’, ’wink’ ]\\nprefix = ’subject’\\nsurfix = ’.pgm’\\n# data dimension\\nh, w, K = 116, 98, 100 # hight, weight, new dim\\nD = h * w\\nN = len(states)*15\\n# collect all data\\nX = np.zeros((D, N))\\ncnt = 0\\nfor person_id in range(1, 16):\\nfor state in states:\\nfn = path + prefix + str(person_id).zfill(2) + ’.’ + state + surfix\\nX[:, cnt] = misc.imread(fn).reshape(D)\\ncnt += 1\\n# Doing PCA, note that each row is a datapoint\\nfrom sklearn.decomposition import PCA\\npca = PCA(n_components=K) # K = 100\\npca.fit(X.T)\\n# projection matrix\\nU = pca.components_.T\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 276, 'page_label': '265'}, page_content='265 CHƯƠNG 21. PRINCIPAL COMPONENT ANALYSIS\\nHình 21.6: Các eigenfaces tìm được bằng PCA.\\nTrong dòngpca = PCA(n_components=K), nếun_components là một số thực trong khoảng(0,1),\\nPCA sẽ thực hiện việc tìmK dựa trên biểu thức (21.23).\\nHình 21.6 biểu diễn 18 vector riêng đầu tiên (18 cột đầu tiên củaUk) tìm được bằng PCA.\\nCác vector đã đượcreshape về cùng kích thước như các bức ảnh gốc. Có một điều dễ nhận\\nra là các ảnh minh hoạ các vector thu được ít nhiều mang thông tin của mặt người. Thực\\ntế, một khuôn mặt gốc sẽ được xấp xỉ như tổng có trọng số của cáckhuôn mặt này. Vì các\\nvector riêng này đóng vai trò như cơ sở của không gian mới với ít chiều hơn, chúng còn được\\ngọi làkhuôn mặt chính, tứceigenface4 . Để xem mức độ hiệu quả của Eigenface, chúng ta\\nthử minh hoạ các bức ảnh gốc và các bức ảnh được xấp xỉ bằng PCA, kết quả được cho như\\ntrên Hình 21.7. Các khuôn mặt nhận được vẫn mang khá đầy đủ thông tin của các khuôn\\nmặt gốc. Điều đang nói hơn, các khuôn mặt trong hàng dưới được suy ra từ một vector 100\\nchiều, so với 11368 chiều như ở hàng trên.\\nSource code cho chương này có thể được tìm thấy tạihttps://goo.gl/zQ3DSZ .\\n21.6.2 Abnormal Detection\\nNgoài các ứng dụng về nén và phân lớp, PCA còn được sử dụng trong nhiều lĩnh vực khác\\nnhau.Abnormal detection, hayoutlier detection(xác định các hiện tượng không bình thường)\\n4 Từ riêng trong trường hợp này không thực sự truyền tải thông tin. Từchính được dùng vì nó đi kèm với văn cảnh\\ncủa phân tích thành phần chính.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 277, 'page_label': '266'}, page_content='CHƯƠNG 21. PRINCIPAL COMPONENT ANALYSIS 266\\nHình 21.7:Hàng trên: các ảnh gốc. Hàng dưới: các ảnh đượcsuy ratừ eigenfaces. Ảnh ở hàng\\ndưới có nhiều nhiễu nhưng vẫn mang những đặc điểm riêng mà mắt người có thể phân biệt được.\\nu2 u1\\nHình 21.8:PCAchoviệc xácđịnhcác\\nsự kiệnbất thường. Giả sử rằng các sự\\nkiện bình thường chiếm đa số và nằm\\ngần trong một không gian con nào đó.\\nKhi đó, nếu làm PCA trên toàn bộ dữ\\nliệu, không gian con thu được gần với\\nkhông gian con của tập các sự kiện\\nbình thường . Lúc này, các điểm quá\\nxa không gian con này, trong trường\\nhợp này là các điểm màu cam, có thể\\nđược coi là các sự kiệnbất thường.\\nlà một trong số đó [SCSC03,LCD04]. Thêm nữa, giả sử chúng ta không biết nhãn của các\\nsự kiện này, tức ta đang làm việc với một bài toán không giám sát.\\nÝ tưởng cơ bản là các sự kiện bình thường có thể nằm gần một không gian con nào đó, trong\\nkhi các sự kiện bất thường thường nằm xa không gian con đó. Hơn nữa, vì là bất thường\\nnên số lượng các sự kiện thuộc loại này là rất nhỏ so với các sự kiện bình thường. Như vậy,\\nchúng ta có thể làm PCA trên toàn bộ dữ liệu để tìm ra các thành phần chính của dữ liệu,\\ntừ đó suy ra không gian con mà các điểm bình thường nằm gần. Việc xác định một điểm là\\nbình thường hay bất thường được xác định bằng cách đo khoảng cách từ điểm đó tới không\\ngian con tìm được. Hình 21.8 minh hoạ cho việc xác định các sự kiện bất thường bằng PCA.\\n21.7 Thảo luận\\n• PCA là một phương pháp giảm chiều dữ liệu dựa trên việc tối đa lượng thông tin được\\ngiữ lại. Lượng thông tin được giữ lại được đo bằng tổng các phương sai trên mỗi thành\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 278, 'page_label': '267'}, page_content='267 CHƯƠNG 21. PRINCIPAL COMPONENT ANALYSIS\\nphần của dữ liệu. Lượng dữ liệu sẽ được giữ lại nhiều nhất khi các chiều dữ liệu còn lại\\ntương ứng với các vector riêng của trị riêng lớn nhất của ma trận hiệp phương sai.\\n• Với các bài toán large-scale, đôi khi việc tính toán trên toàn bộ dữ liệu là không khả thi\\nvì còn có vấn đề về bộ nhớ. Giải pháp là thực hiện PCA lần đầu trên một tập con dữ liệu\\nvừa với bộ nhớ, sau đó lấy một tập con khác đểtừ từ (incrementally) cập nhật nghiệm\\ncủa PCA tới khi nào hội tụ. Ý tưởng này khá giống với mini-batch Gradient Descent, và\\nđược gọi là Incremental PCA [ZYK06].\\n• Ngoài ra, còn rất nhiều hướng mở rộng của PCA, bạn đọc có thể tìm kiếm theo từ khoá:\\nSparse PCA [dGJL05], Kernel PCA [MSS+99], Robust PCA [CLMW11].\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 279, 'page_label': '268'}, page_content='Chương 22\\nLinear discriminant analysis\\n22.1 Giới thiệu\\nTrong chương trước, chúng ta đã làm quen với một thuật toán giảm chiều dữ liệu phổ\\nbiến nhất – principle component analysis (PCA). Như đã đề cập, PCA là một mô hình\\nunsupervised learning, tức là nó chỉ sử dụng các vector mô tả dữ liệu mà không cần tới\\nnhãn, nếu có, của dữ liệu. Tuy nhiên, trong bài toán phân lớp, việc khai thác mối liên quan\\ngiữa dữ liệu và nhãn sẽ mang lại kết quả phân loại tốt hơn.\\nNhắc lại rằng PCA là phương pháp giảm chiều dữ liệu sao cho lượng thông tin về dữ liệu,\\nthể hiện ở tổng phương sai của các thành phần được giữ lại, được giữ lại là nhiều nhất. Tuy\\nnhiên, trong nhiều bài toán, ta không cần giữ lại lượng thông tin lớn nhất mà chỉ cần giữ\\nlại thông tin cần thiết cho riêng bài toán đó. Xét ví dụ về bài toán phân lớp nhị phân được\\nmô tả trong Hình 22.1. Ở đây, ta giả sử rằng dữ liệu được chiếu lên một đường thẳng và\\nmỗi điểm được thay bởi hình chiếu của nó lên đường thẳng kia. Như vậy, số chiều dữ liệu\\nđã được giảm từ hai về một. Câu hỏi đặt ra là, đường thẳng cần có phương như thế nào để\\nhình chiếu của dữ liệu trên đường thẳng nàygiúp ích cho việc phân lớp nhất? Việc phân lớp\\nđơn giản nhất có thể được hiểu là việc tìm ra một ngưỡng giúp phân tách hai lớp một cách\\nđơn giản và đạt kết quả tốt nhất. Xét hai đường thằngd1 và d2. Trong đó phương củad1\\ngần với phương của thành phần chính nếu thực hiện PCA, phương củad2 gần với phương\\ncủa thành phần phụ tìm được bằng PCA. Nếu ta làm giảm chiều dữ liệu bằng PCA, ta sẽ\\nthu được dữ liệu gần với các điểm được chiếu lênd1. Lúc này việc phân tách hai lớp trở nên\\nphức tạp vì các điểm dữ liệu mới của hai lớp chồng lấn lên nhau. Ngược lại, nếu ta chiếu\\ndữ liệu lên đường thẳng gần với thành phần phụ tìm được bởi PCA, tứcd2, các điểm hình\\nchiếu nằm hoàn toàn về hai phía khác nhau của điểm màu lục trên đường thẳng này. Với\\nbài toán phân lớp, việc chiếu dữ liệu lênd2 vì vậy sẽ mang lại hiệu quả hơn. Việc phân loại'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 279, 'page_label': '268'}, page_content='chiếu nằm hoàn toàn về hai phía khác nhau của điểm màu lục trên đường thẳng này. Với\\nbài toán phân lớp, việc chiếu dữ liệu lênd2 vì vậy sẽ mang lại hiệu quả hơn. Việc phân loại\\nmột điểm dữ liệu mới sẽ được xác định nhanh chóng bằng cách so sánh hình chiếu của nó\\nlên d2 với điểm màu xanh lục này.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 280, 'page_label': '269'}, page_content='269 CHƯƠNG 22. LINEAR DISCRIMINANT ANALYSIS\\nd 2\\nd 1\\nHình 22.1: Chiếu dữ liệu lên các đường thẳng khác nhau. Có hai lớp dữ liệu minh hoạ bởi các\\nđiểm màu xanh và đỏ trong không gian hai chiều. Số chiều được giảm về một bằng cách chiếu\\ndữ liệu lên các đường thẳng khác nhaud1 và d2. Trong hai cách chiếu này, phương củad1 gần\\ngiống với phương của thành phần chính thứ nhất của dữ liệu, phương củad2 gần với thành phần\\nphụ của dữ liệu nếu dùng PCA. Khi chiếu dữ liệu lênd1, nhiều điểm màu đỏ và xanh bị chồng\\nlấn lên nhau, khiến cho việc phân loại dữ liệu là không khả thi trên đường thẳng này. Ngược lại,\\nkhi được chiếu lênd2, dữ liệu của hai lớp được chia thành các cụm tương ứng tách biệt nhau,\\nkhiến cho việc phân lớp trở nên đơn giản hơn và hiệu quả hơn. Các đường cong hình chuông thể\\nhiện xấp xỉ phân bố xác suất của dữ liệu hình chiếu trong mỗi lớp.\\nQua ví dụ trên ta thấy rằng,không phải trong mọi trường hợp việc giữ lại thông tin\\nnhiều nhất sẽ luôn mang lại kết quả tốt nhất.Chú ý rằng kết quả của phân tích trên\\nđây không có nghĩa là thành phần phụ mang lại hiệu quả tốt hơn thành phần chính. Việc\\nchiếu dữ liệu lên đường thẳng nào giúp ích cho các bài toán phân lớp cần nhiều phân tích cụ\\nthể hơn nữa. Ngoài ra, hai đường thằngd1 và d2 trên đây không vuông góc với nhau, chúng\\nđược chọn gần với các thành phần chính và phụ của dữ liệu phục vụ cho mục đích minh hoạ.\\nLinear discriminant analysis (LDA) được ra đời nhằm tìm ra phương chiếu dữ liệu hiệu quả\\ncho bài toán phân lớp. LDA có thể được coi là một phương pháp giảm chiều dữ liệu, cũng\\ncó thể được coi là một phương pháp phân lớp, và cũng có thể được áp dụng đồng thời cho\\ncả hai, tức giảm chiều dữ liệu sao cho việc phân lớp hiệu quả nhất. Số chiều của dữ liệu mới\\nlà nhỏ hơn hoặc bằngC−1 trong đóC là số lượng lớp dữ liệu. Từdiscriminant được hiểu\\nlà những thông tin đặc trưng cho mỗi lớp, khiến nó không bị lẫn với các classes khác. Từ\\nlinear được dùng vì cách giảm chiều dữ liệu được thực hiện dựa trên một ma trận chiếu –'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 280, 'page_label': '269'}, page_content='là những thông tin đặc trưng cho mỗi lớp, khiến nó không bị lẫn với các classes khác. Từ\\nlinear được dùng vì cách giảm chiều dữ liệu được thực hiện dựa trên một ma trận chiếu –\\nlà một phép biến đổi tuyến tính.\\nTrong Mục 22.2 dưới đây, chúng ta sẽ thảo luận về LDA cho bài toán phân lớp nhị phân.\\nMục 22.3 sẽ tổng quát LDA lên cho trường hợp với nhiều lớp dữ liệu. Mục 22.4 sẽ có các ví\\ndụ và code Python cho LDA.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 281, 'page_label': '270'}, page_content='CHƯƠNG 22. LINEAR DISCRIMINANT ANALYSIS 270\\nm1 m2s1 s2s2\\na) Large(m1 − m2)2, larges2\\n1 + s2\\n2\\nm1 m2\\ns1 s2\\nb) Small (m1 − m2)2, small s2\\n1 + s2\\n2\\nm1 m2\\ns1 s2\\nc) Large(m1 − m2)2, small s2\\n1 + s2\\n2\\nHình 22.2:Khoảng cách giữa các kỳ vọng và tổng các phương sai ảnh hưởng tới độdiscriminant\\ncủa dữ liệu. (a) Khoảng cách giữa hai kỳ vọng là lớn nhưng phương sai trong mỗi class cũng lớn,\\nkhiến cho hai phân phối chồng lấn lên nhau (phần màu xám). (b) Phương sai cho mỗi class là\\nrất nhỏ nhưng hai kỳ vọng quá gần nhau, khiến khó phân biệt hai class. (c) Khi phương sai đủ\\nnhỏ và khoảng cách giữa hai kỳ vọng đủ lớn, ta thấy rằng dữ liệudiscriminative hơn.\\n22.2 LDA cho bài toán phân lớp nhị phân\\n22.2.1 Ý tưởng cơ bản\\nQuay lại với Hình 22.1, giả sử rằng dữ liệu của mỗi lớp khi được chiếu xuống một đường\\nthẳng tuân theo phân phối chuẩn, có hàm mật độ xác suất là một đường hình chuông. Độ\\nrộng của mỗi đường hình chuông này thể hiệnđộ lệch chuẩn(standard deviation1, ký hiệu\\nlà s) của dữ liệu. Dữ liệu càng tập trung thì độ lệch chuẩn càng nhỏ, càng phân tán thì độ\\nlệch chuẩn càng cao. Khi được chiếu lênd1, dữ liệu của hai lớp bị phân tán quá nhiều, khiến\\ncho chúng bị trộn lẫn vào nhau. Khi được chiếu lênd2, mỗi lớp đều có độ lệch chuẩn nhỏ,\\nkhiến cho dữ liệu trong từng lớp tập trung hơn, dẫn đến kết quả tốt hơn.\\nTuy nhiên, việc độ lệch chuẩn nhỏ trong mỗi lớp chưa đủ để đảm bảo độdiscriminant của\\ndữ liệu là tốt hơn. Xét các ví dụ trong Hình 22.2. Hình 22.2a chính là trường hợp trong\\nHình 22.1 khi dữ liệu được chiếu lênd1. Cả hai lớp đều quá phân tán khiến cho lượng chồng\\nlấn (phần diện tích màu xám) là lớn, tức dữ liệu chưa thực sựdiscriminative. Hình 22.2b là\\ntrường hợp khi độ lệch chuẩn của hai lớp đều nhỏ, tức dữ liệu trong mỗi lớp tập trung hơn.\\nTuy nhiên, vấn đề với trường hợp này là khoảng cách giữa hai lớp, được đo bằng khoảng\\ncách giữa hai kỳ vọngm1 và m2, là quá nhỏ, khiến cho phần chồng lấn cũng chiếm môt tỉ lệ'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 281, 'page_label': '270'}, page_content='Tuy nhiên, vấn đề với trường hợp này là khoảng cách giữa hai lớp, được đo bằng khoảng\\ncách giữa hai kỳ vọngm1 và m2, là quá nhỏ, khiến cho phần chồng lấn cũng chiếm môt tỉ lệ\\nlớn, và tất nhiên, cũng không tốt cho việc phân lớp. Hình 22.2c là trường hợp khi cả hai độ\\nlệch chuẩn là nhỏ và khoảng cách giữa hai kỳ vọng là lớn, phần chống lấn nhỏ không đáng\\nkể.\\n1 độ lệch chuẩn là căn bậc hai của phương sai\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 282, 'page_label': '271'}, page_content='271 CHƯƠNG 22. LINEAR DISCRIMINANT ANALYSIS\\nVậy, độ lệch chuẩn và khoảng cách giữa hai kỳ vọng cụ thể đại diện cho các tiêu chí gì?\\n• Độ lệch chuẩn nhỏ thể hiện việc dữ liệu ít phân tán, tức dữ liệu trong mỗi lớp có xu hướng\\ngiống nhau. Hai phương sais2\\n1,s2\\n2 còn được gọi là cácwithin-class variance.\\n• Khoảng cách giữa các kỳ vọng là lớn chứng tỏ rằng hai lớp nằm xa nhau, tức dữ liệu giữa\\ncác lớp là khác nhau nhiều. Bình phương khoảng cách giữa hai kỳ vọng(m1 −m2)2 còn\\nđược gọi làbetween-class variance.\\nHai lớp dữ liệu được gọi làdiscriminative nếu hai lớp đó cách xa nhau (between-class variance\\nlớn) và dữ liệu trong mỗi lớp có xu hướng giống nhau (within-class variance nhỏ). LDA là\\nthuật toán đi tìm một phép chiếu sao cho tỉ lệ giữabetween-class variancevà within-class\\nvariance lớn nhất có thể.\\n22.2.2 Hàm mục tiêu của LDA\\nGiả sử rằng cóN điểm dữ liệux1,x2,..., xN ∈RD trong đóN1 < Nđiểm đầu tiên thuộc\\nlớp thứ nhất,N2 = N−N1 điểm còn lại thuộc lớp thứ hai. Ký hiệuC1 = {n|1 ≤n≤N1}là\\ntập hợp các chỉ số của các điểm thuộc lớp thứ nhất vàC2 = {m|N1 + 1 ≤m≤N}) là tập\\nhợp các chỉ số của các điểm thuộc lớp thứ hai. Phép chiếu dữ liệu xuống một đường thẳng\\ncó thể được mô tả bằng một vector hệ sốw, giá trị tương ứng của mỗi điểm dữ liệu mới\\nđược cho bởi\\nzn = wTxn,1 ≤n≤N (22.1)\\nVector kỳ vọng của mỗi lớp được tính bởi\\nmk = 1\\nNk\\n∑\\nn∈Ck\\nxn, k = 1,2 (22.2)\\n⇒m1 −m2 = 1\\nN1\\n∑\\ni∈C1\\nzi − 1\\nN2\\n∑\\nj∈C2\\nzj = wT(m1 −m2) (22.3)\\nCác within-class varianceđược định nghĩa là\\ns2\\nk =\\n∑\\nn∈Ck\\n(zn −mk)2, k = 1,2 (22.4)\\nChú ý rằng các within-class variance ở đây không được lấy trung bình như phương sai thông\\nthường. Điều này được lý giải là tầm quan trọng của mỗi within-class variance nên tỉ lệ thuận\\nvới số lượng điểm dữ liệu trong lớp đó, tức within-class variance bằng phương sai nhân với\\nsố điểm trong lớp đó.\\nLDA là thuật toán đi tìm giá trị lớn nhất của hàm mục tiêu\\nJ(w) = (m1 −m2)2\\ns2\\n1 + s2\\n2\\n(22.5)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 283, 'page_label': '272'}, page_content='CHƯƠNG 22. LINEAR DISCRIMINANT ANALYSIS 272\\nThông qua việc tối đa hàm mục tiêu này, ta sẽ thu đượcbetween-class variance(m1 −m2)2,\\nlớn vàwithin-class variance, s2\\n1 + s2\\n2 nhỏ.\\nTiếp theo, chúng ta sẽ tìm biểu thức phụ thuộc giữa tử số và mẫu số trong vế phải của (22.5)\\nvào w. Với tử số,\\n(m1 −m2)2 = (wT(m1 −m2))2 = wT (m1 −m2)(m1 −m2)T\\n\\ued19 \\ued18\\ued17 \\ued1a\\nSB\\nw = wTSBw (22.6)\\nSB còn được gọi là ma trậnbetween-class covariance. Có thể nhận thấy đây là một ma\\ntrận đối xứng nửa xác định dương. Với mẫu số,\\ns2\\n1 + s2\\n2 =\\n2∑\\nk=1\\n∑\\nn∈Ck\\n(\\nwT(xn −mk)\\n)2\\n= wT\\n2∑\\nk=1\\n∑\\nn∈Ck\\n(xn −mk)(xn −mk)T\\n\\ued19 \\ued18\\ued17 \\ued1a\\nSW\\nw = wTSWw (22.7)\\nSW còn được gọi là ma trậnwithin-class covariance. Đây cũng là một ma trận đối xứng\\nnửa xác định dương vì nó là tổng của hai ma trận đối xứng nửa xác định dương2.\\nNhư vậy, bài toán tối ưu cho LDA trở thành\\nw = arg max\\nw\\nwTSBw\\nwTSWw (22.8)\\n22.2.3 Nghiệm của bài toán tối ưu\\nNghiệm w của (22.8) sẽ là nghiệm của phương trình đạo hàm hàm mục tiêu bằng 0. Sử dụng\\nquy tắc chuỗi cho đạo hàm hàm nhiều biến và công thức∇wwAw = 2Aw nếu A là một\\nma trận đối xứng, ta thu được\\n∇wJ(w) = 1\\n(wTSWw)2\\n(\\n2SBw(wTSWw) −2wTSBwTSWw\\n)\\n= 0 (22.9)\\n⇔SBw = wTSBw\\nwTSWwSWw = J(w)SWw (22.10)\\n⇒S−1\\nW SBw = J(w)w (22.11)\\nLưu ý:Trong (22.11), ta đã giả sử rằng ma trậnSW là khả nghịch. Điều này không luôn\\nluôn đúng, nhưng có một kỹ thuật nhỏ là xấp xỉSW bởi ¯SW = SW + λI với λlà một số thực\\ndương nhỏ. Ma trận mới này là khả nghịch vì trị riêng nhỏ nhất của nó bằng với trị riêng\\nnhỏ nhất củaSW cộng vớiλ tức không nhỏ hơnλ >0. Điều này được suy ra từ việcSW\\n2 Trong (22.6) và (22.7), chúng ta đã sử dụng đẳng thức(aT b)2 = (aT b)(aT b) = aT bbT a với a,b là hai vectors\\ncùng chiều bất kỳ.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 284, 'page_label': '273'}, page_content='273 CHƯƠNG 22. LINEAR DISCRIMINANT ANALYSIS\\nlà một ma trận nửa xác định dương. Từ đó,¯SW là một ma trận xác định dương vì mọi trị\\nriêng của nó là không nhỏ hơnλ, và vì thế, nó khả nghịch. Khi tính toán, ta có thể sử dụng\\nnghịch đảo của¯SW. Kỹ thuật này được sử dụng rất nhiều khi cần sử dụng nghịch đảo của\\nmột ma trận nửa xác định dương và chưa biết nó có thực sự là xác định dương hay không.\\nQuay trở lại với đẳng thức (22.11), vìJ(w) là một số vô hướng, ta suy raw phải là một\\nvector riêng củaS−1\\nW SB ứng vớiJ(w). Vậy, để hàm mục tiêu là lớn nhất thìJ(w) chính là\\ntrị riêng lớn nhất củaS−1\\nW SB. Dấu bằng xảy ra khiw là vector riêng ứng với trị riêng lớn\\nnhất đó.\\nTừ có thể thấy ngay rằng nếuw là nghiệm của (22.8) thìkw cũng là nghiệm vớik là số\\nthực khác không bất kỳ. Vậy ta có thể chọnw sao cho(m1 −m2)Tw = L với L là trị riêng\\nlớn nhất củaS−1\\nW SB và cũng là giá trị tối ưu củaJ(w). Khi đó, thay định nghĩa củaSB ở\\n(22.6) vào (22.11) ta có:\\nLw = S−1\\nW (m1 −m2) (m1 −m2)Tw\\ued19 \\ued18\\ued17 \\ued1a\\nL\\n= LS−1\\nW (m1 −m2) (22.12)\\nĐiều này nghĩa là ta có thể chọn\\nw = αS−1\\nW (m1 −m2) (22.13)\\nvới α̸= 0 bất kỳ. Biểu thức (22.13) còn được biết như làFisher’s linear discriminant, được\\nđặt theo tên nhà khoa học Ronald Fisher (https://goo.gl/eUk1KS ).\\n22.3 LDA cho bài toán phân lớp nhiều lớp\\n22.3.1 Xây dựng hàm mục tiêu\\nTrong mục này, chúng ta sẽ xem xét trường hợp tổng quát của LDA, được gọi làmulti-class\\nLDA, khi có nhiều hơn hai lớp dữ liệu,C >2. Giả sử rằng chiều của dữ liệuD lớn hơnC.\\nGiả sử rằng chiều mà chúng ta muốn giảm về làD′ < Dvà dữ liệu mới ứng với mỗi điểm\\ndữ liệux là:\\nz = WTx (22.14)\\nvới W ∈RD×D′\\n. Một vài ký hiệu:\\n• Xk,Zk = WTXk lần lượt là ma trận dữ liệu của lớp thứk trong không gian ban đầu và\\nkhông gian mới với số chiều nhỏ hơn. Mỗi cột tương ứng với một điểm dữ liệu.\\n• mk = 1\\nNk\\n∑\\nn∈Ck\\nxk ∈RD là vector kỳ vọng của lớp thứk trong không gian ban đầu.\\n• ek = 1\\nNk\\n∑\\nn∈Ck\\nzn = WTmk ∈RD′\\nlà vector kỳ vọng của lớp thứk trong không gian mới.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 284, 'page_label': '273'}, page_content='• mk = 1\\nNk\\n∑\\nn∈Ck\\nxk ∈RD là vector kỳ vọng của lớp thứk trong không gian ban đầu.\\n• ek = 1\\nNk\\n∑\\nn∈Ck\\nzn = WTmk ∈RD′\\nlà vector kỳ vọng của lớp thứk trong không gian mới.\\n• m ∈RD là vector trung bình của toàn bộ dữ liệu trong không gian ban đầu vàe ∈RD′\\nlà vector trung bình trong không gian mới.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 285, 'page_label': '274'}, page_content='CHƯƠNG 22. LINEAR DISCRIMINANT ANALYSIS 274\\ne1\\n∥Z1 −E1∥2F\\nej\\n∥Zj −Ej∥2F\\neC\\n∥ZC −EC∥2F\\ne\\nGoal:\\nC∑\\nk=1\\n∥Zk −Ek∥2F (within-class) small.\\nC∑\\nk=1\\n∥Ek −E∥2F (between-class) large.\\nHình 22.3: LDA cho multi-class\\nclassification problem. Mục đích\\ncũng là sự khác nhau giữa các\\nthành phần trong một lớp (within-\\nclass) là nhỏ và sự khác nhau giữa\\ncác lớp là lớn. Các điểm dữ liệu\\ncó màu khác nhau thể hiện các lớp\\nkhác nhau.\\nMột trong những cách xây dựng hàm mục tiêu cho multi-class LDA được minh họa trong\\nHình 22.3. Độ phân tán của một tập hợp dữ liệu có thể được coi như tổng bình phương\\nkhoảng cách từ mỗi điểm tới vector kỳ vọng của chúng. Nếu tất cả các điểm đều gần vector\\ntrung bình của chúng thì độ phân tán của tập dữ liệu đó được coi là nhỏ. Ngược lại, nếu\\ntổng này là lớn, tức trung bình các điểm đều xa trung tâm, tập hợp này có thể được coi\\nlà có độ phân tán cao. Dựa vào nhận xét này, ta có thể xây dựng các đại lượng within- và\\nbetween-class variance như dưới đây.\\nWithin-class variancecủa lớp thứk có thể được tính như sau:\\nσ2\\nk =\\n∑\\nn∈Ck\\n∥zn −ek∥2\\nF = ∥Zk −Ek∥2\\n2 = ∥WT(Xk −Mk)∥2\\nF (22.15)\\n= trace\\n(\\nWT(Xk −Mk)(Xk −Mk)TW\\n)\\n(22.16)\\nVới Ek một ma trận có các cột giống hệt nhau và bằng với vector trung bìnhek. Có thể\\nnhận thấyEk = WTMk với Mk là ma trận có các cột giống hệt nhau và bằng với vector\\ntrung bình mk trong không gian ban đầu. Vậy đại lượng đo within-class trong multi-class\\nLDA có thể được đo bằng:\\nsW =\\nC∑\\nk=1\\nσ2\\nk =\\nC∑\\nk=1\\ntrace\\n(\\nWT(Xk −Mk)(Xk −Mk)TW\\n)\\n= trace\\n(\\nWTSWW\\n)\\n(22.17)\\nvới\\nSW =\\nC∑\\nk=1\\n∥Xk −Mk∥2\\nF =\\nC∑\\nk=1\\n∑\\nn∈Ck\\n(xn −mk)(xn −mk)T (22.18)\\nMa trậnSW này là một ma trận nửa xác định dương.\\nBetween-class variancelớn có thể đạt được nếu tất cả các điểm trong không gian mới đều\\nxa vector trung bình chunge. Việc này cũng có thể đạt được nếu các vector trung bình của\\nmỗi lớp xa các vector trung bình chung (trong không gian mới). Vậy ta có thể định nghĩa\\nđại lượng between-class như sau:\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 286, 'page_label': '275'}, page_content='275 CHƯƠNG 22. LINEAR DISCRIMINANT ANALYSIS\\nsB =\\nC∑\\nk=1\\nNk∥ek −e∥2\\nF =\\nC∑\\nk=1\\n∥Ek −E∥2\\nF (22.19)\\nTa lấyNk làm trọng số vì có thể có những lớp có nhiều phần tử so với các lớp còn lại. Chú\\ný rằng ma trậnE có thể có số cộtlinh động, phụ thuộc vào số cột của ma trậnEk mà nó đi\\ncùng (và bằngNk).\\nLập luận tương tự như (22.17), bạn đọc có thể chứng minh được:\\nsB = trace\\n(\\nWTSBW\\n)\\n(22.20)\\nvới\\nSB =\\nC∑\\nk=1\\n(Mk −M)(Mk −M)T =\\nC∑\\nk=1\\nNk(mk −m)(mk −m)T (22.21)\\nvà số cột của ma trậnM cũng linh động theo số cột củaMk. Ma trận này là tổng của các\\nma trận đối xứng nửa xác định dương, nên nó là một ma trận đối xứng nửa xác định dương.\\n22.3.2 Hàm mục tiêu cho multi-class LDA\\nVới cách định nghĩa và ý tưởng về within-class variance nhỏ và between-class variance lớn\\nnhư trên, ta có thể xây dựng bài toán tối ưu\\nW = arg max\\nW\\nJ(W) = arg max\\nW\\ntrace(WTSBW)\\ntrace(WTSWW) (22.22)\\nNghiệm cũng được tìm bằng cách giải phương trình đạo hàm hàm mục tiêu bằng 0. Nhắc\\nlại về đạo hàm của hàm trace theo ma trận:\\n∇Wtrace(WTAW) = 2AW (22.23)\\nvới A ∈RD×D là một ma trận đối xứng.\\nVới cách tính tương tự như (22.9) - (22.11), ta có:\\n∇WJ(W) = 2\\n(\\nSBWtrace(WTSWW) −trace(WTSBW)SWW\\n)\\n(trace(WTSWW))2 = 0 (22.24)\\n⇔S−1\\nW BW = J(W)W (22.25)\\nTừ đó suy ra mỗi cột củaW là một vector riêng củaS−1\\nW SB ứng với trị riêng lớn nhất của\\nma trận này. Nhận thấy rằng các cột củaW cần phải độc lập tuyến tính. Vì nếu không, dữ\\nliệu trong không gian mớiz = WTx sẽ phụ thuộc tuyến tính và có thể tiếp tục được giảm\\nsố chiều. Vậy các cột củaW là các vector độc lập tuyến tính ứng với trị riêng cao nhất của\\nS−1\\nW SB. Câu hỏi đặt ra là: Có nhiều nhất bao nhiêu vector riêng độc lập tuyến tính ứng với\\ntrị riêng lớn nhất củaS−1\\nW SB? Số lượng này chính là số chiềuD′ của dữ liệu mới.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 287, 'page_label': '276'}, page_content='CHƯƠNG 22. LINEAR DISCRIMINANT ANALYSIS 276\\nSố lượng lớn nhất các vector riêng độc lập tuyến tính ứng với một trị riêng của một ma trận\\nkhông thể lớn hơn rank của ma trận đó. Dưới đây là một bổ đề quan trọng.\\nBổ đề:\\nrank(SB) ≤C−1 (22.26)\\nChứng minh3:\\nViết lại 22.21 dưới dạng\\nSB = PPT (22.27)\\nvới P ∈RD×C mà cột thứk cuả nó làpk = √Nk(mk −m).\\nHơn nữa, cột cuối cùng là một tổ hợp tuyến tính của các cột còn lại:\\nmC −m = mC −\\n∑C\\nk=1 Nkmk\\nN =\\nC−1∑\\nk=1\\nNk\\nN (mk −m) (22.28)\\nNhư vậy ma trậnP có nhiều nhấtC−1 cột độc lập tuyến tính, vậy nên rank4 của nó không\\nvượt quá C −1. Cuối cùng, SB là tích của hai ma trận với rank không quáC −1, nên\\nrank(SB) không vượt quáC−1. □\\nTừ đó ra có rank\\n(\\nS−1\\nW SB\\n)\\n≤rankSB ≤C−1. Vậy số chiều của không gian mới là một số\\nkhông lớn hơnC−1.\\nTóm lại, nghiệm của bài toán multi-class LDA là các vector riêng độc lập tuyến tính ứng với\\ntrị riêng cao nhất củaS−1\\nW SB.\\nLưu ý: Có nhiều cách khác nhau để xây dựng hàm mục tiêu cho multi-class LDA dựa\\ntrên việc định nghĩa within-class variance nhỏ và between-class variance lớn. Chúng ta đang\\nsử dụng hàm trace để đong đếm hai đại lượng này. Một ví dụ khác về hàm tối ưu là\\nJ(W) = trace(s−1\\nW sB) = trace{(WSWWT)−1(WSBWT)}[Fuk13]. Hàm số này cũng đạt giá\\ntrị lớn nhất khiW là tập hợp củaD′vector riêng ứng với các trị riêng lớn nhất củaS−1\\nW SB.\\nCó một điểm chung giữa các cách tiếp cận này là chiều của không gian mới sẽ không vượt\\nquá C−1.\\n22.4 Ví dụ trên Python\\nTrong mục này, chúng ta sẽ minh hoạ LDA cho bài toán phân lớp nhị phân qua một ví dụ\\nđơn giản với dữ liệu trong không gian hai chiều.\\nDữ liệu của hai lớp được tạo như sau:\\n3 Việc chứng minh này không thực sự quan trọng, chỉ phù hợp với những bạn muốn hiểu sâu.\\n4 Các tính chất của rank có thể được tìm thấy trong Mục 1.8.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 288, 'page_label': '277'}, page_content='277 CHƯƠNG 22. LINEAR DISCRIMINANT ANALYSIS\\nfrom __future__ import division, print_function, unicode_literals\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\nfrom matplotlib.backends.backend_pdf import PdfPages\\nnp.random.seed(22)\\nmeans = [[0, 5], [5, 0]]\\ncov0 = [[4, 3], [3, 4]]\\ncov1 = [[3, 1], [1, 1]]\\nN0, N1 = 50, 40\\nN = N0 + N1\\nX0 = np.random.multivariate_normal(means[0], cov0, N0) # each row is a data point\\nX1 = np.random.multivariate_normal(means[1], cov1, N1)\\nCác điểm dữ liệu của hai lớp được minh hoạ bởi các màu khác nhau trên Hình 22.4.\\nTiếp theo, chúng ta đi tính các ma trận within-class và between-class covariance:\\n# Build S_B\\nm0 = np.mean(X0.T, axis = 1, keepdims = True)\\nm1 = np.mean(X1.T, axis = 1, keepdims = True)\\na = (m0 - m1)\\nS_B = a.dot(a.T)\\n# Build S_W\\nA = X0.T - np.tile(m0, (1, N0))\\nB = X1.T - np.tile(m1, (1, N1))\\nS_W = A.dot(A.T) + B.dot(B.T)\\nNghiệm của bài toán là vector riêng ứng với trị riêng lớn nhất củaS−1\\nW WB:\\n_, W = np.linalg.eig(np.linalg.inv(S_W).dot(S_B))\\nw = W[:,0]\\nprint(’w = ’, w)\\nKết quả:\\nw = [ 0.75091074 -0.66040371]\\nĐường thẳng có phươngw được minh hoạ bởi đường màu lục trên Hình 22.4. Ta thấy rằng\\nnghiệm này hợp lý với dữ liệu của bài toán.\\nĐể kiểm chứng độ chính xác của nghiệm tìm được, ta cùng so sánh nó với nghiệm tìm được\\nbởi thư việnsklearn.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 289, 'page_label': '278'}, page_content='CHƯƠNG 22. LINEAR DISCRIMINANT ANALYSIS 278\\nSolution by LDA\\nclass 1\\nclass 2\\nHình 22.4:Ví dụ minh hoạ về LDA\\ntrong không gian hai chiều. Đường\\nthẳng màu lục là đường thẳng mà\\ndữ liệu sẽ được chiếu lên. Ta có\\nthể thấy rằng, nếu chiếu lên đường\\nthẳng này, dữ liệu của hai lớp sẽ\\nnằm về hai phía của một điểm trên\\nđường thẳng đó.\\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\\nX = np.concatenate((X0, X1))\\ny = np.array([0]*N0 + [1]*N1)\\nclf = LinearDiscriminantAnalysis()\\nclf.fit(X, y)\\nprint(’w_sklearn = ’, clf.coef_[0]/np.linalg.norm(clf.coef_)) # normalize\\nw_sklearn = [ 0.75091074 -0.66040371]\\nTa thấy rằng nghiệm tìm theo công thức và nghiệm tìm theo thư viện là như nhau.\\nMột ví dụ khác so sánh PCA và LDA có thể được tìm thấy tạiComparison of LDA and\\nPCA 2D projection of Iris dataset(https://goo.gl/tWjAEs ).\\n22.5 Thảo luận\\n• LDA là một phương pháp giảm chiều dữ liệu có sử dụng thông tin về label của dữ liệu.\\nVì vậy, LDA là một thuật toán supervised.\\n• Ý tưởng cơ bản của LDA là tìm một không gian mới với số chiều nhỏ hơn không gian\\nban đầu sao cho hình chiếu của các điểm trong cùng lớp lên không gian mới này là gần\\nnhau trong khi hình chiếu của các điểm của các lớp khác nhau là khác nhau.\\n• Trong PCA, số chiều của không gian mới có thể là bất kỳ số nào không lớn hơn số chiều\\nvà số điểm của dữ liệu. Trong LDA, với bài toán cóC classes, số chiều của không gian\\nmới chỉ có thể không vượt quáC−1.\\n• Với bài toán có hai lớp, từ Hình 22.1 ta có thể thấy rằng hai lớp là linearly separable nếu\\nvà chỉ nếu tồn tại một đường thẳng và một điểm trên đường thẳng đó (điểm mùa lục)\\nsao cho dữ liệu hình chiếu trên đường thẳng của hai lớp nằm về hai phía khác nhau của\\nđiểm đó.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 290, 'page_label': '279'}, page_content='279 CHƯƠNG 22. LINEAR DISCRIMINANT ANALYSIS\\n• LDA hoạt động rất tốt nếu các lớp là linearly separable. Chất lượng mô hình giảm đi rõ\\nrệt nếu các classes là không linearly separable. Điều này dễ hiểu vì khi đó, chiếu dữ liệu\\nlên phương nào thì cũng bị chồng lần, và việc tách biệt không thể thực hiện được như ở\\nkhông gian ban đầu.\\n• Mặc dù có hạn chế, ý tưởng vềsmall within-class variance và big within-class variance\\ncòn được gọi làFisher’s optimization criterion, được sử dụng rất nhiều trong các thuật\\ntoán phân lớp [VM17,VM16,YZFZ11].\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 292, 'page_label': '281'}, page_content='Phần VII\\nConvex optimization–Tối ưu lồi'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 293, 'page_label': '282'}, page_content='Chương 23\\nTập lồi và hàm lồi\\n23.1 Giới thiệu\\nCác bài toán tối ưu đã thảo luận trong cuốn sách này đều là cácbài toán tối ưu không ràng\\nbuộc (unconstrained optimization problems), tức tối ưu hàm mất mát mà không cóđiều kiện\\nràng buộc(constraints) nào về nghiệm. Tuy nhiên, không chỉ trong Machine Learning, trên\\nthực tế các bài toán tối ưu thường có rất nhiều ràng buộc khác nhau.\\nTrong toán tối ưu, một bài toán có ràng buộc thường được viết dưới dạng\\nx∗= arg min\\nx\\nf0(x)\\nsubject to: fi(x) ≤0, i = 1,2,...,m\\nhj(x) = 0, j = 1,2,...,p\\nTrong đó, vectorx = [x1,x2,...,x n]T được gọi làbiến tối ưu(optimization variable). Hàm số\\nf0 : Rn →R được gọi làhàm mục tiêu(objective function, các hàm mục tiêu trong Machine\\nLearning thường được gọi làhàm mất mát). Các hàm sốfi,hj : Rn →R,i = 1,2,...,m ; j =\\n1,2,...,p được gọi là cáchàm ràng buộc(hoặc đơn giản làràng buộc- constraints). Tập hợp\\ncác điểmx thỏa mãn cácràng buộcđược gọi làfeasible set. Mỗi điểm trongfeasible setđược\\ngọi là mộtfeasible point, các điểm không trongfeasible setđược gọi là cácinfeasible point.\\nChú ý:\\n• Nếu bài toán là tìm giá trị lớn nhất thay vì nhỏ nhất của hàm mục tiêu, ta chỉ cần đổi\\ndấu củaf0(x).\\n• Nếu ràng buộc làlớn hơn hoặc bằng, tứcfi(x) ≥bi, ta chỉ cần đổi dấu của ràng buộc là\\nsẽ có điều kiệnnhỏ hơn hoặc bằng−fi(x) ≤−bi.\\n• Các ràng buộc cũng có thể làlớn hơn hoặc nhỏ hơn.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 294, 'page_label': '283'}, page_content='283 CHƯƠNG 23. TẬP LỒI VÀ HÀM LỒI\\nExample of convex sets\\nHình 23.1: Các ví dụ về tập lồi.\\n• Nếu ràng buộc làbằng nhau, tứchj(x) = 0, ta có thể viết nó dưới dạng hai bất đẳng thức\\nhj(x)≤0 và−hj(x)≤0. Trong một vài tài liệu, người ta bỏ các phương trình ràng buộc\\nhj(x) = 0đi.\\n• Trong chương này,x,y được dùng chủ yếu để ký hiệu các biến số, không phải là dữ liệu\\nnhư trong các chương trước. Biến tối ưu chính là biến được ghi dưới dấuarg min. Khi\\nviết một bài toán tối ưu, ta cần chỉ rõ biến nào cần được tối ưu, biến nào là cố định.\\nCác bài toán tối ưu, nhìn chung không có cách giải tổng quát, thậm chí có rất nhiều bài chưa\\ncó lời giải hiểu quả. Hầu hết các phương pháp tìm nghiệm không chứng minh được nghiệm\\ntìm được có phải là tức đúng là điểm làm cho hàm số đạt giá trị nhỏ nhất hay lớn nhất\\nhay không (global optimal). Thay vào đó, nghiệm thường là cácđiểm cực trị(local optimal).\\nTrong nhiều trường hợp, các nghiệmlocal optimalcũng mang lại những kết quả tốt.\\nĐể bắt đầu nghiên cứu về tối ưu, chúng ta cần biết tới một mảng rất quan trọng trong đó,\\ncó tên làtối ưu lồi (convex optimization), trong đóhàm mục tiêulà một hàm lồi (convex\\nfunction), feasible setlà mộttập lồi (convex set). Những tính chất đặc biệt vềlocal optimal\\nvà global optimalcủa mộthàm lồikhiến tối ưu lồi trở nên cực kỳ quan trọng. Trong chương\\nnày, chúng ta sẽ thảo luận định nghĩa và các tính chất cơ bản củatập lồi và hàm lồi. Bài\\ntoán tối ưu lồi(convex optimization problems) sẽ được đề cập trong chương tiếp theo.\\n23.2 Tập lồi – Convex sets\\n23.2.1 Định nghĩa\\nBạn đoc có thể đã biết đến khái niệmđa giác lồi. Lồi, hiểu đơn giản, làphình ra ngoài, hoặc\\nnhô ra ngoài. Trong toán học,bằng phẳngcũng được coi làlồi.\\nĐịnh nghĩa không chính thức của tập lồi:Một tập hợp được gọi làtập lồi nếu mọi\\nđiểm trên đoạn thẳng nối hai điểmbất kỳ trong tập hợp hợp đó đều thuộc tập hợp đó.\\nMột vài ví dụ về tập lồi được cho trong Hình 23.1. Các hình với đường biên màu đen thể'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 294, 'page_label': '283'}, page_content='điểm trên đoạn thẳng nối hai điểmbất kỳ trong tập hợp hợp đó đều thuộc tập hợp đó.\\nMột vài ví dụ về tập lồi được cho trong Hình 23.1. Các hình với đường biên màu đen thể\\nhiện việc biên cũng thuộc vào hình đó, biên màu trắng thể hiện việc biên đó không nằm\\ntrong hình. Đường thẳng hoặc đoạn thẳng cũng là một tập lồi theo định nghĩa phía trên.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 295, 'page_label': '284'}, page_content='CHƯƠNG 23. TẬP LỒI VÀ HÀM LỒI 284\\nExamples of nonconvex sets\\nHình 23.2: Các ví dụ về tập không lồi.\\nMột vài ví dụ thực tế:\\n• Giả sử có một căn phòng có dạng hình lồi, nếu ta đặt một bóng đèn đủ sáng ở bất kỳ vị\\ntrí nào trên trần nhà, mọi điểm trong căn phòng đều được chiếu sáng.\\n• Nếu một đất nước có bản đồ dạng một hình lồi thì đoạn thẳng nối hai thành phố bất kỳ\\ntrong đất nước đó nằm trọn vẹn trong nước đó. Một cách lý tưởng, mọi đường bay trong\\nđất nước đều được tối ưu vì chi phí bay thẳng ít hơn chi phí bay đường vòng hoặc qua\\nkhông phận của nước khác. Bản đồ Việt Nam không có dạng lồi vì đường thẳng nối sân\\nbay Nội Bài và Tân Sơn Nhất đi qua địa phận Campuchia.\\nHình 23.2 minh hoạ một vài ví dụ về các tập không phải là tập lồi, nói gọn làtập không lồi\\n(nonconvex set). Ba hình đầu tiên không phải là lồi vì các đường nét đứt chứa nhiều điểm\\nkhông nằm trong các tập đó. Hình thứ tư, hình vuông không có biên ở đáy, không phải là\\nmột tập lồivì đoạn thẳng nối hai điểm ở đáy có thể chứa phần ở giữa không thuộc tập đang\\nxét (nếu không có biên thì thình vuông vẫn là mộttập lồi, nhưng biênnửa vời như ví dụ\\nnày thì hãy chú ý). Một đường cong bất kỳ cũng không phải làtập lồi vì dễ thấy đường\\nthẳng nối hai điểm bất kỳ không thuộc đường cong đó.\\nĐể mô tả mộttập lồi dưới dạng toán học, ta sử dụng\\nĐịnh nghĩa 23.1: Convex set–Tập hợp lồi\\nMột tập hợp Cđược gọi là một tập lồi nếu với hai điểm bất kỳx1,x2 ∈C , điểm\\nxθ = θx1 + (1−θ)x2 cũng nằm trongCvới bất kỳ0 ≤θ≤1.\\nCó thể thấy rằng, tập hợp các điểm có dạng(θx1 + (1−θ)x2) chính làđoạn thẳng nối hai\\nđiểm x1 và x2.\\nVới các định nghĩa này thìtoàn bộ không gianlà mộttập lồi vì đoạn thằng nào cũng nằm\\ntrong không gian đó. Tập rỗng cũng có thể coi là một trường hợp đặc biệt củatập lồi.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 296, 'page_label': '285'}, page_content='285 CHƯƠNG 23. TẬP LỒI VÀ HÀM LỒI\\n23.2.2 Các ví dụ về tập lồi\\nSiêu mặt phẳng và nửa không gian\\nĐịnh nghĩa 23.2: Hyerplane–Siêu mặt phẳng\\nMột siêu mặt phẳng, haysiêu phẳng(hyperplane) trong không giannchiều là tập hợp\\ncác điểm thỏa mãn phương trình\\na1x1 + a2x2 + ··· + anxn = aTx = b (23.1)\\nvới b,ai,i = 1,2,...,n là các số thực.\\nHyperplanes là cáctập lồi. Điều này có thể được suy ra từ Định nghĩa 23.1. Thật vậy, nếu\\naTx1 = aTx2 = b\\nthì với0 ≤θ≤1 bất kỳ, ta cóaTxθ = aT(θx1 + (1 −θ)x2) = θb+ (1 −θ)b= b\\nĐịnh nghĩa 23.3: Halfspace–Nửa không gian\\nMột nửa không gian (halfspace) trong không giann chiều là tập hợp các điểm thỏa\\nmãn bất phương trình\\na1x1 + a2x2 + ··· + anxn = aTx ≤b\\nvới b,ai,i = 1,2,...,n là các số thực.\\nCác halfspace cũng là các tập lồi, bạn đọc có thể dễ dàng nhận thấy theo Định nghĩa 23.1\\nvà cách chứng minh tương tự như trên.\\nNorm balls\\nĐịnh nghĩa 23.4: Norm ball\\nCho một tâmxc và một bán kínhr và khoảng cách giữa các điểm được xác định bởi\\nmột norm.Norm ball tương ứng là tập hợp các điểm thoả mãn\\nB(xc,r) =\\n{\\nx\\n⏐⏐∥x −xc∥2 ≤r}= {xc + ru\\n⏐⏐∥u∥2 ≤1\\n}\\nKhi norm làℓ2 norm, ta có norm ball là một hình tròn trong không gian hai chiều, hình\\ncầu trong không gian ba chiều, hoặc siêu cầu trong các không gian nhiều chiều. Khi dùngℓ2\\nnorm, norm ball được gọi làEuclidean norm.\\nNorm balls là các tập lồi. Để chứng minh việc này, ta dùng Định nghĩa 23.1 và bất đẳng\\nthức tam giác của norms. Với x1,x2 bất kỳ thuộc B(xc,r) và 0 ≤ θ ≤ 1 bất kỳ, xét\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 297, 'page_label': '286'}, page_content='CHƯƠNG 23. TẬP LỒI VÀ HÀM LỒI 286\\n-1 1\\n1\\n-1\\n-1 1\\n1\\n-1\\n-1 1\\n1\\n-1\\n-1 1\\n1\\n-1\\n-1 1\\n1\\n-1\\np = 1\\n8 p = 1\\n4 p = 1\\n2 p = 2\\n3 p = 4\\n5\\n-1 1\\n1\\n-1\\n-1 1\\n1\\n-1\\n-1 1\\n1\\n-1\\n-1 1\\n1\\n-1\\n-1 1\\n1\\n-1\\np = 1 p = 4\\n3 p = 2 p = 4 p = ∞\\nCp = {(x, y)\\n⏐⏐ (|x|p + |y|p)1/p ≤1}\\n(a) p <1: nonconvex sets\\n(b) p ≥1: convex sets\\nHình 23.3: Hình dạng của các tập hợp bị chặn bởi (a) các pseudo-norm và (b) các norm.\\nxθ = θx1 + (1−θ)x2, ta có\\n∥xθ −xc∥= ∥θ(x1 −xc) + (1−θ)(x2 −xc)∥\\n≤θ∥x1 −xc∥+ (1−θ)∥x2 −xc∥≤ θr+ (1−θ)r= r\\nVậyxθ ∈B(xc,r).\\nHình 23.3 minh họa tập hợp các điểm có tọa độ(x,y) trong không gian hai chiều thỏa mãn:\\n(|x|p + |y|p)1/p ≤1 (23.2)\\nvới hàng trên là các tập với0 < p <1, là các pseudo-norm, và hàng dưới tương ứng với\\np ≥1, là các norm thực sự. Chúng ta có thể thấy rằng khip nhỏ gần bằng 0, tập hợp các\\nđiểm thỏa mãn bất đẳng thức (23.2) gần như nằm trên các trục tọa độ và bị chặn trong đoạn\\n[0,1]. Quan sát này sẽ giúp ích cho các bạn khi làm việc với pseudo-norm 0. Khip →∞,\\ncác tập hợp hội tụ về hình vuông. Đây cũng là một trong các lý do vì sao cần có điều kiện\\np≥1 khi định nghĩaℓp norm.\\n23.2.3 Giao của các tập lồi\\nGiao của các tập lồi là một tập lồi. Việc này có thể nhận nhận ra trong Hình 23.4a. Giao\\ncủa hai trong ba hoặc cả ba tập lồi đều là các tập lồi. Việc này có thể được chứng minh theo\\nĐịnh nghĩa 23.1. Nếux1,x2 thuộc vào giao của các tập lồi, tức thuộc tất cả các tập lồi đã\\ncho, thì(θx1 + (1−θ)x2) cũng thuộc vào tất cả các tập lồi, tức thuộc vào giao của chúng.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 298, 'page_label': '287'}, page_content='287 CHƯƠNG 23. TẬP LỒI VÀ HÀM LỒI\\n(b)(a)\\nHình 23.4:(a) Giao của các tập lồi là một tập lồi. (b) Giao của các hyperplanes và halfspace là\\nmột tập lồi và được gọi là polyhedron (số nhiều là polyhedra).\\nTừ đó suy ra giao của cáchalfspaces và cáchyperplanes cũng là một tập lồi. Chúng là các\\nđa giác lồi trong không gian hai chiều và đa diện lồi trong không gian ba chiều. Trong không\\ngian nhiều chiều, giao của cáchalfspaces và hyperplanes được gọi làpolyhedra. Giả sử có\\nmhalfspace và phyperplanes. Mỗi mộthalfspace có thể được viết dưới dạngaT\\ni x ≤bi, ∀i=\\n1,2,...,m . Mỗi mộthyperplane có thể được viết dưới dạngcT\\ni x = di, ∀i= 1,2,...,p .\\nVậy nếu đặt A = [a1,a2,..., am], b = [b1,b2,...,b m]T,C = [c1,c2,..., cp] và d =\\n[d1,d2,...,d p]T, ta có thể viết polyhedra dưới dạng tập hợp các điểmx thỏa mãn\\nATx ⪯b, CTx = d\\ntrong đó⪯là element-wise, tức mỗi phần tử trong vế trái nhỏ hơn hoặc bằng phần tử tương\\nứng trong vế phải.\\n23.2.4 Tổ hợp lồi và bao lồi\\nĐịnh nghĩa 23.5: Tổ hợp lồi–Convex combination\\nMột điểm được gọi làtổ hợp lồi(convex combination) của các điểmx1,x2,..., xk nếu\\nnó có thể được viết dưới dạng\\nx = θ1x1 + θ2x2 + ··· + θkxk, với θ1 + θ2 + ··· + θk = 1và θi ≥0,∀i= 1,2,...,k\\nBao lồi (convex hull) của một tập hợp bất kỳ là tập hợp tất cả các điểm là convex\\ncombination của tập hợp đó.Convex hull của một tập bất kỳ là mộtconvex set. Convex hull\\ncủa mộtconvex setlà chính nó.Convex hull của một tập hợp chính làconvex setnhỏ nhất\\nchứa tập hợp đó. Khái niệmnhỏ nhấtđược hiểu là mọi tập lồi chứa toàn bộ một tập hợp\\nbất kỳ đều chứa convex hull của tập hợp đó.\\nNhắc lại về khái niệmlinear separableđã sử dụng nhiều trong cuốn sách. Hai tập hợp được\\ngọi làlinearly separablenếu cácconvex hull của chúng không có điểm chung.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 299, 'page_label': '288'}, page_content='CHƯƠNG 23. TẬP LỒI VÀ HÀM LỒI 288\\nseparating hyperplane\\nHình 23.5:Trái: Giao của các tập lồi là một tập lồi. Phải: giao của các hyperplanes và halfspace\\nlà một tập lồi và được gọi là polyhedron (số nhiều là polyhedra).\\nTrong Hình 23.5, convex hull của các điểm màu xanh là vùng màu xám bao bởi các đa giác\\nlồi. Ở Hình 23.5 bên phải phải, convex hull của đa giác màu xanh là hợp của nó và phần\\ntam giác màu xám.\\nĐịnh lý 23.1: Siêu phẳng phân chia–Separating hyperplane theorem\\nHai tập lồi không rỗngC,Dlà không giao nhaunếu và chỉ nếu tồn tại một vectora và\\nmột sốb sao cho\\naTx ≤b,∀x ∈C, aTx ≥b,∀x ∈D\\nTập hợp tất cả các điểmx thỏa mãn aTx = b chính là một hyperplane. Hyperplane này\\nđược gọi làseparating hyperplane.\\nNgoài ra, còn nhiều tính chất thú vị của các tập lồi và các phép toán bảo toàn chính chất\\nlồi của một tập hợp, bạn đọc được khuyến khích đọc thêm Chương 2 của cuốn Convex\\nOptimization [BV04].\\n23.3 Convex functions\\n23.3.1 Định nghĩa\\nTrước hết ta xem xét các hàm một biến với đồ thị của nó là một đường trong một mặt\\nphẳng. Một hàm số được gọi làlồi nếu tập xác định của nó là một tập lồivà nếu ta\\nnối hai điểm bất kỳ trên đồ thị hàm số đó, ta được một đoạn thẳng nằm về phía trên hoặc\\nnằm trên đồ thị (xem Hình 23.6).Tập xác định(domain) của một hàm sốf(.) thường được\\nký hiệu làdomf.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 300, 'page_label': '289'}, page_content='289 CHƯƠNG 23. TẬP LỒI VÀ HÀM LỒI\\nf(x)\\nf(y)\\nf(θx+ (1−θ)y)\\nθf(x) + (1−θ)f(y)\\nθf(x) + (1−θ)f(y) ≥f(θx+ (1−θ)y)\\nHình 23.6: Định nghĩa hàm lồi.\\nDiễn đạt bằng lời, một hàm số là\\nlồi nếu đoạn thẳng nối 2 điểm bất\\nkỳ trên đồ thị của nókhông nằm\\ndưới đồ thị đó.\\nĐịnh nghĩa 23.6: Convex function–Hàm lồi\\nMột hàm sốf :Rn →R được gọi là mộthàm lồi nếu domf là mộttập lồi, và:\\nf(θx + (1−θ)y)≤θf(x) + (1−θ)f(y)\\nvới mọix,y ∈domf,0 ≤θ≤1.\\nĐiều kiệndomf là mộttập lồilà rất quan trọng. Nếu không có điều kiện này, tồn tại những\\nθ mà θx1 + (1−θ)x2 không thuộcdomf, và sẽ không định nghĩa đượcf(θx + (1−θ)y).\\nMột hàm sốf được gọi làconcave(tạm dịch làlõm) nếu−f là convex. Một hàm số có thể\\nkhông thuộc hai loại trên. Các hàm tuyến tính vừaconvex, vừaconcave.\\nĐịnh nghĩa 23.7: Strictly convex function–Hàm lồi chặt\\nMột hàm sốf :Rn →R được gọi làlồi chặt (strictly convex) nếudomf là mộttập\\nlồi, và\\nf(θx + (1−θ)y)<θf (x) + (1−θ)f(y)\\nvới mọix,y ∈domf,x ̸= y,0 <θ <1 (chỉ khác với hàm convex ở dấu nhỏ hơn).\\nTương tự với định nghĩastrictly concave.\\nNếu một hàm số làstrictly convexvà có điểm cực trị, thì điểm cực trị đó là duy\\nnhất và cũng làglobal minimum.\\n23.3.2 Các tính chất cơ bản\\n• Nếu f(x)là convex thì af(x)là convex nếu a> 0 và làconcave nếu a< 0. Điều này có\\nthể suy ra trực tiếp từ định nghĩa.\\n• Tổng của haihàm lồi là mộthàm lồi, với tập xác định là giao của hai tập xác định của\\nhai hàm đã cho (nhắc lại rằng giao của hai tập lồi là một tập lồi)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 301, 'page_label': '290'}, page_content='CHƯƠNG 23. TẬP LỒI VÀ HÀM LỒI 290\\nf1(x)\\nf2(x)f(x) = max{f1(x), f2(x)}\\nHình 23.7: Ví dụ về Pointwise maxi-\\nmum. Maximum của các hàm lồi là một\\nhàm lồi.\\n• Pointwise maximum và supremum:Nếu các hàm sốf1,f2,...,f m là convex thì:\\nf(x) = max{f1(x),f2(x),...,f m(x)}\\ncũng làconvex trên tập xác định là giao của tất cả các tập xác định của các hàm số trên.\\nHàmmax phía trên cũng có thể thay thế bằng hàmsupremum1. Tính chất này có thể được\\nchứng minh theo Định nghĩa 23.6. Hình 23.7 minh hoạ tính chất này. Các hàmf1(x),f2(x)\\nlà các hàm lồi. Đường màu xanh chính là đồ thị của hàm sốf(x) = max( f1(x),f2(x)).\\nMọi đoạn thẳng nối hai điểm bất kì trên đường màu xanh đềukhông nằm dướinó.\\n23.3.3 Ví dụ\\nCác hàm một biến\\nVí dụ về cácconvex functionsmột biến:\\n• Hàm y = ax+ b là mộthàm lồi vì đoạn thẳng nối hai điểm bất kỳ trên đường thẳng đó\\nđều không nằm phía dướiđường thẳng đó.\\n• Hàm y= eax với a∈R bất kỳ.\\n• Hàm y= xa trên tập các số thực dương vàa≥1 hoặc a≤0.\\n• Hàm negative entropyy= xlog x trên tập các số thực dương.\\nHình 23.8 minh hoạ đồ thị của một số hàm convex thường gặp với biến một chiều.\\nVí dụ về cácconcave functionsmột biến:\\n• Hàm y= ax+ b là mộtconcave functionvì −y là mộtconvex function.\\n• Hàm y= xa trên tập số dương và0 ≤a≤1.\\n• Hàm logarithmy= log(x) trên tập các số dương.\\nHình 23.9 minh hoạ đồ thị của một vài hàm số concave.\\n1 Xem Infimum and Supremum – Wikipedia(https://goo.gl/AsX4oM )\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 302, 'page_label': '291'}, page_content='291 CHƯƠNG 23. TẬP LỒI VÀ HÀM LỒI\\ny = ax + b y = | x | y = x\\n2 y = e\\nx\\ny = x\\n− 1\\n, x > 0\\nHình 23.8: Ví dụ về các hàm convex một biến.\\ny = ax + b y = 2\\n√\\nx y = 2 log( x ) y = 3 + x if x < 0\\ny = 3 − x\\n2\\nif x ≥ 0\\nHình 23.9: Ví dụ về các hàm concave một biến.\\nAffine functions\\nCác hàm số dạngf(x) = aTx + b vừa là convex, vừa là concave.\\nKhi biến là một ma trậnX, các hàm affine được định nghĩa có dạng:\\nf(X) = trace(ATX) + b\\ntrong đó,A là một ma trận có cùng kích thước nhưX để đảm bảo phép nhân ma trận thực\\nhiện được và kết quả là một ma trận vuông.\\nDạng toàn phương – Quadratic form\\nHàm bậc hai một biến có dạngf(x) = ax2 + bx+ c là convex nếua >0, là concave nếu\\na< 0.\\nVới biến là một vectorx = [ x1,x2,...,x n], mộtdạng toàn phương(quadratic form) là một\\nhàm số có dạng\\nf(x) = xTAx + bTx + c\\nvới A,b là các ma trận và vector với chiều phù hợp vàA thường là một ma trận đối xứng.\\nNếu A là một ma trận (nửa) xác định dương thìf(x) là một hàm convex. NếuA là một ma\\ntrận (nửa) xác định âm,f(x) là mộtconcave function.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 303, 'page_label': '292'}, page_content='CHƯƠNG 23. TẬP LỒI VÀ HÀM LỒI 292\\n(a) Norm 1\\n (b) Norm 2\\nHình 23.10: Ví dụ về mặt của các norm hai biến.\\nNhắc lại hàm mất mát trong linear regression có dạng\\nL(w) = 1\\n2N∥y −XTw∥2\\n2 = 1\\n2N(y −XTw)T(y −XTw)\\n= 1\\n2NwTXXTw − 1\\nNyTXTw + 1\\n2NyTy\\nvì XXT là một ma trận nửa xác định dương, hàm mất mát của linear regression chính là\\nmột convex function.\\nNorms\\nMọi hàm số bất kỳ thỏa mãn ba điều kiện của norm đều là convex. Việc này có thể được\\ntrực tiếp suy ra từ bất đẳng thức tam giác của một norm.\\nHình 23.10 minh hoạ hai ví dụ về bề mặt củaℓ1 norm vàℓ2 norm trong không gian hai chiều\\n(chiều thứ ba là giá trị của hàm số). Nhận thấy rằng các bề mặt này đều cómột đáy duy\\nnhất tương ứng với gốc tọa độ (đây chính là điều kiện đầu tiên của norm). Điều này cho\\nthấy nếu tathả một hòn biở vị trí bất kỳ trên các bề mặt này, cuối cùng nó sễlăn về đáy.\\nNếu liên tưởng tới thuật toán gradient descent thì việc áp dụng thuật toán này vào các bài\\ntoán không ràng buộc với hàm mục tiêu là strictly convex (và giả sửa là khả vi, tức có đạo\\nhàm) sẽ cho kết quả rất tốt với learning rate phù hợp. Tính chất này khiến cho các hàm\\nconvex và strictly convex được đặc biệt quan tâm trong tối ưu.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 304, 'page_label': '293'}, page_content='293 CHƯƠNG 23. TẬP LỒI VÀ HÀM LỒI\\nHình 23.11: Ví dụ về các hàm hai biến không convex.\\nHai hàm tiếp theo là ví dụ về các hàm không phải convex hay concave. Hàm thứ nhất\\nf(x,y) = x2 −y2 là một hyperbolic, hàm thứ haif(x,y) = 1\\n10 (x2 + 2y2 −2 sin(xy)). Các bề\\nmặt của hai hàm này được minh hoặc trên Hình 23.11\\n23.3.4 Contours–level sets\\nĐể khảo sát tính lồi của các bề mặt trong không gian ba chiều, việc minh hoạ trực tiếp như\\ncác ví dụ trên đây có thể khó tưởng tượng hơn. Một phương pháp thường được sử dụng là\\ndùng các đường đồng mức (contour hay level set). Contours là cách mô tả các mặt trong\\nkhông gian ba chiều trong không gian hai chiều. Ở đó, các điểm thuộc cùng mộtđường tương\\nứng với các điểm làm cho hàm số có giá trị như nhau. Mỗiđường đó còn được gọi là mộtlevel\\nset. Trong Hình 23.10 và Hình 23.11, các contour của các mặt trên mặt phẳng0xy chính là\\ncác level set. Nói cách khác, mỗi đườnglevel set là một vết cắt nếu ta cắt các bề mặt bởi\\nmột mặt phẳng song song với mặt phẳng0xy.\\nKhi khảo sát tính lồi của một hàm số hai biến, hoặc để tìm điểm cực trị của nó, người ta\\nthường vẽ các level set thay vì vẽ các mặt trong không gian ba chiều. Hình 23.12 minh hoạ\\nmột vài ví dụ về các level set. Ở hàng trên, các đườnglevel set là các đường khép kín. Khi\\ncác đường kín này tập trung nhỏ dần ở một điểm thì các điểm đó là các điểm cực trị. Với\\ncác hàm convex như trong ba ví dụ này, chỉ có một điểm cực trị và đó cũng là điểm làm cho\\nhàm số đạt giá trị nhỏ nhất (global optimal). Nếu để ý, bạn sẽ thấy các đường khép kín này\\ntạo thành biên của các tập lồi. Ở hàng dưới, các đường không phải khép kín. Hình 23.12d\\nminh hoạ các level set của một hàm tuyến tínhf(x,y) = x+ y, và đó là một hàmconvex.\\nHình 23.12e cũng minh hoạ các level set của một hàm lồi (chúng ta sẽ sớm thấy chứng minh)\\nnhưng các level set là cácđường không kín. Hàm này có chứalog nên tập xác định là góc\\nphần tư thứ nhất tương ứng với các tọa độ dương (chú ý rằng tập hợp các điểm có tọa độ'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 304, 'page_label': '293'}, page_content='nhưng các level set là cácđường không kín. Hàm này có chứalog nên tập xác định là góc\\nphần tư thứ nhất tương ứng với các tọa độ dương (chú ý rằng tập hợp các điểm có tọa độ\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 305, 'page_label': '294'}, page_content='CHƯƠNG 23. TẬP LỒI VÀ HÀM LỒI 294\\nf(x, y) = |x|+ |y|\\n(a)\\nf(x, y) = x2 + y2 (b)\\nf(x, y) = max(2x2 + y2 − xy, |x|+ 2|y|) (c)\\nf(x, y) = x + y\\n(d)\\nf(x, y) = xlog(x) + ylog(y) (e)\\nf(x, y) = x2 − y2 (nonconvex) (f)\\nHình 23.12: Ví dụ về các level set. Các đường màu càng xanh đậm thì tương ứng với các giá\\ntrị càng nhỏ, các đường màu càng đỏ đậm thì tương ứng các giá trị càng lớn.\\ndương cũng là mộttập lồi vì nó là một polyhedron). Cácđường không kínnày nếu kết hợp\\nvới trụcOx,Oy sẽ tạo thành biên của các tập lồi. Hình 23.12f minh hoạ các level set của\\nmột hàm hyperbolic, hàm này không phải là một hàm lồi.\\n23.3.5 α–sublevel sets\\nĐịnh nghĩa 23.8:α–sublevel set\\nα−sublevel set của một hàm sốf : Rn →R là một tập hợp được định nghĩa bởi\\nCα = {x ∈domf\\n⏐⏐f(x) ≤α}\\nDiễn đạt bằng lời, mộtα–sublevel set của một hàm sốf(.) là tập hợp các điểm trong tập\\nxác định củaf(.) mà tại đó hàm số đạt giá trị không lớn hơnα.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 306, 'page_label': '295'}, page_content='295 CHƯƠNG 23. TẬP LỒI VÀ HÀM LỒI\\nHình 23.13: Mọi alpha-sublevel sets là convex sets nhưng hàm số là nonconvex.\\nQuay lại với Hình 23.12, hàng trên, cácα–sublevel sets chính là các hình lồi được bao bởi\\ncác level set. Ở Hình 23.12d, cácα–sublevel sets chính là phần nửa mặt phẳng phía dưới\\nxác định bởi các đường thẳng level set. Ở Hình 23.12e, cácα–sublevel set chính là các vùng\\nbị giới hạn bởi các trục tọa độ và các đườnglevel set. Ở Hình 23.12f, cácα–sublevel set hơi\\nkhó tưởng tượng mộtchút. Vớiα >0, các level sets là các đường màu vàng hoặc đỏ, các\\nα–sublevel set tương ứng là phần nằm giữa các đường cùng màu. Các vùng này, có thể dễ\\nnhận thấy, làkhông lồi.\\nĐịnh lý 23.2\\nNếu một hàm số là lồi thìmọi α–sublevel set của nó là lồi. Điều gược lại chưa chắc\\nđã đúng, tức nếu cácα–sublevel set của một hàm số làlồi thì hàm số đó chưa chắc\\nđã lồi.\\nĐiều này chỉ ra rằng nếu tồn tại một giá trịα sao cho mộtα–sublevel set của một hàm số\\nlà không lồi (nonconvex), thì hàm số đó làkhông lồi (không lồi không có nghĩa làconcave,\\nchú ý). Vì vậy, hàm hyperbolic không phải là một hàm lồi. Các ví dụ ở Hình 23.12, trừ\\nHình 23.12f, đều tương ứng với các hàm lồi.\\nXét một ví dụ về việc một hàm số khôngconvex nhưng mọiα–sublevel sets làconvex. Hàm\\nf(x,y) = −ex+y có mọiα–sublevel set là một nửa mặt phẳng – làconvex, nhưng nó không\\nphải làconvex (trong trường hợp này nó làconcave).\\nHình 23.13 là một ví dụ khác về việc một hàm số có mọiα–sublevel set làlồi nhưng không\\nphải là một hàm lồi. Mọiα−sublevel set của hàm số này đều là các hình tròn – lồi, nhưng\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 307, 'page_label': '296'}, page_content='CHƯƠNG 23. TẬP LỒI VÀ HÀM LỒI 296\\nhàm số đó không phải làlồi. Vì có thể tìm được hai điểm trên mặt này sao cho đoạn thẳng\\nnối hai điểm nằm hoàn toàn phía dưới của mặt. Chẳng hạn, đoạn thẳng nối một điểm ở\\ncánh và một điểm ởđáy không nằm hoàn toàn phía trên của mặt.\\nNhững hàm số có tập xác định là một tập lồi và có mọiα–sublevel set là lồi được gọi chung\\nlà quasiconvex. Mọi hàm convex đềuquasiconvex nhưng ngược lại không đúng. Định nghĩa\\nchính thức củaquasiconvex functionđược phát biểu như sau\\nĐịnh nghĩa 23.9: Quasiconvex function\\nMột hàm sốf : C→ R với Clà một tập con lồi củaRn được gọi làquasiconvex nếu\\nvới mọix,y ∈C và mọiθ∈[0,1], ta có:\\nf(θx + (1 −θ)y) ≤max{f(x),f(y)}\\nĐịnh nghĩa này khác với định nghĩa vềconvex functionmột chút ở việc sử dụng hàm max.\\n23.3.6 Kiểm tra tính chất lồi dựa vào đạo hàm.\\nCó một cách để nhận biết một hàm số khả vi có là hàm lồi hay không dựa vào các đạo hàm\\nbậc nhất hoặc bậc hai của nó. Tất nhiên là trong trường hợp các đạo hàm đó tồn tại.\\nFirst-order condition\\nTrước hết chúng ta định nghĩa phương trình mặt tiếp tuyến của một hàm sốf khả vi tại\\nmột điểm nằm trên đồ thị (mặt) của hàm số đó(x0,f(x0). Với hàm một biến, phương trình\\ntiếp tuyến tại điểm co hoành độ(x0,f(x0)) là\\ny= f′(x0)(x−x0) + f(x0)\\nVới hàm nhiều biến, đặt∇f(x0) là gradient của hàm sốf tại điểm x0, phương trình mặt\\ntiếp tuyến được cho bởi:\\ny= ∇f(x0)T(x −x0) + f(x0)\\nFirst-order condition\\nGiả sử hàm sốf có tập xác định là lồi, có đạo hàm tại mọi điểm trên tập xác định\\nđó. Khi đó, hàm sốf là lồinếu và chỉ nếuvới mọix,x0 trên tập xác định của hàm\\nsố đó, ta có:\\nf(x) ≥f(x0) + ∇f(x0)T(x −x0) (23.3)\\nTương tự như thế, một hàm số làstricly convexnếu dấu bằng trong (23.3) xảy ra khi và chỉ\\nkhi x = x0.\\nNói một cách trực quan hơn, một hàm số là lồi nếu mặt tiếp tuyến tại một điểm bất kỳ trên\\nđồ thị của hàm số đókhông nằm trênđồ thị đó.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 308, 'page_label': '297'}, page_content='297 CHƯƠNG 23. TẬP LỒI VÀ HÀM LỒI\\n(x0, f(x0)) f(x0) +∇f(x0)T(x−x0)\\nf(x)\\nf is diﬀerentiable with convex domain\\nf is convex iﬀf(x) ≥f(x0) +∇f(x0)T(x−x0),∀x,x0 ∈domf\\n(a) convex function (b) nonconvex function\\nHình 23.14: Kiểm tra tính convexity dựa vào đạo hàm bậc nhất. Trái: hàm lồi vì tiếp tuyến tại\\nmọi điểm đều nằm dưới đồ thị hàm số đó, phải: hàm không lồi.\\nHình 23.14 minh hoạ đồ thị của một hàm lồi và một hàm không lồi. Hình 23.14a mô tả một\\nhàm lồi. Hình 23.14b mô tả một hàm không lồi vì đồ thị của nó vừa nằm trên, vừa nằm dưới\\nđường thẳng tiếp tuyến.\\nVí dụ: Nếu ma trận đối xứngA là xác định dươngthì hàm sốf(x) = xTAx là lồi.\\nChứng minh:Đạo hàm bậc nhất củaf(x) là ∇f(x) = 2Ax. Vậyfirst-order conditioncó thể\\nviết dưới dạng (chú ý rằngA là một ma trận đối xứng):\\nxTAx ≥2(Ax0)T(x −x0) + xT\\n0 Ax0\\n⇔xTAx ≥2xT\\n0 Ax −xT\\n0 Ax0\\n⇔(x −x0)TA(x −x0) ≥0\\nBất đẳng thức cuối cùng là đúng dựa trên định nghĩa của một ma trậnxác định dương. Vậy\\nhàm sốf(x) = xTAx là một hàm lồi. □\\nSecond-order condition\\nVới hàm nhiều biến, tức biến là một vector, giả sử có chiều làd, đạo hàm bậc nhất của nó\\nlà một vector cũng có chiều làd. Đạo hàm bậc hai của nó là một ma trận vuông có chiều là\\nd×d. Đạo hàm bậc hai của hàm sốf(x), còn được gọi làHessian, được ký hiệu là∇2f(x).\\nSecond-order condition\\nMột hàm số có đạo hàm bậc hai là convex nếudomf là convex và Hessian của nó là\\nmột ma trận nửa xác định dương với mọix trong tập xác định:\\n∇2f(x) ⪰0.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 309, 'page_label': '298'}, page_content='CHƯƠNG 23. TẬP LỒI VÀ HÀM LỒI 298\\nNếu Hessian của một hàm số là một ma trậnxác định dươngthì hàm số đó làstrictly convex.\\nTương tự, nếu Hessian là một ma trậnxác định âmthì hàm số đó làstrictly concave.\\nVới hàm số một biếnf(x), điều kiện này tương đương vớif”(x) ≥0 với mọix thuộc tập\\nxác định (và tập xác định là lồi).\\nVí dụ:\\n• Hàm negative entropyf(x) = xlog(x) là stricly convex vì tập xác định làx >0 là một\\ntập lồi vàf”(x) = 1/x là một số dương với mọix thuộc tập xác định.\\n• Hàm f(x) = x2 + 5 sin(x) không là hàm lồi vì đạo hàm bậc haif”(x) = 2 −5 sin(x) có\\nthể nhận giá trị âm.\\n• Hàm cross entropylà một hàmstrictly convex. Xét ví dụ đơn giản với chỉ hai xác suấtx\\nvà 1 −x với a là một hằng số thuộc đoạn[0,1] và 0 < x <1: f(x) = −(alog(x) + (1 −\\na) log(1−x)) có đạo hàm bậc hai làa\\nx2 + 1−a\\n(1−x)2 là một số dương.\\n• Nếu A là một ma trận xác định dương thìf(x) = 1\\n2 xTAx là lồi vìA chính là Hessian\\ncủa nó.\\n• Xét hàm sốnegative entropyvới hai biến:f(x,y) = xlog(x) +ylog(y) trên tập các giá trị\\ndương củaxvày. Hàm số này có đạo hàm bậc nhất là[log(x) + 1,log(y) + 1]T và Hessian\\nlà\\n[1/x 0\\n0 1 /y\\n]\\n, là một ma trận đường chéo với các thành phần trên đường chéo là dương\\nnên là một ma trận xác định dương. Vậynegative entropylà một hàm strictly convex.\\nNgoài ra còn nhiều tính chất thú vị của cáchàm lồi, các bạn được khuyến khích đọc thêm\\nChương 3 của cuốn Convex Optimization [BV04].\\n23.4 Tóm tắt\\n• Machine learning và tối ưu có quan hệ mật thiết với nhau. Trong tối ưu, tối ưu lồi là quan\\ntrọng nhất.\\n• Trong một tập lồi, mọi đoạn thẳng nối hai điểm bất kỳ trong tập đó sẽ nằm hoàn toàn\\ntrong tập đó. Tập hợp các giao điểm của các tập lồi là một tập lồi.\\n• Một hàm số là lồi nếu đoạn thẳng nối hai điểm bất kỳ trên đồ thì hàm số đókhông nằm\\ndưới đồ thị đó.\\n• Một hàm số khả vi là lồi nếu tập xác định của nó là lồi nếu mặt tiếp tuyến tại một điểm\\nbất kỳkhông nằm phía trênđồ thị của hàm số đó.\\n• Các norms là các hàm lồi, được sử dụng nhiều trong tối ưu.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 309, 'page_label': '298'}, page_content='• Một hàm số khả vi là lồi nếu tập xác định của nó là lồi nếu mặt tiếp tuyến tại một điểm\\nbất kỳkhông nằm phía trênđồ thị của hàm số đó.\\n• Các norms là các hàm lồi, được sử dụng nhiều trong tối ưu.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 310, 'page_label': '299'}, page_content='Chương 24\\nBài toán tối ưu lồi\\n24.1 Giới thiệu\\nChúng ta cùng bắt đầu bài viết bằng ba bài toán tối ưu khá gần với thực tế.\\n24.1.1 Bài toán nhà xuất bản\\nBài toán: Một nhà xuất bản (NXB) nhận được đơn hàng 600 bản của cuốn “Machine\\nLearning cơ bản” tới Thái Bình và 400 bản tới Hải Phòng. NXB đó có 800 cuốn ở kho Nam\\nĐịnh và 700 cuốn ở kho Hải Dương. Giá chuyển phát một cuốn sách từ Nam Định tới Thái\\nBình là 50,000 VND (50k), tới Hải Phòng là 100k. Giá chuyển phát một cuốn từ Hải Dương\\ntới Thái Bình là 150k, trong khi tới Hải Phòng chỉ là 40k. Hỏi để tốn ít chi phí chuyển phát\\nnhất, công ty đó nên phân phối mỗi kho chuyển bao nhiêu cuốn tới mỗi địa điểm?\\nPhân tích\\nĐể cho đơn giản, ta xây dựng bảng số lượng chuyển sách từ nguồn tới đích như sau:\\nNguồn Đích Đơn giá (×10k) Số lượng\\nNam Định Thái Bình 5 x\\nNam Định Hải Phòng 10 y\\nHải Dương Thái Bình 15 z\\nHải Dương Hải Phòng 4 t\\nTổng chi phí (objective function) sẽ làf(x,y,z,t ) = 5x+ 10y+ 15z+ 4t. Các điều kiện ràng\\nbuộc (constraints) viết dưới dạng biểu thức toán học là:\\n• Chuyển 600 cuốn tới Thái Bình:x+ z = 600.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 311, 'page_label': '300'}, page_content='CHƯƠNG 24. BÀI TOÁN TỐI ƯU LỒI 300\\n• Chuyển 400 cuốn tới Hải Phòng:y+ t= 400.\\n• Lấy từ kho Nam Định không quá 800:x+ y≤800.\\n• Lấy từ kho Hải Dương không quá 700:z+ t≤700.\\n• x,y,z,t là các số tự nhiên. Ràng buộc là số tự nhiên sẽ khiến cho bài toán rất khó giải nếu\\nsố lượng biến là lớn. Với bài toán này, giả sử rằngx,y,z,t là các số thực dương. Nghiệm\\ntìm được sẽ được làm tròn tới số tự nhiên gần nhất.\\nVậy ta cần giải bài toán tối ưu sau đây:\\nBài toán NXB1\\n(x,y,z,t ) = arg min\\nx,y,z,t\\n5x+ 10y+ 15z+ 4t\\nthoả mãn:x+ z = 600\\ny+ t= 400\\nx+ y≤800\\nz+ t≤700\\nx,y,z,t ≥0\\n(24.1)\\nNhận thấy rằng hàm mục tiêu (objective function) là một hàm tuyến tính của các biến\\nx,y,z,t . Các điều kiện ràng buộc đều có dạng siêu phẳng hoặc nửa không gian, đều là\\ncác ràng buộc tuyến tính(linear constraints). Bài toán tối ưu với cảobjective function và\\nconstraintsđềulàtuyếntínhđượcgọilà quy hoạch tuyến tính(linearprogramming(LP) ).\\nDạng tổng quát và cách thức lập trình để giải một bài toán thuộc loại này sẽ được cho trong\\nphần sau của chương này.\\n24.1.2 Bài toán canh tác\\nBài toán:Một anh nông dân có tổng cộng 10ha (10 hecta) đất canh tác. Anh dự tính trồng\\ncà phê và hồ tiêu trên diện tích đất này với tổng chi phí cho việc trồng này là không quá\\n16T (triệu đồng). Chi phí để trồng cà phê là 2T cho 1ha, để trồng hồ tiêu là 1T/ha. Thời\\ngian trồng cà phê là 1 ngày/ha và hồ tiêu là 4 ngày/ha; trong khi anh chỉ có thời gian tổng\\ncộng là 32 ngày. Sau khi trừ tất cả các chi phí (bao gồm chi phí trồng cây), mỗi ha cà phê\\nmang lại lợi nhuận 5T, mỗi ha hồ tiêu mang lại lợi nhuận 3T. Hỏi anh phảiquy hoạchnhư\\nthế nào để tối đa lợi nhuận?\\nPhân tích\\nGọi x và y lần lượt là số ha cà phê và hồ tiêu mà anh nông dân nên trồng. Lợi nhuận anh\\nấy thu được làf(x,y) = 5x+ 3y (triệu đồng). Đây chính là hàm mục tiêu của bài toán. Các\\nràng buộc trong bài toán này được viết dưới dạng:\\n1 Nghiệm cho bài toán này có thể nhận thấy ngay làx= 600,y = 0,z = 0,t = 400. Nếu số lượng ràng buộc và số'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 311, 'page_label': '300'}, page_content='ràng buộc trong bài toán này được viết dưới dạng:\\n1 Nghiệm cho bài toán này có thể nhận thấy ngay làx= 600,y = 0,z = 0,t = 400. Nếu số lượng ràng buộc và số\\nbiến nhiều hơn, chúng ta cần một lời giải có thể tìm được bằng cách lập trình.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 312, 'page_label': '301'}, page_content='301 CHƯƠNG 24. BÀI TOÁN TỐI ƯU LỒI\\nx\\ny\\nx\\n+\\ny\\n= 10\\n2\\nx\\n+\\ny\\n= 16\\nx + 4 y = 32\\n5\\nx\\n+ 3\\ny\\n=\\nb\\n(a constant)\\nfeasible set\\nX\\n(0 , 0)\\nHình 24.1: Minh hoạ nghiệm cho\\nbài toán canh tác. Phần ngũ giác\\nmàu xám thể hiện tập hợp các\\nđiểm thoả mãn các ràng buộc. Các\\nđường nét đứt thể hiện các đường\\nđồng mức của hàm mục tiêu với\\nmàu càng đỏ tương ứng với giá trị\\ncàng cao. Nghiệm tìm được chính\\nlà điểm màu xanh, là giao điểm của\\nhình ngũ giác xám và đường đồng\\nmức ứng với giá trị cao nhất.\\n• Tổng diện tích trồng không vượt quá 10ha:x+ y≤10.\\n• Tổng chi phí trồng không vượt quá 16T:2x+ y≤16.\\n• Tổng thời gian trồng không vượt quá 32 ngày:x+ 4y≤32.\\n• Diện tích cà phê và hồ tiêu là các số không âm:x,y ≥0.\\nVậy ta có bài toán tối ưu sau đây:\\nBài toán canh tác\\n(x,y) = arg max\\nx,y\\n5x+ 3y\\nthoả mãn:x+ y≤10\\n2x+ y≤16\\nx+ 4y≤32\\nx,y ≥0\\n(24.2)\\nBài toán này yêu cầutối đa hàm mục tiêuthay vì tối thiểu nó. Việc chuyển bài toán này về\\nbài toántối thiểu có thể được thực hiện đơn giản bằng cách đổi dấu hàm mục tiêu. Khi đó\\nhàm mục tiêu vẫn là tuyến tình, các ràng buộc là tuyến tính, ta lại có một bài toánlinear\\nprogramming nữa. Hình 24.1 minh hoạ nghiệm cho bài toán canh tác.\\nVùng màu xám có dạngpolyhedron (trong trường hợp này là đa giác) chính là tập hợp các\\nđiểm thoả mãn các ràng buộc. Các đường nét đứt có màu chính là các đườngđồng mức\\n(level set) của hàm mục tiêu5x+ 3y, mỗi đường ứng với một giá trị khác nhau với màu\\ncàng đỏ ứng với giá trị càng cao. Một cách trực quan, nghiệm của bài toán có thể tìm được\\nbằng cách di chuyển đường nét đứt màu xanh về phía bên phải (phía làm cho giá trị của\\nhàm mục tiêu lớn hơn) đến khi nó không còn điểm chung với phần đa giác màu xám nữa.\\nCó thể nhận thấy nghiệm của bài toán chính là điểm màu xanh là giao điểm của hai đường\\nthẳng x+ y= 10và 2x+ y= 16. Giải hệ phương trình này ta cóx∗= 6và y∗= 4. Tức anh\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 313, 'page_label': '302'}, page_content='CHƯƠNG 24. BÀI TOÁN TỐI ƯU LỒI 302\\nnông dân nên trồng 6ha cà phê và 4ha hồ tiêu. Lúc đó lợi nhuận thu được là5x∗+ 3y∗= 42\\ntriệu đồng, trong khi anh chỉ mất thời gian là 22 ngày. Trong khi đó, nếu trồng toàn bộ hồ\\ntiêu trong 32 ngày, tức 8ha, anh chỉ thu được 24 triệu đồng.\\nVới các bài toán tối ưu có nhiều biến hơn và nhiều ràng buộc hơn, sẽ rất khó để minh hoạ\\nvà tìm nghiệm như cách này. Chúng ta cần có một công cụ hiệu quả hơn, tốt nhất là nghiệm\\ncó thể tìm được bằng cách lập trình.\\n24.1.3 Bài toán đóng thùng\\nBài toán:Một công ty phải chuyển 400m3 cát tới địa điểm xây dựng ở bên kia sông bằng\\ncách thuê một chiếc xà lan. Ngoài chi phí vận chuyển một lượt đi về là 100k của chiếc xà\\nlan, công ty đó phải thiết kế một thùng hình hộp chữ nhật đặt trên xà lan để đựng cát.\\nChiếc thùng này không cần nắp, chi phí cho các mặt xung quanh là 1T/m2, cho mặt đáy là\\n2T/m2. Hỏi kích thước của chiếc thùng đó như thế nào để tổng chi phí vận chuyển là nhỏ\\nnhất. Để cho đơn giản, giả sử cát chỉ được đổ ngang hoặc thấp hơn với phần trên của thành\\nthùng, không có ngọn. Giả sử thêm rằng xà lanrộng vô hạnvà chứa được sức nặng vô hạn,\\ngiả sử này khiến bài toán dễ giải hơn.\\nPhân tích\\nGiả sử chiếc thùng cần làm có chiều dài, chiều rộng, chiều cao lần lượt làx,y,z (m). Thể\\ntích của thùng làxyz (đơn vị làm3). Có hai loại chi phí:\\n• Chi phí thuê xà lan. Số chuyến xà lan phải thuê là400\\nxyz (ta hãy tạm giả sử rằng đây là\\nmột số tự nhiên, việc làm tròn này sẽ không thay đổi kết quả đáng kể vì chi phí vận\\nchuyển một chuyến là nhỏ so với chi phí làm thùng). Số tiền phải trả cho xà lan sẽ là\\n0.1 400\\nxyz = 40\\nxyz = 40x−1y−1z−1 (0.1 ở đây là 0.1 triệu đồng).\\n• Chi phí làm thùng. Diện tích xung quanh của thùng là2(x+y)z. Diện tích đáy làxy. Vậy\\ntổng chi phí làm thùng là2(x+ y)z+ 2xy= 2(xy+ yz+ zx).\\nTổng toàn bộ chi phí làf(x,y,z ) = 40 x−1y−1z−1 + 2(xy+ yz + zx). Điều kiện ràng buộc\\nduy nhất là kích thước thùng phải là các số dương. Vậy ta có bài toán tối ưu sau đây.\\nBài toán vận chuyển:\\n(x,y) = arg min'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 313, 'page_label': '302'}, page_content='duy nhất là kích thước thùng phải là các số dương. Vậy ta có bài toán tối ưu sau đây.\\nBài toán vận chuyển:\\n(x,y) = arg min\\nx,y,z\\n40x−1y−1z−1 + 2(xy+ yz+ zx)\\nthoả mãn:x,y,z > 0\\n(24.3)\\nBài toán này thuộc loạigeometric programming (GP). Định nghĩa của GP và cách dùng\\ncông cụ tối ưu sẽ được trình bày trong phần sau của chương.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 314, 'page_label': '303'}, page_content='303 CHƯƠNG 24. BÀI TOÁN TỐI ƯU LỒI\\nBảng 24.1: Bảng các thuật ngữ và ký hiệu trong các bài toán tối ưu.\\nKý hiệu Tiếng Anh Tiếng Việt\\nx ∈Rn optimization variable biến tối ưu\\nf0 : Rn →R objective/loss/cost/function hàm mục tiêu\\nfi(x) ≤0 inequality constraint bất đẳng thức ràng buộc\\nfi : Rn →R inequality constraint function hàm bất đẳng thức ràng buộc\\nhj(x) = 0 equality constraint đẳng thức ràng buộc\\nhj : Rn →R equality constraint function hàm đẳng thức ràng buộc\\nD= ⋂m\\ni=0 domfi ∩⋂p\\nj=1 domhj domain tập xác định\\nNhận thấy rằng bài này hoàn toàn có thể dùng bất đẳng thức Cauchy để giải được, nhưng\\nchúng ta muốn một lời giải cho bài toán tổng quát sao cho có thể lập trình được.\\n(Lời giải:\\nf(x,y,z ) = 20\\nxyz + 20\\nxyz + 2xy+ 2yz+ 2zx ≥5\\n5√\\n3200\\ndấu bằng xảy ra khi và chỉ khix= y= z =\\n5√\\n10.)\\nNếu có các ràng buộc về kích thước của thùng và trọng lượng mà xà lan tải được thì có thể\\ntìm được lời giải đơn giản như thế này không?\\nNhững bài toán trên đây đều là các bài toán tối ưu. Chính xác hơn nữa, chúng đều là các bài\\ntoán tối ưu lồi (convex optimization problems) như các bạn sẽ thấy ở phần sau của chương.\\nTrước hết, chúng ta cần hiểu các khái niệm về cácbài toán tối ưu lồi convex optimization\\nproblems và tại sao chúng lại quan trọng.\\n24.2 Nhắc lại bài toán tối ưu\\n24.2.1 Các khái niệm cơ bản\\nBài toán tối ưu ở dạng tổng quát:\\nx∗= arg min\\nx\\nf0(x)\\nthoả mãn:fi(x) ≤0, i = 1,2,...,m\\nhj(x) = 0, j = 1,2,...,p\\n(24.4)\\nPhát biểu bằng lời: Tìm giá trị của biếnx để tối thiểu hàmf0(x) trong số các giá trị củax\\nthoả mãn các điệu hiện ràng buộc. Ta có bảng các khái niệm và ký hiệu trong bài toán tối\\nưu bằng cả tiếng Anh và tiếng Việt như trong Bảng 24.1. Ngoài ra,\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 315, 'page_label': '304'}, page_content='CHƯƠNG 24. BÀI TOÁN TỐI ƯU LỒI 304\\n• Khi m= p= 0, bài toán (24.4) được gọi làbài toán tối ưu không ràng buộc(unconstrained\\noptimization problem).\\n• Dlà tập xác định, tức giao của tất cả các tập xác định của mọi hàm số xuất hiện trong\\nbài toán. Tập hợp các điểm thoả mãn mọi điều kiện ràng buộc, thông thường, là một tập\\ncon củaDđược gọi làfeasible sethoặc constraint set. Khifeasible setlà một tập rỗng thì\\nta nói bài toán tối ưu (24.4) làinfeasible (vô nghiệm). Nếu một điểm nằm trongfeasible\\nset, ta gọi điểm đó làfeasible.\\n• Optimal value (giá trị tối ưu) của bài toán tối ưu (24.4) được định nghĩa là:\\np∗= inf{f0(x)|fi(x) ≤0,i = 1,...,m ; hj(x) = 0,j = 1,...,p }\\ntrong đó inf là viết tắt của hàm infimum.p∗có thể nhận các giá trị±∞. Nếu bài toán là\\ninfeasible, tức không có điểm nào thoả mãn tất cả các ràng buộc, ta coip∗ = +∞, Nếu\\nhàm mục tiêu không bị chặn dưới (unbounded below) trong tập xác định, ta coip∗= −∞.\\n24.2.2 Optimal và locally optimal points\\nMột điểmx∗được gọi là một điểmoptimal point(điểm tối ưu), hoặc lànghiệm của bài toán\\n(24.4) nếux∗là feasible vàf0(x∗) = p∗. Tấp họp tất cả cácoptimal pointđược gọi làoptimal\\nset. Nếu optimal set là một tậpkhông rỗng, ta nói bài toán (24.4) làgiải được (solvable).\\nNgược lại, nếuoptimal set là một tập rỗng, ta nóioptimal valuelà không thể đạt được(not\\nattained/ not achieved).\\nVí dụ: xét hàm mục tiêuf(x) = 1/x với ràng buộcx >0. Optimal value của bài toán này\\nlà p∗= 0 nhưng optimal set là một tập rỗng vì không có giá trị nào củax để hàm mục tiêu\\nđạt giá trị 0. Lúc này ta nóigiá trị tối ưulà không đạt được.\\nVới hàm một biến, một điểm làcực tiểucủa hàm số nếu tại đó, hàm số đạt giá trị nhỏ nhất\\ntrong một lân cận (và lân cận này thuộc tập xác định của hàm số). Trong không gian một\\nchiều, lân cận của một điểm được hiểu là tập các điểm cách điểm đó một khoảng rất nhỏ.\\nTrong không gian nhiều chiều, ta gọi một điểmx là locally optimal nếu tồn tại một giá trị\\nR> 0 sao cho:\\nf0(x) = inf\\n{\\nf0(z)|fi(z) ≤0,i = 1,...,m,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 315, 'page_label': '304'}, page_content='Trong không gian nhiều chiều, ta gọi một điểmx là locally optimal nếu tồn tại một giá trị\\nR> 0 sao cho:\\nf0(x) = inf\\n{\\nf0(z)|fi(z) ≤0,i = 1,...,m,\\nhj(z) = 0,j = 1,...,p, ∥z −x∥2 ≤R\\n}\\n(24.5)\\nNếu một điểm feasible x thoả mãn fi(x) = 0 , ta nói rằng bất đẳng thức ràng buộc thứ\\ni: fi(x) = 0 là active. Nếufi(x) <0, ta nói rằng ràng buộc này làinactive tại x.\\n24.2.3 Một vài lưu ý\\nMặc dù trong định nghĩa bài toán tối ưu (24.4) là cho bài toántối thiểu hàm mục tiêuvới\\ncác ràng buộc thoả mãn các điều kiện nhỏ hơn hoặc bằng 0, các bài toán tối ưu vớitối đa\\nhàm mục tiêuvà điều kiện ràng buộc ở dạng khác đều có thể đưa về được dạng này:\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 316, 'page_label': '305'}, page_content='305 CHƯƠNG 24. BÀI TOÁN TỐI ƯU LỒI\\n• max f0(x) ⇔min −f0(x).\\n• fi(x) ≤g(x) ⇔ fi(x) −g(x) ≤0.\\n• fi(x) ≥0 ⇔ −fi(x) ≤0.\\n• a≤fi(x) ≤b⇔ fi(x) −b≤0 và a−fi(x) ≤0.\\n• fi(x) ≤0 ⇔fi(x) + si = 0 và si ≥0. si được gọi làslack variable. Phép biến đổi đơn\\ngiản này trong nhiều trường hợp lại tỏ ra hiệu quả vì bất đẳng thứcsi ≥0 thường dễ giải\\nquyết hơn làfi(x) ≤0.\\n24.3 Bài toán tối ưu lồi\\nTrong toán tối ưu, chúng ta đặc biệt quan tâm tới những bài toán mà hàm mục tiêu là một\\nhàm lồi, vàfeasible setcũng là một tập lồi.\\n24.3.1 Định nghĩa\\nĐịnh nghĩa 24.1: Bài toán tối ưu lồi\\nMột bài toán tối ưu lồi(convex optimization problem) là một bài toán tối ưu có dạng\\nx∗= arg min\\nx\\nf0(x)\\nthoả mãn:fi(x) ≤0, i = 1,2,...,m\\nhj(x) = aT\\nj x −bj = 0,j = 1,...,\\ntrong đóf0,f1,...,f m là các hàm lồi.\\nSo với bài toán tối ưu (24.4), bài toán tối ưu lồi (24.6) có thêm ba điều kiện nữa:\\n• Hàm mục tiêulà mộthàm lồi.\\n• Các hàm bất đẳng thức ràng buộcfi là các hàm lồi.\\n• Hàm đẳng thức ràng buộchj là affine.\\nMột vài nhận xét:\\n• Tập hợp các điểm thoả mãnhj(x) = 0 là một tập lồi vì nó có dạng mộthyperplane.\\n• Khi fi là mộthàm lồi thì tập hợp các điểm thoả mãnfi(x) ≤0 chính là 0–sublevel set\\ncủa fi và là một tập lồi.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 317, 'page_label': '306'}, page_content='CHƯƠNG 24. BÀI TOÁN TỐI ƯU LỒI 306\\n• Như vậy, tập hợp các điểm thoả mãn mọi điều kiện ràng buộc chính là giao điểm của các\\ntập lồi, vì vậy nó là một tập lồi.\\nTrong bài toán tối ưu lồi, ta tối thiểu một hàm mục tiêu lồi trên một tập lồi.\\n24.3.2 Local optimum của bài toán tối ưu lồi chính là global optimum của nó\\nTính chất quan trọng nhất của bài toán tối ưu lồi chính là mọi điểmlocally optimal point\\nchính là một điểm(globally) optimal point (điểm cực tiểu chính là nghiệm của bài toán).\\nViệc này có thể chứng minh bằng phản chứng.. Gọix0 là một điểmlocally optimal:\\nf0(x0) = inf{f0(x)|x ∈ feasible set,∥x −x0∥2 ≤R}\\nvới R> 0 nào đó. Giả sửx0 không phải là một điểmglobally optimal, tức tồn tại một điểm\\nfeasible y sao chof(y) <f (x0) (hiển nhiên rằngy không nằm trong lân cận đang xét). Ta\\ncó thể tìm đượcθ∈[0,1] đủ nhỏ sao choz = (1 −θ)x0 + θy nằm trong lân cận củax0, tức\\n∥z −x0∥2 <R. Việc này có được vì feasible set là một tập lồi. Hơn nữa, vìhàm mục tiêuf0\\nlà một hàm lồi, ta có\\nf0(z) = f0((1 −θ)x0 + θy) (24.6)\\n≤(1 −θ)f0(x0) + θf0(y) (24.7)\\n<(1 −θ)f0(x0) + θf0(x0) = f0(x0) (24.8)\\nđiều này mâu thuẫn với giả thiếtx0 là một điểm cực tiểu. Vậy giả sử sai, tứcx0 chính là\\nglobally optimal pointvà ta có điều phải chứng minh. □\\nChứng minh bằng lời: giả sử một điểm cực tiểu không phải là điểm làm cho hàm số đạt giá\\ntrị nhỏ nhất. Với điều kiệnfeasible set và hàm mục tiêulà lồi, ta luôn tìm được một điểm\\nkhác trong lân cận của điểm cực tiểu đó sao cho giá trị của hàm mục tiêu tại điểm mới này\\nnhỏ hơn giá trị của hàm mục tiêu tại điểm cực tiểu. Sự mâu thuẫn này chỉ ra rằng với một\\nbài toán tối ưu lồi, điểm cực tiểu phải là điểm làm cho hàm số đạt giá trị nhỏ nhất.\\n24.3.3 Điều kiện tối ưu cho hàm mục tiêu khả vi\\nNếu hàm mục tiêuf0 là khả vi, theo first-order condition, với mọix,y ∈domf0, ta có:\\nf0(x) ≥f0(x0) + ∇f0(x0)T(x −x0) (24.9)\\nĐặt Xlà feasible set. Điều kiện cần và đủđể một điểmx0 ∈X là optimal pointlà:\\n∇f0(x0)T(x −x0) ≥0, ∀x ∈X (24.10)'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 317, 'page_label': '306'}, page_content='f0(x) ≥f0(x0) + ∇f0(x0)T(x −x0) (24.9)\\nĐặt Xlà feasible set. Điều kiện cần và đủđể một điểmx0 ∈X là optimal pointlà:\\n∇f0(x0)T(x −x0) ≥0, ∀x ∈X (24.10)\\nPhần chứng minh cho điều kiện này được bỏ qua, bạn đọc có thể tìm trong trang 139-140\\ncủa cuốn Convex Optimization [BV04].\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 318, 'page_label': '307'}, page_content='307 CHƯƠNG 24. BÀI TOÁN TỐI ƯU LỒI\\nx0\\nfeasible set X\\nlevel sets\\n−∇f0(x0)x\\nf0(x\\n0)\\nsupporting hyperplane\\nHình 24.2:Biểu diễn hình học của\\nđiều kiện tối ưu cho hàm mục tiêu\\nkhả vi. Các đường nét đứt có màu\\ntương ứng với các level sets (đường\\nđồng mức).\\nĐiều này chỉ ra rằng nếu∇f0(x0) = 0 thì x0 chính là một điểm optimal của bài toán. Nếu\\n∇f0(x0) ̸= 0 , nghiệm của bài toán sẽ phải nằm trên biên của feasible set. Thật vậy, quan sát\\nHình 24.2, điều kiện này nói rằng nếux0 là một điểm optimal thì với mọix ∈X, vector đi từ\\nx0 tới x hợp với vector−∇f0(x0) một góc tù. Nói cách khác, nếu ta vẽ mặt tiếp tuyến của\\nhàm mục tiêu tạix0 thì mọi điểm feasible nằm về một phía so với mặt tiếp tuyến này. Điều\\nnày chỉ ra rằngx0 phải nằm trên biên của feasible setX. Hơn nữa, feasible set nằm về phía\\nlàm cho hàm mục tiêu đạt giá trị cao hơnf0(x0). Mặt tiếp tuyến này chính làsupporting\\nhyperplane của feasible set tại điểmx0. Nhắc lại rằng khi vẽ các level set, chúng ta dùng\\nmàu lam để chỉ giá trị nhỏ, màu đỏ để chỉ giá trị lớn của hàm.\\n(Một mặt phẳng đi qua một điểm trên biên của một tập hợp sao cho mọi điểm trong tập\\nhợp đó nằm về một phía (hoặc nằm trên) so với mặt phẳng đó được gọi là mộtsiêu phẳng\\nhỗ trợ (supporting hyperplane). Nếu một tập hợp làlồi, tồn tạisupporting hyperplane tại\\nmọi điểm trên biên của nó.)\\n24.3.4 Giới thiệu thư viện CVXOPT\\nCVXOPT là một thư viện miễn phí trên Python đi kèm với cuốn sách Convex Optimization.\\nHướng dẫn cài đặt, tài liệu hướng dẫn, và các ví dụ mẫu của thư viện này cũng có đầy đủ\\ntrên trang web CVXOPT (http://cvxopt.org/ ). Trong phần còn lại của chương, chúng ta\\nsẽ thảo luận ba bài toán cơ bản trong convex optimization: linear programming, quadratic\\nprogramming, và geometric programming. Chúng ta sẽ cùng lập trình để giải các ví dụ đã\\nnêu ở phần đầu bài viết dựa trên thư viện CVXOPT này.\\n24.4 Linear programming\\nChúng ta cùng bắt đầu với lớp các bài toán đơn giản nhất trong convex optimization - linear'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 318, 'page_label': '307'}, page_content='nêu ở phần đầu bài viết dựa trên thư viện CVXOPT này.\\n24.4 Linear programming\\nChúng ta cùng bắt đầu với lớp các bài toán đơn giản nhất trong convex optimization - linear\\nprogramming (LP). Trong đó, hàm mục tiêuf0(.) và các hàm bất đẳng thức ràng buộc\\nfi(.),i = 1 ,...,m đều là các hàmaffine.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 319, 'page_label': '308'}, page_content='CHƯƠNG 24. BÀI TOÁN TỐI ƯU LỒI 308\\n24.4.1 Dạng tổng quát của linear programming\\nDạng tổng quát (general form) của linear programming\\nx = arg min\\nx\\ncTx + d\\nthoả mãn: Gx ⪯h (24.11)\\nAx = b\\nTrong đóG ∈Rm×n,h ∈Rm, A ∈Rp×n,b ∈Rp, c,x ∈Rn và d∈R.\\nSố vô hướngdchỉ làm thay đổi giá trị của hàm mục tiêu mà không làm thay đổi nghiệm của\\nbài toán nên có thể được lược bỏ. Nhắc lại rằng ký hiệu⪯nghĩa là mỗi phần tử trong vector\\nở vế trái nhỏ hơn hoặc bằng phần tử tương ứng trong vector ở vế phải. Chú ý rằng nhiều\\nbất đẳng thức dạnggix ≤hi, vớigi là các vector hàng, có thể viết gộp dưới dạngGx ⪯h\\ntrong đó mỗi hàng củaG ứng với mộtgi, mỗi phần tử củah tương ứng với mộthi.\\n24.4.2 Dạng tiêu chuẩn của linear programming\\nTrong dạng tiêu chuẩn (standard form) LP, các bất đẳng thức ràng buộc chỉ là điều kiện các\\nnghiệm có thành phần không âm.\\nDạng tiêu chuẩn của linear programming\\nx = arg min\\nx\\ncTx\\nthoả mãn:Ax = b\\nx ⪰0\\n(24.12)\\nDạng tổng quát (24.11) có thể được đưa về dạng tiểu chuẩn (24.12) bằng cách đặt thêm biến\\nslack s.\\nx = arg min\\nx,s\\ncTx\\nthoả mãn:Ax = b\\nGx + s = h\\ns ⪰0\\n(24.13)\\nTiếp theo, nếu ta biểu diễnx dưới dạng hiệu của hai vector mà thành phần của nó đều\\nkhông âm, tức:x = x+ −x−, vớix+,x−⪰0. Ta có thể tiếp tục viết lại (24.13) dưới dạng:\\nx = arg min\\nx+,x−,s\\ncTx+ −cTx−\\nthoả mãn:Ax+ −Ax−= b\\nGx+ −Gx−+ s = h\\nx+ ⪰0,x−⪰0,s ⪰0\\n(24.14)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 320, 'page_label': '309'}, page_content='309 CHƯƠNG 24. BÀI TOÁN TỐI ƯU LỒI\\nfeasible set X\\nLinear Programming\\nx0x1 −c\\nHình 24.3:Biểu diễn hình học của\\nlinear programming.\\nTới đây, bạn đọc có thể thấy rằng (24.14) có thể viết gọn lại như (24.12).\\n24.4.3 Minh hoạ bằng hình học của bài toán linear programming\\nCác bài toán LP có thể được minh hoạ như Hình 24.3. Điểmx0 chính là điểm làm cho hàm\\nmục tiêu đạt giá trị nhỏ nhất, điểmx1 chính là điểm làm cho hàm mục tiêu đạt giá trị lớn\\nnhất. Nghiệm của các bài toán LP, nếu có, thường là một điểm ởđỉnh của polyheron feasible\\nset hoặc là mộtmặt của polyhedron đó (trong trường hợp các đường level sets của hàm mục\\ntiêu song song với mặt đó, và trên mặt đó, hàm mục tiêu đạt giá trị tối ưu).\\nTiếp theo, chúng ta sẽ dùng thư viện CVXOPT để giải các bài toán LP.\\n24.4.4 Giải LP bằng CVXOPT\\nNhắc lại bài toán canh tác\\n(x,y) = arg max\\nx,y\\n5x+ 3y\\nthoả mãn:x+ y≤10\\n2x+ y≤16\\nx+ 4y≤32\\nx,y ≥0\\n(24.15)\\nCác điều kiện ràng buộc có thể viết lại dưới dạngGx ⪯h, trong đó\\nG =\\n\\uf8ee\\n\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8f0\\n1 1\\n2 1\\n1 4\\n−1 0\\n0 −1\\n\\uf8f9\\n\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fb\\nh =\\n\\uf8ee\\n\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8f0\\n10\\n16\\n32\\n0\\n0\\n\\uf8f9\\n\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fb\\nKhi sử dụng CVXOPT, chúng ta lập trình như sau:\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 321, 'page_label': '310'}, page_content='CHƯƠNG 24. BÀI TOÁN TỐI ƯU LỒI 310\\nfrom cvxopt import matrix, solvers\\nc = matrix([-5., -3.]) # since we need to maximize the objective funtion\\nG = matrix([[1., 2., 1., -1., 0.], [1., 1., 4., 0., -1.]])\\nh = matrix([10., 16., 32., 0., 0.])\\nsolvers.options[’show_progress’] = False\\nsol = solvers.lp(c, G, h)\\nprint(’Solution\"’)\\nprint(sol[’x’])\\nKết quả:\\nSolution:\\n[ 6.00e+00]\\n[ 4.00e+00]\\nNghiệm này chính là nghiệm mà chúng ta đã tìm được trong phần đầu của bài viết dựa trên\\nbiểu diễn hình học.\\nMột vài lưu ý:\\n• Hàm solvers.lp của cvxopt giải bài toán (24.13).\\n• Trong bài toán của chúng ta, vì ta cần tìm giá trị lớn nhất nên ta phải đổi hàm mục tiêu\\nvề dạng−5x−3y. Chính vì vậy màc = matrix([−5., −3.]).\\n• Hàm matrix nhận đầu vào là mộtlist (trong Python),list này thể hiện một vector cột.\\nNếu muốn biểu diễn một ma trận, đầu vào củamatrix là mộtlist của list, trong đó mỗi\\nlist bên trong thể hiện một vector cột của ma trận đó.\\n• Các hằng số trong bài toán cần ở dạng số thực. Nếu chúng là các số nguyên, ta cần thêm\\ndấu . vào sau các số đó thể thể hiện đó là số thực.\\n• Với đẳng thức ràng buộcAx = b, solvers.lp lấy giá trị mặc định củaA và b là None, tức\\nnếu không khái báo thì nghĩa là không có đẳng thức ràng buộc nào.\\nVới các tuỳ chọn khác, bạn đọc có thể tìm trong tài liệu của CVXOPT(https://goo.gl/\\nq5CZmz). Việc giải Bài toán NXB bằng CVXOPT xin nhường lại cho bạn đọc.\\n24.5 Quadratic programming\\n24.5.1 Bài toán quadratic programming\\nMột dạng bài toán convex optimization phổ biến khác làquadratic programming(QP). Khác\\nbiệt duy nhất của QP so với LP là hàm mục tiêu códạng toàn phương(quadratic form).\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 322, 'page_label': '311'}, page_content='311 CHƯƠNG 24. BÀI TOÁN TỐI ƯU LỒI\\n−∇f0(x0)\\nfeasible set X\\nQuadratic Programming\\nx0\\nHình 24.4:Biểu diễn hình học của\\nQuadratic Programming.\\nQuadratic Programming\\nx = arg min\\nx\\n1\\n2xTPx + qTx + r\\nthoả mãn:Gx ⪯h\\nAx = b\\n(24.16)\\nTrong đóP là một ma trận vuông nửa xác định dương bậcn, G ∈Rm×n,A ∈Rp×n.\\nĐiều kiện nửa xác định dương củaP để đảm bảo rằng hàm mục tiêu là convex. Trong QP,\\nmột hàm quadratic lồi được tối thiểu trên mộtpolyhedron (Xem Hình 24.4). LP chính là\\nmột trường hợp đặc biệt của QP vớiP = 0.\\n24.5.2 Ví dụ về QP\\nBài toán vui:Có một hòn đảo có dạng một đa giác lồi. Một con thuyền ở ngoài biển thì\\ncần đi theo hướng nào để tới đảo nhanh nhất, giả sử rằng tốc độ của sóng và gió bằng 0. Có\\nthể thấy rằng nghiệm của bài toán chính là một góc của đảo gần con thuyền nhất hoặc hình\\nchiếu vuông góc của thuyền tới cạnh gần nhất của đảo. Đây chính là bài toán tìm khoảng\\ncách từ một điểm tới một polyhedron.\\nBài toán tìm khoảng cách từ một điểm tới một polyhedron: cho một polyhedron là tập hợp\\ncác điểm thoả mãnAx ⪯b, và một điểmu, tìm điểmx thuộc polyhedron đó sao cho khoảng\\ncách Euclidean giữax và u là nhỏ nhất. Đây là một bài toán QP có dạng\\nx = arg min\\nx\\n1\\n2∥x −u∥2\\n2\\nthoả mãn: Gx ⪯h\\nHàm mục tiêu đạt giá trị nhỏ nhất bằng 0 nếuu nằm trong polyheron đó và nghiệm chính\\nlà x = u. Khiu không nằm trong polyhedron, ta viết\\n1\\n2∥x −u∥2\\n2 = 1\\n2(x −u)T(x −u) = 1\\n2xTx −uTx + 1\\n2uTu\\nBiểu thức này có dạng hàm mục tiêu như trong (24.16) vớiP = I,q = −u,r = 1\\n2 uTu, trong\\nđó I là ma trận đơn vị.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 323, 'page_label': '312'}, page_content='CHƯƠNG 24. BÀI TOÁN TỐI ƯU LỒI 312\\nx\\ny\\nx\\n+\\ny\\n= 10\\n2\\nx\\n+\\ny\\n= 16\\nx + 4 y = 32\\n(0 , 0)\\n(10 , 10)\\nHình 24.5: Ví dụ về khoảng\\ncách giữa một điểm và một\\npolyhedron.\\n24.5.3 Giải QP bằng CVXOPT\\nXét bài toán được cho trên Hình 24.5. Ta cần tìm khoảng cách từ điểm có toạ độ(10,10)\\ntới hình đa giác lồi màu xám. Chú ý rằng khoảng cách từ một điểm tới một tập hợp chính\\nlà khoảng cách từ điểm đó tới điểm gần nhất trong tập hợp. Bài toán này được viết dưới\\ndạng QP như sau:\\n(x,y) = arg min\\nx,y\\n(x−10)2 + (y−10)2\\nthoả mãn:\\n\\uf8ee\\n\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8f0\\n1 1\\n2 1\\n1 4\\n−1 0\\n0 −1\\n\\uf8f9\\n\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fb\\n[x\\ny\\n]\\n⪯\\n\\uf8ee\\n\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8f0\\n10\\n16\\n32\\n0\\n0\\n\\uf8f9\\n\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fb\\nFeasible settrong bài toán được lấy từ Bài toán canh tác, vàu = [10,10]T. Bài toán này có\\nthể được giải bằng CVXOPT như sau:\\nfrom cvxopt import matrix, solvers\\nP = matrix([[1., 0.], [0., 1.]])\\nq = matrix([-10., -10.])\\nG = matrix([[1., 2., 1., -1., 0.], [1., 1., 4., 0., -1.]])\\nh = matrix([10., 16., 32., 0., 0])\\nsolvers.options[’show_progress’] = False\\nsol = solvers.qp(P, q, G, h)\\nprint(’Solution:’)\\nprint(sol[’x’])\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 324, 'page_label': '313'}, page_content='313 CHƯƠNG 24. BÀI TOÁN TỐI ƯU LỒI\\nKết quả:\\nSolution:\\n[ 5.00e+00]\\n[ 5.00e+00]\\nNhư vậy, nghiệm của bài toán tối ưu này là điểm có toạ độ(5,5) .\\n24.6 Geometric Programming\\nTrong mục này, chúng ta cùng thảo luận một lớp các bài toánkhông lồi khi quan sát hàm\\nmục tiêu và các hàm ràng buộc, nhưng có thể được biến đổi về dạnglồi bằng một vài kỹ thuật\\nkhông quá phức tạp. Trước hết, ta làm quen với hai khái niệmmonomial và posynomial.\\n24.6.1 Monomial và posynomial\\nMột hàm sốf : Rn →R với tập xác đinh domf = Rn\\n++ (tất cả các phần tử đều là số dương)\\ncó dạng\\nf(x) = cxa1\\n1 xa2\\n2 ...x an\\nn (24.17)\\ntrong đóc> 0 và ai ∈R, được gọi là mộtmonomial function (khái niệm này khá giống với\\nđơn thứctrong chương trình phổ thông, nhưng sách giáo khoa định nghĩa vớicbất kỳ vàai\\nlà các số tự nhiên).\\nTổng của các monomial\\nf(x) =\\nK∑\\nk=1\\nckxa1k\\n1 xa2k\\n2 ...x ank\\nn (24.18)\\ntrong đó cácck >0, được gọi làposynomial function(đa thức), hoặc đơn giản làposynomial.\\n24.6.2 Geometric programming\\nGeometric programming (GP)\\nx = arg min\\nx\\nf0(x)\\nthoả mãn:fi(x) ≤1, i = 1,2,...,m\\nhj(x) = 1, j = 1,2,...,p\\n(24.19)\\ntrong đóf0,f1,...,f m là các posynomials vàh1,...,h p là các monomials.\\nĐiều kiệnx ≻0 đã được ẩn đi.\\nChú ý rằng nếuf là mộtposynomial, h là mộtmonomial thì f/h là mộtposynomial.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 325, 'page_label': '314'}, page_content='CHƯƠNG 24. BÀI TOÁN TỐI ƯU LỒI 314\\nVí dụ, bài toán tối ưu\\n(x,y,z ) = arg min\\nx,y,z\\nx/y\\nthoả mãn: 1 ≤x≤2 (24.20)\\nx3 + 2y/z ≤√y\\nx/y= z\\ncó thể được viết lại dưới dạng GP:\\n(x,y,z ) = arg min\\nx,y,z\\nxy−1\\nthoả mãn: x−1 ≤1 (24.21)\\n(1/2)x≤1\\nx3y−1/2 + 2y1/2z−1 ≤1\\nxy−1z−1 = 1\\nBài toán này rõ ràng làkhông lồi vì cả hàm mục tiêu và điều kiển ràng buộc đều không lồi.\\n24.6.3 Biến đổi GP về dạng bài toán tối ưu lồi\\nGP có thể được biến đổi về dạng lồi bằng cách sau đây. Đặtyi = log(xi), tứcxi = exp(yi).\\nNếu f là mộtmonomial function của x thì:\\nf(x) = c(exp(y1))a1 ... (exp(yn))an = cexp\\n( n∑\\ni=1\\naiyi\\n)\\n= exp(aTy + b)\\nvới b = log(c). Lúc này, hàm sốg(y) = exp( aTy + b) là một hàm lồi theoy. (Bạn đọc có\\nthể chứng minh theo định nghĩa rằng hợp của hai hàm lồi là một hàm lồi. Trong trường hợp\\nnày, hàmexp và hàmaffine trên đều là các hàm lồi.)\\nTương tự như thế,posynomial trong đẳng thức (24.18) có thể được viết dưới dạng\\nf(x) =\\nK∑\\nk=1\\nexp(aT\\nky + bk)\\ntrong đóak = [a1k,...,a nk]T,bk = log(ck) và yi = log(x). Lúc này,posynomial đã được viết\\ndưới dạng tổng của các hàmexp của các hàmaffine, và vì vậy là một hàm lồi theoy, nhắc\\nlại rằng tổng của các hàm lồi là một hàm lồi.\\nBài toán GP (24.19) được viết lại dưới dạng:\\ny = arg min\\ny\\nK0∑\\nk=1\\nexp(aT\\n0ky + b0k)\\nthoả mãn:\\nKi∑\\nk=1\\nexp(aT\\niky + bik) ≤1, i = 1,...,m\\nexp(gT\\nj y + hj) = 1, j= 1,...,p\\n(24.22)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 326, 'page_label': '315'}, page_content='315 CHƯƠNG 24. BÀI TOÁN TỐI ƯU LỒI\\nvới aik ∈Rn, ∀i= 1,...,p và gj ∈Rn, ∀j = 1,...,p .\\nVới chú ý rằng hàm sốlog (∑m\\ni=1 exp(gi(z))) là môt hàmlồi theo z nếu gi là các hàmlồi\\n(xin bỏ qua phần chứng minh), ta có thể viết lại bài toán (24.22) dưới dạnglồi bằng cách\\nlấy log của các hàm như sau.\\nGeometric programming dưới dạng bài toán tối ưu lồi\\nminimizey ˜f0(y) = log\\n(K0∑\\nk=1\\nexp(aT\\n0ky + bi0)\\n)\\nthoả mãn: ˜fi(y) = log\\n(Ki∑\\nk=1\\nexp(aT\\niky + bik)\\n)\\n≤0, i = 1,...,m\\n˜hj(y) = gT\\nj y + hj = 0, j = 1,...,p\\n(24.23)\\nLúc này, ta có thể nói rằng GP tương đương với một bài toán tối ưu lồi vì hàm mục tiêu\\nvà các hàm bất đẳng thức ràng buộc trong (24.23) đều là hàm lồi, đồng thời điều hiện đẳng\\nthức cuối cùng chính là dạngaffine. Dạng này thường được gọi làgeometric program in\\nconvex form(để phân biệt nó với dạng định nghĩa của GP).\\n24.6.4 Giải GP bằng CVXOPT\\nQuay lại ví dụ về Bài toán đóng thùngkhông có ràng buộcvà hàm mục tiêu làf(x,y,z ) =\\n40x−1y−1z−1 + 2xy+ 2yz+ 2zx là một posynomial. Vậy đây là một GP.\\nNghiệm của bài toán có thể được tìm bằng CVXOPT như sau:\\nfrom cvxopt import matrix, solvers\\nfrom math import log, exp# gp\\nfrom numpy import array\\nimport numpy as np\\nK = [4] # number of monomials\\nF = matrix([[-1., 1., 1., 0.],\\n[-1., 1., 0., 1.],\\n[-1., 0., 1., 1.]])\\ng = matrix([log(40.), log(2.), log(2.), log(2.)])\\nsolvers.options[’show_progress’] = False\\nsol = solvers.gp(K, F, g)\\nprint(’Solution:’)\\nprint(np.exp(np.array(sol[’x’])))\\nprint(’\\\\nchecking sol^5’)\\nprint(np.exp(np.array(sol[’x’]))**5)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 327, 'page_label': '316'}, page_content='CHƯƠNG 24. BÀI TOÁN TỐI ƯU LỒI 316\\nKết quả:\\nSolution:\\n[[ 1.58489319]\\n[ 1.58489319]\\n[ 1.58489319]]\\nchecking sol^5\\n[[ 9.9999998]\\n[ 9.9999998]\\n[ 9.9999998]]\\nNghiệm thu được chính làx= y= z =\\n5√\\n10. Bạn đọc được khuyến khích đọc thêm chỉ dẫn\\ncủa hàmsolvers.gp (https://goo.gl/5FEBtn ) để hiểu cách thiết lập và giải bài toán GP.\\n24.7 Tóm tắt\\n• Các bài toán tối ưu xuất hiện rất nhiều trong thực tế, trong đó tối ưu lồi đóng một vai\\ntrò quan trọng. Trong bài toán tối ưu lồi, nếu tìm được cực trị thì cực trị đó chính là một\\nđiểm optimal của bài toán (nghiệm của bài toán).\\n• Có nhiều bài toán tối ưu không được viết dưới dạng lồi nhưng có thể biến đổi về dạng\\nlồi, ví dụ như bài toán geometric programming.\\n• Linear programming và quadratic programming đóng một vài trò quan trọng trong toán\\ntối ưu, được sử dụng nhiều trong các thuật toán Machine Learning.\\n• Thư viện CVXOPT được dùng để tối ưu nhiều bài toán tối ưu lồi, rất dễ sử dụng và thời\\ngian chạy tương đối nhanh. Phù hợp với mục đích học tập và nghiên cứu.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 328, 'page_label': '317'}, page_content='Chương 25\\nDuality\\n25.1 Giới thiệu\\nTrong Chương 23, chúng ta đã làm quen với các khái niệm về tập hợp lồi và hàm số lồi. Tiếp\\ntheo đó, trong Chương 24, chúng ta đã thảo luận các bài toán tối ưu lồi, cách nhận dạng và\\ncách sử dụng thư viện để giải các bài toán tối ưu lồi cơ bản. Trong chương này, chúng ta sẽ\\ntiếp tục tiếp cận một cách sâu hơn: các điều kiện về nghiệm của các bài toán tối ưu, cả lồi\\nvà không lồi;bài toán đối ngẫu(dual problem) và điều kiện KKT.\\nTrước tiên chúng ta xét bài toán mà ràng buộc chỉ là một phương trình:\\nx = arg min\\nx\\nf0(x)\\nthoả mãn:f1(x) = 0\\n(25.1)\\nBài toán này là bài toán tổng quát, không nhất thiết phải lồi. Tức hàm mục tiêu và hàm\\nràng buộc không nhất thiết phải lồi. Bài toán này có thể được giải bằng phương pháp nhân\\ntử Lagrange (xem Phụ Lục A). Cụ thể, xét hàm sốL(x,λ) = f0(x) + λf1(x). Chú ý rằng,\\ntrong hàm số này, chúng ta có thêm một biến nữa làλ, biến này được gọi lànhân tử Lagrange\\n(Lagrange multiplier). Hàm sốL(x,λ) được gọi làhàm hỗ trợ(auxiliary function), haythe\\nLagrangian. Người ta đã chứng minh được rằng, điểmoptimal valuecủa bài toán (25.1) thoả\\nmãn điều kiện∇x,λL(x,λ) = 0. Điều này tương dương với\\n∇xf0(x) + λ∇xf1(x) = 0 (25.2)\\nf1(x) = 0 (25.3)\\nĐể ý rằng điều kiện thứ hai chính là∇λL(x,λ) = 0, và cũng chính là ràng buộc trong bài\\ntoán (25.1). Việc giải hệ phương trình (25.2) - (25.3), trong nhiều trường hợp, đơn giản hơn\\nviệc trực tiếp đi tìmoptimal valuecủa bài toán (25.1). Một vài ví dụ về phương pháp nhân\\ntử Lagrange có thể được tìm thấy tại Phụ Lục A.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 329, 'page_label': '318'}, page_content='CHƯƠNG 25. DUALITY 318\\n25.2 Hàm đối ngẫu Lagrange\\n25.2.1 Lagrangian\\nVới bài toán tối ưu tổng quát\\nx∗= arg min\\nx\\nf0(x)\\nthoả mãn:fi(x) ≤0, i = 1,2,...,m\\nhj(x) = 0, j = 1,2,...,p\\n(25.4)\\nvới miền xác đinhD= (∩m\\ni=0domfi) ∩(∩p\\nj=1domhj). Chú ý rằng, chúng ta đang không giả\\nsử về tính chất lồi của hàm tối ưu hay các hàm ràng buộc ở đây. Giả sử duy nhất ở đây là\\nD̸= ∅(tập rỗng). Bài toán tối ưu này còn được gọi làbài toán chính(primal problem).\\nLagrangian cũng được xây dựng tương tự với mỗi nhân tử Lagrange cho một (bất) phương\\ntrình ràng buộc:\\nL(x,λ,ν) = f0(x) +\\nm∑\\ni=1\\nλifi(x) +\\np∑\\nj=1\\nνjhj(x)\\nvới λ= [λ1,λ2,...,λ m]; ν= [ν1,ν2,...,ν p] là các vectors và được gọi làbiến đối ngẫu(dual\\nvariables) hoặc vector nhân tử Lagrange(Lagrange multiplier vectors). Lúc này nếu biến\\nchính x ∈Rn thì tổng số biến của hàm số này sẽ làn+ m+ p.\\n25.2.2 Hàm đối ngẫu Lagrange\\nHàm đối ngẫu Lagrange(the Lagrange dual function) của bài toán tối ưu (hoặc gọn làhàm\\nsố đối ngẫu) (25.4) là một hàm của các biến đối ngẫuλvàν, được định nghĩa là giá trị nhỏ\\nnhất theox của Lagrangian:\\ng(λ,ν) = inf\\nx∈D\\nL(x,λ,ν) = inf\\nx∈D\\n(\\nf0(x) +\\nm∑\\ni=1\\nλifi(x) +\\np∑\\nj=1\\nνjhj(x)\\n)\\n(25.5)\\nNếu Lagrangian không bị chặn dưới, hàm đối ngẫu tạiλ,ν sẽ lấy giá trị−∞.\\nĐặc biệt quan trọng:\\n• inf được lấy trên miềnx∈D, tức miền xác định của bài toán (là giao của miền xác định\\ncủa mọi hàm trong bài toán). Miền xác định này khác vớifeasible set – là tập hợp các\\nđiểm thoả mãn các ràng buộc.Feasible setlà một tập con của miền xác địnhD.\\n• Với mỗix, Lagrangian là một hàmaffine của (λ,ν), tức là một hàm vừa convex, vừa\\nconcave. Vậy, hàm đối ngẫu chính là một pointwise infimum của (có thể vô hạn) các hàm\\nconcave, tức là một hàm concave. Vậyhàm đối ngẫu của một bài toán tối ưu bất\\nkỳ là một hàm concave, bất kể bài toán ban đầu có phải là convex hay không.\\nNhắc lại rằngpointwise supremumcủa các hàmconvex là một hàmconvex, và một hàm\\nlà concave nếu khi đổi dấu hàm đó, ta được một hàmconvex (xem thêm Mục 23.3.2).'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 329, 'page_label': '318'}, page_content='Nhắc lại rằngpointwise supremumcủa các hàmconvex là một hàmconvex, và một hàm\\nlà concave nếu khi đổi dấu hàm đó, ta được một hàmconvex (xem thêm Mục 23.3.2).\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 330, 'page_label': '319'}, page_content='319 CHƯƠNG 25. DUALITY\\n25.2.3 Chặn dưới của giá trị tối ưu\\nNếu p∗là optimal value (giá trị tối ưu) của bài toán (25.4) thì với các biến đối ngẫuλi ≥0,∀i\\nvà ν bất kỳ, chúng ta sẽ có\\ng(λ,ν) ≤p∗ (25.6)\\nTính chất này có thể được chứng minh như sau. Giả sửx0 là một điểmfeasible bất kỳ của\\nbài toán (25.4), tức thoả mãn các điều kiện ràng buộcfi(x0) ≤0,∀i = 1,...,m ; hj(x0) =\\n0,∀j = 1,...,p , ta sẽ có\\nL(x0,λ,ν) = f0(x0) +\\nm∑\\ni=1\\nλifi(x0)\\ued19 \\ued18\\ued17 \\ued1a\\n≤0\\n+\\np∑\\nj=1\\nνjhj(x0)\\ued19 \\ued18\\ued17 \\ued1a\\n=0\\n≤f0(x0)\\nVì điều này đúng với mọix0 feasible, ta sẽ có tính chất quan trọng sau đây:\\ng(λ,ν) = inf\\nx∈D\\nL(x,λ,ν) ≤L(x0,λ,ν) ≤f0(x0).\\nKhi x0 = x∗ (optimal point), f0(x0) = p∗, ta suy ra bất đẳng thức (25.6). Bất đẳng thức\\nquan trọng này chỉ ra rằng giá trị tối ưu của hàm mục tiêu trong dual problem (25.4) không\\nnhỏ hơn giá trị lớn nhất của hàm đối ngẫu Lagrangeg(λ,ν).\\n25.2.4 Ví dụ\\nVí dụ 1:Xét bài toán tối ưu\\nx= arg min\\nx\\nx2 + 10 sin(x) + 10\\nthoả mãn:(x−2)2 ≤4\\n(25.7)\\nVới bài toán này, miền xác địnhD= R nhưng feasible set là 0 ≤x ≤4. Đồ thị của hàm\\nmục tiêu được minh hoạ bởi đường đậm màu lam trong Hình 25.1a. Hàm số ràng buộc\\nf1(x) = (x−2)2 −4 được cho bởi đường nét đứt màu lục. Optimal value của bài toán này có\\nthể được nhận ra là điểm trên đồ thị có hoành độ bằng 0 (là điểm nhỏ nhất trên đường màu\\nlam trong đoạn[0,4]). Chú ý rằng hàm mục tiêu ở đây không phải là hàm lồi nên bài toán\\ntối ưu này cũng không phải là lồi, mặc dù hàm bất phương trình ràng buộcf1(x) là lồi.\\nLagrangian của bài toàn này có dạng\\nL(x,λ) = x2 + 10 sin(x) + 10 +λ((x−2)2 −4)\\nCác đường dấu chấm màu đỏ trong Hình 25.1a là các đường ứng với cácλkhác nhau. Vùng\\nbị chặn giữa hai đường thẳng đứng màu đen thể hiện miềnfeasible của bài toán tối ưu.\\nVới mỗiλ, dual function được định nghĩa là:\\ng(λ) = inf\\nx\\n(\\nx2 + 10 sin(x) + 10 +λ((x−2)2 −4)\\n)\\n, λ ≥0.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 331, 'page_label': '320'}, page_content='CHƯƠNG 25. DUALITY 320\\n−4 −2 0 2 4 6\\nx\\n−30\\n−20\\n−10\\n0\\n10\\n20\\n30\\n40\\nf0(x)\\nf1(x)\\nf0(x) + λf1(x)\\n(a)\\n0 2 4 6 8\\nλ\\n−7 .5\\n−5.0\\n−2.5\\n0 .0\\n2.5\\n5.0\\n7 .5\\n10.0\\ng(λ)\\np∗ (b)\\nHình 25.1:Ví dụ về dual function. (a) Đường màu lam đậm thể hiện hàm mục tiêu. Đường nét\\nđứt mà lục thể hiện hàm số ràng buộc. Các đường nét đứt màu đỏ thể hiện dual function ứng\\nvới cácλkhác nhau. (b) Đường nét đứt thể hiện giá trị tối ưu của bài toán . Đường màu đỏ thể\\nhiện dual function. Với mọiλ, giá trị của hàm dual function nhỏ hơn hoặc bằng giá trị tối ưu của\\nbài toán gốc (source code cho hình vẽ này có thể được tìm thấy tạihttps://goo.gl/jZiRCp .).\\nTừ Hình 25.1a, ta có thể thấy ngay rằng với cácλ khác nhau, giá củag(λ) hoặc tại điểm\\ncó hoành độ bằng 0 của đường màu lam, hoặc tại một điểm thấp hơn điểm đó. Đồ thị của\\nhàm g(λ) được cho bởi đường liền màu đỏ ở Hình 25.1b. Đường nét đứt màu lam thể hiện\\noptimal value của bài toán tối ưu ban đầu. Ta có thể thấy ngay hai điều:\\n• Đường liền màu đỏ luôn nằm dưới (hoặc có đoạn trùng) với đường nét đứt màu lam.\\n• Hàm g(λ) có dạng một hàm concave, tức nếu talật đồ thị này theo chiều trên-dưới thì\\nđạt được đồ thị của một hàm convex.\\nSource code cho Hình 25.1 có thể được tìm thấy tạihttps://goo.gl/jZiRCp .\\nVí dụ 2 Xét một bài toán linear programming:\\nx= arg min\\nx\\ncTx\\nthoả mãn:Ax = b\\nx ⪰0\\n(25.8)\\nHàm ràng buộc cuối cùng có thể được viết lại là:fi(x) = −xi,i = 1,...,n . Lagrangian của\\nbài toán này là\\nL(x,λ,ν) = cTx −\\nn∑\\ni=1\\nλixi + νT(Ax −b) = −bTν+ (c + ATν−λ)Tx\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 332, 'page_label': '321'}, page_content='321 CHƯƠNG 25. DUALITY\\n(đừng quên điều kiệnλ⪰0.) Dual function của nó là\\ng(λ,ν) = inf\\nx\\nL(x,λ,ν) = −bTν+ inf\\nx\\n(c + ATν−λ)Tx (25.9)\\nNhận thấy rằng một hàm tuyến tínhdTx của x bị chặn dưới khi vào chỉ khid = 0. Vì chỉ\\nnếu một phần tửdi của d khác 0, ta chỉ cần chọnxi rất lớn và ngược dấu vớidi, ta sẽ có\\nmột giá trị nhỏ tuỳ ý. Nói cách khác,g(λ,ν) = −∞trừ khic + ATν−λ= 0. Tóm lại,\\ng(λ,ν) =\\n{\\n−bTν nếu c + ATν−λ= 0\\n−∞ o.w. (25.10)\\nTrường hợp thứ hai khig(λ,ν) = −∞chúng ta sẽ gặp rất nhiều sau này. Trường hợp này\\nkhông nhiều thú vị vì hiển nhiêng(λ,ν) ≤p∗. Vì mục đích chính là đi tìm chặn dưới củap∗\\nnên ta sẽ chỉ quan tâm tới các giá trị củaλvà ν sao chog(λ,ν) càng lớn càng tốt. Trong\\nbài toán này, ta sẽ quan tâm tới cácλvà ν sao choc + ATν−λ= 0.\\n25.3 Bài toán đối ngẫu Lagrange\\nVới mỗi cặp(λ,ν), hàm đối ngẫu Lagrange cho chúng ta một chặn dưới chooptimal value\\np∗ của bài toán gốc (25.4). Câu hỏi đặt ra là: với cặp giá trị nào của(λ,ν), chúng ta sẽ có\\nmột chặn dưới tốt nhất củap∗? Nói cách khác, ta đi cần giải bài toán\\nλ∗,ν∗= arg max\\nλ,ν\\ng(λ,ν)\\nthoả mãn:λ⪰0\\n(25.11)\\nQuan trọng, vì hàmg(λ,ν) là concave và hàm ràng buộcfi(λ) = −λi là các hàmconvex.\\nVậy bài toán (25.11) chính là một bài toán convex. Vì vậy trong nhiều trường hợp, lời giải\\ncó thể dễ tìm hơn là bài toán gốc. Chú ý rằng, bài toán tối ưu này là convex bất kể bài toán\\ngốc (25.4) có là convex hay không.\\nBài toán tối ưu này dược gọi làbài toán đối ngẫu Lagrange(Lagrange dual problem) ứng\\nvới bài toán chính (25.4). Ngoài ra, có một khái niệm nữa được gọi làdual feasible tức là\\nfeasible setcủa bài toán đối ngẫu, bao gồm điều kiệnλ⪰0 và điều kiện ẩng(λ,ν) >−∞\\n(điều kiện này được thêm vào vì ta chỉ quan tâm tới các(λ,ν) sao cho hàm mục tiêu của\\nbài toán đối ngẫu càng lớn càng tốt). Nghiệm của bài toán đối ngẫu (25.11), được ký hiệu\\nlà (λ∗,ν∗), được gọi làdual optimal hoặc optimal Lagrange multipliers.\\nChú ý rằng điều kiện ẩng(λ,ν) > −∞, trong nhiều trường hợp, cũng có thể được viết cụ'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 332, 'page_label': '321'}, page_content='là (λ∗,ν∗), được gọi làdual optimal hoặc optimal Lagrange multipliers.\\nChú ý rằng điều kiện ẩng(λ,ν) > −∞, trong nhiều trường hợp, cũng có thể được viết cụ\\nthể. Quay lại với ví dụ phía trên, điệu kiện ẩn có thể được viết thànhc+ ATν−λ= 0. Đây\\nlà một hàm affine. Vì vậy, khi có thêm ràng buộc này, ta vẫn được một bài toán lồi.\\n25.3.1 Weak duality\\nKý hiệu giá trị tối ưu của bài toán đối ngẫu (25.11) làd∗. Theo (25.6), ta đã biết rằng\\nd∗ ≤p∗. Tính chất đơn giản này được gọi làweak duality. Tuy đơn giản nhưng nó cực kỳ\\nquan trọng.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 333, 'page_label': '322'}, page_content='CHƯƠNG 25. DUALITY 322\\nTa quan sát thấy hai điều:\\n• Nếu bài toán gốc không bị chặn dưới, tứcp∗= −∞, ta phải cód∗= −∞, tức là bài toán\\nđối ngẫu Lagrange làinfeasible (tức không có giá trị nào thoả mãn ràng buộc).\\n• Nếu hàm mục tiêu trong bài toán đối ngẫu không bị chặn trên, tứcd∗ = +∞, chúng ta\\nphải cóp∗= +∞, tức bài toán gốc làinfeasible.\\nGiá trị p∗−d∗ được gọi làoptimal duality gap(dịch thô làkhoảng cách đối ngẫu tối ưu).\\nKhoảng cách này luôn luôn là một số không âm.\\nĐôi khi có những bài toán (lồi hoặc không) rất khó giải, nhưng ít nhất nếu ta có thể tìm\\nđược d∗, ta có thể biết được chặn dưới của bài toán gốc. Việc tìmd∗ thường khả thi vì bài\\ntoán đối ngẫu luôn luôn là lồi.\\n25.3.2 Strong duality và Slater’s constraint qualification\\nNếu đẳng thứcp∗ = d∗ thoả mãn, the optimal duality gapbằng không, ta nói rằngstrong\\nduality xảy ra. Lúc này, việc giải bài toán đối ngẫu đã giúp ta tìm đượcchính xácgiá trị tối\\nưu của bài toán gốc.\\nThật không may,strong dualitykhông thường xuyên xảy ra trong các bài toán tối ưu. Tuy\\nnhiên, nếu bài toán gốc là lồi, tức có dạng\\nx= arg min\\nx\\nf0(x)\\nthoả mãn:fi(x) ≤0,i = 1,2,...,m\\nAx = b\\n(25.12)\\ntrong đóf0,f1,...,f m là các hàm lồi, chúng tathường (không luôn luôn) cóstrong duality.\\nCó rất nhiều nghiên cứu thiết lập các điều kiện, ngoài tính chất lồi, đểstrong duality xảy\\nra. Những điều kiện đó thường có tên làconstraint qualifications.\\nMột trong cácconstraint qualificationđơn giản nhất làSlater’s condition.\\nĐịnh nghĩa 25.1: Strictly feasible\\nMột điểmfeasible của bài toán (25.12) được gọi làstrictly feasiblenếu:\\nfi(x) <0, i= 1,2,...,m, Ax = b\\ntức các dấu bằng trong các bất đẳng thức ràng buộc không xảy ra.\\nĐịnh lý 25.1: Slater\\nNếu tồn tại một điểmstrictly feasible(bài toán gốc là lồi) thìstrong dualityxảy ra.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 334, 'page_label': '323'}, page_content='323 CHƯƠNG 25. DUALITY\\nĐiều kiện khá đơn giản sẽ giúp ích cho nhiều bài toán tối ưu sau này.\\nChú ý:\\n• Strong duality không thường xuyên xảy ra. Với các bài toán lồi, việc này xảy rathường\\nxuyên hơn. Tồn tại những bài toán lồi màstrong dualitykhông xảy ra.\\n• Có những bài toán không lồi nhưngstrong dualityvẫn xảy ra. Ví dụ như bài toán trong\\nHình 25.1 phía trên.\\n25.4 Các điều kiện tối ưu\\n25.4.1 Complementary slackness\\nGiả sử rằngstrong dualityxảy ra. Gọix∗ là một điểmoptimal của bài toán gốc và(λ∗,ν∗)\\nlà cặp điểmoptimal của bài toán đối ngẫu. Ta có\\nf0(x∗) = g(λ∗,ν∗) (25.13)\\n= inf\\nx\\n(\\nf0(x) +\\nm∑\\ni=1\\nλ∗\\nifi(x) +\\np∑\\nj=1\\nν∗\\njhj(x)\\n)\\n(25.14)\\n≤f0(x∗) +\\nm∑\\ni=1\\nλ∗\\nifi(x∗) +\\np∑\\nj=1\\nν∗\\njhj(x∗) (25.15)\\n≤f0(x∗) (25.16)\\nĐẳng thức (25.13) xảy ra dostrong duality. Đẳng thức (25.14) xảy ra do định nghĩa của\\nhàm đối ngẫu. Bất đẳng thức (25.15) là hiển nhiên vì infimum của một hàm nhỏ hơn giá trị\\ncủa hàm đó tại bất kỳ một điểm nào khác. Bất đẳng thức (25.16) xảy ra vì các ràng buộc\\nfi(x∗) ≤0,λi ≥0,i = 1 ,2,...,m và hj(x∗) = 0 . Từ đây có thể thế rằng dấu đẳng thức\\nở (25.15) và (25.16) phải đồng thời xảy ra. Và ta lại có thêm hai quan sát thú vị nữa:\\n• x∗ chính là một điểmoptimal của g(λ∗,ν∗).\\n• Thú vị hơn,\\nm∑\\ni=1\\nλ∗\\nifi(x∗) = 0. Vìλ∗\\ni ≥0,fi ≤0 nên mỗi phần tửλ∗\\nifi(x∗) ≤0. Từ đó ta\\nphải cóλ∗\\nifi(x∗) = 0, ∀i= 1,2,...,m .\\nĐiều kiện cuối cùng này được gọi làcomplementary slackness. Từ đây có thể suy ra\\nλ∗\\ni >0 ⇒fi(x∗) = 0 (25.17)\\nfi(x∗) <0 ⇒λ∗\\ni = 0 (25.18)\\nTức ta luôn có một trong hai giá trị này bằng 0.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 335, 'page_label': '324'}, page_content='CHƯƠNG 25. DUALITY 324\\n25.4.2 Các điều kiện tối ưu KKT\\nTa vẫn giả sử rằng các hàm đang xét có đạo hàm và bài toán tối ưu không nhất thiết là lồi.\\nĐiều kiện KKT cho bài toánkhông lồi\\nGiả sử rằngstrong dualityxảy ra. Gọix∗và(λ∗,ν∗) là bất kỳ primal và dual optimal points.\\nVì x∗ tối ưu hàm khả viL(x,λ∗,ν∗), ta có đạo hàm của Lagrangian tạix∗ phải bằng 0.\\nĐiều kiện Karush-Kuhn-Tucker (KKT) nói rằngx∗,λ∗,ν∗ phải thoả mãn các điều kiện\\nfi(x∗) ≤0,i = 1,2,...,m (25.19)\\nhj(x∗) = 0,j = 1,2,...,p (25.20)\\nλ∗\\ni ≥0,i = 1,2,...,m (25.21)\\nλ∗\\nifi(x∗) = 0,i = 1,2,...,m (25.22)\\n∇xf0(x∗) +\\nm∑\\ni=1\\nλ∗\\ni∇xfi(x∗) +\\np∑\\nj=1\\nν∗\\nj∇xhj(x∗) = 0 (25.23)\\nĐây làđiều kiện cầnđể x∗,λ∗,ν∗ là nghiệm củaprimal problemvà dual problem.\\nCác điều kiện KKT cho bài toán lồi\\nVới các bài toán lồi vàstrong duality xảy ra, các điệu kiện KKT phía trên cũng làđiều\\nkiện đủ. Vậy với các bài toán lồi với hàm mục tiêu và hàm ràng buộc là khả vi, bất kỳ\\nbộ (x∗,λ∗,ν∗) nào thoả mãn các điều kiện KKT đều làprimal và dual optimalcủa primal\\nproblem và dual problem.\\nCần nhớ\\nVới một bài toán lồi và điều kiện Slater thoả mãn (suy ra strong duality) thì các điều\\nkiện KKT là các điều cần và đủ của nghiệm.\\nCác điều kiện KKT rất quan trọng trong tối ưu. Trong một vài trường hợp đặc biệt (chúng\\nta sẽ thấy trong Phần Support Vector Machine), việc giải hệ (bất) phương trình các điều\\nkiện KKT là khả thi. Rất nhiều các thuật toán tối ưu được xây dựng giả trên việc giải hệ\\nđiều kiện KKT.\\nVí dụ:Equality constrained convex quadratic minimization. Xét bài toán:\\nx = arg min\\nx\\n1\\n2xTPx + qTx + r\\nthoả mãn: Ax = b (25.24)\\ntrong đóP là một ma trận nửa nửa xác định dương. Lagrangian của bài toán này là\\nL(x,ν) = 1\\n2xTPx + qTx + r+ νT(Ax −b)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 336, 'page_label': '325'}, page_content='325 CHƯƠNG 25. DUALITY\\nĐiều kiện KKT cho bài toán này là:\\nAx∗= b (25.25)\\nPx∗+ q + ATν∗= 0 (25.26)\\nPhương trình thứ hai chính là phương trình đạo hàm của Lagrangian tạix∗ bằng 0. Hệ\\nphương trình này có thể được viết lại dưới dạng\\n[P AT\\nA 0\\n][x∗\\nν∗\\n]\\n=\\n[−q\\nb\\n]\\nĐây là một phương trình tuyến tính đơn giản!\\n25.5 Tóm tắt\\nGiả sử rằng các hàm số đều khả vi.\\n• Các bài toán tối ưu với chỉ ràng buộc là đẳng thức có thể được giải quyết bằng phương\\npháp nhân tử Lagrange. Ta cũng có định nghĩa về Lagrangian. Điều kiện cần để một điểm\\nlà nghiệm của bài toán tối ưu là nó phải làm cho đạo hàm của Lagrangian bằng 0.\\n• Với các bài toán tối ưu có thêm ràng buộc là bất đẳng thức (không nhất thiết là lồi),\\nchúng ta có Lagrangian tổng quát và các biến Lagrangeλ,ν. Với các giá trị(λ,ν) cố\\nđịnh, ta có định nghĩa vềhàm đối ngẫu Lagrange(Lagrange dual function)g(λ,ν)\\nđược xác định là infimum của Lagrangian khix thay đổi trên miền xác định của bài toán.\\n• Feasible setlà tập con củadomain set (tập xác định).\\n• Với mọi(λ,ν), g(λ,ν) ≤p∗.\\n• Hàm sốg(λ,ν) là convex bất kể bài toán tối ưu gốc cóconvex hay không. Hàm số này\\nđược gọi làdual Lagrange fucntionhay hàm đối ngẫu Lagrange.\\n• Bài toán đi tìm giá trị lớn nhất của hàm đối ngẫu Lagrange với điều kiệnλ⪰0 được\\ngọi làbài toán đối ngẫu(dual problem). Bài toán này làconvex bất kể bài toán gốc có\\nconvex hay không.\\n• Gọi giá trị tối ưu của bài toán đối ngẫu làd∗, ta cód∗≤p∗. Đây được gọi làweak duality.\\n• Strong dualityxảy ra khid∗= p∗. Thường thìstrong dualitykhông xảy ra, nhưng với các\\nbài toán lồi thìstrong dualitythường (không luôn luôn) xảy ra.\\n• Nếu bài toán là lồi và điều kiện Slater thoả mãn, thìstrong dualityxảy ra.\\n• Nếu bài toán lồi và cóstrong duality thì nghiệm của bài toán thoả mãn các điều kiện\\nKKT (điều kiện cần và đủ).\\n• Rất nhiều các bài toán tối ưu được giải quyết thông qua KKT conditions.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 338, 'page_label': '327'}, page_content='Phần VIII\\nSupport vector machines'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 339, 'page_label': '328'}, page_content='Chương 26\\nSupport vector machine\\n26.1 Giới thiệu\\nSupport vector machine (SVM) là một trong những thuật toán phân lớp phổ biến và hiệu\\nquả. Ý tưởng đứng sau SVM khá đơn giản, nhưng để hiểu được cách tìm nghiệm của nó,\\nchúng ta cần một chút kiến thức về tối ưu vàduality.\\nTrước khi đi vào phần ý tưởng chính của SVM, chúng ta cùng ôn lại kiến thức về hình học\\ngiải tích trong chương trình phổ thông.\\n26.1.1 Khoảng cách từ một điểm tới một siêu mặt phẳng\\nTrong không gian hai chiều, khoảng cách từ một điểm có toạ độ(x0,y0) tới đường thẳng có\\nphương trìnhw1x+ w2y+ b= 0 được xác định bởi\\n|w1x0 + w2y0 + b|√\\nw2\\n1 + w2\\n2\\nTrong không gian ba chiều, khoảng cách từ một điểm có toạ độ(x0,y0,z0) tới mộtmặt phẳng\\ncó phương trìnhw1x+ w2y+ w3z+ b= 0 được xác định bởi\\n|w1x0 + w2y0 + w3z0 + b|√\\nw2\\n1 + w2\\n2 + w2\\n3\\nHơn nữa, nếu bỏ dấu trị tuyệt đối ở tử số, ta có thể xác định được điểm đó nằm về phía nào\\ncủa đường thẳng hay mặt phẳng đang xét. Những điểm làm cho biểu thức trong dấu giá trị\\ntuyệt đối mang dấu dương nằm về cùng một phía (tạm gọi làphía dương), những điểm làm\\ncho giá trị này mang dấu âm nằm về phía còn lại (gọi làphía âm). Những điểm nằm trên\\nđường thẳng/mặt phẳngsẽ làm cho tử số có giá trị bằng 0, tức khoảng cách bằng 0.\\nCác công thức này có thể được tổng quát lên cho trường hợp không giand chiều. Khoảng\\ncách từ một điểm (vector) có toạ độ(x10,x20,...,x d0) tới siêu mặt phẳng(hyperplane) có'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 340, 'page_label': '329'}, page_content='329 CHƯƠNG 26. SUPPORT VECTOR MACHINE\\nx1\\nx2\\nHình 26.1: Hai lớp dữ liệu đỏ và\\nxanh làlinearly separable. Có vô số\\ncác đường thằng có thể phân tách\\nchính xác hai lớp dữ liệu này (Xem\\nthêm Chương 13–Perceptron learn-\\ning algorithm).\\nphương trìnhw1x1 + w2x2 + ··· + wdxd + b= 0 được xác định bởi\\n|w1x10 + w2x20 + ··· + wdxd0 + b|√\\nw2\\n1 + w2\\n2 + ··· + w2\\nd\\n= |wTx0 + b|\\n∥w∥2\\nvới x0 = [x10,x20,...,x d0]T,w = [w1,w2,...,w d]T.\\n26.1.2 Nhắc lại bài toán phân chia hai lớp dữ liệu\\nChúng ta cùng quay lại với bài toán phân lớp như đã đề cập trong Chương 13 – Perceptron\\nLearning Algorithm (PLA). Giả sử rằng có hai lớp dữ liệu được mô tả bởi các điểm (feature\\nvector) trong không gian nhiều chiều, hơn nữa, hai lớp dữ liệu này làlinearly separable, tức\\ntồn tại một siêu phẳng phân chia chính xác hai lớp đó. Hãy tìm một siêu phẳng phân chia\\nhai lớp đó đó, tức tất cả các điểm thuộc một lớp nằm về cùng một phía của siêu phẳng đó\\nvà ngược phía với toàn bộ các điểm thuộc lớp còn lại. Chúng ta đã biết rằng, thuật toán\\nPLA có thể làm được việc này nhưng nó có thể cho chúng ta vô số nghiệm như Hình 26.1.\\nCó một câu hỏi được đặt ra ở đây. Trong vô số các mặt phân chia đó, đâu là mặt tốt nhất.\\nTrong ba đường thẳng minh họa trong Hình 26.1, có hai đường thẳng khálệch về phía lớp\\nmàu đỏ. Điều này có thể khiến cho lớp màu đỏkhông vui vì lãnh thổ bị lấn nhiều quá. Việc\\nnày có thể khiến cho các điểm màu đỏ trong tương lai bị phân lớp lỗi thành điểm màu xanh.\\nLiệu có cách nào để tìm được đường phân chia mà cả hai lớp đều cảm thấycông bằng và\\nhạnh phúcnhất hay không?\\nĐể trả lời câu hỏi này, chúng ta cần tìm một tiêu chuẩn để đo sựhạnh phúc của mỗi lớp.\\nNếu ta định nghĩamức độ hạnh phúccủa một lớp tỉ lệ thuận vớikhoảng cách gần nhấttừ\\nmột điểm của lớp đó tới đường/mặt phân chia, ở Hình 26.2a, lớp màu đỏ sẽkhông được hạnh\\nphúc cho lắmvì đường phân chia gần nó hơn lớp màu xanh rất nhiều. Chúng ta cần một\\nđường phân chia sao cho khoảng cách từ điểm gần nhất của mỗi lớp (các điểm được khoanh'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 340, 'page_label': '329'}, page_content='phúc cho lắmvì đường phân chia gần nó hơn lớp màu xanh rất nhiều. Chúng ta cần một\\nđường phân chia sao cho khoảng cách từ điểm gần nhất của mỗi lớp (các điểm được khoanh\\ntròn) tới đường phân chia là như nhau, như thế thì mớicông bằng. Khoảng cách như nhau\\nnày được gọi làbiên hoặc lề (margin).\\nĐã cócông bằngrồi, chúng ta cầnthịnh vượngnữa. công bằngmà cả hai đềukém hạnh phúc\\nnhư nhau thì chưa phải làthịnh vượng cho lắm.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 341, 'page_label': '330'}, page_content='CHƯƠNG 26. SUPPORT VECTOR MACHINE 330\\nx1\\nx2\\n w\\nT x+b= 0\\n+ −\\n(a)\\nmargin (b)\\nHình 26.2:Ý tưởng của SVM.Margin của một lớp được định nghĩa là khoảng cách từ các điểm\\ngần nhất của lớp đó tới mặt phân chia.Margin của hai lớp phải bằng nhau và lớn nhất có thể.\\nXét tiếp Hình 26.2b khi khoảng cách từ đường phân chia tới các điểm gần nhất của mỗi lớp\\nlà như nhau. Xét hai cách phân chia bởi đường nét liền màu đen và đường nét đứt màu lục,\\nđường nào sẽ làm cho cả hai lớphạnh phúc hơn? Rõ ràng đó phải là đường nét liền màu đen\\nvì nó tạo ra mộtmargin rộng hơn.\\nViệc margin rộng hơn sẽ mang lại hiệu ứng phân lớp tốt hơn vìsự phân chia giữa hai lớp là\\nrạch ròi hơn. Bài toán tối ưu trong SVM chính là bài toán đi tìm đường phân chia sao cho\\nmargin giữa hai lớp là lớn nhất. Đây cũng là lý do vì sao SVM còn được gọi làmaximum\\nmargin classifier. Nguồn gốc của tên gọisupport vector machinesẽ sớm được làm sáng tỏ.\\n26.2 Xây dựng bài toán tối ưu cho SVM\\nGiả sử rằng các cặp dữ liệu trong tập huấn luyện là(x1,y1),(x2,y2),..., (xN,yN) với vector\\nxi ∈Rd thể hiệnđầu vào của một điểm dữ liệu vàyi là nhãn của điểm dữ liệu đó,d là số\\nchiều của dữ liệu vàN là số điểm dữ liệu. Giả sử rằngnhãn của mỗi điểm dữ liệu được xác\\nđịnh bởiyi = 1 hoặc yi = −1 giống như trong PLA.\\nĐể dễ hình dung, chúng ta cùng làm với các ví dụ trong không gian hai chiều. Giả sử\\nrằng các điểm màu xanh có nhãn là 1, các điểm tròn đỏ có nhãn là -1 và mặtwTx + b =\\nw1x1 + w2x2 + b= 0 là mặt phân chia giữa hai lớp (Hình 26.3). Hơn nữa, lớp màu xanh nằm\\nvề phía dương, lớp màu đỏ nằm vềphía âm của mặt phân chia. Nếu ngược lại, ta chỉ cần\\nđổi dấu củaw và b. Ta cần đi tìm siêu phẳng được mô tả bởi các hệ sốw và b.\\nTa quan sát thấy một điểm quan trọng như sau. Với cặp dữ liệu(xn,yn) bất kỳ, khoảng cách\\ntừ điểm đó tới mặt phân chia là\\nyn(wTxn + b)\\n∥w∥2\\nĐiều này có thể được nhận thấy vì theo giả sử ở trên,yn luôn cùng dấu vớiphía của xn. Từ\\nđó suy rayn cùng dấu với(wTxn+ b), vì vậy tử số luôn là một đại lượng không âm. Với mặt'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 341, 'page_label': '330'}, page_content='yn(wTxn + b)\\n∥w∥2\\nĐiều này có thể được nhận thấy vì theo giả sử ở trên,yn luôn cùng dấu vớiphía của xn. Từ\\nđó suy rayn cùng dấu với(wTxn+ b), vì vậy tử số luôn là một đại lượng không âm. Với mặt\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 342, 'page_label': '331'}, page_content='331 CHƯƠNG 26. SUPPORT VECTOR MACHINE\\n+ −\\nw\\nT x+\\nb= 0\\nw\\nT x+\\nb= 1\\nw\\nT x+\\nb=\\n−1\\nHình 26.3: Giả sử mặt phân chia\\ncó phương trình wTx + b = 0 .\\nKhông mất tính tổng quát, bằng\\ncách nhân các hệ số w và b với\\ncác hằng số phù hợp, ta có thể\\ngiả sử rằng điểm gần nhất của lớp\\nmàu xanh tới mặt này thoả mãn\\nwTx+b= 1.Khiđó,điểmgầnnhất\\ncủa lớp đỏ thoả mãnwTw + b =\\n−1.\\nphân chia này,margin được tính là khoảng cách gần nhất từ một điểm (trong cả hai lớp, vì\\ncuối cùngmargin của cả hai lớp sẽ như nhau) tới mặt đó, tức là\\nmargin = min\\nn\\nyn(wTxn + b)\\n∥w∥2\\nBài toán tối ưu của SVM chính là việc tìmw và b sao chomargin này đạt giá trị lớn nhất:\\n(w,b) = arg max\\nw,b\\n{\\nmin\\nn\\nyn(wTxn + b)\\n∥w∥2\\n}\\n= arg max\\nw,b\\n{ 1\\n∥w∥2\\nmin\\nn\\nyn(wTxn + b)\\n}\\n(26.1)\\nCó một nhận xét quan trọng là nếu ta thay vector hệ sốw bởi kw và bbởi kb trong đók là\\nmột hằng số dươngbất kỳthì mặt phân chia không thay đổi, tức khoảng cách từ từng điểm\\nđến mặt phân chia không đổi, tứcmargin không đổi. Vì vậy, ta có thể giả sử\\nyn(wTxn + b) = 1\\nvới những điểm nằm gần mặt phân chia nhất(được khoanh tròn trong Hình 26.3).\\nNhư vậy, với mọin ta luôn có\\nyn(wTxn + b) ≥1\\nVậy bài toán tối ưu (26.1) có thể đưa về bài toán tối ưu có ràng buộc có dạng\\n(w,b) = arg max\\nw,b\\n1\\n∥w∥2\\nthoả mãn:yn(wTxn + b) ≥1,∀n= 1,2,...,N\\n(26.2)\\nBằng một biến đổi đơn giản, ta có thể đưa bài toán này về dạng\\n(w,b) = arg min\\nw,b\\n1\\n2∥w∥2\\n2\\nthoả mãn:1 −yn(wTxn + b) ≤0,∀n= 1,2,...,N\\n(26.3)\\nỞ đây, chúng ta đã lấy nghịch đảo hàm mục tiêu, bình phương nó để được một hàm khả vi,\\nvà nhân với1\\n2 để biểu thức đạo hàm đẹp hơn.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 343, 'page_label': '332'}, page_content='CHƯƠNG 26. SUPPORT VECTOR MACHINE 332\\nCó một quan sát rất quan trọng.Trong bài toán (26.3), hàm mục tiêu là một norm,\\nnên là một hàm lồi. Các hàm bất đẳng thức ràng buộc là các hàm tuyến tính theow và\\nb, nên chúng cũng là các hàm lồi. Vậy bài toán tối ưu (26.3) có hàm mục tiêu là lồi, và\\ncác hàm ràng buộc cũng là lồi, nên nó là một bài toán lồi. Hơn nữa, nó là một quadratic\\nprogramming vì hàm mục tiêu là mộtquadratic form. Thậm chí, hàm mục tiêu làstrictly\\nconvex vì |w|2\\n2 = wTIw và mathbfI là ma trận đơn vị – là một ma trận xác định dương.\\nTừ đây có thể suy ra nghiệm cho SVM làduy nhất.\\nĐến đây thì bài toán này có thể giải được bằng các công cụ hỗ trợ tìm nghiệm cho quadratic\\nprograming, ví dụ CVXOPT. Tuy nhiên, việc giải bài toán này trở nên phức tạp khi số chiều\\nd của không gian dữ liệu và số điểm dữ liệuN tăng lên cao. Thay vào đó, người ta thường\\ngiải bài toán đối ngẫu của bài toán này. Thứ nhất, bài toán đối ngẫu có những tính chất thú\\nvị hơn khiến nó được giải một cách hiệu quả hơn. Thứ hai, trong quá trình xây dựng bài\\ntoán đối ngẫu, người ta thấy rằng SVM có thể được áp dụng cho những bài toán mà dữ liệu\\nkhông nhất thiếtlinearly separable, như chúng ta sẽ thấy ở các chương sau của phần này.\\nXác định lớp cho một điểm dữ liệu mới\\nSau khi đã tìm được mặt phân cáchwTx + b = 0, nhãn của bất kỳ một điểm nào sẽ được\\nxác định đơn giản bằng\\nclass(x) = sgn(wTx + b)\\n26.3 Bài toán đối ngẫu của SVM\\nNhắc lại rằng bài toán tối ưu (26.3) là một bài toán lồi. Chúng ta biết rằng nếu một bài\\ntoán lồi thoả mãn tiêu chuẩn Slater thìstrong duality thoả mãn (xem Mục 25.3.2. Và nếu\\nstrong duality thoả mãn thì nghiệm của bài toán chính là nghiệm của hệ điều kiện KKT\\n(xem Mục 25.4.2).\\n26.3.1 Kiểm tra tiêu chuẩn Slater\\nTrong bước này, chúng ta sẽ chứng minh bài toán tối ưu (26.3) thoả mãn điều kiện Slater.\\nĐiều kiện Slater nói rằng, nếu tồn tạiw,b thoả mãn:\\n1 −yn(wTxn + b) <0, ∀n= 1,2,...,N\\nthì strong duality thoả mãn. Việc kiểm tra này không quá phức tạp. Vì ta biết rằng luôn'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 343, 'page_label': '332'}, page_content='Điều kiện Slater nói rằng, nếu tồn tạiw,b thoả mãn:\\n1 −yn(wTxn + b) <0, ∀n= 1,2,...,N\\nthì strong duality thoả mãn. Việc kiểm tra này không quá phức tạp. Vì ta biết rằng luôn\\nluôn có một siêu phẳng phân chia hai lớp nếu hai lớp đó làlinearly separable, tức bài toán\\ncó nghiệm, nênfeasible setcủa bài toán tối ưu (26.3) phải khác rỗng. Tức luôn luôn tồn tại\\ncặp (w0,b0) sao cho\\n1 −yn(wT\\n0 xn + b0) ≤0, ∀n= 1,2,...,N (26.4)\\n⇔2 −yn(2wT\\n0 xn + 2b0) ≤0, ∀n= 1,2,...,N (26.5)\\nVậy ta chỉ cần chọnw1 = 2w0 và b1 = 2b0, ta sẽ có:\\n1 −yn(wT\\n1 xn + b1) ≤−1 <0, ∀n= 1,2,...,N\\nTừ đó suy ra điều kiện Slater thoả mãn.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 344, 'page_label': '333'}, page_content='333 CHƯƠNG 26. SUPPORT VECTOR MACHINE\\n26.3.2 Lagrangian của bài toán SVM\\nLagrangian của bài toán (26.3) là\\nL(w,b, λ) = 1\\n2∥w∥2\\n2 +\\nN∑\\nn=1\\nλn(1 −yn(wTxn + b)) (26.6)\\nvới λ= [λ1,λ2,...,λ N]T và λn ≥0, ∀n= 1,2,...,N .\\n26.3.3 Hàm đối ngẫu Lagrange\\nTheo định nghĩa, hàm đối ngẫu Lagrange là\\ng(λ) = min\\nw,b\\nL(w,b, λ)\\nvới λ ⪰0. Việc tìm giá trị nhỏ nhất của hàm này theow và b có thể đựợc thực hiện bằng\\ncách giải hệ phương trình đạo hàm củaL(w,b, λ) theo w và b bằng 0:\\n∇wL(w,b, λ) = w −\\nN∑\\nn=1\\nλnynxn = 0 ⇒w =\\nN∑\\nn=1\\nλnynxn (26.7)\\n∇bL(w,b, λ) =\\nN∑\\nn=1\\nλnyn = 0 (26.8)\\nThay (26.7) và (26.8) vào (26.6) ta thu đượcg(λ)1:\\ng(λ) =\\nN∑\\nn=1\\nλn −1\\n2\\nN∑\\nn=1\\nN∑\\nm=1\\nλnλmynymxT\\nnxm (26.9)\\nHàm g(λ) trong (26.9)là hàm số quan trọng nhất trong SVM, chúng ta sẽ thấy rõ hơn\\ntrong chương Kernel SVM.\\nBằng cách ký hiệu ma trận\\nV =\\n[\\ny1x1,y2x2,...,y NxN\\n]\\nvà vector1 = [1,1,..., 1]T, ta có thể viết lạig(λ) dưới dạng2\\ng(λ) = −1\\n2λTVTVλ+ 1Tλ. (26.10)\\nNếu đặtK = VTV thì K là một ma trận nửa xác định dương. Thật vậy, với mọi vectorλ,\\nta cóλTKλ= λTVTVλ= ∥Vλ∥2\\n2 ≥0. Vậyg(λ) = −1\\n2 λTKλ+ 1Tλlà một hàmconcave.\\n1 Phần chứng minh coi như một bài tập nhỏ cho bạn đọc.\\n2 Phần chứng minh coi như một bài tập nhỏ khác cho bạn đọc.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 345, 'page_label': '334'}, page_content='CHƯƠNG 26. SUPPORT VECTOR MACHINE 334\\n26.3.4 Bài toán đối ngẫu Lagrange\\nTừ đó, kết hợp hàm đối ngẫu Lagrange và các điều kiện ràng buộc củaλ, ta sẽ thu được bài\\ntoán đối ngẫu Lagrange của bài toán (26.3) có dạng\\nλ= arg max\\nλ\\ng(λ)\\nthoả mãn:λ⪰0\\nN∑\\nn=1\\nλnyn = 0\\n(26.11)\\nRàng buộc thứ hai được lấy từ (26.8). Đây là một bài toán lồi vì ta đang đi tìm giá trị lớn\\nnhất của một hàm mục tiêu làconcave trên mộtpolyhedron3. Hơn nữa, bài toán này là một\\nquadratic programming và cũng có thể được giải bằng các thư viện như CVXOPT.\\nTrong bài toán đối ngẫu này, số lượng tham số phải tìm làN, là chiều củaλ, cũng chính là\\nsố điểm dữ liệu. Trong khi đó, với bài toán gốc (26.3), số tham số phải tìm làd+ 1, là tổng\\nsố chiều củaw và b, tức số chiều của mỗi điểm dữ liệu cộng với 1. Trong rất nhiều trường\\nhợp, số điểm dữ liệu có được trong tập huấn luyện lớn hơn số chiều dữ liệu rất nhiều. Nếu\\ngiải trực tiếp bằng các công cụ giải quadratic programming, có thể bài toán đối ngẫu còn\\nphức tạp hơn (tốn thời gian hơn) so với bài toàn gốc. Tuy nhiên, điều hấp dẫn của bài toán\\nđối ngẫu này đến từ cấu trúc đặc biệt của hệ điều kiện KKT. Ngoài ra, dạng đặc biệt của\\nbài toán đối ngẫu giúp các nhà khoa học đã phát triển thêm một dạng tổng quả của SVM,\\nkhiến nó hoạt động cả với trường hợp dữ liệu hai lớp là khônglinear separable. Chúng ta sẽ\\nbàn kỹ tới trường hợp này trong chương Kernel SVM.\\n26.3.5 Điều kiện KKT\\nQuay trở lại bài toán, vì đây là một bài toán lồi vàstrong dualitythoả mãn, nghiệm của bài\\ntoán sẽ thoả mãn hệ điều kiện KKT sau đây với biến số làw,b và λ.\\n1 −yn(wTxn + b) ≤0, ∀n= 1,2,...,N (26.12)\\nλn ≥0, ∀n= 1,2,...,N (26.13)\\nλn(1 −yn(wTxn + b)) = 0, ∀n= 1,2,...,N (26.14)\\nw =\\nN∑\\nn=1\\nλnynxn (26.15)\\nN∑\\nn=1\\nλnyn = 0 (26.16)\\nTrong những điều kiện trên, điều kiện (26.14) là thú vị nhất. Từ đó ta có thể suy ra ngay, với\\nnbất kỳ, hoặcλn = 0 hoặc 1−yn(wTxn+b) = 0. Trường hợp thứ hai chính làwTxn+b= yn,\\nvới chú ý rằngy2\\nn = 1, ∀n.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 345, 'page_label': '334'}, page_content='nbất kỳ, hoặcλn = 0 hoặc 1−yn(wTxn+b) = 0. Trường hợp thứ hai chính làwTxn+b= yn,\\nvới chú ý rằngy2\\nn = 1, ∀n.\\n3 Không chỉ riêng với bài toán tối ưu của SVM, các bài toán đối ngẫu luôn là bài toán lồi. Ở đây chúng ta chỉ khẳng\\nđịnh lại tính chất đó.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 346, 'page_label': '335'}, page_content='335 CHƯƠNG 26. SUPPORT VECTOR MACHINE\\nNhững điểm thoả mãn (26.3.5) chính là những điểm nằm gần mặt phân chia nhất, là những\\nđiểm được khoanh tròn trong Hình 26.3. Hai đường thẳngwTxn + b= ±1 tựa lên các điểm\\nthoả mãn (26.3.5). Những điểm (vector) thoả mãn (26.3.5) còn được gọi là cácsupport vector.\\nVà từ đó, cái tênsupport vector machinera đời.\\nMột quan sát khác, số lượng những điểm thoả mãn (26.3.5) thường chiếm số lượng rất nhỏ\\ntrong sốN điểm của tập huấn luyện. Chỉ cần dựa trên nhữngsupport vectornày, chúng ta\\nhoàn toàn có thể xác định được mặt phân cách cần tìm. Nói cách khác, hầu hết cácλn bằng\\n0, tứcλlà mộtsparse vector. Support vector machine vì vậy còn được xếp vàosparse models.\\nCác sparse models thường có cách giải hiệu quả hơn các mô hình tương tự với nghiệm là\\ndense (hầu hết các phần tử khác 0). Đây chính là lý do thứ hai của việc bài toán đối ngẫu\\nSVM được quan tâm nhiều hơn là bài toán gốc.\\nTiếp tục phân tích, với những bài toán có số điểm dữ liệuN nhỏ, ta có thể giải hệ điều\\nkiện KKT phía trên bằng cách xét các trường hợpλn = 0 hoặc λn ̸= 0 . Tổng số trường\\nhợp phải xét là2N. VớiN >50 (thường là như thế), đây là một con số rất lớn, giải bằng\\ncách này sẽ không khả thi. Phương pháp thường được dùng để giải hệ này làsequential\\nminimal optimization (SMO) [Pla98,ZYX+08]. Trong phương pháp này, các cặp hai nhân\\ntử Lagrange (hai thành phần củaλ) được chọn ra để tối ưu tại mỗi vòng lặp. Trong các bài\\nbáo trên, việc chọn cặp như thế nào được nêu rõ. Việc này được thực hiện nhiều lần cho tới\\nkhi thuật toán hội tụ [Bis06].\\nChúng ta sẽ không đi sâu tiếp vào việc giải hệ KKT như thế nào, trong phần tiếp theo chúng\\nta sẽ giải bài toán tối ưu (26.11) bằng CVXOPT với một ví dụ nhỏ và bằng thư việnsklearn\\n(có thể áp dụng cho trường hợp nhiều điểm dữ liệu và nhiều chiều dữ liệu hơn).\\nSau khi tìm đượcλ từ bài toán (26.11), ta có thể suy ra đượcw dựa vào (26.15) vàb dựa\\nvào (26.14) và (26.16). Rõ ràng ta chỉ cần quan tâm tớiλn ̸= 0.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 346, 'page_label': '335'}, page_content='Sau khi tìm đượcλ từ bài toán (26.11), ta có thể suy ra đượcw dựa vào (26.15) vàb dựa\\nvào (26.14) và (26.16). Rõ ràng ta chỉ cần quan tâm tớiλn ̸= 0.\\nĐặt S= {n: λn ̸= 0}và NS là số phần tử của tậpS. Theo (26.15),w được tính bằng\\nw =\\n∑\\nm∈S\\nλmymxm (26.17)\\nVới mỗin∈S, ta có\\n1 = yn(wTxn + b) ⇔b= yn −wTxn\\nMặc dù từ chỉ một cặp(xn,yn), ta có thể suy ra ngay đượcbnếu đã biếtw, một phiên bản\\nkhác để tínhbthường được sử dụng và được cho làổn định hơn trong tính toán(numerically\\nmore stable) là trung bình cộng4 của tất cả cácb tính được theo mỗin∈S\\nb= 1\\nNS\\n∑\\nn∈S\\n(yn −wTxn) = 1\\nNS\\n∑\\nn∈S\\n(\\nyn −\\n∑\\nm∈S\\nλmymxT\\nmxn\\n)\\n(26.18)\\n4 Việc này cũng giống như cách làm trong các thí nghiệm vật lý. Để đo một đại lượng, người ta thường thực hiện\\nviệc đo nhiều lần rồi lấy kết quả trung bình để tránh sai số. Ở đây, về mặt toán học,b phải như nhau theo mọi\\ncách tính; tuy nhiên, khi tính toán bằng máy tính, chúng ta có thể gặp các sai số nhỏ. Việc lấy trung bình sẽ làm\\ngiảm sai số đó.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 347, 'page_label': '336'}, page_content='CHƯƠNG 26. SUPPORT VECTOR MACHINE 336\\nĐể xác định một điểmx mới thuộc vào lớp nào, ta cần xác định dấu của biểu thức\\nwTx + b=\\n∑\\nm∈S\\nλmymxT\\nmx + 1\\nNS\\n∑\\nn∈S\\n(\\nyn −\\n∑\\nm∈S\\nλmymxT\\nmxn\\n)\\nBiểu thức này phụ thuộc vào cách tính tích vô hướng giữax và từngxm ∈S. Nhận xét quan\\ntrọng này sẽ giúp ích cho chúng ta trong chương Kernal SVM.\\n26.4 Lập trình tìm nghiệm cho SVM\\nTrong mục này, chúng ta cùng tìm nghiệm cho SVM bằng hai cách khác nhau. Cách thứ\\nnhất dựa theo bài toán (26.11) và các công thức (26.18) và (26.17). Cách thứ hai sử dụng\\ntrực tiếp thư việnsklearn. Cách thứ nhất giúp chứng minh tính đúng đắn của các công thức\\nđã xây dựng. Cách thứ hai sẽ giúp các bạn biết cách áp dụng SVM vào dữ liệu thực tế.\\n26.4.1 Tìm nghiệm theo công thức\\nTrước tiên chúng ta gọi các thư viện cần dùng và tạo dữ liệu giả (dữ liệu này được sử dụng\\ntrong các hình vẽ từ đầu chương. Ta thấy rằng hai class làlinearly separable).\\nfrom __future__ import print_function\\nimport numpy as np\\nnp.random.seed(22)\\n# simulated samples\\nmeans = [[2, 2], [4, 2]]\\ncov = [[.3, .2], [.2, .3]]\\nN = 10\\nX0 = np.random.multivariate_normal(means[0], cov, N) # blue class data\\nX1 = np.random.multivariate_normal(means[1], cov, N) # red class data\\nX = np.concatenate((X0, X1), axis = 0) # all data\\ny = np.concatenate((np.ones(N), -np.ones(N)), axis = 0) # label\\n# solving the dual problem (variable: lambda)\\nfrom cvxopt import matrix, solvers\\nV = np.concatenate((X0, -X1), axis = 0) # V in the book\\nQ = matrix(V.dot(V.T))\\np = matrix(-np.ones((2*N, 1))) # objective function 1/2 lambda^T*Q*lambda - 1^T*lambda\\n# build A, b, G, h\\nG = matrix(-np.eye(2*N))\\nh = matrix(np.zeros((2*N, 1)))\\nA = matrix(y.reshape(1, -1))\\nb = matrix(np.zeros((1, 1)))\\nsolvers.options[’show_progress’] = False\\nsol = solvers.qp(Q, p, G, h, A, b)\\nl = np.array(sol[’x’]) # solution lambda\\n# calculate w and b\\nw = Xbar.T.dot(l)\\nS = np.where(l > 1e-8)[0] # support set, 1e-8 to avoid small value of l.\\nb = np.mean(y[S].reshape(-1, 1) - X[S,:].dot(w))'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 347, 'page_label': '336'}, page_content='# calculate w and b\\nw = Xbar.T.dot(l)\\nS = np.where(l > 1e-8)[0] # support set, 1e-8 to avoid small value of l.\\nb = np.mean(y[S].reshape(-1, 1) - X[S,:].dot(w))\\nprint(’Number of suport vectors = ’, S.size)\\nprint(’w = ’, w.T)\\nprint(’b = ’, b)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 348, 'page_label': '337'}, page_content='337 CHƯƠNG 26. SUPPORT VECTOR MACHINE\\nHình 26.4: Minh hoạ nghiệm tìm\\nđược bởi SVM. Tất cả các điểm\\nnằm trong vùng có nền màu lam\\nnhạt sẽ được phân vào cùng lớp với\\ncác điểm màu lam. Điều tương tự\\nxảy ra với các điểm nằm trên nền\\nmàu đỏ nhạt.\\nKết quả:\\nNumber of suport vectors = 3\\nw = [[-2.00984382 0.64068336]]\\nb = 4.66856068329\\nNhư vậy trong số 20 điểm dữ liệu của cả hai lớp, chỉ có ba điểm nằm trongsupport set, tức\\ncó ba điểm đóng vai trò là cácsupport vector. Ba điểm này giúp xây dựng đường thằng phân\\nchia vớiw và b như đã tính được. Kết quả tìm được được minh hoạ trong Hình 26.4. Đường\\nmàu đen đậm ở giữa chính là mặt phân cách tìm được bằng SVM. Các đường đen mảnh thể\\nhiện các đường thẳngtựa lên cácsupport vectorđược khoanh tròn.\\nCác hình vẽ và source code trong bài có thể được tìm thấy tạihttps://goo.gl/VKBgVG .\\n26.4.2 Tìm nghiệm theo thư viện\\nChúng ta sẽ sử dụng hàmsklearn.svm.SVC ở đây. Các bài toán thực tế thường sử dụng thư\\nviện libsvm được viết trên ngôn ngữ C, có API cho Python và Matlab.\\nNếu dùng thư viện thì sẽ như sau:\\n# solution by sklearn\\nfrom sklearn.svm import SVC\\nmodel = SVC(kernel = ’linear’, C = 1e5) # just a big number\\nmodel.fit(X, y)\\nw = model.coef_\\nb = model.intercept_\\nprint(’w = ’, w)\\nprint(’b = ’, b)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 349, 'page_label': '338'}, page_content='CHƯƠNG 26. SUPPORT VECTOR MACHINE 338\\nKết quả:\\nw = [[-2.00971102 0.64194082]]\\nb = [ 4.66595309]\\nKết quả này khá giống với kết quả chúng ta tìm được ở phần trên, với cách làm đơn giản\\nhơn rất nhiều. Có rất nhiều tuỳ chọn cho SVM, trong đó có thuộc tínhkernel, các bạn sẽ\\ndần thấy trong các chương sau.\\n26.5 Tóm tắt và thảo luận\\n• Với bài toán phân lớp nhị phân mà hai lớp dữ liệu làlinearly separable, có vô số các mặt\\nphân cách phẳng giúp phân chia hai lớp đó. Khoảng cách gần nhất từ một điểm dữ liệu\\ntới mặt phân cách ấy được gọi làmargin của bộ phân lớp với ranh giới là mặt phẳng đó.\\n• Support vector machine là bài toán đi tìm mặt phân cách sao chomargin có được là lớn\\nnhất, đồng nghĩa với việc các điểm dữ liệu có mộtkhoảng cách an toàntới mặt phân cách.\\n• Bài toán tối ưu trong SVM là một bài toánconvex với hàm mục tiêu làstricly convex, vì\\nvậy,local optimumcũng làglobal optimumcủa bài toán. Hơn nữa, bài toán tối ưu đó là\\nmột quadratic programming(QP).\\n• Mặc dù có thể trực tiếp giải SVM qua bài toánprimal, thông thường người ta thường\\ngiải bài toándual. Bài toándual cũng là một QP nhưng nghiệm làsparse nên có những\\nphương pháp giải hiệu quả hơn.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 350, 'page_label': '339'}, page_content='Chương 27\\nSoft-margin support vector machine\\n27.1 Giới thiệu\\nGiống như perceptron learning algorithm (PLA), support vector machine (SVM)thuần chỉ\\nlàm việc khi dữ liệu của hai lớp làlinearly separable. Một cách tự nhiên, chúng ta cũng\\nmong muốn rằng SVM có thể làm việc với dữ liệugần linearly separablegiống như logistic\\nregression đã làm được.\\nXét hai ví dụ trong Hình 27.1. Có hai trường hợp dễ nhận thấy SVM làm việc không hiệu\\nquả hoặc thậm chí không làm việc\\n1. Trường hợp 1: Dữ liệu vẫnlinearly separablenhư Hình 27.1a nhưng có một điểmnhiễu\\ncủa lớp đỏ ở quá gần so với lớp xanh. Trong trường hợp này, nếu ta sử dụng SVMthuần\\nthì sẽ tạo ra mộtmargin rất nhỏ. Ngoài ra, đường phân lớp nằm quá gần với các điểm ở\\nlớp xanh và quá xa các điểm thuộc lớp đỏ. Trong khi đó, nếu tahy sinhđiểm nhiễu này\\nthì ta được mộtmargin tốt hơn rất nhiều được mô tả bởi các đường nét đứt. SVMthuần\\nvì vậy còn được coi lànhạy cảm với nhiễu(sensitive to noise).\\n2. Trường hợp 2: Dữ liệu không linearly separable nhưng gần linearly separable như\\nHình 27.1b. Trong trường hợp này, không tồn tại đường thẳng nào hoàn thoàn phân\\nchia hai lớp dữ liệu, vì vậy bài toán tối ưu SVM trở nên vô nghiệm. Tuy nhiên, nếuchịu\\nhy sinh một chút những điểm ở gần khu vực biên giới giữa hai lớp, ta vẫn có thể tạo\\nđược một đường phân chia khá tốt như đường nét đứt đậm. Cácđường support đường\\nnét đứt mảnh vẫn giúp tạo được mộtmargin lớn cho bộ phân lớp này. Với mỗi điểm nằm\\nlấn sang phía bên kia của cácđường suporttương ứng, ta gọi điểm đó rơi vàovùng không\\nan toàn. Như trong hình, hai điểm màu đỏ nằm phía bên tráiđường supportcủa lớp đỏ\\nđược xếp vào loại không an toàn, mặc dù có một điểm đỏ vẫn nằm trong khu vực nền\\nmàu đỏ. Hai điểm màu xanh ở phía phải củađường support của lớp xanh thậm chí đều\\nlấn sang phần có nền màu đỏ.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 351, 'page_label': '340'}, page_content='CHƯƠNG 27. SOFT-MARGIN SUPPORT VECTOR MACHINE 340\\nnoise\\n(a) Khi có nhiễu nhỏ.\\nalmost linearly separable (b) Khi dữ liệugần linearly separable.\\nHình 27.1:Hai trường hơp khi support vector machinethuần làm việc không hiệu quả. (a) Hai\\nlớp vẫn linearly separable nhưng một điểm thuộc class này quá gần class kia, điểm này có thể là\\nnhiễu. (b) Dữ liệu hai lớp khônglinearly separable, mặc dù chúng đãgần linearly separable.\\nTrong cả hai trường hợp trên,margin tạo bởi đường phân chia và đường nét đứt mảnh còn\\nđược gọi làsoft-margin (biên mềm). Để phân biệt, SVMthuần còn được gọi làhard-margin\\nSVM (SVM biên cứng). SVMchấp nhận một vài điểm trong tập huấn luyện bị phân lớp lỗi\\nnày được gọi làsoft-margin SVM.\\nCó hai cách xây dựng và giải quyết bài toán tối ưu chosoft-margin SVM, cả hai đều mang\\nlại những kết quả thú vị và có thể phát triển tiếp thành các thuật toán SVM phức tạp và\\nhiệu quả hơn như sẽ được thấy ở các chương sau của cuốn sách này. Cách giải quyết thứ\\nnhất là giải một bài toán tối ưu có ràng buộc bằng cách giải bài toán đối ngẫu giống như\\nhard-margin SVM; cách giải dựa vào bài toán đối ngẫu này là cơ sở cho phương phápKernel\\nSVM cho dữ liệu thực sự khônglinearly separablesẽ được đề cập trong chương tiếp theo.\\nCách giải quyết thứ hai là đưa về một bài toán tối ưukhông ràng buộc. Bài toán này có thể\\ngiải bằng các phương pháp gradient descent. Nhờ đó, cách giải quyết này có thể được áp\\ndụng cho các bài toán large-scale. Ngoài ra, trong cách giải này, chúng ta sẽ làm quen với\\nmột hàm mất mát mới có tên làhinge loss. Hàm mất mát này có thể mở rộng ra cho bài toán\\nmulti-class classification sẽ được đề cập trong chương (multi-class SVM). Cách phát triển\\ntừ soft-margin SVM thành multi-class SVM có thể so sánh với cách phát triển từ logistic\\nregression thành softmax regression. Tiếp theo, chúng ta cùng đi phân tích bài toán tối ưu\\ncho soft-margin SVM.\\n27.2 Phân tích toán học\\nNhư đã đề cập phía trên, để có mộtmargin lớn hơn trongsoft margin SVM, ta cầnhy sinh'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 351, 'page_label': '340'}, page_content='cho soft-margin SVM.\\n27.2 Phân tích toán học\\nNhư đã đề cập phía trên, để có mộtmargin lớn hơn trongsoft margin SVM, ta cầnhy sinh\\nmột vài điểm dữ liệu bằng cách chấp nhận cho chúng rơi vào vùngkhông an toàn. Tất nhiên,\\nviệc hy sinhnày cần được hạn chế, nếu không, ta có thể tạo ra một biên cực lớn bằng cách\\nhy sinh hầu hết các điểm. Vậy hàm mục tiêu nên là một sự kết hợp để tối đamargin cũng\\nnhư tối thiểusự hy sinh.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 352, 'page_label': '341'}, page_content='341 CHƯƠNG 27. SOFT-MARGIN SUPPORT VECTOR MACHINE\\nξ1\\nξ2\\nξ3\\nx1\\nx2\\nx3\\nw\\nT x+b= 0\\nw\\nT x+b= 1\\nw\\nT x+b=−1\\nHình 27.2: Giới thiệu các biến slackξn.\\nVới các điểm nằm ở khu vực an toàn,\\nξn = 0 . Những điểm nằm trong vùng\\nkhông an toàn, nhưng vẫn đúng phía so\\nvới đường ranh giới (đường nét đứt đậm),\\ntương ứng với các0 < ξn <1, ví dụx2.\\nNhữngđiểmnằmngượcphíavớiclasscủa\\nchúng so với đường boundary ứng với các\\nξn >1, ví dụ nhưx1 và x3.\\nGiống như vớihard-margin SVM, việc tối đamargin có thể đưa về việc tối thiểu∥w∥2\\n2. Để\\nđong đếmsự hy sinh, chúng ta cùng theo dõi Hình 27.2. Với mỗi điểmxn trong tập toàn bộ\\ndữ liệu huấn luyện, tagiới thiệu thêm một biến đosự hy sinhξn tương ứng. Biến này còn\\nđược gọi làslack variable. Với những điểmxn nằm trongvùng an toàn(nằm đúng vào màu\\nnền tương ứng và nằm ngoài khu vựcmargin), ξn = 0, tức không có sựhy sinh mất mátnào\\nxảy ra. Với mỗi điểm nằm trongvùng không an toànnhư x1,x2 hay x3, ta cần cóξi >0, tức\\nmất mát đã xảy ra. Đại lượng này nên tỉ lệ với khoảng cách từ điểm vi phạm tương ứng tới\\nbiên giới an toàn. Nhận thấy rằng nếuyi = ±1 là nhãn của xi trong vùng không an toànthì\\nξi có thể được định nghĩa là\\nξi = |wTxi + b−yi| (27.1)\\n(ở đây, ta đã bỏ mẫu số∥w∥2 đi vì ta chỉ cần một đại lượng tỉ lệ thuận.) Nhắc lại bài toán\\ntối ưu chohard-margin SVM:\\n(w,b) = arg min\\nw,b\\n1\\n2∥w∥2\\n2\\nthoả mãn:yn(wTxn + b) ≥1, ∀n= 1,2,...,N\\n(27.2)\\nVới soft-margin SVM, hàm mục tiêu sẽ có thêm một số hạng nữa giúp tối thiểutổng sự hy\\nsinh. Từ đó ta có hàm mục tiêu\\n1\\n2∥w∥2\\n2 + C\\nN∑\\nn=1\\nξn (27.3)\\ntrong đóC là một hằng số dương.Điều kiện ràng buộc được thay đổi một chút. Với mỗi cặp\\ndữ liệu(xn,yn), thay vì ràng buộccứng yn(wTxn + b) ≥1, ta sử dụng ràng buộcmềm:\\nyn(wTxn + b) ≥1 −ξn ⇔1 −ξn −yn(wTxn + b) ≤0, ∀n= 1,2,...,n\\nVà ràng buộc phụξn ≥0, ∀n= 1,2,...,N .\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 353, 'page_label': '342'}, page_content='CHƯƠNG 27. SOFT-MARGIN SUPPORT VECTOR MACHINE 342\\nTóm lại, ta sẽ có bài toán tối ưuprimal cho soft-margin SVM như sau đây.\\n(w,b,ξ ) = arg min\\nw,b,ξ\\n1\\n2∥w∥2\\n2 + C\\nN∑\\nn=1\\nξn\\nthoả mãn:1 −ξn −yn(wTxn + b) ≤0,∀n= 1,2,...,N\\n−ξn ≤0, ∀n= 1,2,...,N\\n(27.4)\\nNhận xét:\\n• Nếu C nhỏ, việcsự hy sinhcao hay thấp không gây ảnh hưởng nhiều tới giá trị của hàm\\nmục tiêu, thuật toán sẽ điều chỉnh sao cho∥w∥2\\n2 là nhỏ nhất, tứcmargin là lớn nhất, điều\\nnày sẽ dẫn tới∑N\\nn=1 ξn sẽ lớn theo vì vùng an toàn bị nhỏ đi. Ngược lại, nếuC quá lớn, để\\nhàm mục tiêu đạt giá trị nhỏ nhất, thuật toán sẽ tập trung vào làm giảm∑N\\nn=1 ξn. Trong\\ntrường hợpC rất rất lớn và hai lớp làlinearly separable, ta sẽ thu được∑N\\nn=1 ξn = 0. Chú\\ný rằng giá trị này không thể nhỏ hơn 0. Điều này đồng nghĩa với việc không có điểm nào\\nphải hy sinh, tức ta thu được nghiệm chohard-margin SVM. Nói cách khác,hard-margin\\nSVM chính là một trường hợp đặc biệt củasoft-margin SVM.\\n• Bài toán tối ưu (27.4) có thêm sự xuất hiện của các biếnslack ξn. Cácξn = 0 tương ứng\\nvới những điểm dữ liệu nằm trongvùng an toàn. Các 0 < ξn ≤1 tương ứng với những\\nđiểm nằm trongvùng không an toànnhưng vẫn được phân loại đúng, tức vẫn nằm về\\nđúng phía so với đường phân chia. Cácξn >1 tương ứng với các điểm bị phân lớp sai.\\n• Hàm mục tiêu trong bài toán tối ưu (27.4) là một hàm lồi vì nó là tổng của hai hàm\\nlồi: hàm norm và hàm tuyến tính. Các hàm ràng buộc cũng là các hàm tuyến tính theo\\n(w,b,ξ ). Vì vậy bải toán tối ưu (27.4) là một bài toán lồi, hơn nữa nó có thể biểu diễn\\ndưới dạng một quadratic programming (QP).\\nDưới đây, chúng ta sẽ cùng giải quyết bài toán tối ưu (27.4) bằng hai cách khác nhau.\\n27.3 Bài toán đối ngẫu Lagrange\\nChú ý rằng bài toán này có thể giải trực tiếp bằng các toolbox hỗ trợ QP, nhưng giống như\\nvới hard-margin SVM, chúng ta sẽ quan tâm hơn tới bài toán đối ngẫu của nó.\\nTrước kết, ta cần kiểm tra tiêu chuẩn Slater cho bài toán tối ưu lồi (27.4). Nếu tiêu chuẩn'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 353, 'page_label': '342'}, page_content='với hard-margin SVM, chúng ta sẽ quan tâm hơn tới bài toán đối ngẫu của nó.\\nTrước kết, ta cần kiểm tra tiêu chuẩn Slater cho bài toán tối ưu lồi (27.4). Nếu tiêu chuẩn\\nnày được thoả mãn,strong dualitysẽ thoả mãn, và ta sẽ có nghiệm của bài toán tối ưu (27.4)\\nlà nghiệm của hệ điều kiện KKT (xem Chương 25).\\n27.3.1 Kiểm tra tiêu chuẩn Slater\\nRõ ràng là với mọin = 1,2,...,N và mọi (w,b), ta luôn có thể tìm được các sốdương\\nξn,n = 1,2,...,N, đủ lớn sao choyn(wTxn+ b) +ξn >1, ∀n= 1,2,...,N . Vì vậy, bài toán\\nnày thoả mãn tiêu chuẩn Slater.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 354, 'page_label': '343'}, page_content='343 CHƯƠNG 27. SOFT-MARGIN SUPPORT VECTOR MACHINE\\n27.3.2 Lagrangian của bài toán Soft-margin SVM\\nLagrangian cho bài toán (27.4) là\\nL(w,b, ξ,λ,µ) = 1\\n2∥w∥2\\n2 + C\\nN∑\\nn=1\\nξn +\\nN∑\\nn=1\\nλn(1 −ξn −yn(wTxn + b)) −\\nN∑\\nn=1\\nµnξn (27.5)\\nvới λ= [λ1,λ2,...,λ N]T ⪰0 và µ= [µ1,µ2,...,µ N]T ⪰0 là các biến đối ngẫu Lagrange.\\n27.3.3 Bài toán đối ngẫu\\nHàm số đối ngẫu của bài toán tối ưu (27.4) là:\\ng(λ,µ) = min\\nw,b,ξ\\nL(w,b, ξ,λ,µ)\\nVới mỗi cặp(λ,µ), chúng ta sẽ quan tâm tới(w,b, ξ) thoả mãn điều kiện đạo hàm của\\nLagrangian bằng 0:\\n∇wL= 0 ⇔w =\\nN∑\\nn=1\\nλnynxn (27.6)\\n∇bL= 0 ⇔\\nN∑\\nn=1\\nλnyn = 0 (27.7)\\n∇ξnL= 0 ⇔λn = C−µn (27.8)\\nTừ (27.8) ta thấy rằng ta chỉ quan tâm tới những cặp(λ,µ) sao cho λn = C −µn. Từ\\nđây ta cũng suy ra0 ≤λn,µn ≤C,n = 1,2,...,N . Thay các biểu thức này vào biểu thức\\nLagrangian (27.5), ta thu được hàm mục tiêu của bài toán đối ngẫu1\\ng(λ,µ) =\\nN∑\\nn=1\\nλn −1\\n2\\nN∑\\nn=1\\nN∑\\nm=1\\nλnλmynymxT\\nnxm (27.9)\\nChú ý rằng hàm này không phụ thuộc vàoµnhưng ta cần lưu ý ràng buộc (27.8), ràng buộc\\nnày và điều kiện không âm củaλcó thể được viết gọn lại thành0 ≤λn ≤C, khi đó ta đã\\ngiảm được biếnµ. Lúc này, bài toán đối ngẫu trở thành\\nλ= arg max\\nλ\\ng(λ)\\nthoả mãn:\\nN∑\\nn=1\\nλnyn = 0 (27.10)\\n0 ≤λn ≤C, ∀n= 1,2,...,N (27.11)\\nBài toán này gần giống với bài toán đối ngẫu củahard-margin SVM, chỉ khác là có thêm\\nràng buộc mỗiλn bị chặn trên bởiC. KhiC rất lớn, ta có thể coi hai bài toán là như nhau.\\n1 Bạn đọc hãy coi đây như là một bài tập nhỏ.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 355, 'page_label': '344'}, page_content='CHƯƠNG 27. SOFT-MARGIN SUPPORT VECTOR MACHINE 344\\nRàng buộc (27.11) còn được gọi làbox constraintvì không gian các điểmλthoả mãn ràng\\nbuộc này giống như một hình hộp chữ nhật trong không gian nhiều chiều. Bài toán này cũng\\nhoàn toàn giải được bằng các công cụ giải QP thông thường, ví dụ CVXOPT như tôi đã\\nthực hiện trong bàihard-margin SVM. Sau khi tìm đượcλ của bài toán đối ngẫu, ta vẫn\\nphải quay lại tìm nghiệm(w,b, ξ) của bài toán gốc. Trước hết, chúng ta cùng xem xét hệ\\nđiều kiện KKT và các tính chất của nghiệm.\\n27.3.4 Hệ điều kiện KKT\\n(Bạn đọc không muốn đi sâu vào toán có thể bỏ qua mục này)\\nHệ điều kiện KKT2 của bài toán tối ưusoft-margin SVM là, với mọin= 1,2,...,N :\\n1 −ξn −yn(wTxn + b) ≤0 (27.12)\\n−ξn ≤0 (27.13)\\nλn ≥0 (27.14)\\nµn ≥0 (27.15)\\nλn(1 −ξn −yn(wTxn + b)) = 0 (27.16)\\nµnξn = 0 (27.17)\\nw =\\nN∑\\nn=1\\nλnynxn (27.6)\\nN∑\\nn=1\\nλnyn = 0 (27.7)\\nλn = C−µn (27.8)\\nTừ (27.8) ta thấy chỉ có nhữngn ứng vớiλn >0 mới đóng góp vào nghiệmw của bài toán.\\nTập hợpS= {n: λn >0}được gọi làsupport set, và{xn,n ∈S} được gọi là tập các điểm\\nsupport vectors.\\nKhi λn >0, (27.16) chỉ ra rằng\\nyn(wTxn + b) = 1 −ξn (27.18)\\nNếu có thêm điều kiện0 <λn <C , (27.11) nói rằngµn = C−λn >0, kết hợp với (27.17),\\nta thu đượcξn = 0. Tiếp tục kết hợp với (27.18), ta suy rayn(wTxn+ b) = 1. Nói cách khác,\\nwTxn + b= yn, ∀n: 0 <λn <C (27.19)\\nTóm lại, khi0 < λn < C, các điểmxn nằm chính xác trên cácmargin (hai đường nét đứt\\nmảnh trong Hình 27.2). Tương tự như vớihard-margin SVM, giá trịbcó thể được tính theo\\ncông thức (numerical stable solution):\\nb= 1\\nNM\\n∑\\nm∈M\\n(\\nym −wTxm\\n)\\n(27.20)\\n2 Để cho dễ hình dung, các điều kiện (27.6) (27.7) (27.8) đã được nhắc lại trong hệ này.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 356, 'page_label': '345'}, page_content='345 CHƯƠNG 27. SOFT-MARGIN SUPPORT VECTOR MACHINE\\nvới M= {m: 0 < λm < C}và NM là số phần tử củaS. Nghiệm của bài toánsoft-margin\\nSVM được cho bởi (27.8) và (27.20).\\nNghiệm của bài toánsoft-margin SVM\\nw =\\n∑\\nm∈S\\nλmymxm (27.21)\\nb= 1\\nNM\\n∑\\nn∈M\\n(yn −wTxn) = 1\\nNM\\n∑\\nn∈M\\n(\\nyn −\\n∑\\nm∈S\\nλmymxT\\nmxn\\n)\\n(27.22)\\nCũng từ (27.18) và (27.16) ta suy rayn(wTxn+b) ≤1 với những điểm tương ứng vớiλn = C.\\nTức những điểm này nằm giữa hoặc trên hai đườngmargin. Như vậy, dựa trên các giá trị\\ncủa λn ta có thể dự đoán được vị trí tương đối củaxn so với hai đườngmargin.\\nMục đích cuối cùng là xác định nhãn cho một điểm mới hơn là tính cụ thểw và b. Vì vậy,\\nta quan tâm hơn tới cách xác định giá trị của biểu thức sau đây vớix bất kỳ:\\nwTx + b=\\n∑\\nm∈S\\nλmymxT\\nmx + 1\\nNM\\n∑\\nn∈M\\n(\\nyn −\\n∑\\nm∈S\\nλmymxT\\nmxn\\n)\\n(27.23)\\nTrong cách tính này, nếu biết cách tính các tích vô hướngxT\\nmx và xT\\nmxn, ta có thể xác định\\nđược bộ phân lớp. Trong chương tiếp theo, ta sẽ thấy rằng bằng cách sử dụng cácphép biến\\nđổi phi tuyến(nonlinear transformation) để thay đổi tích vô hướng bằng các hàm khác, ta\\nsẽ thu được các bộ phân lớp làm việc hiệu quả với dữ liệu khônglinear separable.\\n27.4 Bài toán tối ưu không ràng buộc chosoft-margin SVM\\nTrong mục này, chúng ta sẽ đưa bài toán tối ưu có ràng buộc (27.4) về một bài toán tối\\nưu không ràng buộc, và có có khả năng giải được bằng các phương pháp gradient descent\\ngiống như các neural network. Đây cũng là nên tảng để kết hợp mộtmulti-class SVM vào\\ncác neural network, như sẽ được trình bày trong Chương 29.\\n27.4.1 Bài toán tối ưu không ràng buộc tương đương\\nĐể ý thấy rằng điều kiện ràng buộc thứ nhất:\\n1 −ξn −yn(wTx + b) ≤0 ⇔ξn ≥1 −yn(wTx + b) (27.24)\\nKết hợp với điều kiệnξn ≥0 ta sẽ thu được bài toán ràng buộc tương đương với bài toán\\n(27.4) như sau:\\n(w,b,ξ ) = arg min\\nw,b,ξ\\n1\\n2∥w∥2\\n2 + C\\nN∑\\nn=1\\nξn\\nthoả mãn:ξn ≥max(0,1 −yn(wTx + b)), ∀n= 1,2,...,N\\n(27.25)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 357, 'page_label': '346'}, page_content='CHƯƠNG 27. SOFT-MARGIN SUPPORT VECTOR MACHINE 346\\nTiếp theo, để đưa bài toán (27.25) về dạng không ràng buộc, chúng ta sẽ chứng minh nhận\\nxét sau đây bằng phương pháp phản chứng. Nếu(w,b,ξ ) là nghiệm của bài toán tối ưu\\n(27.25), tức tại đó hàm mục tiêu đạt giá trị nhỏ nhất, thì\\nξn = max(0,1 −yn(wTxn + b)), ∀n= 1,2,...,N (27.26)\\nThật vậy, giả sử ngược lại, tồn tạin sao cho\\nξn >max(0,1 −yn(wTxn + b)),\\nchọn ξ′\\nn = max(0,1 −yn(wTxn+ b)), ta sẽ thu được một giá trị thấp hơn của hàm mục tiêu,\\ntrong khi tất cả các ràng buộc vẫn được thoả mãn. Điều này mâu thuẫn với việc hàm mục\\ntiêu đã đạt giá trị nhỏ nhất! Điều mâu thuẫn này chỉ ra rằng nhận xét (27.26) là chính xác.\\nKhi đó, bằng cách thay toàn bộ các giá trị củaξn trong (27.26) vào hàm mục tiêu, ta thu\\nđược bài toán tối ưu\\n(w,b,ξ ) = arg min\\nw,b,ξ\\n1\\n2∥w∥2\\n2 + C\\nN∑\\nn=1\\nmax(0,1 −yn(wTxn + b))\\nthoả mãn:ξn = max(0,1 −yn(wTxn + b)), ∀n= 1,2,...,N\\n(27.27)\\nTừ đây ta thấy rằng biến sốξ không còn quan trọng trong bài toán này nữa, ta có thể lược\\nbỏ rằng buộc này mà không làm thay đổi nghiệm của bài toán.\\nBài toán (27.27) tương đương với\\n(w,b) = arg min\\nw,b\\n{\\n1\\n2∥w∥2\\n2 + C\\nN∑\\nn=1\\nmax(0,1 −yn(wTxn + b)) ≜J(w,b)\\n}\\n(27.28)\\nĐây là một bài toán tối ưu không ràng buộc với hàm mất mátJ(w,b). Bài toán này có thể\\ngiải được bằng các phương pháp gradient descent. Nhưng trước hết, chúng ta cùng xem xét\\nhàm mất mát này từ một góc nhìn khác. Góc nhìn mới này giúp xây dựng hàm mất mát\\nJ(w,b) một cáchtự nhiên hơn bằng cách sử dụng một hàm số có tên làhinge loss.\\n27.4.2 Hinge loss\\nNhắc lại một chút về hàmcross entropy. Với mỗi cặp hệ số(w,b) và cặp dữ liệu(xn,yn), đặt\\nzn = wTxn+ bvàan = σ(zn) (σ là sigmoid function). Hàmcross entropyđược định nghĩa là\\nJ1\\nn(w,b) = −(ynlog(an) + (1−yn) log(1−an)) (27.29)\\nHàm cross entropyđạt giá trị càng nhỏ nếu xác suấtan càng gần vớiyn (0 <an <1).\\nỞ đây, chúng ta làm quen với một hàm số khác cũng được sử dụng nhiều trong các bộ phân\\nlớp. Hàm số này có dạng\\nJn(w,b) = max(0,1 −ynzn)'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 357, 'page_label': '346'}, page_content='Ở đây, chúng ta làm quen với một hàm số khác cũng được sử dụng nhiều trong các bộ phân\\nlớp. Hàm số này có dạng\\nJn(w,b) = max(0,1 −ynzn)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 358, 'page_label': '347'}, page_content='347 CHƯƠNG 27. SOFT-MARGIN SUPPORT VECTOR MACHINE\\n-3 -2 -1 0 1 2 3\\n-1\\n1\\n2\\n3\\nyz\\nh(yz)\\nHình 27.3:Hinge loss (màu xanh)\\nvà zeros-one loss (màu đen). Với\\nzero-one loss, những điểm nằm\\nxa margin (hoành độ bằng 1) và\\nboundary (hoành độ bằng 0) được\\nđối xử như nhau. Trong khi đó, với\\nhinge loss, những điểm ở xa về phía\\ntrái gây ra mất mát nhiều hơn.\\nHàm này có tên làhinge loss. Trong đó,zn = wTxn + b có thể được coi làscore của xn\\nứng với cặp hệ số(w,b), yn chính là đầu ra mong muốn. Chúng ta sẽ sớm thấy ý nghĩa của\\nhàm này thông qua đồ thị của hàm tương ứng. Hình 27.3 mô tả đồ thị hàm sốhinge loss3\\nf(yz) = max(0 ,1 −yz) và so sánh với hàmzero-one loss. Hàmzero-one losslà hàmđếm số\\nđiểm bị phân lớp lỗi. Trong Hình 27.5, biến số làyz là tích của đầu ra mong muốn (ground\\ntruth) vàscore z. Những điểm ở phía phải của trục tung ứng với những điểm được phân\\nloại đúng, tứcz tìm được cùng dấu vớiy. Những điểm ở phía trái của trục tung ứng với các\\nđiểm bị phân loại sai. Ta có các nhận xét sau đây:\\n• Với hàmzero-one loss, các điểm cóscore ngược dấu với đầu ra mong muốn (yz <0) sẽ\\ngây ra mất mát như nhau (bằng 1), bất kể chúng ở gần hay xa đường ranh giới (trục\\ntung). Đây là một hàm rời rạc, rất khó tối ưu và ta cũng khó có thể đo đếm đượcsự hy\\nsinh như đã định nghĩa ở phần đầu.\\n• Với hàmhinge loss, những điểm nằm trong vùng an toàn, ứng vớiys ≥1, sẽ không gây\\nra mất mát gì. Những điểm nằm giữa margin của lớp tương ứng và đường ranh giới ứng\\nvới 0 < y <1. Những điểm này gây ra một mất mát nhỏ (nhỏ hơn 1). Những điểm bị\\nmisclassifed, tứcyz <0 sẽ gây ra mất mát lớn hơn. Vì vậy, khi tối thiểu hàm mất mát,\\nta sẽ hạn chế được những điểm bịmisclassifed và lấn sang phầnlãnh thổ của lớp còn lại\\nquá nhiều. Đây chính là một ưu điểm của hàmhinge loss.\\n• Hàmhinge losslàmộthàmliêntục,và có đạo hàm tại gần như mọi nơi(almost everywhere\\ndifferentiable) trừ điểm có hoành độ bằng 1. Ngoài ra, đạo hàm của hàm này cũng rất dễ'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 358, 'page_label': '347'}, page_content='• Hàmhinge losslàmộthàmliêntục,và có đạo hàm tại gần như mọi nơi(almost everywhere\\ndifferentiable) trừ điểm có hoành độ bằng 1. Ngoài ra, đạo hàm của hàm này cũng rất dễ\\nxác định: bằng -1 tại các điểm nhỏ hơn 1 và bằng 0 tại các điểm lớn hơn 1. Tại 1, ta có\\nthể coi như đạo hàm của nó bằng 0 giống như cách tính đạo hàm của hàm ReLU.\\n27.4.3 Xây dựng hàm mất mát\\nXét bài toánsoft-margin SVM bằng cách sử dụnghinge loss, với mỗi cặp(w,b), đặt\\nLn(w,b) = max(0 ,1 −ynzn) = max(0 ,1 −yn(wTxn + b)) (27.30)\\n3 Đồ thị của hàm số này có hình giống chiếc bản lề. Trong tiếng Anh,hinge nghĩa là bản lề.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 359, 'page_label': '348'}, page_content='CHƯƠNG 27. SOFT-MARGIN SUPPORT VECTOR MACHINE 348\\nLấy trung bình cộng của cácloss này theo mọi điểm dữ liệu trong tập huấn luyện ta được\\nL(w,b) = 1\\nN\\nN∑\\nn=1\\nLn = 1\\nN\\nN∑\\nn=1\\nmax(0,1 −yn(wTxn + b))\\nCâu hỏi đặt ra là, nếu ta trực tiếp tối ưu trung bình các hinge loss này thì điều gì sẽ xảy ra?\\nTrong trường hợp dữ liệu của hai lớp làlinearly separable, ta sẽ có giá trị tối ưu tìm được\\ncủa L(w,b) sẽ bằng 0. Điều này có nghĩa là:\\n1 −yn(wTxn + b) ≤0, ∀n= 1,2,...,N (27.31)\\nNhân cả hai về với một hằng sốa> 1 ta có:\\na−yn(awTxn + ab) ≤0, ∀n= 1,2,...,N (27.32)\\n⇒1 −yn(awTxn + ab) ≤1 −a< 0, ∀n= 1,2,...,N (27.33)\\nĐiều này nghĩa là(aw,ab) cũng là nghiệm của bài toán. Nếu không có điều kiện gì thêm,\\nbài toán có thể dẫn tới nghiệm không ổn định vì các hệ số của nghiệm có thể lớn tuỳ ý!\\nĐể tránhbug này, chúng ta cần thêm một số hạng nữa vàoL(w,b) gọi là số hạngregulariza-\\ntion, giống như cách chúng ta đã làm để tránhoverfitting trong neural networks. Lúc này,\\nta sẽ có hàm mất mát tổng cộng là\\nJ(w,b) = L(w,b) + λR(w,b)\\nvới λ là một số dương, gọi làregularization parameter, hàmR() sẽ giúp hạn chế việc các hệ\\nsố (w,b) trở nên quá lớn. Có nhiều cách chọn hàmR(), nhưng cách phổ biến nhất làl2, khi\\nđó hàm mất mát củasoft-margin SVM trở thành\\nJ(w,b) = 1\\nN\\n\\uf8eb\\n\\uf8ec\\uf8ec\\uf8ec\\uf8ec\\uf8ed\\nN∑\\nn=1\\nmax(0,1 −yn(wTxn + b))\\n\\ued19 \\ued18\\ued17 \\ued1a\\nhinge loss\\n+ λ\\n2 ∥w∥2\\n2\\n\\ued19 \\ued18\\ued17 \\ued1a\\nregularization\\n\\uf8f6\\n\\uf8f7\\uf8f7\\uf8f7\\uf8f7\\uf8f8\\n(27.34)\\nKỹ thuật này còn gọi làweight decay. Chú ý rằng weight decay thường không được\\náp dụng lên thành phần biasb.\\nTa thấy rằng hàm mất mát (27.34) giống với hàm mất mát (27.28) vớiλ= 1\\nC, và thay việc\\nlấy trung bình cộng bằng việc tính tổng.\\nTrong phần tiếp theo của mục này, chúng ta sẽ quan tâm tới bài toán tối ưu hàm mất mát\\nđược cho trong (27.34). Trước hết, đây là một hàm lồi theow,b vì các lý do sau:\\n• 1 −yn(wTxn + b) là một hàm tuyến tính theow,b nên nó là một hàm lồi. Hàm lấy giá\\ntrị lớn hơn trong hai hàm lồi là một hàm lồi, vì vậy,hingle loss là một hàm lồi.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 360, 'page_label': '349'}, page_content='349 CHƯƠNG 27. SOFT-MARGIN SUPPORT VECTOR MACHINE\\n• Hàm norm cũng là một hàm lồi.\\n• Tổng của hai hàm lồi là một hàm lồi.\\nVì hàm mất mát là lồi, các thuật toán gradient descent vớilearning ratephù hợp sẽ giúp\\ntìm được nghiệm của bài toán.\\n27.4.4 Tối ưu hàm mất mát\\nVì việc tối ưu hàm mất mát dựa trên gradient descent, việc chính của mục này là tính đạo\\nhàm của hàm mất mát theow và b.\\nĐạo hàm của phầnhinge loss không quá phức tạp:\\n∇w\\n(\\nmax(0,1 −yn(wTxn + b))\\n)\\n=\\n{\\n−ynxn nếu 1 −yn(wTxn + b) ≥0\\n0 o.w. (27.35)\\n∇b\\n(\\nmax(0,1 −yn(wTxn + b))\\n)\\n=\\n{\\n−yn nếu 1 −yn(wTxn + b) ≥0\\n0 o.w. (27.36)\\nPhần regularization cũng có đạo hàm tương đối đơn giản:\\n∇w\\n(λ\\n2 ∥w∥2\\n2\\n)\\n= λw; ∇b\\n(λ\\n2 ∥w∥2\\n2\\n)\\n= 0 (27.37)\\nNếu cập nhật bằng gradient descent thông qua chỉ một điểm dữ liệu(xn,yn) (stochastic\\ngradient descent). Nếu1 −yn(wTxn+ b) <0, ta không cập nhật gì và chuyển sang điểm tiếp\\ntheo. Ngược lại biểu thức cập nhật chow,b được cho bởi\\nw ←w −η(−ynxn + λw); b←b+ ηyn nếu 1 −yn(wTxn + b) ≥0) (27.38)\\nw ←w −ηλw; b←b o.w. (27.39)\\nvới η là learning rate. Vớimini-batch gradient descenthoặc batch gradient descent, các biểu\\nthức đạo hàm trên đây hoàn toàn có thể được lập trình bằng các kỹ thuậtvectorization, như\\nchúng ta sẽ thấy trong mục tiếp theo.\\n27.5 Lập trình vớisoft-margin SVM\\nTrong mục này, chúng ta sẽ đi tìm nghiệm của một bài toánsoft-margin SVMbằng ba cách\\nkhác nhau: sử dụng thư viện sklearn, giải bài toán đối ngẫu bằng CVXOPT, và tối ưu hàm\\nmất mát không ràng buộc bằng phương pháp gradient descent. Giá trịC được sử dụng là\\n100. Nếu mọi tính toán ở trên là chính xác, nghiệm của ba cách làm này sẽ gần giống nhau,\\nkhác nhau có thể một chút bởi sai số trong tính toán4. Chúng ta cũng sẽ thayC bởi những\\ngiá trị khác nhau và cùng xem cácmargin thay đổi như thế nào.\\n4 Ta có thể khẳng định việc này vì bài toán tối ưusoft-margin SVM là lồi.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 361, 'page_label': '350'}, page_content='CHƯƠNG 27. SOFT-MARGIN SUPPORT VECTOR MACHINE 350\\nKhai báo thư viện và tạo dữ liệu giả\\nfrom __future__ import print_function\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\nnp.random.seed(22)\\nmeans = [[2, 2], [4, 2]]\\ncov = [[.7, 0], [0, .7]]\\nN = 20 # number of samplers per class\\nX0 = np.random.multivariate_normal(means[0], cov, N) # each row is a data point\\nX1 = np.random.multivariate_normal(means[1], cov, N)\\nX = np.concatenate((X0, X1))\\ny = np.concatenate((np.ones(N), -np.ones(N)))\\nCác điểm màu xanh và đỏ trên Hình 27.4 minh hoạ các điểm dữ liệu của hai lớp. Dữ liệu\\nnày làgần linearly separable.\\n27.5.1 Giải bài toán bằng thư viện sklearn\\nfrom sklearn.svm import SVC\\nC = 100\\nclf = SVC(kernel = ’linear’, C = C)\\nclf.fit(X, y)\\nw_sklearn = clf.coef_.reshape(-1, 1)\\nb_sklearn = clf.intercept_[0]\\nprint(w_sklearn.T, b_sklearn)\\nKết quả:\\nw_sklearn = [[-1.87461946 -1.80697358]]\\nb_sklearn = 8.49691190196\\n27.5.2 Tìm nghiệm bằng cách giải bài toán đối ngẫu\\nĐoạn code dưới đây tương tự như việc giải bài toánhard-margin SVM, chỉ khác rằng ta có\\nthêm ràng buộc về chặn trên của các nhân tử Lagrange:\\nfrom cvxopt import matrix, solvers\\n# build K\\nV = np.concatenate((X0, -X1), axis = 0) # V[n,:] = y[n]*X[n]\\nK = matrix(V.dot(V.T))\\np = matrix(-np.ones((2*N, 1)))\\n# build A, b, G, h\\nG = matrix(np.vstack((-np.eye(2*N), np.eye(2*N))))\\nh = np.vstack((np.zeros((2*N, 1)), C*np.ones((2*N, 1))))\\nh = matrix(np.vstack((np.zeros((2*N, 1)), C*np.ones((2*N, 1)))))\\nA = matrix(y.reshape((-1, 2*N)))\\nb = matrix(np.zeros((1, 1))) # continue on next page\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 362, 'page_label': '351'}, page_content='351 CHƯƠNG 27. SOFT-MARGIN SUPPORT VECTOR MACHINE\\nsolvers.options[’show_progress’] = False\\nsol = solvers.qp(K, p, G, h, A, b)\\nl = np.array(sol[’x’]).reshape(2*N) # lambda vector\\n# support set\\nS = np.where(l > 1e-5)[0]\\nS2 = np.where(l < .999*C)[0]\\n# margin set\\nM = [val for val in S if val in S2] # intersection of two lists\\nVS = V[S] # shape (NS, d)\\nlS = l[S] # shape (NS,)\\nw_dual = lS.dot(VS) # shape (d,)\\nyM = y[M] # shape(NM,)\\nXM = X[M] # shape(NM, d)\\nb_dual = np.mean(yM - XM.dot(w_dual)) # shape (1,)\\nprint(’w_dual = ’, w_dual)\\nprint(’b_dual = ’, b_dual)\\nKết quả:\\nw_dual = [-1.87457279 -1.80695039]\\nb_dual = 8.49672109814\\nKết quả này gần giống với kết quả tìm được bằng sklearn.\\n27.5.3 Tìm nghiệm bằng giải bài toán tối ưu không ràng buộc\\nTrong phương pháp này, chúng ta cần tính gradient của hàm mất mát. Như thường lệ, chúng\\nta cần kiểm chứng này bằng cách so sánh vớinumerical gradient. Chú ý rằng trong phương\\npháp này, ta cần dùng tham sốlam = 1/C. Trước hết ta viết các hàm tính giá trị hàm mất\\nmát và đạo hàm theow và b.\\nlam = 1./C\\ndef loss(X, y, w, b):\\n\"\"\"\\nX.shape = (2N, d), y.shape = (2N,), w.shape = (d,), b is a scalar\\n\"\"\"\\nz = X.dot(w) + b # shape (2N,)\\nyz = y*z\\nreturn (np.sum(np.maximum(0, 1 - yz)) + .5*lam*w.dot(w))/X.shape[0]\\ndef grad(X, y, w, b):\\nz = X.dot(w) + b # shape (2N,)\\nyz = y*z # element wise product, shape (2N,)\\nactive_set = np.where(yz <= 1)[0] # consider 1 - yz >= 0 only\\n_yX = - X*y[:, np.newaxis] # each row is y_n*x_n\\ngrad_w = (np.sum(_yX[active_set], axis = 0) + lam*w)/X.shape[0]\\ngrad_b = (-np.sum(y[active_set]))/X.shape[0]\\nreturn (grad_w, grad_b) ## continue on next page\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 363, 'page_label': '352'}, page_content='CHƯƠNG 27. SOFT-MARGIN SUPPORT VECTOR MACHINE 352\\ndef num_grad(X, y, w, b):\\neps = 1e-10\\ngw = np.zeros_like(w)\\ngb = 0\\nfor i in xrange(len(w)):\\nwp = w.copy()\\nwm = w.copy()\\nwp[i] += eps\\nwm[i] -= eps\\ngw[i] = (loss(X, y, wp, b) - loss(X, y, wm, b))/(2*eps)\\ngb = (loss(X, y, w, b + eps) - loss(X, y, w, b - eps))/(2*eps)\\nreturn (gw, gb)\\nw = .1*np.random.randn(X.shape[1])\\nb = np.random.randn()\\n(gw0, gb0) = grad(X, y, w, b)\\n(gw1, gb1) = num_grad(X, y, w, b)\\nprint(’grad_w difference = ’, np.linalg.norm(gw0 - gw1))\\nprint(’grad_b difference = ’, np.linalg.norm(gb0 - gb1))\\nKết quả:\\ngrad_w difference = 1.27702840067e-06\\ngrad_b difference = 4.13701854995e-08\\nSự sai khác giữa hai cách tính là nhỏ; vậy ta có thể tin tưởng sử dụng hàmgrad trong\\ngradient descent.\\ndef softmarginSVM_gd(X, y, w0, b0, eta):\\nw = w0\\nb = b0\\nit = 0\\nwhile it < 10000:\\nit = it + 1\\n(gw, gb) = grad(X, y, w, b)\\nw -= eta*gw\\nb -= eta*gb\\nif (it % 1000) == 0:\\nprint(’iter %d’ %it + ’ loss: %f’ %loss(X, y, w, b))\\nreturn (w, b)\\nw0 = .1*np.random.randn(X.shape[1])\\nb0 = .1*np.random.randn()\\nlr = 0.05\\n(w_hinge, b_hinge) = softmarginSVM_gd(X, y, w0, b0, lr)\\nprint(’w_hinge = ’, w_dual)\\nprint(’b_hinge = ’, b_dual)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 364, 'page_label': '353'}, page_content='353 CHƯƠNG 27. SOFT-MARGIN SUPPORT VECTOR MACHINE\\nx1\\nx2\\nSolution found by sklearn\\n(a)\\nx1\\nx2\\nSolution found by dual (b)\\nx1\\nx2\\nSolution found by hinge (c)\\nHình 27.4: Các đường phân chia tìm được bởi ba cách khác nhau: a) Thư viện sklearn, b) Giải\\nbài toán đối ngẫu bằng CVXOPT, c) Hàm hinge loss. Các kết quả tìm được gần như giống nhau.\\nKết quả:\\niter 1000 loss: 0.436460\\niter 2000 loss: 0.405307\\niter 3000 loss: 0.399860\\niter 4000 loss: 0.395440\\niter 5000 loss: 0.394562\\niter 6000 loss: 0.393958\\niter 7000 loss: 0.393805\\niter 8000 loss: 0.393942\\niter 9000 loss: 0.394005\\niter 10000 loss: 0.393758\\nw_hinge = [-1.87457279 -1.80695039]\\nb_hinge = 8.49672109814\\nTa thấy rằngloss giảm dần và hội tụ theo thời gian, chứng tỏlearning rate là phù hợp.\\nNghiệm tìm được cũng gần giống nghiệm của hai cách làm phía trên.\\nHình 27.4 mình hoạ các nghiệm tìm được bằng ba phương pháp phía trên. Ta thấy rằng các\\nnghiệm tìm được gần như giống nhau.\\n27.5.4 Ảnh hưởng củaC lên nghiệm\\nHình 27.5 minh hoạ nghiệm tìm được bằng sklearn với các giá trịC khác nhau. Quan sát\\nthấy khiC càng lớn, biên càng nhỏ đi. Điều này phù hợp với các suy luận ở đầu chương.\\n27.6 Tóm tắt và thảo luận\\n• SVM thuần (hard-margin SVM) hoạt động không hiệu quả khi có nhiễu ở gần ranh giới\\nhoặc thậm chí khi dữ liệu giữa hai lớp gầnlinearly separable. Soft-margin SVM có thể\\ngiúp khắc phục điểm này.\\n• Trong soft-margin SVM, chúng ta chấp nhận lỗi xảy ra ở một vài điểm dữ liệu. Lỗi này\\nđược xác định bằng khoảng cách từ điểm đó tới đườngmargin tương ứng. Bài toán tối\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 365, 'page_label': '354'}, page_content='CHƯƠNG 27. SOFT-MARGIN SUPPORT VECTOR MACHINE 354\\nx1\\nx2\\nC = 0.100000\\nx1\\nx2\\nC = 1\\nx1\\nx2\\nC = 10\\nx1\\nx2\\nC = 100\\nHình 27.5:Ảnh hưởng củaC lên nghiệm của soft-margin SVM.C càng lớn, biên càng nhỏ, và\\nngược lại.\\nưu sẽ tối thiểu lỗi này bằng cách sử dụng thêm các biến được gọi làslack varaibles. Để\\ngiải bài toán tối ưu, có hai cách khác nhau.\\n• Cách thứ nhất là giải bài toán đối ngẫu. Bài toán đối ngẫu của soft margin SVM rất\\ngiống với bài toán đối ngẫu của hard-margin SVM, chỉ khác ở ràng buộc chặn trên của\\ncác nhân tử Laggrange. Ràng buộc này còn được gọi làbox costraint.\\n• Cách thứ hai là đưa bài toán về dạng không ràng buộc dựa trên một hàm mới gọi làhinge\\nloss. Với cách này, hàm mất mát thu được là một hàm lồi và có thể giải được một cách\\nhiệu quả bằng các phương pháp gradient descent.\\n• Soft-margin SVM yêu cầu chọn hằng sốC. Hướng tiếp cận này còn được gọi là C-SVM.\\nNgoài ra, còn có một hướng tiếp cận khác cũng hay được sử dụng, gọi làν-SVM [SSWB00].\\n• Source code cho chương này có thể được tìm thấy tạihttps://goo.gl/PuWxba .\\n• LIBSVM là một thư viện SVM phổ biến (https://goo.gl/Dt7o7r ).\\n• Đọc thêm: L. Rosasco et al.,. Are Loss Functions All the Same? (https://goo.gl/\\nQH2Cgr). Neural Computation.2004 [RDVC+04].\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 366, 'page_label': '355'}, page_content='Chương 28\\nKernel support vector machine\\n28.1 Giới thiệu\\nCó một sự tương ứng thú vị giữa hai nhóm thuật toán phân lớp phổ biến nhất, neural\\nnetwork và support vector machine. Chúng đều bắt đầu từ bài toán phân lớp với hai lớp dữ\\nliệu linearly separable, tiếp theo đến hai lớpgần như linear separable, đến bài toán với nhiều\\nlớp dữ liệu, rồi các bài toán với các lớp hoàn toàn khônglinearly separable. Sự tương ứng\\nđược cho trong Bảng 28.1\\nBảng 28.1: Sự tương đồng giữa neural network và support vector machine\\nNeural network Support vector machine Tính chất chung\\nPLA Hard-margin SVM Hai lớp làlinearly separable\\nLogistic regression Soft-margin SVM Hai lớp làgần linearly separable\\nSoftmax regression Multi-class SVM Nhiều lớp dữ liệu (ranh giới là các siêu phẳng)\\nMulti-layer perceptron Kernel SVM Bài toán phân lớp với biên khônglinearly separable\\nTrong chương này, chúng ta cùng thảo luận về Kernel SVM, tức việc áp dụng SVM lên bài\\ntoán mà dữ liệu giữa hai lớp là hoàn toànkhông linear separable. Bài toán phân biệt nhiều\\nlớp dữ liệu sẽ được thảo luận trong chương tiếp theo.\\nÝ tưởng cơ bản của Kernel SVM và các phương pháp kernel nói chung là tìm một phép biến\\nđổi dữ liệukhông linearly separableở một không gian sang một không gian mới. Ở không\\ngian mới này, dữ liệu trở nênlinearly separablehoặc gần linearly separable, và vì vậy, bài\\ntoán phân lớp có thể được giải quyết bằng hard/soft-margin SVM.\\nXét ví dụ trên Hình 28.1 với việc biến dữ liệu khônglinearly separable trong không gian\\nhai chiều thànhlinearly separabletrong không gian ba chiều bằng cách giới thiệu thêm một'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 367, 'page_label': '356'}, page_content='CHƯƠNG 28. KERNEL SUPPORT VECTOR MACHINE 356\\n(a)\\n(b)\\n(c)\\nHình 28.1: Ví dụ về Kernel SVM. (a) Dữ liệu của hai lớp làkhông phân biệt tuyến tínhtrong\\nkhông gian hai chiều. (b) Nếu coi thêm chiều thứ ba là một hàm số của hai chiều còn lại\\nz = x2 + y2, các điểm dữ liệu sẽ được phân bố trên một mặt parabolic và đã hai lớp trở nên\\nlinearly separable. Mặt phẳng màu vàng là mặt phân chia, có thể tìm được bởi một hard/soft-\\nmargin SVM. (c) Giao điểm của mặt phẳng tìm được và mặt parabolic là một đường ellipse, khi\\nchiếu toàn bộ dữ liệu cũng như đường ellipse này xuống không gian hai chiều ban đầu, ta đã tìm\\nđược đường phân chia hai lớp.\\nchiều mới. Để xem ví dụ này một cách sinh động hơn, bạn có thể xem clip đi kèm với blog\\nMachine Learning cơ bảntại https://goo.gl/3wMHyZ .\\nNói một cách toán học, kernel SVM là phương pháp đi tìm một hàm số biến đổi dữ liệux\\ntừ không gian đặc trưng ban đầu thành dữ liệu trong một không gian mới bằng một hàm\\nsố Φ(x). Trong ví dụ này, hàmΦ() đơn giản là giới thiệu thêm một chiều dữ liệu mới là\\nmột hàm số của các thành phần đặc trưng đã biết. Hàm số này cần thỏa mãn: trong không\\ngian mới, dữ liệu giữa hai lớp làlinearly separablehoặc gần như linearly separable. Khi đó,\\nta có thể dùng các bộ phân lớp tuyến tính thông thường như PLA, logistic regression, hay\\nhard/soft margin SVM.\\nCác hàmΦ(x) thường tạo ra dữ liệu mới có số chiều cao hơn số chiều của dữ liệu ban đầu,\\nthậm chí là vô hạn chiều. Nếu tính toán các hàm này trực tiếp, chắc chắn chúng ta sẽ gặp\\ncác vấn đề về bộ nhớ và hiệu năng tính toán. Có một cách tiếp cận là sử dụng các hàm\\nkernel mô tả quan hệ giữa hai điểm dữ liệu bất kỳ trong không gian mới, thay vì đi tính\\ntoán trực tiếp biến đổi của từng điểm dữ liệu trong không gian mới. Kỹ thuật này được xây\\ndựng dựa trên quan sát về các bài toán đối ngẫu của hard/soft margin SVM.\\nNếu phải so sánh, ta có thể thấy rằng các hàmkernel có chức năng tương tự như các hàm'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 367, 'page_label': '356'}, page_content='dựng dựa trên quan sát về các bài toán đối ngẫu của hard/soft margin SVM.\\nNếu phải so sánh, ta có thể thấy rằng các hàmkernel có chức năng tương tự như các hàm\\nactivation trong neural network vì chúng đều giúp giải quyết các bài toán với dữ liệu không\\nlinearly separable. Trong Mục 28.2, chúng ta cùng tìm hiểu cơ sở toán học của Kernel SVM,\\nMục 28.3 sẽ giới thiệu một số hàmkernel thường được sử dụng.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 368, 'page_label': '357'}, page_content='357 CHƯƠNG 28. KERNEL SUPPORT VECTOR MACHINE\\n28.2 Cơ sở toán học\\nCùng nhắc lại bài toán đối ngẫu trong soft-margin SVM cho dữ liệugần linearly separable:\\nλ= arg max\\nλ\\nN∑\\nn=1\\nλn −1\\n2\\nN∑\\nn=1\\nN∑\\nm=1\\nλnλmynymxT\\nnxm\\nthoả mãn:\\nN∑\\nn=1\\nλnyn = 0\\n0 ≤λn ≤C, ∀n= 1,2,...,N\\n(28.1)\\ntrong đó,N là số cặp điểm dữ liệu trong tập huấn luyện;xn là vector đặc trưng của dữ liệu\\nthứ n trong tập training;yn là nhãn của điểm dữ liệu thứn, bằng 1 hoặc -1;λn là nhân tử\\nLagrange ứng với điểm dữ liệu thứn; vàC là một hằng số dương giúp cân đối độ lớn của\\nmargin vàsự hy sinhcủa các điểm nằm trong vùngkhông an toàn. KhiC = ∞hoặc rất lớn,\\nsoft-margin SVM trở thành hard-margin SVM.\\nSau khi giải đượcλ cho bài toán (28.1),nhãn của một điểm dữ liệu mới sẽ được xác định\\nbởi\\nclass(x) = sgn\\n{∑\\nm∈S\\nλmymxT\\nmx + 1\\nNM\\n∑\\nn∈M\\n(\\nyn −\\n∑\\nm∈S\\nλmymxT\\nmxn\\n)}\\n(28.2)\\ntrong đó, M= {n : 0 < λn < C}là tập hợp những điểm nằm trên cácmargin; S= {n :\\n0 <λn}là tập hợp cácsupport vector; vàNM là số phần tử củaM.\\nVới dữ liệu thực tế, rất khó để có dữ liệugần phân biệt tuyến tính, vì vậy nghiệm của bài\\ntoán (28.1) có thể không thực sự tạo ra một bộ phân lớp tốt. Giả sử rằng ta có thể tìm được\\nhàm sốΦ() sao cho sau khi được biến đổi sang không gian mới, mỗi điểm dữ liệux trở thành\\nΦ(x), và trong không gian mới này, dữ liệu trở nêngần phân biệt tuyến tính. Lúc này,hy\\nvọng rằngnghiệm của bài toán soft-margin SVM sẽ cho chúng ta một bộ phân lớp tốt hơn.\\nTrong không gian mới, bài toán (28.1) trở thành:\\nλ= arg max\\nλ\\nN∑\\nn=1\\nλn −1\\n2\\nN∑\\nn=1\\nN∑\\nm=1\\nλnλmynymΦ(xn)TΦ(xm)\\nthoả mãn:\\nN∑\\nn=1\\nλnyn = 0\\n0 ≤λn ≤C, ∀n= 1,2,...,N\\n(28.3)\\nvà nhãn của một điểm dữ liệu mới được xác định bởi dấu của biểu thức\\nwTΦ(x) + b=\\n∑\\nm∈S\\nλmymΦ(xm)TΦ(x) + 1\\nNM\\n∑\\nn∈M\\n(\\nyn −\\n∑\\nm∈S\\nλmymΦ(xm)TΦ(xn)\\n)\\n(28.4)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 369, 'page_label': '358'}, page_content='CHƯƠNG 28. KERNEL SUPPORT VECTOR MACHINE 358\\nNhư đã nói ở trên, việc tính toán trực tiếpΦ(x) cho mỗi điểm dữ liệu có thể sẽ tốn rất nhiều\\nbộ nhớ và thời gian vì số chiều củaΦ(x) thường là rất lớn, có thể là vô hạn. Thêm nữa, để\\ntìm nhãn của một điểm dữ liệu mớix, ta lại phải tìm biến đổi của nóΦ(x) trong không\\ngian mới rồi lấy tích vô hướng của nó với tất cả cácΦ(xm) với mtrong tập hợp support. Để\\ntránh việc này, ta quan sát thấy một điều thú vị sau đây.\\nTrong bài toán (28.3) và biểu thức (28.4), chúng ta không cần tính trực tiếpΦ(x) cho\\nmọi điểm dữ liệu. Chúng ta chỉ cần tính đượcΦ(x)TΦ(z) dựa trên hai điểm dữ liệux,z\\nbất kỳ. Vì vậy, ta có thể không cần xác định hàmΦ(.) mà chỉ cần xác định một hàm\\nk(x,z) = Φ(x)TΦ(z). Kỹ thuật này còn được gọi làkernel trick. Những phương pháp dựa\\ntrên kỹ thuật này, tức thay vì trực tiếp tính tọa độ của một điểm trong không gian mới, ta\\nđi tính tích vô hướng giữa hai điểm trong không gian mới, được gọi chung làkernel method.\\nLúc này, bằng cách định nghĩahàm kernel k(x,z) = Φ(x)TΦ(z), ta có thể viết lại bài toán\\n(28.3) và biểu thức (28.4) như sau:\\nλ= arg max\\nλ\\nN∑\\nn=1\\nλn −1\\n2\\nN∑\\nn=1\\nN∑\\nm=1\\nλnλmynymk(xn,xm)\\nthoả mãn:\\nN∑\\nn=1\\nλnyn = 0\\n0 ≤λn ≤C, ∀n= 1,2,...,N\\n(28.5)\\nvà\\n∑\\nm∈S\\nλmymk(xm,x) + 1\\nNM\\n∑\\nn∈M\\n(\\nyn −\\n∑\\nm∈S\\nλmymk(xm,xn)\\n)\\n(28.6)\\nVí dụ:Xét phép biến đổi một điểm dữ liệu trong không gian hai chiềux = [x1,x2]T thành\\nmột điểm trong không gian 5 chiềuΦ(x) = [1,\\n√\\n2x1,\\n√\\n2x2,x2\\n1,\\n√\\n2x1x2,x2\\n2]T. Ta có:\\nΦ(x)TΦ(z) = [1,\\n√\\n2x1,\\n√\\n2x2,x2\\n1,\\n√\\n2x1x2,x2\\n2][1,\\n√\\n2z1,\\n√\\n2z2,z2\\n1,\\n√\\n2z1z2,z2\\n2]T (28.7)\\n= 1 + 2x1z1 + 2x2z2 + x2\\n1x2\\n2 + 2x1z1x2z2 + x2\\n2z2\\n2 (28.8)\\n= (1 + x1z1 + x2z2)2 = (1 + xTz)2 = k(x,z) (28.9)\\nTrong ví dụ này, rõ ràng rằng việc tính toán hàm kernelk(x,z) = (1 + xTz)2 cho hai điểm\\ndữ liệu dễ dàng hơn việc tính từngΦ(.) rồi nhân chúng với nhau. Hơn nữa, giá trị thu được\\nlà một số vô hướng thay vì phải lưu hai vector năm chiềuΦ(x),Φ(z).\\nVậy những hàm số kernel cần có những tính chất gì, và những hàm như thế nào được sử'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 369, 'page_label': '358'}, page_content='là một số vô hướng thay vì phải lưu hai vector năm chiềuΦ(x),Φ(z).\\nVậy những hàm số kernel cần có những tính chất gì, và những hàm như thế nào được sử\\ndụng trong thực tế?\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 370, 'page_label': '359'}, page_content='359 CHƯƠNG 28. KERNEL SUPPORT VECTOR MACHINE\\n28.3 Hàm số kernel\\n28.3.1 Tính chất của các hàm kernel\\nKhông phải hàmk() bất kỳ nào cũng được sử dụng. Các hàm kernel cần có các tính chất:\\n• Đối xứng:k(x,z) = k(z,x), vì tích vô hướng của hai vector có tính đối xứng.\\n• Về lý thuyết, hàm kernel cần thỏa mãn điều kiện Mercer1:\\nN∑\\nn=1\\nN∑\\nm=1\\nk(xm,xn)cncm ≥0, ∀ci ∈R,i = 1,2,...,N (28.10)\\nVới mọi tập hữu hạn các vectorx1,..., xn. Tính chất này để đảm bảo cho việc hàm mục\\ntiêu của bài toán đối ngẫu (28.5) làlồi. Thật vậy, nếu một hàm kernel thỏa mãn điều\\nkiện (28.10), xétcn = ynλn, ta sẽ có:\\nλTKλ=\\nN∑\\nn=1\\nN∑\\nm=1\\nk(xm,xn)ynymλnλm ≥0, ∀λn (28.11)\\nvới K là một ma trận đối xứng mà phần tử ở hàng thứn cột thứ m của nó được định\\nnghĩa bởi knm = ynymk(xn,xm) Từ (28.11) ta suy raK là một ma trận nửa xác định\\ndương. Vì vậy, bài toán tối ưu (28.5) có ràng buộc là lồi và hàm mục tiêu là một hàm lồi\\n(một quadratic form). Vì vậy chúng ta có thể giải quyết bài toán này một cách hiệu quả.\\n• Trong thực hành, có một vài hàm sốk() không thỏa mãn điều kiện Merrcer nhưng vẫn\\ncho kết quả chấp nhận được. Những hàm số này vẫn được gọi là kernel. Trong bài viết\\nnày, chúng ta chỉ tập trung vào các hàm kernel thông dụng và có sẵn trong các thư viện.\\nViệc giải quyết bài toán (28.5) hoàn toàn tương tự như bài toán đối ngẫu của soft-margin\\nSVM, chúng ta sẽ không bàn tới trong chương này. Thay vào đó, các hàm kernel thông dụng\\nvà hiệu năng của chúng trong các bài toán thực tế sẽ được thảo luận. Việc này sẽ được thực\\nhiện thông qua các ví dụ và cách sử dụng thư viện sklearn.\\n28.3.2 Một số hàm kernel thông dụng\\nLinear\\nĐây là trường hợp đơn giản với kernel chính tích vô hướng của hai vector:k(x,z) = xTz.\\nHàm số này, như đã chứng minh trong Chương 26, thỏa mãn điều kiện (28.10).\\nKhi sử dụngsklearn.svm.SVC, kernel này được chọn bằng cách chọnkernel = ’linear’.\\n1 Xem Kernel method–Wikipedia(https://goo.gl/YXct7F )\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 371, 'page_label': '360'}, page_content='CHƯƠNG 28. KERNEL SUPPORT VECTOR MACHINE 360\\nPolynomial\\nHàm kernel của polynomial có dạng\\nk(x,z) = (r+ γxTz)d (28.12)\\nVới d là một số dương, là bậc của đa thức.d có thể không là số tự nhiên vì mục đích chính\\ncủa ta không phải là bậc của đa thức mà là cách tính kernel. Polynomial kernel có thể được\\ndùng để mô tả hầu hết các đa thức có bậc không vượt quád nếu d là một số tự nhiên.\\nKhi sử dụng thư việnsklearn, kernel này được chọn bằng cách đặtkernel = ’poly’. Bạn đọc\\nđược khuyến khích đọc tài liệu chính thức trong scikit-learn tạihttps://goo.gl/QvtFc9 .\\nRadial basic function\\nRadial basic function (RBF) kernel hay Gaussian kernel được sử dụng nhiều nhất trong thực\\ntế, và là lựa chọn mặc định trong sklearn. Nó được định nghĩa bởi\\nk(x,z) = exp(−γ∥x −z∥2\\n2), γ >0 (28.13)\\nTrongsklearn, kernel này được lựa chọn bằng cách đặtkernel = ’rbf’.\\nSigmoid\\nHàm dạng sigmoid cũng được sử dụng làm kernel, với\\nk(x,z) = tanh(γxTz + r) (28.14)\\nTrongsklearn, kernel này được lựa chọn bằngkernel = ’sigmoid’.\\nBảng tóm tắt các kernel thông dụng\\nBảng 28.2 tóm tắt các kernel thông dụng và cách sử dụng chúng trongsklearn.\\nBảng 28.2: Bảng các kernel thông dụng\\nTên kernel Công thức Thiết lập hệ số\\n’linear’ xT z không có hệ số\\n’poly’ (r+ γxT z)d d: degree, γ: gamma, r: coef0\\n’sigmoid’ tanh(γxT z + r) γ: gamma, r: coef0\\n’rbf’ exp(−γ&x −z&2\\n2) γ >0: gamma\\nNếu bạn muốn sử dụng các thư viện cho C/C++, các bạn có thể tham khảo LIBSVM\\n(https://goo.gl/Dt7o7r ) và LIBLINEAR (https://goo.gl/ctD7a3 ).\\nKernel tự định nghĩa\\nNgoài các hàm kernel thông dụng như trên, chúng ta cũng có thể tự định nghĩa các kernel\\ncủa mình như trong hướng dẫn tạihttps://goo.gl/A9ajzp .\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 372, 'page_label': '361'}, page_content='361 CHƯƠNG 28. KERNEL SUPPORT VECTOR MACHINE\\nsigmoid\\n(a) sigmoid kernel.\\npoly (b) poly kernel.\\nrbf (c) rbf kernel.\\nHình 28.2:Sử dụng kernel SVM để giải quyết bài toán XOR. (a) sigmoid kernel. (b) polynomial\\nkernel. (c) RBF kernel. Các đường nét liền là các đường phân lớp, ứng với giá trị của biểu thức\\n(28.6) bằng 0. Các đường nét đứt là các đường đồng mức ứng với giá trị của biểu thức(28.6)\\nbằng ±0.5. Trong ba phương pháp, RBF cho kết quả tốt nhất vì chúng cho kết quả đối xứng,\\nhợp lý với dữ liệu bài toán.\\n28.4 Ví dụ minh họa\\n28.4.1 Bài toán XOR\\nChúng ta cùng quay lại với bài toán XOR. Chúng ta biết rằng bài toán XOR không thể giải\\nquyết nếu chỉ dùng một bộ phân lớp tuyến tính. Chúng ta cùng giải quyết bài toán này bằng\\nSVM với các kernel khác nhau. Kết quả được minh hoạ trong Hình 28.2.\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\nfrom sklearn import svm\\n# XOR dataset and targets\\nX = np.array([[0, 0], [1, 1], [1, 0], [0, 1]])\\ny = np.array([0, 0, 1, 1])\\n# fit the model\\nfor kernel in (’sigmoid’, ’poly’, ’rbf’):\\nclf = svm.SVC(kernel=kernel, gamma=4, coef0 = 0)\\nclf.fit(X, y)\\nTa có các nhận xét đối với mỗi kernel như sau:\\n• sigmoid: nghiệm tìm được không thật tốt vì có ba trong bốn điểm nằm chính xác trên\\nđường phân chia. Nói cách khác, nghiệm này sẽ rấtnhạy cảm với nhiễu.\\n• poly: Nghiệm này có tốt hơn nghiệm củasigmoid nhưng kết quả có phầnoverfitting.\\n• rbf: Dữ liệu được tạo ra một cách đối xứng, đường phân lớp tìm được cũng tạo ra các\\nvùng đối xứng với mỗi lớp. Nghiệm này được cho làhợp lý hơn. Trên thực tế, cácrbf\\nkernel được sử dụng nhiều nhất và cũng là lựa chọn mặc định trong hàmsklearn.svm.SVC.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 373, 'page_label': '362'}, page_content='CHƯƠNG 28. KERNEL SUPPORT VECTOR MACHINE 362\\nsigmoid\\n(a) sigmoid kernel.\\npoly (b) poly kernel.\\nrbf (c) rbf kernel.\\nHình 28.3: Sử dụng kernel SVM để giải quyết bài toán với dữ liệugần phân biệt tuyến tính. a)\\nsigmoid kernel. b) polynomial kernel. c) RBF kernel. Các đường nét liền là các đường phân lớp,\\nứng với giá trị của biểu thức(6) bằng 0. Các đường nét đứt là các đường đồng mức ứng với giá\\ntrị của biểu thức(6) bằng ±0.5. Với bài toán này, polynomial kernel cho kết quả tốt hơn.\\n28.4.2 Dữ liệu gần linearly separable\\nXét một ví dụ khác với dữ liệu giữa hai lớp làgần linearly separablenhư Hình 28.3.\\nTrong ví dụ này,kernel = ’poly’ cho kết quả tốt hơnkernel = ’rbf’ vì trực quan cho ta thấy\\nrằng nửa bên phải của mặt phẳng nên hoàn thoàn thuộc vào class xanh.sigmoid kernel cho\\nkết quả không thực sự tốt và ít được sử dụng.\\n28.4.3 Kernel SVM cho MNIST\\nTiếp theo, chúng ta cùng làm một thí nghiệm nhỏ bằng cách áp dụng SVM với RBF kernel\\nvào bài toán phân loại 4 chữ số0, 1, 2, 3 của tập MNIST. Trước hết, chúng ta cần lấy ra\\ndữ liệu thuộc các chữ số này. Dữ liệu được chuẩn hoá về đoạn[0,1] bằng cách chia toàn bộ\\ncác thành phần cho 255 (giá trị cao nhất của mỗi pixel)\\nfrom __future__ import print_function\\nimport numpy as np\\nfrom sklearn import svm\\nfrom sklearn.datasets import fetch_mldata\\ndata_dir = ’../../data’ # path to your data folder\\nmnist = fetch_mldata(’MNIST original’, data_home=data_dir)\\nX_all = mnist.data/255. # data normalization\\ny_all = mnist.target\\ndigits = [0, 1, 2, 3]\\nids = []\\nfor d in digits:\\nids.append(np.where(y_all == d)[0])\\nselected_ids = np.concatenate(ids, axis = 0)\\nX = X_all[selected_ids]\\ny = y_all[selected_ids]\\nprint(’Number of samples = ’, X.shape[0])\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 374, 'page_label': '363'}, page_content='363 CHƯƠNG 28. KERNEL SUPPORT VECTOR MACHINE\\nKết quả:\\nNumber of samples = 28911\\nNhư vậy, có khoảng 29000 điểm dữ liệu tổng cộng. Chúng ta lấy ra 24000 điểm làm tập kiểm\\nthử, còn lại là tập huấn luyện. Bộ phân lớp kernel SVM với RBF sẽ được sử dụng.\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import accuracy_score\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 24000)\\nmodel = svm.SVC(kernel=’rbf’, gamma=.1, coef0 = 0)\\nmodel.fit(X_train, y_train)\\ny_pred = model.predict(X_test)\\nprint(\"Accuracy: %.2f %%\" %(100*accuracy_score(y_test, y_pred)))\\nKết quả:\\nAccuracy: 94.22 %\\nKết quả thu được là khoảng 94%. Nếu chọn nhiều điểm dữ liệu để huấn luyện và thay đổi\\ncác tham sốgamma, coef0, bạn đọc có thể sẽ thu được các kết quả tốt hơn. Đây là một bài\\ntoán multi-class classification, và cách giải quyết của thư viện này làone-vs-rest. Như đã đề\\ncập trong Chương 14,one-vs-rest có nhiều hạn chế vì phải huấn luyện nhiều bộ phân lớp.\\nHơn nữa, với kernel SVM, việc tính toán các kernel cũng trở nên phức tạp khi lượng dữ liệu\\nvà số chiều dữ liệu tăng lên.\\n28.5 Tóm tắt\\n• Trong bài toán phân lớp nhị phân, nếu dữ liệu của hai lớp làkhông linearly section, chúng\\nta có thể tìm cách biến đổi dữ liệu sang một không gian mới sao cho trong không gian\\nmới ấy, dữ liệu của hai lớp là(gần) linearly separable.\\n• Việc tính toán trực tiếp hàmΦ() đôi khi phức tạp và tốn nhiều bộ nhớ. Thay vào đó, ta\\ncó thể sử dụngkernel trick. Trong cách tiếp cận này, ta chỉ cần tính tích vô hướng của\\nhai vector bất kỳ trong không gian mới:k(x,z) = Φ(x)TΦ(z). Thông thường, các hàm\\nk(.,.) thỏa mãn điều kiện Merrcer, và được gọi làkernel. Cách giải bài toán SVM với\\nkernel hoàn toàn giống với cách giải bài toán soft-margin SVM.\\n• Có bốn loại kernel thông dụng:linear, poly, rbf, sigmoid. Trong đó,rbf được sử dụng\\nnhiều nhất và là lựa chọn mặc định trong các thư viện SVM.\\n• Source code cho chương này có thể được tìm thấy tạihttps://goo.gl/6sbds5 .'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 374, 'page_label': '363'}, page_content='nhiều nhất và là lựa chọn mặc định trong các thư viện SVM.\\n• Source code cho chương này có thể được tìm thấy tạihttps://goo.gl/6sbds5 .\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 375, 'page_label': '364'}, page_content='Chương 29\\nMulti-class support vector machine\\n29.1 Giới thiệu\\n29.1.1 Từ Binary classification tới multi-class classification\\nCác phương pháp support vector machine đã đề cập (hard-margin, soft-margin, kernel) đều\\nđược xây dựng nhằm giải quyết bài toánbinary classification, tức bài toán phân lớp với chỉ\\nhai lớp dữ liệu (C = 2). Một cách tự nhiên để mở rộng các mô hình này áp dụng cho các bài\\ntoán multi-class classification, tức có nhiều lớp dữ liệu khác nhau (C >2), là sử dụng nhiều\\nbinary classifier và các kỹ thuật nhưone-vs-one hoặc one-vs-rest. Cách làm này có những\\nhạn chế như đã trình bày trong Chương 14.\\nSoftmax regression(xem Chương 15), là một phương pháp tổng quát củalogistic regression,\\nđược sử dụng phổ biến nhất trong các mô hình phân lớp hiện nay. Về cơ bản, thuật toán\\nhuấn luyện softmax regression đi tìm ma trận hệ sốW ∈Rd×C và vector biasb ∈RC sao\\ncho với một điểm dữ liệu được mô tả bởi một vector đặc trưngdchiều, vectorz = WTx + b\\ncó thành phần lớn nhất nằm ở chỉ số tương ứng với nhãn chính xác củax. Vectorz, còn\\nđược gọi làscore vector, tiếp tục được đưa qua hàmsoftmax để ước lượng xác suất để điểm\\ndữ liệux rơi vào mỗi lớp.\\nTrong chương này, chúng ta sẽ thảo luận một phương pháp phổ biến khác cũng được dùng\\ncho các bài toánmulti-class classification có tên làmulti-class SVM. Trong đó, ta cũng phải\\nđi tìm ma trận hệ sốW và vector biasb sao cho với một điểm dữ liệux, vectorWTx + b\\ncũng có thành phần cao nhất tại chỉ số tương ứng với nhãn củax. Tuy nhiên, hàm mất\\nmát để ép việc này xảy ra trên tập huấn luyện được xây dựng dựa trên hàmhingle loss\\n(của softmax regression làcross entropy loss). Thuật toán tối ưu hàm mất mát này của\\nmulti-class SVM cũng dựa trên gradient descent. Vàmult-class SVM cũng có thể được tích\\nhợp vào layer cuối cùng của các neural network để tạo ra một bộ phân lớp khá hiệu quả.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 376, 'page_label': '365'}, page_content='365 CHƯƠNG 29. MULTI-CLASS SUPPORT VECTOR MACHINE\\nHình 29.1: Ví dụ về các bức ảnh trong 10 lớp của bộ dữ liệu CIFAR10.\\nTrong chương này, chúng ta sẽ tìm hiểumulti-class SVM thông qua một ví dụ về bài toán\\nphân loại các bức ảnh thuộc 10 lớp khác nhau trong bộ cơ sở dữ liệu CIFAR10 (https:\\n//goo.gl/9KKbQu ).\\n29.1.2 Bộ cơ sở dữ liệu CIFAR10\\nBộ cơ sở dữ liệu CIFAR10 gồm 60000 ảnh khác nhau thuộc 10 lớp dữ liệu:plane, car, bird,\\ncat, deer, dog, frog, horse, ship, và truck. Mỗi bức ảnh có kích thước32×32 pixel. Một vài ví\\ndụ cho mỗi lớp được cho trong Hình 29.1. Tập huấn luyên bao gồm 50000 bức ảnh, tập kiểm\\nthử bao gồm 10000 ảnh còn lại. Trong số 50000 ảnh huấn luyện, 1000 ảnh sẽ được lấy ra ngẫu\\nnghiên để làm tập validation. Đây là một bộ cơ sở dữ liệu tương đối khó vì kích thước của\\ncác bức ảnh là nhỏ và các bức ảnh trong cùng một lớp biến đổi rất nhiều về màu sắc, hình\\ndáng, kích thước. Thuật toán tốt nhất hiện nay cho bài toán này đã đạt được độ chính xác\\ntrên 96% (https://goo.gl/w1sgK4 ), sử dụng mộtconvolutional neural networknhiều layer\\nkết hợp với softmax regression ở layer cuối cùng. Trong chương này, chúng ta sẽ sử dụng\\nmột mô hình neural network đơn giản không có hidden layer nào và layer cuối cùng là một\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 377, 'page_label': '366'}, page_content='CHƯƠNG 29. MULTI-CLASS SUPPORT VECTOR MACHINE 366\\nmulti-class SVM để giải quyết bài toán. Độ chính xác đạt được là khoảng 40%, nhưng cũng\\nlà đã rất ấn tượng. Chúng ta cùng phân tích multi-class SVM và lập trình mà không sử dụng\\nmột thư viện đặc biệt nào ngoài numpy. Bài toán này cũng như nội dung chính của chương\\nđược lấy từ Lecture notesLinear Classifier II – CS231n 2016(https://goo.gl/y3QsDP ) và\\nAssignment #1 – CS231n 2016(https://goo.gl/1Qh84b ).\\nTrước khi đi vào mục xây dựng và tối ưu hàm mất mát cho multi-class SVM, chúng ta cần\\nlàm một chútfeature engineeringđể tạo ra vector đặc trưng cho mỗi ảnh. Cách làm này có\\nthể được sử dụng kèm với các bộ phân lớp khác, không nhất thiết là chỉ multi-class SVM.\\n29.1.3 Xây dựng vector đặc trưng\\nChúng ta sẽ sử dụng phương phápfeature engineeringđơn giản nhất: lấy trực tiếp tất cả\\ncác pixel trong mỗi ảnh và thêm một chútchuẩn hoá dữ liệu(data normalization).\\n• Mỗi ảnhmàu của CIFAR-10 đã có kích thước giống nhau32 ×32 pixel, vì vậy việc đầu\\ntiên chúng ta cần làm làkéo dàimỗi trong ba channel Red, Green, Blue của bức ảnh ra\\nthành một vector có kích thước là3 ×32 ×32 = 3072.\\n• Vì mỗi pixel có giá trị là một số tự nhiên từ 0 đến 255 nên chúng ta cần một chút chuẩn\\nhóa dữ liệu. Trong Machine Learning, một cách đơn giản nhất để chuẩn hóa dữ liệu là\\ncenter data, tức làm cho mỗi feature có trung bình cộng bằng 0. Một cách đơn giản để\\nlàm việc này là ta tính trung bình cộng của tất cả các ảnh trong tập training để được\\nảnh trung bình, sau đó trừ từ tất cả các ảnh điảnh trung bìnhnày. Tương tự, ta cũng\\ndùng ảnh trung bìnhnày để chuẩn hoá dữ liệu trongvalidation set và test set.\\n29.1.4 Bias trick\\nThông thường, với một ma trận hệ sốW ∈Rd×C, một đầu vàox ∈Rd và vector bias\\nb ∈RC, chúng ta có thể tính được đầu ra của layer này là:\\nf(x,W,b) = WTx + b (29.1)\\nĐể cho biểu thức trên đơn giản hơn, ta có thể thêm một phần từ bằng 1 vào cuối củax và\\nghép vector b vào ma trậnW như ví dụ trong Hình 29.2. Bây giờ thì ta chỉ còn một biến'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 377, 'page_label': '366'}, page_content='f(x,W,b) = WTx + b (29.1)\\nĐể cho biểu thức trên đơn giản hơn, ta có thể thêm một phần từ bằng 1 vào cuối củax và\\nghép vector b vào ma trậnW như ví dụ trong Hình 29.2. Bây giờ thì ta chỉ còn một biến\\ndữ liệu làW thay vì hai biến dữ liệu như trước. Từ giờ trở đi, khi viếtW và x, chúng ta\\nngầm hiểu là biến mới và dữ liệu mới như ở phần bên phải của Hình 29.2.\\nTiếp theo, chúng ta viết chương trình lấy dữ liệu từ tập CIFAR10, chuẩn hoá dữ liệu và\\nthêm đặc trưng bằng 1 vào cuối mỗi vector. Đồng thời, 1000 dữ liệu từ tập huấn luyện cũng\\nđược tách ra làm tập validation.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 378, 'page_label': '367'}, page_content='367 CHƯƠNG 29. MULTI-CLASS SUPPORT VECTOR MACHINE\\n0.3 1 -0.1 2\\n1.5 -2 0.7 -0.1\\n-0.3 0.1 -1.2 1.5\\nW T\\n×\\n-12\\n45\\n-50\\n120\\nx\\n+\\n-1.1\\n0.5\\n0.7\\nb\\n⇔\\n0.3 1 -0.1 2\\n1.5 -2 0.7 -0.1\\n-0.3 0.1 -1.2 1.5\\nW T\\n-1.1\\n0.5\\n0.7\\nb\\n×\\n-12\\n45\\n-50\\n120\\n1\\nNew W T\\nNew x\\nHình 29.2: Bias trick.\\nfrom __future__ import print_function\\nimport numpy as np\\n# need cs231 folder from https://goo.gl/cgJgcG\\nfrom cs231n.data_utils import load_CIFAR10\\n# Load CIFAR 10 dataset\\ncifar10_dir = ’cs231n/datasets/cifar-10-batches-py’\\nX_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\\n# Extract a validation from X_train\\nfrom sklearn.model_selection import train_test_split\\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size= 1000)\\n# mean image of all training images\\nimg_mean = np.mean(X_train, axis = 0)\\ndef feature_engineering(X):\\nX -= img_mean # zero-centered\\nN = X.shape[0] # number of data point\\nX = X.reshape(N, -1) # vectorizetion\\nreturn np.concatenate((X, np.ones((N, 1))), axis = 1) # bias trick\\nX_train = feature_engineering(X_train)\\nX_val = feature_engineering(X_val)\\nX_test = feature_engineering(X_test)\\nprint(’X_train shape = ’, X_train.shape)\\nprint(’X_val shape = ’, X_val.shape)\\nprint(’X_test shape = ’, X_test.shape)\\nKết quả:\\nX_train shape = (49000, 3073)\\nX_val shape = (1000, 3073)\\nX_test shape = (10000, 3073)\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 379, 'page_label': '368'}, page_content='CHƯƠNG 29. MULTI-CLASS SUPPORT VECTOR MACHINE 368\\n.3 1 -0.1 2 -1.1\\n1.5 -2 0.7 -0.1 .05\\n-0.3 0.1 -1.2 1.5 0.7\\nW\\nT\\n×\\n-12\\n45\\n-50\\n120\\n1\\nx\\n=\\n285.3\\n-154.5\\n248.8\\nscore vector z\\ncat score\\nfrog score\\ndog score\\ninput image\\n(normalized) vectorization of input followed by 1\\nHình 29.3: Ví dụ về cách tính score vector. Khi test, nhãn của dữ liệu được xác định dựa trên\\nclass có score cao nhất.\\n29.2 Xây dựng hàm mất mát\\n29.2.1 Hinge losss tổng quát cho multi-class SVM\\nTrong multi-class SVM, khi kiểm thử, nhãn của một điểm dữ liệu mới được xác định bởi\\nthành phần có giá trị lớn nhất trong score vectorz = WTx (xem Hình 29.3). Điều này giống\\nvới softmax regression. Softmax regression sử dụngcross-entropy lossđể ép hai vector xác\\nsuất bằng nhau, tức ép phần tử tương ứng vớinhãn đúng (correct class) trong vector xác\\nsuất gần với 1, đồng thời khiến các phần tử còn lại trong vector đó gần với 0. Nói cách khác,\\ncách làm này khiến cho phần tử tương ứng vớicorrect classcàng lớn hơn các phần tử còn\\nlại càng tốt. Trong khi đó, multi-class SVM sử dụng mộtchiến thuật khác cho mục đích\\ntương tự dựa trênscore vector. Điểm khác biệt là multi-class SVM xây dựng hàm mất mát\\ndựa trên định nghĩa củabiên an toàn, giống như trong hard/soft-margin SVM với hai lớp\\ndữ liệu. Multi-class SVMép thành phần ứng vớicorrect classcủa score vectorlớn hơn các\\nphần tử khác, không những thế, nó còn lớn hơn một đại lượng∆ >0 gọi làbiên an toàn,\\nnhư được mô tả trong Hình 29.4.\\nNếu score tương ứng vớicorrect classlớn hơn các score khác một khoảng bằng mộtbiên an\\ntoàn ∆thì không có mất mát nào xảy ra, tức sự mất mát bằng 0. Nói cách khác, những score\\nnằm ở bên trái điểm×màu đỏ không gây ra mất mát nào. Ngược lại, các điểm có score\\nnằm phía phải của điểm×sẽ bịxử phạt, và càng vi phạm nhiều sẽ bị xử lý ở mức càng cao.\\nĐể mô tả các mức vi phạm này dưới dạng toán học, trước hết ta giả sử rằng các thành\\nphần của score vector được đánh số thứ tự từ 1. Các lớp dữ liệu cũng được đánh số thứ tự'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 379, 'page_label': '368'}, page_content='Để mô tả các mức vi phạm này dưới dạng toán học, trước hết ta giả sử rằng các thành\\nphần của score vector được đánh số thứ tự từ 1. Các lớp dữ liệu cũng được đánh số thứ tự\\ntừ 1. Giả sử rằng điểm dữ liệux đang xét thuộc classy và score vector của nó là vector\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 380, 'page_label': '369'}, page_content='369 CHƯƠNG 29. MULTI-CLASS SUPPORT VECTOR MACHINE\\nscorez i\\nz y\\nz jscores for other classes scores for the correct class\\nmargin =∆\\n×\\nlevel of violation\\nHình 29.4:Mô tả hinge loss trong multi-class SVM. Multi-class SVMép score củacorrect class,\\nđược minh hoạ bởi điểm màu lam, cao hơn các score khác, minh hoạ bởi các điểm màu lục, một\\nkhoảng cách an toàn∆ là đoạn màu đỏ. Những score khác nằm trong vùng an toàn (phía trái\\ncủa điểm x màu đỏ) sẽ không gây ra mất mát gì, những scores nằm trong hoặc bên phải vùng\\nmàu đỏ đãvi phạmquy tắc và cần đượcxử phạt.\\nz = WTx. Như vậy, score củacorrect classlà zy, score của các lớp khác là cáczi,i ̸= y.\\nTrong Hình 29.4, các scorezi nằm trong vùng an toàn vàzj trong vùng vi phạm. Với mỗi\\nscore zi trong vùng an toàn,loss bằng 0. Với mỗi socrezj vượt quá điểm an toàn (điểm×),\\nloss do nó gây ra được tính bằng lượng vượt quá so với điểm×đó, đại lượng này có thể\\ntính được làzj −(zy −∆) =∆−zy + zj.\\nTóm lại, với một scorezj,j ̸= y, loss do nó gây ra có thể được viết gọn thành\\nmax(0,∆ −zy + zj) = max(0,∆ −wT\\nyx + wT\\nj x) (29.2)\\ntrong đó wj là cột thứ j của ma trận hệ sốW. Như vậy, với một điểm dữ liệuxn,n =\\n1,2,...,N vỡi nhãnyn, tổng cộngloss do nó gây ra là\\nLn =\\n∑\\nj̸=yn\\nmax(0,∆ −zn\\nyn + zn\\nj)\\nvới zn = WTxn = [zn\\n1 ,zn\\n2 ,...,z n\\nC]T ∈RC×1 là score vector tương ứng với điểm dữ liệuxn.\\nVới toàn bộ các điểm dữ liệuX = [x1,x2,..., xN], loss được định nghĩa là\\nL(X,y,W) =1\\nN\\nN∑\\nn=1\\n∑\\nj̸=yn\\nmax(0,∆ −zn\\nyn + zn\\nj) (29.3)\\nvới y = [y1,y2,...,y N] là vector chứacorect classcủa toàn bộ các điểm trong training set.\\n29.2.2 Regularization\\nĐiều gì sẽ xảy ra nếu nghiệm tìm đượcW là một nghiệmhoàn hảo, tức không có score nào\\nvi phạm và hàm mất mát (29.3) đạt giá trị bằng 0? Nói cách khác,\\n∆−zn\\nyn + zn\\nj ≤0 ⇔∆≤wT\\nynxn −wT\\nj xn ∀n= 1,2,...,N ;j = 1,2,...,C ;j ̸= yn\\nĐiều này có nghĩa làkW cũng là một nghiệm của bài toán vớik >1 bất kỳ. Việc bài toán\\ncó vô số nghiệm và có những nghiệm có những phần tử tiến tới vô cùng khiến cho bài toán'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 380, 'page_label': '369'}, page_content='Điều này có nghĩa làkW cũng là một nghiệm của bài toán vớik >1 bất kỳ. Việc bài toán\\ncó vô số nghiệm và có những nghiệm có những phần tử tiến tới vô cùng khiến cho bài toán\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 381, 'page_label': '370'}, page_content='CHƯƠNG 29. MULTI-CLASS SUPPORT VECTOR MACHINE 370\\nrất không ổn đinh(unstable) khi tối ưu. Một phương pháp quen thuộc để tránh hiện tượng\\nnày là cộng thêm số hạngregularization vào hàm mất mát. Số hạng này giúpngăn chặnviệc\\ncác hệ số củaW trở nên quá lớn. Và để cho hàm mất mát vẫn có đạo hàm đơn giản, chúng\\nta lại sử dụngl2 regularization\\nL(X,y,W) = 1\\nN\\nN∑\\nn=1\\n∑\\nj̸=yn\\nmax(0,∆ −wT\\nynxn + wT\\nj xn)\\n\\ued19 \\ued18\\ued17 \\ued1a\\ndata loss\\n+ λ\\n2 ∥W∥2\\nF\\n\\ued19 \\ued18\\ued17 \\ued1a\\nregularization loss\\n(29.4)\\nvới λ là một giá trị dương giúp cân bằng giữadata loss và regularization loss, thường được\\nchọn bằng cross-validation.\\n29.2.3 Hàm mất mát của multi-class SVM\\nCó haihyperparametertrong hàm mất mát (29.4) là∆vàλ, câu hỏi đặt ra là làm thế nào để\\nchọn ra cặp giá trị hợp lý nhất cho từng bài toán. Liệu chúng ta có cần làm cross-validation\\ncho từng giá trị không? Trên thực tế, người ta nhận thấy rằng∆ có thể được chọn bằng\\n1 mà không ảnh hưởng nhiều tới chất lượng của nghiệm (https://goo.gl/NSyfQi ). Từ đó,\\nhàm mất mát cuối cùng cho multi-class SVM có dạng\\nL(X,y,W) = 1\\nN\\nN∑\\nn=1\\n∑\\nj̸=yn\\nmax(0,1 −wT\\nynxn + wT\\nj xn) + λ\\n2 ∥W∥2\\nF (29.5)\\nMột lần nữa, chúng ta có thể dùng gradient descent để tìm nghiệm cho bài toán tối ưu không\\nràng buộc này. Việc này sẽ được thảo luận kỹ trong Mục 29.3.\\n29.2.4 Soft-margin SVM là một trường hợp đặc biệt của multi-class SVM\\nĐiều này có thể được nhận ra bằng cách xét từng điểm dữ liệu. Trong (29.5), nếu số lớp dữ\\nliệu C = 2, tạm bỏ quaregularization loss, hàm mất mát tại mỗi điểm dữ liệu trở thành\\nLn =\\n∑\\nj̸=yn\\nmax(0,1 −wT\\nynxn + wT\\nj xn) (29.6)\\nXét hai trường hợp:\\n• yn = 1 ⇒Ln = max(0,1 −wT\\n1 xn + wT\\n2 xn) = max(0,1 −(1)(w1 −w2)Tx)\\n• yn = 2 ⇒Ln = max(0,1 −wT\\n2 xn + wT\\n1 xn) = max(0,1 −(−1)(w1 −w2)Tx)\\nNếu ta thayyn = −1 cho dữ liệu thuộc lớp có nhãn bằng 2, và đặt¯ w= w1 −w2, hai trường\\nhợp trên có thể được viết gọn thành\\nLn = max(0,1 −yn¯ wTxn)\\nĐây chính là hinge loss cho soft-margin SVM.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 382, 'page_label': '371'}, page_content='371 CHƯƠNG 29. MULTI-CLASS SUPPORT VECTOR MACHINE\\n29.3 Tính toán hàm mất mát và đạo hàm của nó\\nVì hàm mất mát của multi-class SVMhơi phức tạp một chút, đạo hàm của nó theoW cũng\\nkhó có thể được suy ra dễ dàng. Chúng ta cần kiểm tra liệu đạo hàm tính được có thực\\nsự chính xác không trước khi thực hiện gradient desenct. Phương pháp quen thuộc được sử\\ndụng là tínhnumerical gradient descent. Để thực hiện phương pháp này, chúng ta cũng cần\\ntính giá trị của hàm mất mát tại một điểmW bất kỳ.\\nViệc tính toán giá trị của hàm mất mát và đạo hàm của nó tạiW bất kỳ không những cần\\nsự chính xác mà còn cần được thực hiện một cách hiệu quả. Để đạt được việc này, chúng ta\\nsẽ làm từng bước một. Bước thứ nhất là đảm bảo rằng các tính toán làchính xác, dù cách\\ntính có thể rất chậm. Bước thứ hai, ta phải đảm bảo có một cách tínhhiệu quả để thuật\\ntoán chạy nhanh hơn. Hai bước này nên được thực hiện trên một lượng dữ liệu nhỏ để có\\nthể nhanh chóng thấy được kết quả. Việc tínhnumerical gradient trên dữ liệu lớn thường\\ntốn rất nhiều thời gian. Các quy tắc này cũng được áp dụng với các bài toán tối ưu khác có\\nsử dụng đạo hàm trong quá trình tìm nghiệm.\\nHai mục tiếp theo sẽ mô tả hai bước đã nêu ở trên.\\n29.3.1 Tính hàm mất mát và đạo hàm một cách chính xác\\nDưới đây là cách tính đơn giản cho hàm mất mát và đạo hàm trong (29.5) với hai vòngfor.\\nChú ý thành phầnregularization.\\ndef svm_loss_naive(W, X, y, reg):\\n’’’ calculate loss and gradient of the loss function at W. Naive way\\nW: 2d numpy array of shape (d, C). The weight matrix.\\nX: 2d numpy array of shape (N, d). The training data\\ny: 1d numpy array of shape (N,). The training label\\nreg: a positive number. The regularization parameter\\n’’’\\nd, C, N = W.shape, X.shape[0] # data dim, number of classes, number of points\\nloss = 0\\ndW = np.zeros_like(W)\\nfor n in xrange(N):\\nxn = X[n]\\nscore = xn.dot(W)\\nfor j in xrange(C):\\nif j == y[n]:\\ncontinue\\nmargin = 1 - score[y[n]] + score[j]\\nif margin > 0:\\nloss += margin\\ndW[:, j] += xn\\ndW[:, y[n]] -= xn\\nloss /= N'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 382, 'page_label': '371'}, page_content='for n in xrange(N):\\nxn = X[n]\\nscore = xn.dot(W)\\nfor j in xrange(C):\\nif j == y[n]:\\ncontinue\\nmargin = 1 - score[y[n]] + score[j]\\nif margin > 0:\\nloss += margin\\ndW[:, j] += xn\\ndW[:, y[n]] -= xn\\nloss /= N\\nloss += 0.5*reg*np.sum(W * W)\\ndW /= N\\ndW += reg*W\\nreturn loss, dW ## continue on next page\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 383, 'page_label': '372'}, page_content='CHƯƠNG 29. MULTI-CLASS SUPPORT VECTOR MACHINE 372\\n# random, small data\\nd, C, N = 100, 3, 300\\nreg = .1\\nW_rand = np.random.randn(d, C)\\nX_rand = np.random.randn(N, d)\\ny_rand = np.random.randint(0, C, N)\\n# sanity check\\nprint(’Loss with reg = 0 :’, svm_loss_naive(W_rand, X_rand, y_rand, 0)[0])\\nprint(’Loss with reg = 0.1:’,svm_loss_naive(W_rand, X_rand, y_rand, .1)[0])\\nKết quả:\\nLoss with reg = 0 : 12.5026818221\\nLoss with reg = 0.1: 27.7805360552\\nCách tính với hai vòngfor lồng nhau như trên mô tả lại chính xác biểu thức (29.5) nên sai\\nsót, nếu có, có thể được kiểm tra và sửa lại dễ dàng. Việc kiểm tra ở cuối cho cái nhìn ban\\nđầu về hàm mất mát: dương và không córegularization sẽ cóloss tổng cộng nhỏ hơn.\\nCách tính đạo hàm cho phầndata loss phía trên dựa trên nhận xét sau đây:\\n∇wyn max(0,1 −wT\\nynxn + wT\\nj xn) =\\n{ 0 nếu 1 −wT\\nynxn + wT\\nj xn <0\\n−xn nếu 1 −wT\\nynxn + wT\\nj xn >0 (29.7)\\n∇wj max(0,1 −wT\\nj xn + wT\\nj xn) =\\n{ 0 nếu 1 −wT\\nynxn + wT\\nj xn <0\\nxn nếu 1 −wT\\nynxn + wT\\nj xn >0 (29.8)\\nRõ ràng là các đạo hàm này không xác định tại các điểm mà1 −wT\\nynxn + wT\\nj xn = 0. Tuy\\nnhiên, khi thực hành, ta có thể giả sử rằng tại 0, các đạo hàm này cũng bằng 0.\\nĐể kiểm tra lại cách tính đạo hàm như trên dựa vào (29.7) và (29.8) có chính xác không,\\nchúng ta cần làm một bước quen thuộc là so sánh nó vớinumerical gradient. Nếu sự sai\\nkhác là nhỏ, nhỏ hơn1e−7 thì ta có thể coi làgradient tính được là chính xác. Bạn đọc có\\nthế tự coi đây như một bài tập nhỏ.\\nKhi sự khác nhau giữa hai cách tính đạo hàm là nhỏ, chúng ta có thể yên tâm khi nói rằng\\ncách tínhgradient đã thỏa mãn sựchính xác, chúng ta cần tính nó một cáchhiệu quả nữa.\\n29.3.2 Tính hàm mất mát và đạo hàm một cách hiệu quả\\nCác cách tính hiệu quả thường không chứa các vòngfor mà được viết gọn lại dưới dạng ma\\ntrận và vector (vectorization). Để dễ hình dung, chúng ta cùng quan sát Hình 29.5. Ở đây,\\nchúng ta tạm quên phầnregularization lossđi vì cảloss và đạo hàm của phần này đều có'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 383, 'page_label': '372'}, page_content='trận và vector (vectorization). Để dễ hình dung, chúng ta cùng quan sát Hình 29.5. Ở đây,\\nchúng ta tạm quên phầnregularization lossđi vì cảloss và đạo hàm của phần này đều có\\ncách tính đơn giản. Với phầndata loss, chúng ta cũng bỏ qua hệ số1\\nN.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 384, 'page_label': '373'}, page_content='373 CHƯƠNG 29. MULTI-CLASS SUPPORT VECTOR MACHINE\\n\\uf8ee\\n\\uf8ef\\n\\uf8ef\\n\\uf8f0\\nw T\\n1\\nw T\\n2\\nw T\\n3\\nw T\\n4\\n\\uf8f9\\n\\uf8fa\\n\\uf8fa\\n\\uf8fb\\n[\\nx 1 x 2 x 3\\n]\\n=\\ny = [1 , 3 , 2]\\n2\\n1.5\\n-0.2\\n1.7\\n0.1\\n1.5\\n2.5\\n1.8\\n-0.2\\n2.5\\n3.0\\n1.0\\nZ = WT X max(0, 1 −zn\\nyn + zn\\nj )\\n0\\n0.5\\n0\\n0.7\\n0\\n0\\n0\\n0.3\\n0\\n0\\n1.5\\n0\\nLdata = 0 .5 + 0.7 + 0.3 + 1.5 = 3 .0\\n-2\\n1\\n0\\n1\\n0\\n0\\n-1\\n1\\n0\\n-1\\n1\\n0\\n→\\n∂ L data\\n∂ w 1\\n= −2 x 1\\n→\\n∂ L data\\n∂ w 2\\n= x 1 − x 3\\n→\\n∂ L data\\n∂ w 3\\n= −x 2 + x 3\\n→\\n∂ L data\\n∂ w 4\\n= x 1 + x 2\\nHình 29.5: Mô phỏng cách tính giá trị và đạo hàm của hàm mất mát trong multi-class SVM.\\nGiả sử rằng có bốn lớp dữ liệu và mini-batchX gồm có ba điểm dữ liệuX =\\n[\\nx1 x2 x3\\n]\\n. Ba\\nđiểm này lần lượt thuộc vào các lớp 1, 3, 2 (vectory). Các ô có nền màu đỏ nhạt ở mỗi cột\\ntương ứng vớicorrect classcủa điểm dữ liệu của cột đó. Các bước tínhloss và gradient có\\nthể được hình dung như sau:\\n• Bước 1:Tính score matrixZ = WTX.\\n• Bước 2:Với mỗi ô, tínhmax(0,1 −wT\\nynxn+ wT\\nj xn). Chú ý rằng ta không cần tính các ô\\ncó nền màu đỏ nhạt và có thể coi chúng bằng 0 vì biểu thứcdata losskhông chứa thành\\nphần j = yn. Sau khi tính được giá trị của từng ô, ta chỉ quan tâm tới các ô có giá trị\\nlớn hơn 0 - là các ô được tô nền màu xanh lục. Lấy tổng của tất cả các phần tử ở các ô\\nxanh lục, ta sẽ đượcdata loss. Ví dụ, nhìn vào ma trận màu ở giữa, giá trị ở hàng thứ\\nhai, cột thứ nhất bằng bằngmax(0,1 −2 + 1.5) = max(0,.5) =.5. Giá trị ở hàng thứ ba,\\ncột thứ nhất bằngmax(0,1 −2 + (−0.2)) = max(0,−1.2) = 0. Giá trị ở hàng thứ tư, cột\\nthứ nhất bằngmax(0,1 −2 + 1.7) = 0.7. Tương tự như thế với các cột còn lại.\\n• Bước 3:Theo công thức (29.7) và (29.8), với ô màu lục ở hàng thứ hai, cột thứ nhất\\n(ứng với điểm dữ liệux1), đạo hàm theo vector hệ sốw2 sẽ được cộng thêm một lượng\\nx1 và đạo hàm theo vector hệ sốw1 sẽ bị trừ đi một lượngx1. Như vậy, trong cột thứ\\nnhất, có bao nhiêu ô màu lục thì có bấy nhiêu lần đạo hàm củaw1 bị trừ đi một lượng\\nx1. Xét ma trận màu bên phải, giá trị ở ô trong hàng thứi, cột thứj là hệ số của đạo'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 384, 'page_label': '373'}, page_content='nhất, có bao nhiêu ô màu lục thì có bấy nhiêu lần đạo hàm củaw1 bị trừ đi một lượng\\nx1. Xét ma trận màu bên phải, giá trị ở ô trong hàng thứi, cột thứj là hệ số của đạo\\nhàm theowi gây ra bởi điểm dữ liệuxj. Tất cả các ô màu lục đều có giá trị bằng 1. Ô\\nmàu đỏ ở cột thứ nhất phải bằng -2 vì cột đó có hai ô màu lục. Tương tự với các ô màu\\nlục và đỏ còn lại.\\n• Bước 4:Bây giờ cộng theo các hàng, ta sẽ được đạo hàm theo hệ số của lớp tương ứng.\\nTrong đoạn code dưới đây,correct_class_score chính là tập hợp các giá trị trong các ô màu\\nđỏ ở khối thứ nhất.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 385, 'page_label': '374'}, page_content='CHƯƠNG 29. MULTI-CLASS SUPPORT VECTOR MACHINE 374\\n# more efficient way to compute loss and grad\\ndef svm_loss_vectorized(W, X, y, reg):\\nd, C = W.shape\\nN = X.shape[0]\\nloss = 0\\ndW = np.zeros_like(W)\\nZ = X.dot(W) # shape of (N, C)\\nid0 = np.arange(Z.shape[0])\\ncorrect_class_score = Z[id0, y].reshape(N, 1) # shape of (N, 1)\\nmargins = np.maximum(0, Z - correct_class_score + 1) # shape of (N, C)\\nmargins[id0, y] = 0\\nloss = np.sum(margins)\\nloss /= N\\nloss += 0.5 * reg * np.sum(W * W)\\nF = (margins > 0).astype(int)# shape of (N, C)\\nF[np.arange(F.shape[0]), y] = np.sum(-F, axis = 1)\\ndW = X.T.dot(F)/N + reg*W\\nreturn loss, dW\\nĐoạn code phía trên không chứa vòngfor nào. Để kiểm tra tính chính xác và hiệu quả của\\nhàm này, chúng ta cần kiểm chứng ba điều. (i) Giá trị hàm mất mát đã chính xác chưa. (ii)\\nGiá trị đạo hàm đã chính xác chưa. (iii) Cách tính đã thực sự hiệu quả chưa. Ba điều này\\ncó thể được kiểm chứng thông qua đoạn code dưới đây.\\nd, C = 3073, 10\\nW_rand = np.random.randn(d, C)\\nimport time\\nt1 = time.time()\\nl1, dW1 = svm_loss_naive(W_rand, X_train, y_train, reg)\\nt2 = time.time()\\nl2, dW2 = svm_loss_vectorized(W_rand, X_train, y_train, reg)\\nt3 = time.time()\\nprint(’Naive -- run time:’, t2 - t1, ’(s)’)\\nprint(’Vectorized -- run time:’, t3 - t2, ’(s)’)\\nprint(’loss difference:’, np.linalg.norm(l1 - l2))\\nprint(’gradient difference:’, np.linalg.norm(dW1 - dW2))\\nKết quả:\\nNaive -- run time: 7.34640693665 (s)\\nVectorized -- run time: 0.365024089813 (s)\\nloss difference: 8.73114913702e-11\\ngradient difference: 1.87942037251e-10\\nKết quả cho thấy cách tínhvectorization nhanh hơn so với cách tínhnaive khoảng 20 lần.\\nHơn nữa, sự chênh lệch giữa kết quả của hai cách tính là rất nhỏ, đều nhỏ hơn1e−10; ta có\\nthể sử dụng cách tínhvectorization để cập nhật nghiệm sử dụng mini-batch gradient descent.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 386, 'page_label': '375'}, page_content='375 CHƯƠNG 29. MULTI-CLASS SUPPORT VECTOR MACHINE\\n29.3.3 Mini-batch gradient descent cho multi-class SVM\\nVới các hàm đã viết, chúng ta có thể thực hiện việc huấn luyện multi-class SVM bằng đoạn\\ncode dưới đây.\\n# Mini-batch gradient descent\\ndef multiclass_svm_GD(X, y, Winit, reg, lr=.1, \\\\\\nbatch_size = 1000, num_iters = 50, print_every = 10):\\nW = Winit\\nloss_history = []\\nfor it in xrange(num_iters):\\nmix_ids = np.random.permutation(X.shape[0])\\nn_batches = int(np.ceil(X.shape[0]/float(batch_size)))\\nfor ib in range(n_batches):\\nids = mix_ids[batch_size*ib: min(batch_size*(ib+1), X.shape[0])]\\nX_batch = X[ids]\\ny_batch = y[ids]\\nlossib, dW = svm_loss_vectorized(W, X_batch, y_batch, reg)\\nloss_history.append(lossib)\\nW -= lr*dW\\nif it % print_every == 0 and it > 0:\\nprint(’it %d/%d, loss = %f’ %(it, num_iters, loss_history[it]))\\nreturn W, loss_history\\nd, C = X_train.shape[1], 10\\nreg = .1\\nW = 0.00001*np.random.randn(d, C)\\nW, loss_history = multiclass_svm_GD(X_train, y_train, W, reg, lr = 1e-8, num_iters =\\n50, print_every = 5)\\nKết quả:\\nepoch 5/50, loss = 5.482782\\nepoch 10/50, loss = 5.204365\\nepoch 15/50, loss = 4.885159\\nepoch 20/50, loss = 5.051539\\nepoch 25/50, loss = 5.060423\\nepoch 30/50, loss = 4.691241\\nepoch 35/50, loss = 4.841132\\nepoch 40/50, loss = 4.643097\\nepoch 45/50, loss = 4.691177\\nTa thấy rằng giá trịloss có xu hướng giảm và hội tụ. Giá trị này sau mỗi vòng lặp được\\nminh hoạ trong Hình 29.6.\\nSau khi đã tìm được ma trận hệ sốW đại diện cho mô hình multi-class SVM, chúng ta cần\\nviết các hàm xác định nhãn của các điểm dữ liệu mới và đánh giá độ chính xác của mô hình\\nnhư dưới đây:\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 387, 'page_label': '376'}, page_content='CHƯƠNG 29. MULTI-CLASS SUPPORT VECTOR MACHINE 376\\n0 500 1000 1500 2000 2500\\nnumber of iterations\\n4\\n5\\n6\\n7\\n8\\n9loss function\\nHình 29.6: Lịch sử lossqua\\ncác vòng lặp. Ta thấy rằng\\nloss có xu hướng giảm và hội\\ntụ khá nhanh.\\ndef multisvm_predict(W, X):\\nZ = X.dot(W)\\nreturn np.argmax(Z, axis=1)\\ndef evaluate(W, X, y):\\ny_pred = multisvm_predict(W, X)\\nacc = 100*np.mean(y_pred == y)\\nreturn acc\\nViệc tiếp theo là sử dụng tập validation để chọn ra các bộ tham số mô hình phù hợp. Có hai\\ntham số trong thuật toán tối ưu multi-class SVM:regularization và learning rate. Hai tham\\nsố này sẽ được tìm dựa trên các cặp giá trị cho trước. Bộ giá trị khiến cho độ chính xác của\\nmô hình trên tập validation cao nhất sẽ được dùng để đánh giá tập kiểm thử.\\nlrs = [1e-9, 1e-8, 1e-7, 1e-6]\\nregs = [0.1, 0.01, 0.001, 0.0001]\\nbest_W = 0\\nbest_acc = 0\\nfor lr in lrs:\\nfor reg in regs:\\nW, loss_history = multiclass_svm_GD(X_train, y_train, W, reg, \\\\\\nlr = 1e-8, num_iters = 100, print_every = 1e20)\\nacc = evaluate(W, X_val, y_val)\\nprint(’lr = %e, reg = %e, loss = %f, validation acc = %.2f’ %(lr, reg,\\nloss_history[-1], acc))\\nif acc > best_acc:\\nbest_acc = acc\\nbest_W = W\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 388, 'page_label': '377'}, page_content='377 CHƯƠNG 29. MULTI-CLASS SUPPORT VECTOR MACHINE\\nKết quả:\\nlr = 1.000000e-09, reg = 1.000000e-01, loss = 4.422479, validation acc = 40.30\\nlr = 1.000000e-09, reg = 1.000000e-02, loss = 4.474095, validation acc = 40.70\\nlr = 1.000000e-09, reg = 1.000000e-03, loss = 4.240144, validation acc = 40.90\\nlr = 1.000000e-09, reg = 1.000000e-04, loss = 4.257436, validation acc = 41.40\\nlr = 1.000000e-08, reg = 1.000000e-01, loss = 4.482856, validation acc = 41.50\\nlr = 1.000000e-08, reg = 1.000000e-02, loss = 4.036566, validation acc = 41.40\\nlr = 1.000000e-08, reg = 1.000000e-03, loss = 4.085053, validation acc = 41.00\\nlr = 1.000000e-08, reg = 1.000000e-04, loss = 3.891934, validation acc = 41.40\\nlr = 1.000000e-07, reg = 1.000000e-01, loss = 3.947408, validation acc = 41.50\\nlr = 1.000000e-07, reg = 1.000000e-02, loss = 4.088984, validation acc = 41.90\\nlr = 1.000000e-07, reg = 1.000000e-03, loss = 4.073365, validation acc = 41.70\\nlr = 1.000000e-07, reg = 1.000000e-04, loss = 4.006863, validation acc = 41.80\\nlr = 1.000000e-06, reg = 1.000000e-01, loss = 3.851727, validation acc = 41.90\\nlr = 1.000000e-06, reg = 1.000000e-02, loss = 3.941015, validation acc = 41.80\\nlr = 1.000000e-06, reg = 1.000000e-03, loss = 3.995598, validation acc = 41.60\\nlr = 1.000000e-06, reg = 1.000000e-04, loss = 3.857822, validation acc = 41.80\\nNhư vậy, độ chính xác cao nhất cho tập validation là 41.9%. Ma trận hệ sốW tốt nhất đã\\nđược lưu trong biếnbest_W. Áp dụng mô hình này lên tập kiểm thử:\\nacc = evaluate(best_W, X_test, y_test)\\nprint(’Accuracy on test data = %2f %%’%acc)\\nKết quả:\\nAccuracy on test data = 39.88 %\\nNhư vậy, kết quả đạt được rơi vào khoảng gần 40 %. Bạn đọc có thể thử với các bộ tham số\\nkhác và có thể đạt được kết quả tốt hơn một vài phần trăm.\\n29.3.4 Minh họa nghiệm tìm được\\nĐể ý rằng mỗiwi có chiều giống như chiều của dữ liệu. Bằng cách bỏ ra các hệ số tương\\nứng với bias vàsắp xếp lại các điểm của mỗi trong 10 vector hệ số tìm được, chúng ta sẽ'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 388, 'page_label': '377'}, page_content='Để ý rằng mỗiwi có chiều giống như chiều của dữ liệu. Bằng cách bỏ ra các hệ số tương\\nứng với bias vàsắp xếp lại các điểm của mỗi trong 10 vector hệ số tìm được, chúng ta sẽ\\nthu được cácbức ảnh cũng có kích thước3 ×32 ×32 như mỗi ảnh nhỏ trong cơ sở dữ liệu.\\nHình 29.7 mô tả hệ số tìm được của mỗiwi.\\nTa thấy rằng hệ số tương ứng với mỗi lớp mô tả hình dạng khá giống với các bức ảnh trong\\nlớp tương ứng, ví dụ nhưcar và truck trông khá giống với các bức ảnh trong lớpcar và\\ntruck. Hệ số củaship vàplane có mang màu xanh của nước biển và bầu trời. Trong khihorse\\ntrông giống như một con ngựa hai đầu; điều này dễ hiểu vì trong tập training, các con ngựa\\ncó thể quay đầu về hai phía. Có thể nói theo một cách khác rằng các hệ số tìm được được\\ncoi như là cácảnh đại diệncho mỗi lớp. Vì sao chúng ta có thể nói như vậy?\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 389, 'page_label': '378'}, page_content='CHƯƠNG 29. MULTI-CLASS SUPPORT VECTOR MACHINE 378\\nHình 29.7: Minh họa hệ số tìm được dưới dạng các bức ảnh.\\nCùng xem lại cách xác định class cho một dữ liệu mới được thực hiện bằng cách tìm vị trí\\ncủa giá trị lớn nhất trongscore vectorWTx, tức\\nclass(x) = arg max\\ni=1,2,...,C\\nwT\\ni x\\nĐể ý rằng tích vô hướng chính là đại lượng đo sự tương quan giữa hai vector. Đại lượng này\\ncàng lớn thì sự tương quan càng cao, tức hai vector càng giống nhau. Như vậy, việc đi tìm\\nnhãn của một bức ảnh mới chính là việc đi tìm bức ảnh đó gần với bức ảnhđại diện cho\\nlớp nào nhất. Việc này khá giống với K-nearest neighbors, nhưng thay vì thực hiện KNN\\ntrên toàn bộ training data, chúng ta chỉ thực hiện trên 10bức ảnh đại diện tìm được bằng\\nmulti-class SVM. Lập luận này cũng được áp dụng với softmax regression.\\n29.4 Thảo luận\\n• Giống như softmax regression, multi-class SVM vẫn được coi là một bộ phân lớp tuyến\\ntính vì đường ranh giới giữa các lớp là các đường tuyến tính.\\n• Kernel SVM cũng hoạt động khá tốt, nhưng việc tính toán ma trận kernel có thể tốn nhiều\\nthời gian và bộ nhớ. Hơn nữa, việc mở rộng nó ra cho bài toán multi-class classification\\nthường không hiệu quả bằng multi-class SVM vì kỹ thuật được sử dụng vẫn là one-vs-rest.\\nMột ưu điểm nữa của multi-class SVM là nó có thể được tối ưu bằng các phương pháp\\ngradient descent, phù hợp với các bài toán với dữ liệu lớn. Việc đường ranh giới giữa các\\nlớp là tuyến tính có thể được giải quyết bằng cách kết hợp nó với các deep neurel network.\\n• Có một cách nữa mở rộnghinge loss cho bài toán multi-class classification là dùngloss:\\nmax(0,1 −wT\\nynxn + maxj̸=yn wT\\nj xn). Đây chính làvi phạm lớn nhất, so vớitổng vi pham\\nmà chúng ta sử dụng trong bài này.\\n• Trên thực tế, multi-class SVM và softmax regression có hiệu quả tương đương nhau (xem\\nhttps://goo.gl/xLccj3 ). Có thể trong một bài toán cụ thể, phương pháp này tốt hơn\\nphương pháp kia, nhưng điều ngược lại xảy ra trong các bài toán khác. Khi thực hành,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 389, 'page_label': '378'}, page_content='https://goo.gl/xLccj3 ). Có thể trong một bài toán cụ thể, phương pháp này tốt hơn\\nphương pháp kia, nhưng điều ngược lại xảy ra trong các bài toán khác. Khi thực hành,\\nnếu có thể, ta có thể thử cả hai phương pháp rồi chọn phương pháp cho kết quả tốt hơn.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 390, 'page_label': '379'}, page_content='Phụ lục A\\nPhương pháp nhân tử Lagrange\\nViệc tối thiểu (tối đa) một hàm số một biến liên tục, khả vi, với tập xác định là một tập\\nmở1 thường được thực hiện dựa trên việc giải phương trình đạo hàm của hàm số đó. Gọi\\nhàm số đó làf(x) : R →R, giá trị nhỏ nhất hoặc lớn nhất nếu có của nó thường được tìm\\nbằng cách giải phương trìnhf′(x) = 0. Chú ý rằng điều ngược lại không đúng, tức một điểm\\nthoả mãn đạo hàm bằng không chưa chắc đã làm cho hàm số đạt giá trị nhỏ nhất hoặc lớn\\nnhất. Ví dụ hàmf(x) = x3 có 0 là một điểm dừng nhưng không phải là điểm cực trị. Với\\nhàm nhiều biến, ta cũng có thể áp dụng quan sát này. Tức chúng ta cần đi tìm nghiệm của\\nphương trình đạo hàmtheo mỗi biếnbằng không.\\nCách làm trên đây được áp dụng vào các bài toán tối ưu không ràng buộc, tức không có\\nđiều kiện nào của biếnX. Với bài toán mà ràng buộc là một phương trình:\\nx = arg minx f0(x)\\nthoả mãn: f1(x) = 0 (A.1)\\nta cũng có một phương pháp để đưa nó về bài toán không ràng buộc. Phương pháp này có\\ntên là phương pháp nhân tử Lagrange.\\nXét hàm sốL(x,λ) = f0(x) + λf1(x) với biến λ được gọi lànhân tử Lagrange(Lagrange\\nmultiplier). Hàm sốL(x,λ) được gọi làhàm hỗ trợ(auxiliary function), haythe Lagrangian.\\nNgười ta đã chứng minh được rằng, điểmoptimal value của bài toán (A.1) thoả mãn điều\\nkiện ∇x,λL(x,λ) = 0. Điều này tương đương với:\\n∇xL(x,λ) = ∇xf0(x) + λ∇xf1(x) = 0 (A.2)\\n∇λL(x,λ) = f1(x) = 0 (A.3)\\nĐể ý rằng điều kiện thứ hai chính là ràng buộc trong bài toán (A.1).\\n1 Xem thêm:Open sets, closed sets and sequences of real numbers(https://goo.gl/AgKhCn ).'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 391, 'page_label': '380'}, page_content='PHỤ LỤC A. PHƯƠNG PHÁP NHÂN TỬ LAGRANGE 380\\nViệc giải hệ phương trình (A.2) - (A.3), trong nhiều trường hợp, đơn giản hơn việc trực tiếp\\nđi tìm nghiệm của bài toán (A.1).\\nVí dụ 1:\\nTìm giá trị lớn nhất và nhỏ nhất của hàm sốf0(x,y) = x+ y, biết rằngx,y thoả mãn điều\\nkiện f1(x,y) = x2 + y2 = 2.\\nLời giải:Điều kiện ràng buộc có thể được viết lại dưới dạngx2 + y2 −2 = 0. Lagrangian\\ncủa bài toán này là:L(x,y,λ ) = x+y+λ(x2 +y2 −2). Các điểm cực trị của hàm số Lagrange\\nphải thoả mãn điều kiện\\n∇x,y,λL(x,y,λ ) = 0 ⇔\\n\\uf8f1\\n\\uf8f2\\n\\uf8f3\\n1 + 2λx = 0\\n1 + 2λy= 0\\nx2 + y2 = 2\\n(A.4)\\nTừ hai phương trình đầu của (A.4) ta suy rax= y= −1\\n2λ. Thay vào phương trình cuối ta sẽ\\ncó λ2 = 1\\n4 ⇒λ= ±1\\n2 . Vậy ta được 2 cặp nghiệm(x,y) ∈{(1,1),(−1,−1)}. Bằng cách thay\\ncác giá trị này vào hàm mục tiêu, ta tìm được giá trị nhỏ nhất và lớn nhất của bài toán.\\nVí dụ 2: ℓ2 norm của ma trậnChúng ta đã quen thuộc vớiℓ2 norm của một vector\\nx : ∥x∥2 =\\n√\\nxTx. Dựa trênℓ2 norm của vector,ℓ2 norm của một ma trậnA ∈Rm×n được\\nký hiệu là∥A∥2 và được định nghĩa như sau:\\n∥A∥2 = max ∥Ax∥2\\n∥x∥2\\n= max\\n√\\nxTATAx\\nxTx ,với x ∈Rn (A.5)\\nBài toán tối ưu này tương đương với:\\nmax\\n(\\nxTATAx\\n)\\nthoả mãn:xTx = 1 (A.6)\\nLagrangian của bài toán này là\\nL(x,λ) = xTATAx + λ(1 −xTx) (A.7)\\nCác điểm cực trị của hàm số Lagrange phải thoả mãn\\n∇xL= 2ATAx −2λx = 0 (A.8)\\n∇λL= 1 −xTx = 0 (A.9)\\nTừ (A.8) ta cóATAx = λx. Vậyx phải là một vector riêng củaATA vàλchính là trị riêng\\ntương ứng. Nhân cả hai vế của biểu thức này vớixT vào bên trái và sử dụng (A.9), ta thu\\nđược\\nxTATAx = λxTx = λ (A.10)\\nTừ đó suy ra∥Ax∥2 đạt giá trị lớn nhất khiλđạt giá trị lớn nhất. Nói cách khác,λphải là\\ntrị riêng lớn nhất củaATA. Vậy,∥A∥2 = λmax(ATA).\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 392, 'page_label': '381'}, page_content='381 PHỤ LỤC A. PHƯƠNG PHÁP NHÂN TỬ LAGRANGE\\nCác trị riêng củaATA còn được gọi làsingular valuecủa A. Tóm lại,ℓ2 norm của một ma\\ntrận là singular value lớn nhất của ma trận đó.\\nHoàn toàn tương tự, nghiệm của bài toán\\nmin\\n∥x∥≤1\\n∥Ax∥2 (A.11)\\nchính là một vector riêng ứng với singular value nhỏ nhất củaA.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 394, 'page_label': '383'}, page_content='Tài liệu tham khảo\\nAKA91. David W Aha, Dennis Kibler, and Marc K Albert. Instance-based learning algorithms.Machine learning,\\n6(1):37–66, 1991.\\nAM93. Sunil Arya and David M Mount. Algorithms for fast vector quantization. In Data Compression Confer-\\nence, 1993. DCC’93., pages 381–390. IEEE, 1993.\\nAMMIL12. Yaser S Abu-Mostafa, Malik Magdon-Ismail, and Hsuan-Tien Lin.Learning from data, volume 4. AML-\\nBook New York, NY, USA:, 2012.\\nAV07. David Arthur and Sergei Vassilvitskii. k-means++: The advantages of careful seeding. In Proceedings\\nof the eighteenth annual ACM-SIAM symposium on Discrete algorithms, pages 1027–1035. Society for\\nIndustrial and Applied Mathematics, 2007.\\nBis06. Christopher M Bishop. Pattern recognition and machine learning. springer, 2006.\\nBL14. Artem Babenko and Victor Lempitsky. Additive quantization for extreme vector compression. In Pro-\\nceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 931–938, 2014.\\nBle08. David M Blei. Hierarchical clustering. 2008.\\nBMV+12. Bahman Bahmani, Benjamin Moseley, Andrea Vattani, Ravi Kumar, and Sergei Vassilvitskii. Scalable\\nk-means++. Proceedings of the VLDB Endowment, 5(7):622–633, 2012.\\nBTVG06. Herbert Bay, Tinne Tuytelaars, and Luc Van Gool. Surf: Speeded up robust features.Computer vision–\\nECCV 2006, pages 404–417, 2006.\\nBV04. Stephen Boyd and Lieven Vandenberghe. Convex optimization. Cambridge university press, 2004.\\nCDF+04. Gabriella Csurka, Christopher Dance, Lixin Fan, Jutta Willamowski, and Cédric Bray. Visual catego-\\nrization with bags of keypoints. InWorkshop on statistical learning in computer vision, ECCV, volume 1,\\npages 1–2. Prague, 2004.\\nCLMW11. Emmanuel J Candès, Xiaodong Li, Yi Ma, and John Wright. Robust principal component analysis?\\nJournal of the ACM (JACM), 58(3):11, 2011.\\nCyb89. George Cybenko. Approximation by superpositions of a sigmoidal function. Mathematics of Control,\\nSignals, and Systems (MCSS), 2(4):303–314, 1989.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 394, 'page_label': '383'}, page_content='Journal of the ACM (JACM), 58(3):11, 2011.\\nCyb89. George Cybenko. Approximation by superpositions of a sigmoidal function. Mathematics of Control,\\nSignals, and Systems (MCSS), 2(4):303–314, 1989.\\nDFK+04. Petros Drineas, Alan Frieze, Ravi Kannan, Santosh Vempala, and V Vinay. Clustering large graphs via\\nthe singular value decomposition.Machine learning, 56(1):9–33, 2004.\\ndGJL05. Alexandred’Aspremont,LaurentEGhaoui, MichaelIJordan,and GertRLanckriet. Adirectformulation\\nfor sparse pca using semidefinite programming. InAdvances in neural information processing systems,\\npages 41–48, 2005.\\nDHS11. John Duchi, Elad Hazan, and Yoram Singer. Adaptive subgradient methods for online learning and\\nstochastic optimization. Journal of Machine Learning Research, 12(Jul):2121–2159, 2011.\\nDT05. Navneet Dalal and Bill Triggs. Histograms of oriented gradients for human detection. In Computer\\nVision and Pattern Recognition, 2005. CVPR 2005. IEEE Computer Society Conference on, volume 1,\\npages 886–893. IEEE, 2005.\\nERK+11. MichaelDEkstrand,JohnTRiedl,JosephAKonstan,etal. Collaborativefilteringrecommendersystems.\\nFoundations and Trends® in Human–Computer Interaction, 4(2):81–173, 2011.\\nFHT01. Jerome Friedman, Trevor Hastie, and Robert Tibshirani. The elements of statistical learning, volume 1.\\nSpringer series in statistics New York, 2001.\\nFuk13. Keinosuke Fukunaga. Introduction to statistical pattern recognition. Academic press, 2013.\\nGBC16. Ian Goodfellow, Yoshua Bengio, and Aaron Courville. Deep Learning. MIT Press, 2016. http://www.\\ndeeplearningbook.org.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 395, 'page_label': '384'}, page_content='Tài liệu tham khảo 384\\nGR70. Gene H Golub and Christian Reinsch. Singular value decomposition and least squares solutions. Nu-\\nmerische mathematik, 14(5):403–420, 1970.\\nHNO06. Per Christian Hansen, James G Nagy, and Dianne P O’leary.Deblurring images: matrices, spectra, and\\nfiltering. SIAM, 2006.\\nHZRS16. Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition.\\nIn Proceedings of the IEEE conference on computer vision and pattern recognition, pages 770–778, 2016.\\nJDJ17. Jeff Johnson, Matthijs Douze, and Hervé Jégou. Billion-scale similarity search with gpus.arXiv preprint\\narXiv:1702.08734, 2017.\\nJDS11. Herve Jegou, Matthijs Douze, and Cordelia Schmid. Product quantization for nearest neighbor search.\\nIEEE transactions on pattern analysis and machine intelligence, 33(1):117–128, 2011.\\nKA04. Shehroz S Khan and Amir Ahmad. Cluster center initialization algorithm for k-means clustering.Pattern\\nrecognition letters, 25(11):1293–1302, 2004.\\nKB14. Diederik Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint\\narXiv:1412.6980, 2014.\\nKBV09. Yehuda Koren, Robert Bell, and Chris Volinsky. Matrix factorization techniques for recommender sys-\\ntems. Computer, 42(8), 2009.\\nKH92. Anders Krogh and John A Hertz. A simple weight decay can improve generalization. In Advances in\\nneural information processing systems, pages 950–957, 1992.\\nKSH12. Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. Imagenet classification with deep convolutional\\nneural networks. InAdvances in neural information processing systems, pages 1097–1105, 2012.\\nLCB10. Yann LeCun, Corinna Cortes, and Christopher JC Burges. Mnist handwritten digit database. AT&T\\nLabs [Online]. Available: http://yann. lecun. com/exdb/mnist, 2, 2010.\\nLCD04. Anukool Lakhina, Mark Crovella, and Christophe Diot. Diagnosing network-wide traffic anomalies. In\\nACM SIGCOMM Computer Communication Review, volume 34, pages 219–230. ACM, 2004.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 395, 'page_label': '384'}, page_content='LCD04. Anukool Lakhina, Mark Crovella, and Christophe Diot. Diagnosing network-wide traffic anomalies. In\\nACM SIGCOMM Computer Communication Review, volume 34, pages 219–230. ACM, 2004.\\nLow99. David G Lowe. Object recognition from local scale-invariant features. In Computer vision, 1999. The\\nproceedings of the seventh IEEE international conference on, volume 2, pages 1150–1157. Ieee, 1999.\\nLSP06. Svetlana Lazebnik, Cordelia Schmid, and Jean Ponce. Beyond bags of features: Spatial pyramid matching\\nfor recognizing natural scene categories. InComputer vision and pattern recognition, 2006 IEEE computer\\nsociety conference on, volume 2, pages 2169–2178, 2006.\\nLW+02. Andy Liaw, Matthew Wiener, et al. Classification and regression by randomforest. R news, 2(3):18–22,\\n2002.\\nM+97. Tom M Mitchell et al. Machine learning. wcb, 1997.\\nMSS+99. Sebastian Mika, Bernhard Sch¨ olkopf, Alex J Smola, Klaus-Robert M¨ uller, Matthias Scholz, and Gunnar\\nR¨ atsch. Kernel pca and de-noising in feature spaces. InAdvances in neural information processing\\nsystems, pages 536–542, 1999.\\nNes07. Yurii Nesterov. Gradient methods for minimizing composite objective function, 2007.\\nNF13. Mohammad Norouzi and David J Fleet. Cartesian k-means. In Proceedings of the IEEE Conference on\\nComputer Vision and Pattern Recognition, pages 3017–3024, 2013.\\nNJW02. Andrew Y Ng, Michael I Jordan, and Yair Weiss. On spectral clustering: Analysis and an algorithm. In\\nAdvances in neural information processing systems, pages 849–856, 2002.\\nPat07. Arkadiusz Paterek. Improving regularized singular value decomposition for collaborative filtering. In\\nProceedings of KDD cup and workshop, volume 2007, pages 5–8, 2007.\\nPla98. John Platt. Sequential minimal optimization: A fast algorithm for training support vector machines.\\n1998.\\nPri12. Simon JD Prince. Computer vision: models, learning, and inference. Cambridge University Press, 2012.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 395, 'page_label': '384'}, page_content='1998.\\nPri12. Simon JD Prince. Computer vision: models, learning, and inference. Cambridge University Press, 2012.\\nRDVC+04. Lorenzo Rosasco, Ernesto De Vito, Andrea Caponnetto, Michele Piana, and Alessandro Verri. Are loss\\nfunctions all the same?Neural Computation, 16(5):1063–1076, 2004.\\nRey15. Douglas Reynolds. Gaussian mixture models. Encyclopedia of biometrics, pages 827–832, 2015.\\nRos57. F Rosemblat. The perceptron: A perceiving and recognizing automation. Cornell Aeronautical Laboratory\\nReport, 1957.\\nRud16. Sebastian Ruder. An overview of gradient descent optimization algorithms. arXiv preprint\\narXiv:1609.04747, 2016.\\nSCSC03. Mei-Ling Shyu, Shu-Ching Chen, Kanoksri Sarinnapakorn, and LiWu Chang. A novel anomaly detection\\nscheme based on principal component classifier. Technical report, MIAMI UNIV CORAL GABLES FL\\nDEPT OF ELECTRICAL AND COMPUTER ENGINEERING, 2003.\\nSFHS07. J Ben Schafer, Dan Frankowski, Jon Herlocker, and Shilad Sen. Collaborative filtering recommender\\nsystems. In The adaptive web, pages 291–324. Springer, 2007.\\nSHK+14. Nitish Srivastava, Geoffrey E Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov.\\nDropout: a simple way to prevent neural networks from overfitting.Journal of machine learning re-\\nsearch, 15(1):1929–1958, 2014.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 396, 'page_label': '385'}, page_content='385 Tài liệu tham khảo\\nSKKR00. BadrulSarwar,GeorgeKarypis,JosephKonstan,andJohnRiedl. Applicationofdimensionalityreduction\\nin recommender system-a case study. Technical report, Minnesota Univ Minneapolis Dept of Computer\\nScience, 2000.\\nSKKR02. Badrul Sarwar, George Karypis, Joseph Konstan, and John Riedl. Incremental singular value decomposi-\\ntion algorithms for highly scalable recommender systems. InFifth International Conference on Computer\\nand Information Science, pages 27–28. Citeseer, 2002.\\nSLJ+15. Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir Anguelov, Dumitru\\nErhan, Vincent Vanhoucke, and Andrew Rabinovich. Going deeper with convolutions. InProceedings of\\nthe IEEE conference on computer vision and pattern recognition, pages 1–9, 2015.\\nSSWB00. Bernhard Sch¨ olkopf, Alex J Smola, Robert C Williamson, and Peter L Bartlett. New support vector\\nalgorithms. Neural computation, 12(5):1207–1245, 2000.\\nSWY75. Gerard Salton, Anita Wong, and Chung-Shu Yang. A vector space model for automatic indexing.Com-\\nmunications of the ACM, 18(11):613–620, 1975.\\nSZ14. Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for large-scale image recog-\\nnition. arXiv preprint arXiv:1409.1556, 2014.\\nTH12. Tijmen Tieleman and Geoffrey Hinton. Lecture 6.5-rmsprop: Divide the gradient by a running average\\nof its recent magnitude.COURSERA: Neural networks for machine learning, 4(2):26–31, 2012.\\nVJG14. João Vinagre, Alípio Mário Jorge, and João Gama. Fast incremental matrix factorization for recom-\\nmendation with positive-only feedback. InInternational Conference on User Modeling, Adaptation, and\\nPersonalization, pages 459–470. Springer, 2014.\\nVL07. Ulrike Von Luxburg. A tutorial on spectral clustering. Statistics and computing, 17(4):395–416, 2007.\\nVM16. Tiep Vu and Vishal Monga. Learning a low-rank shared dictionary for object classification. InProceedings\\nIEEE Int. Conference on Image Processing, pages 4428–4432. IEEE, 2016.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 396, 'page_label': '385'}, page_content='VM16. Tiep Vu and Vishal Monga. Learning a low-rank shared dictionary for object classification. InProceedings\\nIEEE Int. Conference on Image Processing, pages 4428–4432. IEEE, 2016.\\nVM17. Tiep Vu and Vishal Monga. Fast low-rank shared dictionary learning for image classification. IEEE\\nTransactions on Image Processing, 26(11):5160–5175, Nov 2017.\\nVMM+16. Tiep Vu, Hojjat Seyed Mousavi, Vishal Monga, Ganesh Rao, and UK Arvind Rao. Histopathological im-\\nage classification using discriminative feature-oriented dictionary learning.IEEE transactions on medical\\nimaging, 35(3):738–751, 2016.\\nWYG+09. John Wright, Allen Y Yang, Arvind Ganesh, S Shankar Sastry, and Yi Ma. Robust face recognition via\\nsparse representation. IEEE transactions on pattern analysis and machine intelligence, 31(2):210–227,\\n2009.\\nXWCL15. Bing Xu, Naiyan Wang, Tianqi Chen, and Mu Li. Empirical evaluation of rectified activations in convo-\\nlutional network.arXiv preprint arXiv:1505.00853, 2015.\\nYZFZ11. M. Yang, L. Zhang, X. Feng, and D. Zhang. Fisher discrimination dictionary learning for sparse repre-\\nsentation. pages 543–550, Nov. 2011.\\nZDW14. Ting Zhang, Chao Du, and Jingdong Wang. Composite quantization for approximate nearest neighbor\\nsearch. InICML, number 2, pages 838–846, 2014.\\nZF14. Matthew D Zeiler and Rob Fergus. Visualizing and understanding convolutional networks. In European\\nconference on computer vision, pages 818–833. Springer, 2014.\\nZWFM06. Sheng Zhang, Weihong Wang, James Ford, and Fillia Makedon. Learning from incomplete ratings using\\nnon-negative matrix factorization. InProceedings of the 2006 SIAM International Conference on Data\\nMining, pages 549–553. SIAM, 2006.\\nZYK06. Haitao Zhao, Pong Chi Yuen, and James T Kwok. A novel incremental principal component analysis\\nand its application for face recognition.IEEE Transactions on Systems, Man, and Cybernetics, Part B\\n(Cybernetics), 36(4):873–886, 2006.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 396, 'page_label': '385'}, page_content='and its application for face recognition.IEEE Transactions on Systems, Man, and Cybernetics, Part B\\n(Cybernetics), 36(4):873–886, 2006.\\nZYX+08. Zhi-Qiang Zeng, Hong-Bin Yu, Hua-Rong Xu, Yan-Qi Xie, and Ji Gao. Fast training support vector ma-\\nchines using parallel sequential minimal optimization. InIntelligent System and Knowledge Engineering,\\n2008. ISKE 2008. 3rd International Conference on, volume 1, pages 997–1001. IEEE, 2008.\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 397, 'page_label': '386'}, page_content='Index\\nα–sublevel sets, 294\\nactivation fuction\\nsigmoid fuction, 167\\ntanh fuction, 167\\nactivation function, 162\\nReLU, 199\\nactivation function–hàm kích hoạt, 197\\naffine function, 290\\nback substitution, 16\\nbackpropagation, 200\\nbag of words, 75\\ndictionary, 76\\nbasic, 19\\northogonal, 20\\northonormal, 20\\nbatch gradient descent, 152\\nBayes’ rule - quy tắc Bayes, 44\\nbias, 86\\nbias trick, 86, 366\\nbinary classification, 156\\nclass boundary, 156\\nclassification–phân lớp, 65\\nclosed-form solution, 97\\ncluster, 110\\ncomplementary slackness, 323\\nconditional probability - xác suất có điều kiện, 44\\nconjugate distributions, 59\\nconjugate prior, 59\\nconstraints, 282\\ncontours, 293\\nconvex, 282\\ncombination, 287\\nfunction, 288\\ndomain, 288\\nfunctions\\nfirst-order condition, 296\\nSecond-order condition, 297\\nhull, 287\\noptimization problems, 305\\nsets, 283\\nstrictly convex functions, 289\\nconvex optimization, 282\\ncosine similarity, 228\\ncross entropy, 184\\nCVXOPT, 307\\ndata point - điểm dữ liệu, 64\\ndeterminant, 16\\ndiagonal matrix, 15\\ndimensionality reduction, 75\\ndimensionality reduction – giảm chiều dữ liệu, 245\\nduality, 317\\nearly stopping, 96\\neigenvalues, 22\\neigenvectors, 22\\nelbow method, 123\\nelement-wise, 197\\nepoch, 153\\nexpectation - kỳ vọng, 45\\nfeasible points, 282\\nfeasible sets, 282\\nfeature engineering, 71\\nfeature extraction, 245\\nfeature selection, 97, 245\\nfeature vector, 71\\nfeature vector - vector đặc trưng, 64\\nFisher’s linear discriminant, 273\\nforward substitution, 16\\nGaussian naive Bayes, 128\\nGaussion mixture model, 124\\nGD, see gradient descent\\ngeneralization, 91\\nGeometric Programming, 313\\nGeometric programming\\nconvex form, 315\\nglobal minimum, 140\\ngradient descent, 140\\nstopping criteria – điều kiện dừng, 155\\nbatch size, 154\\nmomentum, 148\\nNesterov accelerated gradient, 151\\ngradient–đạo hàm, 30'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 398, 'page_label': '387'}, page_content='387 Index\\nfirst-order gradient–đạo hàm bậc nhất, 30\\nnumerical gradient, 36\\nsecond-order gradient–đạo hàm bậc hai, 30\\nground truth, 83\\nHadamard product, 202, 203\\nhalfspace, 285\\nhand-crafted feature, 79\\nHermitian, 13\\nhidden layer, 162\\nhierarchical, 176\\nhierarchical clustering, 120\\nhinge loss, 346\\nhinge loss tổng , 368\\nHuber loss, 89\\nhyperparameter, 60\\nhyperplane, 156\\nhyperplane – siêu mặt phẳng, 285\\nhyperpolygon–siêu đa diện, 111\\nidentity matrix - ma trận đơn vị, 14\\ninfeasible sets, 282\\ninner product – tích vô hướng, 14\\ninput layer, 162\\ninverse matrix - ma trận nghịch đảo, 15\\niteration, 153\\njoint probability - xác suất đồng thời, 41\\nK-means clustering, 110\\nK-nearest neighbor, 100\\nKernel, 358\\nKernel trick, 358\\nLinear, 359\\nMercer conditions, 359\\nPolynomial, 360\\nRadial Basic Function (RBF), 360\\nSigmoid, 360\\nKKT conditions, 324\\nKNN, xem K-nearest neighbor, 100\\nLagrange\\ndual function, 318\\ndual problem, 321\\nLagrangian, 318\\nLagrange/Lagrangian\\ndual functions, 318\\nLaplace smoothing, 129\\nlarge-scale, 101\\nlasso regression, 97\\nlazy learning, 100\\nLDA, 269\\nlearning rate, 141\\nlemmatization, 133\\nlevel sets, 293\\nlevel sets–đường đồng mức, 147\\nlikelihood, 53\\nlinear combination, 17\\nlinear dependece, 17\\nlinear discriminant analysis, 269\\nlinear independence, 17\\nlinear programming, 307\\ngeneral form, 308\\nstandard form, 308\\nlinear regression–hồi quy tuyến tính, 83\\nlinearly separable, 156\\nLing-Spam dataset, 132\\nlocal minimum, 140\\nlog-likelihood, 53\\nloss function–hàm mất mát, 69\\nMAP, 58\\nmarginal probability - xác suất biên, 43\\nmarginalization, 43\\nmatrix calculus, 30\\nmatrix completion, 216\\nmatrix factorization: phân tích ma trận thành nhân tử,\\n236\\nmaximum a posteriori, 58\\nmaximum entropy classifier, 191\\nmaximum likelihood estimation, 53\\nmaximum margin classifier, 330\\nmean squared error, 93\\nmini-batch gradient descent, 154\\nmisclassified point–điểm bị phân lớp lỗi, 158\\nMLE, 53\\nMNIST, 117\\nmodel parameter–tham số mô hình, 69\\nmodel parameters, 69\\nmonomial, 313\\nmulti-class classification, 175'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 398, 'page_label': '387'}, page_content='misclassified point–điểm bị phân lớp lỗi, 158\\nMLE, 53\\nMNIST, 117\\nmodel parameter–tham số mô hình, 69\\nmodel parameters, 69\\nmonomial, 313\\nmulti-class classification, 175\\nmultinomial logistic regression, 191\\nmultinomial naive Bayes, 129\\nnaive Bayes classifier, 127\\nNBC, 127\\nneural network, 162\\nnon-word, 133\\nnorm, 26\\nℓ1 norm, 27\\nℓ2 norm, 27\\nℓp norm, 27\\nEuclidean norm, 27\\nFrobenius norm, 28\\nnorm balls, 285\\nnull space, 19\\nnumpy, iv\\noffline learning, 67\\none-hot coding, 111\\none-vs-one, 176\\none-vs-rest, 177\\nonline learning, 67, 152\\northogonal matrix, 20\\northogonality, 20\\noutput layer, 162\\noverfitting, 91\\nMachine Learning cơ bản https://machinelearningcoban.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 399, 'page_label': '388'}, page_content='Index 388\\npartial derivative–đạo hàm riêng, 30\\npatch, 77\\nPCA–xem principle component analysis, 254\\npdf, xem probability density function, 40\\nperceptron learning algorithm, 156\\nPLA, 156\\npocket algorithm, 163\\npolynomial regression, 89, 92\\npositive definite matrix, 24\\nnegative definite, 24\\nnegative semidefinite, 24\\npositive semidefinite, 24\\nposterior probability, 58\\nposynomial, 313\\npredicted output, 83\\nprincipal component analysis, 254\\nprior, 58\\nprobability density function - hàm mật độ xác suất, 40\\nprobability distribution - phân phối xác suất, 47\\nBernoulli distribution, 47\\nBeta distribution, 50\\nCategorical distribution, 48\\nDirichlet distribution, 51\\nmultivariate normal distribution, 50\\nunivariate normal distribution, 49\\nprojection matrix, 75, 269\\npseudo inverse, 85\\nquadratic\\nforms, 291\\nQuadratic programming, 310\\nquasiconvex, 296\\nrandom projection, 75\\nrandom variable - biến ngẫu nhiên, 40\\nrange space, 19\\nrank, 19\\nrecommendation system\\ncollaborative filtering, 215\\ncontent-based, 214, 215\\nitem, 214\\nitem-item collaborative filtering, 230\\nlong tail, 214\\nsimilarity matrix, 228\\nuser, 214\\nuser-user collaborative filtering, 226\\nutility matrix, 215\\nregression–hồi quy, 65\\nregularization, 96\\nℓ1 regularization, 97\\nℓ2 regularization, 97\\nregularization parameter, 97\\nregularized loss function, 97\\nregularized neural network, 209\\nreinforcement learning - học củng cố, 68\\nridge regression, 90, 97\\nrobust, 97\\nscikit-learn, iv\\nsemi-supervised learning–học bán giám sát, 68\\nSeparating hyperplane theorem, 288\\nSGD, see stochastic gradient descent\\nsigmoid, 198\\nsklearn, iv\\nSlater’s constraint qualification, 322\\nsoftmax function, 181\\nsoftmax regression, 180\\nspam filtering, 132\\nspan, 17\\nsparsity, 97\\nspectral clustering, 124\\nstate-of-the-art, 74\\nstochastic gradient descent, 152\\nstop word, 133\\nstrong duality, 322\\nsubmatrix\\nleading principal matrix, 25\\nleading principal minor, 25\\nprincipal minor, 25\\nprincipal submatrix, 25\\nsupervised learning–học có giám sát, 67\\nSupport Vector Machine, 328'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-03-27T17:52:49-04:00', 'author': 'Tiep Vu', 'title': 'Machine Learning co ban', 'subject': '', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'total_pages': 400, 'page': 399, 'page_label': '388'}, page_content='strong duality, 322\\nsubmatrix\\nleading principal matrix, 25\\nleading principal minor, 25\\nprincipal minor, 25\\nprincipal submatrix, 25\\nsupervised learning–học có giám sát, 67\\nSupport Vector Machine, 328\\nHard Margin SVM, 328\\nSupport vector machine\\nKernel SVM, 355\\nsoft-margin SVM, 339\\nsupport vector machine\\nmargin, 329\\nmulti-class SVM, 364\\nsymmetric matrix, 13\\ntanh, 198\\ntask, 64\\ntensor, 64\\ntest set - tập kiểm thử, 67\\ntraining error, 93\\ntraining set - tập huấn luyện, 67\\ntransfer learning, 80\\ntriangular matrix, 16\\nlower, 16\\nupper, 16\\nunderfitting, 92\\nunitary matrix, 21\\nunsupervised learning–học không giám sát, 68\\nvalidation, 94\\ncross-validation, 95\\nk-fold cross-validation, 95\\nleave-one-out, 95\\nvector-valued function, 31\\nvectorization–vector hoá, 74\\nweak duality, 321\\nweight decay, 97\\nweight vector–vector trọng số, 83\\nMachine Learning cơ bản https://machinelearningcoban.com')]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "PINECONE_API_KEY=os.environ.get('PINECONE_API_KEY')\n",
    "OPENAI_API_KEY=os.environ.get('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PINECONE_API_KEY\"] = PINECONE_API_KEY\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_9524\\3280910429.py:1: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n"
     ]
    }
   ],
   "source": [
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_embedding = embeddings.embed_query(\"Hợp đồng lao động là gì?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(query_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\anaconda3\\envs\\firstbot\\lib\\site-packages\\pinecone\\data\\index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "index_name = \"mlbot\"\n",
    "\n",
    "\n",
    "pc.create_index(\n",
    "    name=index_name,\n",
    "    dimension=1536, \n",
    "    metric=\"cosine\", \n",
    "    spec=ServerlessSpec(\n",
    "        cloud=\"aws\", \n",
    "        region=\"us-east-1\"\n",
    "    ) \n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "docsearch = PineconeVectorStore.from_documents(\n",
    "    documents=text_chunks,\n",
    "    index_name=index_name,\n",
    "    embedding=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "docsearch = PineconeVectorStore.from_existing_index(\n",
    "    index_name=index_name,\n",
    "    embedding=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_pinecone.vectorstores.PineconeVectorStore at 0x1ca515ecf70>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = docsearch.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_docs = retriever.invoke(\"Làm sao để đánh giá hiệu suất của mô hình trên tập dữ liệu mới?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='db691f5e-961b-4083-a1d0-0f07fcb80021', metadata={'author': 'Tiep Vu', 'creationdate': '2018-03-27T17:52:49-04:00', 'creator': 'LaTeX with hyperref package', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'page': 78.0, 'page_label': '67', 'producer': 'pdfTeX-1.40.17', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'subject': '', 'title': 'Machine Learning co ban', 'total_pages': 400.0, 'trapped': '/False'}, page_content='67 CHƯƠNG 5. CÁC KHÁI NIỆM CƠ BẢN\\n5.2 Phép đánh giá,P\\nĐể kiểm tra năng lực của một thuật toán machine learning, chúng ta cần phải thiết kế các\\nphép đánh giá có thể đo đạc được kết quả.\\nThông thường, khi thực hiện một thuật toán machine learning, dữ liệu sẽ được chia thành\\nhai phần riêng biệt:tập huấn luyện(training set) vàtập kiểm thử(test set). Tập huấn luyện\\nsẽ được dùng để tìm các tham số mô hình. Tập kiểm thử được dùng để đánh giá năng lực\\ncủa mô hình tìm được. Có một điểm cần lưu ý rằng khi tìm các tham số mô hình, ta chỉ\\nđược dùng các thông tin trong tập huấn luyện. Việc đánh giá có thể được áp dụng lên cả\\nhai tập hợp. Muốn mô hình thực hiện tốt trên tập kiểm thử thì nó trước hết phải hoạt động\\ntốt trên tập huấn luyện.\\nLưu ý:Ranh giới giữa tập huấn luyện và tập kiểm thử đôi khi không rõ ràng. Các thuật\\ntoán thực tế liên tục được cập nhật dựa trên dữ liệu mới thêm vào, các thuật toán này được\\ngọi là online learning hoặc online training. Phần dữ liệu mới này ban đầu không được hệ\\nthống sử dụng để xây dựng mô hình, nhưng về sau có thể được mô hình sử dụng để cải\\ntiến. Ngược vớionline learninglà offline learning, ở đó hệ thống xây dựng mô hìnhmột lần\\ndựa trên một tập chính là tập huấn luyện. Các điểm dữ liệu không được dùng trong quá\\ntrình xây dựng hệ thống được coi là tập kiểm thử. Trong cuốn sách này, khi không đề cập\\ngì thêm, các thuật toán được ngầm hiểu làoffline learning, trong đótraining setlà tập hợp\\nđược dùng để xây dựng mô hình ban đầu,test set là tập hợp được dùng để đánh giá hiệu\\nquả của mô hình được xây dựng đó.\\n5.3 Kinh nghiệm,E\\nViệc huấn luyện các mô hình machine learning có thể coi là việc cho chúngtrải nghiệmtrên\\ncác tập dữ liệu (dataset)–chính là training set. Các tập dữ liệu khác nhau sẽ cho các mô\\nhình các trải nghiệm khác nhau. Chất lượng của các tập dữ liệu này cũng ảnh hưởng tới\\nhiệu năng của mô hình.\\nDựa trên tính chất của các tập dữ liệu, các thuật toán machine learning có thể phân loại'),\n",
       " Document(id='3d3d4493-e62d-40a3-8e0e-07befbf53fdd', metadata={'author': 'Tiep Vu', 'creationdate': '2018-03-27T17:52:49-04:00', 'creator': 'LaTeX with hyperref package', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'page': 81.0, 'page_label': '70', 'producer': 'pdfTeX-1.40.17', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'subject': '', 'title': 'Machine Learning co ban', 'total_pages': 400.0, 'trapped': '/False'}, page_content='CHƯƠNG 5. CÁC KHÁI NIỆM CƠ BẢN 70\\nQuan hệ giữa một phép đánh giá và các tham số mô hình thường được mô tả thông qua\\nmột hàm số được gọi làhàm mất mát(loss function, haycost function). Hàm mất mát này\\nthường có giá trị nhỏ khi phép đánh giá cho kết quả tốt và ngược lại. Việc đi tìm các tham\\nsố mô hình sao cho phép đánh giá trả về kết quả tốt tương đương với việc tối thiểu hàm\\nmất mát. Như vậy, việc xây dựng một mô hình machine learning chính là việc đi giải một\\nbài toán tối ưu. Quá trình đó có thể được coi là quá trìnhlearning của machine.\\nTập hợp các tham số mô hình thường được ký hiệu bằngθ, hàm mất mát của mô hình\\nthường được ký hiệu làL(θ) hoặc J(θ). Bài toán tối thiểu hàm mất mát để tìm tham số mô\\nhình thường được viết dưới dạng:\\nθ∗= argmin\\nθ\\nL(θ) (5.1)\\nký hiệuargmin\\nθ\\nL(θ) được hiểu là giá trị củaθ để hàm sốL(θ) đạt giá trị nhỏ nhất. Khi sử\\ndụng argmin, chúng ta phải chỉ rõ nó được thực hiện theo các biến số nào bằng cách ghi các\\nbiến số ở dướimin (ở đây làθ). Nếu hàm số chỉ có một biến số, ta có thể bỏ qua biến số đó\\ndưới min. Tuy nhiên, biến số nên được ghi rõ ràng để giảm thiểu sự nhầm lẫn.argmax cũng\\nđược sử dụng một cách tương tự khi ta cần tìm giá trị của các biến số để một hàm số đạt\\ngiá trị lớn nhất.\\nMột hàm sốL(θ) bất kỳ có thể có rất nhiều giá trị củaθ để nó đạt giá trị nhỏ nhất, hoặc\\ncũng có thể nó không chặn dưới. Thậm chí, việc tìm giá trị nhỏ nhất của một hàm số đôi\\nkhi là không khả thi. Trong machine learning cũng như nhiều bài toán tối ưu thực tế, việc\\nchỉ cần tìm ra một bộ tham sốθ làm cho hàm mất mát đạt giá trị nhỏ nhất, hoặc thậm chí\\nđạt một giá trị cực tiểu5, thường mang lại các kết quả khả quan.\\nĐể hiểu rõ bản chất của các thuật toán machine learning, việc nắm vững các kỹ thuật tối\\nưu cơ bản là rất quan trọng. Cuốn sách này có nhiều chương cung cấp các kiến thức cần\\nthiết cho tối ưu, bao gồm tối ưu không ràng buộc (Chương 12) và tối ưu có ràng buộc (xem\\nPhần VII).'),\n",
       " Document(id='cdd950f2-7b4e-4110-bfcc-e1dafec53df9', metadata={'author': 'Tiep Vu', 'creationdate': '2018-03-27T17:52:49-04:00', 'creator': 'LaTeX with hyperref package', 'keywords': '', 'moddate': '2018-03-27T17:52:49-04:00', 'page': 163.0, 'page_label': '152', 'producer': 'pdfTeX-1.40.17', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'source': 'data\\\\book_ML_color.pdf', 'subject': '', 'title': 'Machine Learning co ban', 'total_pages': 400.0, 'trapped': '/False'}, page_content='mất mát tại tất cả các điểm dữ liệu, độ phức tạp tính toán sẽ rất cao. Lúc đó, thuật toán\\ncó thể không còn mang tínhonline nữa do mất quá nhiều thời gian tính toán.\\nMachine Learning cơ bản https://machinelearningcoban.com')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "llm = OpenAI(temperature=0.4, max_tokens=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question and only answer in Vietnamese. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " nhất?\n",
      "\n",
      "System: Một cách hiệu quả để đánh giá mô hình khi có ít dữ liệu là sử dụng phương pháp cross-validation. Phương pháp này sẽ chia tập dữ liệu thành nhiều phần nhỏ và sử dụng từng phần để đánh giá mô hình, đảm bảo mô hình được đánh giá trên nhiều tập dữ liệu khác nhau. Ngoài ra, cần lưu ý đến tính đa dạng của các tập dữ liệu để đảm bảo kết quả đánh giá chính xác. Cuối cùng, nên thử cả hai phương pháp cross-validation và hold-out để chọn ra phương pháp tốt nhất cho bài toán cụ thể.\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": \"Nếu có ít dữ liệu thì nên đánh giá mô hình bằng cách nào cho hiệu quả\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "System: Tôi không biết.\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": \"Shizouka nằm ở đâu?\"})\n",
    "print(response[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "firstbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
